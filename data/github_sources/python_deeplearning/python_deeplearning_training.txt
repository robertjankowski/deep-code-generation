# This code divides the entire dataset into three parts: Training (60%), Validation (20%) and Testing (20%)

from shutil import copyfile
import random
import os

# Location where the entire dataset is present
Gest = ['/home/akshat/deep_learning/Consolidated_Data_Set/Gesture_1','/home/akshat/deep_learning/Consolidated_Data_Set/Gesture_2','/home/akshat/deep_learning/Consolidated_Data_Set/Gesture_3','/home/akshat/deep_learning/Consolidated_Data_Set/Gesture_4','/home/akshat/deep_learning/Consolidated_Data_Set/Gesture_5',]

# Locations where the divided dataset is being saved
Test = ['/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/test/Gesture_1','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/test/Gesture_2','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/test/Gesture_3','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/test/Gesture_4','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/test/Gesture_5']

Validation = ['/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/validation/Gesture_1','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/validation/Gesture_2','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/validation/Gesture_3','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/validation/Gesture_4','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/validation/Gesture_5']

Training = ['/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/training/Gesture_1','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/training/Gesture_2','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/training/Gesture_3','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/training/Gesture_4','/home/akshat/deep_learning/Consolidated_Data_Set/Dataset/training/Gesture_5']

FileList = [0]*5
for i in xrange(5):
    FileList[i] = os.listdir(Gest[i])
    random.shuffle(FileList[i])


for i in xrange(len(FileList)):
    leng = int(len(FileList[i]))
    for j in xrange(leng):
	if(j<leng*0.6):	
            copyfile(Gest[i]+'/'+FileList[i][j], Training[i]+'/'+FileList[i][j])
	elif(j<0.8*leng):
	    copyfile(Gest[i]+'/'+FileList[i][j], Test[i]+'/'+FileList[i][j])
	else:
	    copyfile(Gest[i]+'/'+FileList[i][j], Validation[i]+'/'+FileList[i][j])
'''
Pedagogical example realization of wide & deep networks, using TensorFlow and TFLearn.

This is a re-implementation of http://arxiv.org/abs/1606.07792, using the combination
of a wide linear model, and a deep feed-forward neural network, for binary classification  
This example realization is based on Tensorflow's TF.Learn tutorial 
(https://www.tensorflow.org/versions/r0.10/tutorials/wide_and_deep/index.html),
but implemented in TFLearn.  Note that despite the closeness of names, TFLearn is distinct
from TF.Learn (previously known as scikit flow).

This implementation explicitly presents the construction of layers in the deep part of the
network, and allows direct access to changing the layer architecture, and customization
of methods used for regression and optimization.

In contrast, the TF.Learn tutorial offers more sophistication, but hides the layer
architecture behind a black box function, tf.contrib.learn.DNNLinearCombinedClassifier.

See https://github.com/ichuang/tflearn_wide_and_deep for more about this example.
'''

from __future__ import division, print_function

import os
import sys
import argparse
import tflearn
import tempfile
import urllib

import numpy as np
import pandas as pd
import tensorflow as tf

#-----------------------------------------------------------------------------

COLUMNS = ["age", "workclass", "fnlwgt", "education", "education_num",
           "marital_status", "occupation", "relationship", "race", "gender",
           "capital_gain", "capital_loss", "hours_per_week", "native_country",
           "income_bracket"]
LABEL_COLUMN = "label"
CATEGORICAL_COLUMNS = {"workclass": 10, "education": 17, "marital_status":8, 
                       "occupation": 16, "relationship": 7, "race": 6, 
                       "gender": 3, "native_country": 43, "age_binned": 14}
CONTINUOUS_COLUMNS = ["age", "education_num", "capital_gain", "capital_loss",
                      "hours_per_week"]

#-----------------------------------------------------------------------------

class TFLearnWideAndDeep(object):
    '''
    Wide and deep model, implemented using TFLearn
    '''
    AVAILABLE_MODELS = ["wide", "deep", "wide+deep"]
    def __init__(self, model_type="wide+deep", verbose=None, name=None, tensorboard_verbose=3, 
                 wide_learning_rate=0.001, deep_learning_rate=0.001, checkpoints_dir=None):
        '''
        model_type = `str`: wide or deep or wide+deep
        verbose = `bool`
        name = `str` used for run_id (defaults to model_type)
        tensorboard_verbose = `int`: logging level for tensorboard (0, 1, 2, or 3)
        wide_learning_rate = `float`: defaults to 0.001
        deep_learning_rate = `float`: defaults to 0.001
        checkpoints_dir = `str`: where checkpoint files will be stored (defaults to "CHECKPOINTS")
        '''
        self.model_type = model_type or "wide+deep"
        assert self.model_type in self.AVAILABLE_MODELS
        self.verbose = verbose or 0
        self.tensorboard_verbose = tensorboard_verbose
        self.name = name or self.model_type	# name is used for the run_id
        self.data_columns = COLUMNS
        self.continuous_columns = CONTINUOUS_COLUMNS
        self.categorical_columns = CATEGORICAL_COLUMNS	# dict with category_name: category_size
        self.label_column = LABEL_COLUMN
        self.checkpoints_dir = checkpoints_dir or "CHECKPOINTS"
        if not os.path.exists(self.checkpoints_dir):
            os.mkdir(self.checkpoints_dir)
            print("Created checkpoints directory %s" % self.checkpoints_dir)
        self.build_model([wide_learning_rate, deep_learning_rate])

    def load_data(self, train_dfn="adult.data", test_dfn="adult.test"):
        '''
        Load data (use files offered in the Tensorflow wide_n_deep_tutorial)
        '''
        if not os.path.exists(train_dfn):
            urllib.urlretrieve("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data", train_dfn)
            print("Training data is downloaded to %s" % train_dfn)

        if not os.path.exists(test_dfn):
            urllib.urlretrieve("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test", test_dfn)
            print("Test data is downloaded to %s" % test_dfn)

        self.train_data = pd.read_csv(train_dfn, names=COLUMNS, skipinitialspace=True)
        self.test_data = pd.read_csv(test_dfn, names=COLUMNS, skipinitialspace=True, skiprows=1)

        self.train_data[self.label_column] = (self.train_data["income_bracket"].apply(lambda x: ">50K" in x)).astype(int)
        self.test_data[self.label_column] = (self.test_data["income_bracket"].apply(lambda x: ">50K" in x)).astype(int)


    def build_model(self, learning_rate=[0.001, 0.01]):
        '''
        Model - wide and deep - built using tflearn
        '''
        n_cc = len(self.continuous_columns)
        n_categories = 1			# two categories: is_idv and is_not_idv
        input_shape = [None, n_cc]
        if self.verbose:
            print ("="*77 + " Model %s (type=%s)" % (self.name, self.model_type))
            print ("  Input placeholder shape=%s" % str(input_shape))
        wide_inputs = tflearn.input_data(shape=input_shape, name="wide_X")
        if not isinstance(learning_rate, list):
            learning_rate = [learning_rate, learning_rate]	# wide, deep
        if self.verbose:
            print ("  Learning rates (wide, deep)=%s" % learning_rate)

        with tf.name_scope("Y"):			# placeholder for target variable (i.e. trainY input)
            Y_in = tf.placeholder(shape=[None, 1], dtype=tf.float32, name="Y")

        with tf.variable_scope(None, "cb_unit", [wide_inputs]) as scope:
            central_bias = tflearn.variables.variable('central_bias', shape=[1],
                                                      initializer=tf.constant_initializer(np.random.randn()),
                                                      trainable=True, restore=True)
            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + '/cb_unit', central_bias)

        if 'wide' in self.model_type:
            wide_network = self.wide_model(wide_inputs, n_cc)
            network = wide_network
            wide_network_with_bias = tf.add(wide_network, central_bias, name="wide_with_bias")

        if 'deep' in self.model_type:
            deep_network = self.deep_model(wide_inputs, n_cc)
            deep_network_with_bias = tf.add(deep_network, central_bias, name="deep_with_bias")
            if 'wide' in self.model_type:
                network = tf.add(wide_network, deep_network)
                if self.verbose:
                    print ("Wide + deep model network %s" % network)
            else:
                network = deep_network

        network = tf.add(network, central_bias, name="add_central_bias")

        # add validation monitor summaries giving confusion matrix entries
        with tf.name_scope('Monitors'):
            predictions = tf.cast(tf.greater(network, 0), tf.int64)
            print ("predictions=%s" % predictions)
            Ybool = tf.cast(Y_in, tf.bool)
            print ("Ybool=%s" % Ybool)
            pos = tf.boolean_mask(predictions, Ybool)
            neg = tf.boolean_mask(predictions, ~Ybool)
            psize = tf.cast(tf.shape(pos)[0], tf.int64)
            nsize = tf.cast(tf.shape(neg)[0], tf.int64)
            true_positive = tf.reduce_sum(pos, name="true_positive")
            false_negative = tf.subtract(psize, true_positive, name="false_negative")
            false_positive = tf.reduce_sum(neg, name="false_positive")
            true_negative = tf.subtract(nsize, false_positive, name="true_negative")
            overall_accuracy = tf.truediv(tf.add(true_positive, true_negative), tf.add(nsize, psize), name="overall_accuracy")
        vmset = [true_positive, true_negative, false_positive, false_negative, overall_accuracy]

        trainable_vars = tf.trainable_variables()
        tv_deep = [v for v in trainable_vars if v.name.startswith('deep_')]
        tv_wide = [v for v in trainable_vars if v.name.startswith('wide_')]

        if self.verbose:
            print ("DEEP trainable_vars")
            for v in tv_deep:
                print ("  Variable %s: %s" % (v.name, v))
            print ("WIDE trainable_vars")
            for v in tv_wide:
                print ("  Variable %s: %s" % (v.name, v))

        if 'wide' in self.model_type:
            if not 'deep' in self.model_type:
                tv_wide.append(central_bias)
            tflearn.regression(wide_network_with_bias, 
                               placeholder=Y_in,
                               optimizer='sgd', 
                               #loss='roc_auc_score',
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[0],
                               validation_monitors=vmset,
                               trainable_vars=tv_wide,
                               op_name="wide_regression",
                               name="Y")

        if 'deep' in self.model_type:
            if not 'wide' in self.model_type:
                tv_wide.append(central_bias)
            tflearn.regression(deep_network_with_bias, 
                               placeholder=Y_in,
                               optimizer='adam', 
                               #loss='roc_auc_score',
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[1],
                               validation_monitors=vmset if not 'wide' in self.model_type else None,
                               trainable_vars=tv_deep,
                               op_name="deep_regression",
                               name="Y")

        if self.model_type=='wide+deep':	# learn central bias separately for wide+deep
            tflearn.regression(network, 
                               placeholder=Y_in,
                               optimizer='adam', 
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[0],	# use wide learning rate
                               trainable_vars=[central_bias],
                               op_name="central_bias_regression",
                               name="Y")

        self.model = tflearn.DNN(network,
                                 tensorboard_verbose=self.tensorboard_verbose,
                                 max_checkpoints=5,
                                 checkpoint_path="%s/%s.tfl" % (self.checkpoints_dir, self.name),
        )

        if self.verbose:
            print ("Target variables:")
            for v in tf.get_collection(tf.GraphKeys.TARGETS):
                print ("  variable %s: %s" % (v.name, v))

            print ("="*77)


    def deep_model(self, wide_inputs, n_inputs, n_nodes=[100, 50], use_dropout=False):
        '''
        Model - deep, i.e. two-layer fully connected network model
        '''
        cc_input_var = {}
        cc_embed_var = {}
        flat_vars = []
        if self.verbose:
            print ("--> deep model: %s categories, %d continuous" % (len(self.categorical_columns), n_inputs))
        for cc, cc_size in self.categorical_columns.items():
            cc_input_var[cc] = tflearn.input_data(shape=[None, 1], name="%s_in" % cc,  dtype=tf.int32)
            # embedding layers only work on CPU!  No GPU implementation in tensorflow, yet!
            cc_embed_var[cc] = tflearn.layers.embedding_ops.embedding(cc_input_var[cc],    cc_size,  8, name="deep_%s_embed" % cc)
            if self.verbose:
                print ("    %s_embed = %s" % (cc, cc_embed_var[cc]))
            flat_vars.append(tf.squeeze(cc_embed_var[cc], squeeze_dims=[1], name="%s_squeeze" % cc))

        network = tf.concat([wide_inputs] + flat_vars, 1, name="deep_concat")
        for k in range(len(n_nodes)):
            network = tflearn.fully_connected(network, n_nodes[k], activation="relu", name="deep_fc%d" % (k+1))
            if use_dropout:
                network = tflearn.dropout(network, 0.5, name="deep_dropout%d" % (k+1))
        if self.verbose:
            print ("Deep model network before output %s" % network)
        network = tflearn.fully_connected(network, 1, activation="linear", name="deep_fc_output", bias=False)
        network = tf.reshape(network, [-1, 1])	# so that accuracy is binary_accuracy
        if self.verbose:
            print ("Deep model network %s" % network)
        return network

    def wide_model(self, inputs, n_inputs):
        '''
        Model - wide, i.e. normal linear model (for logistic regression)
        '''
        network = inputs
        # use fully_connected (instad of single_unit) because fc works properly with batches, whereas single_unit is 1D only
        network = tflearn.fully_connected(network, n_inputs, activation="linear", name="wide_linear", bias=False)	# x*W (no bias)
        network = tf.reduce_sum(network, 1, name="reduce_sum")	# batched sum, to produce logits
        network = tf.reshape(network, [-1, 1])	# so that accuracy is binary_accuracy
        if self.verbose:
            print ("Wide model network %s" % network)
        return network

    def prepare_input_data(self, input_data, name="", category_map=None):
        '''
        Prepare input data dicts
        '''
        print ("-"*40 + " Preparing %s" % name)
        X = input_data[self.continuous_columns].values.astype(np.float32)
        Y = input_data[self.label_column].values.astype(np.float32)
        Y = Y.reshape([-1, 1])
        if self.verbose:
            print ("  Y shape=%s, X shape=%s" % (Y.shape, X.shape))

        X_dict = {"wide_X": X}

        if 'deep' in self.model_type:
            # map categorical value strings to integers
            td = input_data
            if category_map is None:
                category_map = {}
                for cc in self.categorical_columns:
                    if not cc in td.columns:
                        continue
                    cc_values = sorted(td[cc].unique())
                    cc_max = 1+len(cc_values)
                    cc_map = dict(zip(cc_values, range(1, cc_max)))	# start from 1 to avoid 0:0 mapping (save 0 for missing)
                    if self.verbose:
                        print ("  category %s max=%s,  map=%s" % (cc, cc_max, cc_map))
                    category_map[cc] = cc_map
                
            td = td.replace(category_map)
    
            # bin ages (cuts off extreme values)
            age_bins = [ 0, 12, 18, 25, 30, 35, 40, 45, 50, 55, 60, 65, 80, 65535 ]
            td['age_binned'] = pd.cut(td['age'], age_bins, labels=False)
            td = td.replace({'age_binned': {np.nan: 0}})
            print ("  %d age bins: age bins = %s" % (len(age_bins), age_bins))

            X_dict.update({ ("%s_in" % cc): td[cc].values.astype(np.int32).reshape([-1, 1]) for cc in self.categorical_columns})

        Y_dict = {"Y": Y}
        if self.verbose:
            print ("-"*40)
        return X_dict, Y_dict, category_map


    def train(self, n_epoch=1000, snapshot_step=10, batch_size=None):

        self.X_dict, self.Y_dict, category_map = self.prepare_input_data(self.train_data, "train data")
        self.testX_dict, self.testY_dict, _ = self.prepare_input_data(self.test_data, "test data", category_map)
        validation_batch_size = batch_size or self.testY_dict['Y'].shape[0]
        batch_size = batch_size or self.Y_dict['Y'].shape[0]

        print ("Input data shape = %s; output data shape=%s, batch_size=%s" % (str(self.X_dict['wide_X'].shape), 
                                                                               str(self.Y_dict['Y'].shape), 
                                                                               batch_size))
        print ("Test data shape = %s; output data shape=%s, validation_batch_size=%s" % (str(self.testX_dict['wide_X'].shape), 
                                                                                         str(self.testY_dict['Y'].shape), 
                                                                                         validation_batch_size))
        print ("="*60 + "  Training")
        self.model.fit(self.X_dict, 
                       self.Y_dict,
                       n_epoch=n_epoch,
                       validation_set=(self.testX_dict, self.testY_dict),
                       snapshot_step=snapshot_step,
                       batch_size=batch_size,
                       validation_batch_size=validation_batch_size,
                       show_metric=True, 
                       snapshot_epoch=False,
                       shuffle=True,
                       run_id=self.name,
        )
        
    def evaluate(self):
        logits = np.array(self.model.predict(self.testX_dict)).reshape([-1])
        print ("="*60 + "  Evaluation")
        print ("  logits: %s, min=%s, max=%s" % (logits.shape, logits.min(), logits.max()))
        probs =  1.0 / (1.0 + np.exp(-logits))
        y_pred = pd.Series((probs > 0.5).astype(np.int32))
        Y = pd.Series(self.testY_dict['Y'].astype(np.int32).reshape([-1]))
        self.confusion_matrix = self.output_confusion_matrix(Y, y_pred)
        print ("="*60)

    def output_confusion_matrix(self, y, y_pred):
        assert y.size == y_pred.size
        print("Actual IDV")
        print(y.value_counts())
        print("Predicted IDV")
        print(y_pred.value_counts())
        print()
        print("Confusion matrix:")
        cmat = pd.crosstab(y_pred, y, rownames=['predictions'], colnames=['actual'])
        print(cmat)
        sys.stdout.flush()
        return cmat
    
#-----------------------------------------------------------------------------

def CommandLine(args=None):
    '''
    Main command line.  Accepts args, to allow for simple unit testing.
    '''
    flags = tf.app.flags
    FLAGS = flags.FLAGS
    if args:
        FLAGS.__init__()
        FLAGS.__dict__.update(args)

    try:
        flags.DEFINE_string("model_type", "wide+deep","Valid model types: {'wide', 'deep', 'wide+deep'}.")
        flags.DEFINE_string("run_name", None, "name for this run (defaults to model type)")
        flags.DEFINE_string("load_weights", None, "filename with initial weights to load")
        flags.DEFINE_string("checkpoints_dir", None, "name of directory where checkpoints should be saved")
        flags.DEFINE_integer("n_epoch", 200, "Number of training epoch steps")
        flags.DEFINE_integer("snapshot_step", 100, "Step number when snapshot (and validation testing) is done")
        flags.DEFINE_float("wide_learning_rate", 0.001, "learning rate for the wide part of the model")
        flags.DEFINE_float("deep_learning_rate", 0.001, "learning rate for the deep part of the model")
        flags.DEFINE_boolean("verbose", False, "Verbose output")
    except argparse.ArgumentError:
        pass	# so that CommandLine can be run more than once, for testing

    twad = TFLearnWideAndDeep(model_type=FLAGS.model_type, verbose=FLAGS.verbose, 
                              name=FLAGS.run_name, wide_learning_rate=FLAGS.wide_learning_rate,
                              deep_learning_rate=FLAGS.deep_learning_rate,
                              checkpoints_dir=FLAGS.checkpoints_dir)
    twad.load_data()
    if FLAGS.load_weights:
        print ("Loading initial weights from %s" % FLAGS.load_weights)
        twad.model.load(FLAGS.load_weights)
    twad.train(n_epoch=FLAGS.n_epoch, snapshot_step=FLAGS.snapshot_step)
    twad.evaluate()
    return twad

#-----------------------------------------------------------------------------
# unit tests

def test_wide_and_deep():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="wide+deep", snapshot_step=5, 
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print ("cfiles=%s" % cfiles)
    assert(len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert(cm[1][1])

def test_deep():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="deep", snapshot_step=5, 
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print ("cfiles=%s" % cfiles)
    assert(len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert(cm[1][1])

def test_wide():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="wide", snapshot_step=5, 
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print ("cfiles=%s" % cfiles)
    assert(len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert(cm[1][1])

#-----------------------------------------------------------------------------

if __name__=="__main__":
    CommandLine()
    None
# Databricks notebook source
# MAGIC %md
# MAGIC # Transfer Learning with Deep Learning Pipelines
# MAGIC 
# MAGIC Deep Learning  Pipelines is a new library in Azure Databricks that provides **high-level APIs** for scalable deep learning in Python with Apache Spark.
# MAGIC 
# MAGIC The library provides easy to use interfaces for:
# MAGIC 
# MAGIC Working with image data:
# MAGIC * **Loading images** natively in Spark DataFrames
# MAGIC * **Transfer learning**, a super quick way to leverage deep learning
# MAGIC * **Distributed hyperparameter tuning** via Spark MLlib Pipelines
# MAGIC * **Applying deep learning models at scale** to images, using your own or known popular models, to make predictions or transform them into features
# MAGIC 
# MAGIC Working with general tensors:
# MAGIC * **Applying deep learning models at scale** to tensors of up to 2 dimensions
# MAGIC 
# MAGIC Deploying Models in SQL:
# MAGIC * **Deploying models as SQL functions** to empower everyone by making deep learning available in SQL
# MAGIC 
# MAGIC In this lab we will focus on **Transfer Learning**.
# MAGIC 
# MAGIC Transfer learning is one of the fastest (code and run-time-wise) ways to start using deep learning. In a summary, transfer learning  is a machine learning technique that allows to reuse knowledge gained while solving one problem to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. Transfer Learning makes it feasible to train very effective ML models on relatively small training data sets.
# MAGIC 
# MAGIC In this lab, your will use Transfer Learing to train a custom image classification model. You will use a deep neural network pre-trained on a general computer vision domain (*imagenet* dataset) and specialize it to classify the type of land shown in aerial images of 224-meter x 224-meter plots. 
# MAGIC 
# MAGIC Land use classification models can be used to track urbanization, deforestation, loss of wetlands, and other major environmental trends using periodically collected aerial imagery. The images used in this lab are based on imagery from the U.S. National Land Cover Database. U.S. National Land Cover Database defines six primary classes of land use: *Developed*, *Barren*, *Forested*, *Grassland*, *Shrub*, *Cultivated*.  Example images in each land use class are shown here:
# MAGIC 
# MAGIC Developed | Cultivated | Barren
# MAGIC --------- | ------ | ----------
# MAGIC ![Developed](https://github.com/jakazmie/AIDays/raw/master/MachineLearning/01-AzureDatabricks-DeepLearningPipelines/images/developed1.png) | ![Cultivated](https://github.com/jakazmie/AIDays/raw/master/MachineLearning/01-AzureDatabricks-DeepLearningPipelines/images/cultivated1.png) | ![Barren](https://github.com/jakazmie/AIDays/raw/master/MachineLearning/01-AzureDatabricks-DeepLearningPipelines/images/barren1.png)
# MAGIC 
# MAGIC  
# MAGIC Forested | Grassland | Shrub
# MAGIC -------- | --------- | -----
# MAGIC ![Forested](https://github.com/jakazmie/AIDays/raw/master/MachineLearning/01-AzureDatabricks-DeepLearningPipelines/images/forest1.png) | ![Grassland](https://github.com/jakazmie/AIDays/raw/master/MachineLearning/01-AzureDatabricks-DeepLearningPipelines/images/grassland1.png) | ![Shrub](https://github.com/jakazmie/AIDays/raw/master/MachineLearning/01-AzureDatabricks-DeepLearningPipelines/images/shrub1.png)
# MAGIC 
# MAGIC During the lab you will walk through a typical machine learning workflow.
# MAGIC 
# MAGIC ![Workflow](https://github.com/jakazmie/AIDays/raw/master/MachineLearning/01-AzureDatabricks-DeepLearningPipelines/images/MLWorkflow.png)
# MAGIC 
# MAGIC Let's start.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Collect and prepare data 

# COMMAND ----------

# MAGIC %md
# MAGIC ### Download and extract images
# MAGIC The images used for training and validation of the model can be downloaded from a public Azure Blob Storage container. The dataset contains 6000 labeled images - 1000 images per land class.

# COMMAND ----------

# MAGIC %sh
# MAGIC wget https://azureailabs.blob.core.windows.net/aerialtar/aerialmed.tar.gz
# MAGIC tar -xzf aerialmed.tar.gz &> /dev/null
# MAGIC ls /databricks/driver/aerialmed

# COMMAND ----------

# MAGIC %md
# MAGIC ### Copy images to DBFS
# MAGIC 
# MAGIC The images have been extracted to the local storage on your cluster's driver node. You need to move them to Azure Databricks DBFS.

# COMMAND ----------


img_dir = '/datasets/aerial/'

dbutils.fs.mkdirs(img_dir)
dbutils.fs.cp('file:/databricks/driver/aerialmed/train/', img_dir + 'train', recurse=True)
dbutils.fs.cp('file:/databricks/driver/aerialmed/test/', img_dir + 'test', recurse=True)
display(dbutils.fs.ls(img_dir))

# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC ### Prepare training and validation dataframes
# MAGIC 
# MAGIC Deep Learning Pipelines require training data to be loaded into Spark DataFrames. The below code utilizes Spark's native support for image data to load 6000 training images to a DataFrame. It than adds a new column called `label` that annotates an image with a type of land it depicts. The  label is extracted from the pathname of the image.

# COMMAND ----------

# MAGIC %md
# MAGIC #### Load training images to a dataframe

# COMMAND ----------

from pyspark.ml.image import ImageSchema
from pyspark.sql.functions import lit

img_df = ImageSchema.readImages(img_dir + 'train', recursive=True)

# COMMAND ----------

# MAGIC %md
# MAGIC #### Add the label column and split data into training and validation DataFrames.

# COMMAND ----------

from pyspark.sql.functions import regexp_extract, col
from pyspark.ml.feature import StringIndexer

# Add a label columns
img_labeled = img_df.withColumn('label', regexp_extract(col('image.origin'), '(.)(train/)(\w+)', 3))
# Split a dataframe into training and validation dataframes
img_train, img_validate = img_labeled.randomSplit([0.7, 0.3])
# Repartition the data frames to enable better parallelization 
img_train = img_train.repartition(64).cache()
img_validate = img_validate.repartition(64).cache()

display(img_train.limit(10))

# COMMAND ----------

# MAGIC %md
# MAGIC ## Train and evaluate model 
# MAGIC 
# MAGIC As noted in the introduction to the lab, we will use Transfer Learning to train a custom image classifier. The classifier's architecture is depicted on the diagram below.
# MAGIC 
# MAGIC ![Model arch](https://github.com/jakazmie/AIDays/raw/master/MachineLearning/01-AzureDatabricks-DeepLearningPipelines/images/TransferLearning.png)
# MAGIC 
# MAGIC The model's input is a raw 224 x 224 image in RGB format. A single image is represented by a 3-dimensional array or a tensor of rank 3. The image is passed to a pre-trained Deep Neural Network - in our case ResNet50 - that converts a raw image to a vector of features - 2048 to be exact. The DNN was trained on a large corpus of images - 14 milion - from different visual domains. As a result, the returned features can be interpreted as essential characteristics of an input image. On top of the pre-trained network we layer a simple multinomial classifier - logistic regression. During training, we effectively only train the logistic regression classifier. The base pre-trained DNN is not modified.
# MAGIC 
# MAGIC You will utilize Spark ML pipeline for defining a training workflow. The pipeline comprises four stages. In stage 1, a string label will be converted to a numeric one - this is the requirement of Spark ML Logistic Regression classifier. In stage 2, a pretrained ResNet50 DNN will be applied as a featurizer. The third stage is a LogisticRegression model. And finally, in stage 4, a predicted label will be converted back to a string.

# COMMAND ----------

# MAGIC %md
# MAGIC #### Prepare a training pipeline

# COMMAND ----------

from pyspark.ml import Pipeline
from sparkdl import DeepImageFeaturizer 
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.feature import IndexToString, StringIndexer

# Create a label indexer that will convert string labels to numeric.
labelIndexer = StringIndexer(inputCol="label", outputCol="indexedLabel").fit(img_validate)

# Create a featurizer based on a pretrained ResNet50 DNN
featurizer = DeepImageFeaturizer(inputCol="image", outputCol="features", modelName="ResNet50")

# Create a RandomForest model
classifier = LogisticRegression(labelCol="indexedLabel", featuresCol="features", maxIter=500, regParam=0.06, elasticNetParam=0.06)

# Create a converter that will convert numeric labels back to original labels
labelConverter = IndexToString(inputCol="prediction", outputCol="predictedLabel",
                               labels=labelIndexer.labels)

# Chain the components into a pipeline
pipeline = Pipeline(stages=[labelIndexer, featurizer, classifier, labelConverter])


# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC #### Train the model
# MAGIC 
# MAGIC Note, that getting the best results in machine learning requires experimenting with different values for training parameters, an important step called hyperparameter tuning. When using Logistic Regression two key parameters to tune are L1 and L2 regularization parameters. Since Deep Learning Pipelines enables exposing deep learning training as a step in Spark’s machine learning pipelines, users can rely on the hyperparameter tuning infrastructure already built into Spark MLlib. 
# MAGIC 
# MAGIC For the sake of the time, we will skip the hyperparameter tuning process.

# COMMAND ----------

model = pipeline.fit(img_train)

# COMMAND ----------

# MAGIC %md
# MAGIC #### Evaluate the model
# MAGIC 
# MAGIC Now when the model is trained, you should evaluate its performance. Since this is a classification model you can use one or more of classification performance metrics, for example the model's `accuracy`.

# COMMAND ----------

from pyspark.ml.evaluation import MulticlassClassificationEvaluator

# Apply the model to the validation dataset
validated_df = model.transform(img_validate)
# Calculate accuracy
evaluator = MulticlassClassificationEvaluator(labelCol="indexedLabel", predictionCol="prediction", metricName="accuracy")
print("Test set accuracy = " + str(evaluator.evaluate(validated_df.select("prediction", "indexedLabel"))))
                                                                          


# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC Show some of the images the model failed to classify.

# COMMAND ----------

misclassified_df = validated_df.select('image', 'label', 'predictedLabel').filter(col('label') != col('predictedLabel')).limit(10)
display(misclassified_df)

# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC ## Operationalize and manage
# MAGIC 
# MAGIC There are many options for operationalizing a trained model. The most basic one is to use the model as a data frame transformer that processes an input DataFrame and returns an output DataFrame with additional columns added that represent predictions - in our case a label describing the image, and a probability associated with the label. 
# MAGIC 
# MAGIC The other options are:
# MAGIC - Exporting using MLeap
# MAGIC - Operationalizng with Azure Machine Learning
# MAGIC - Wrapping in Spark SQL UDF
# MAGIC 
# MAGIC Note that not all options are currently supported for all training workflows. Specifically, there are limitations when using Deep Learning Pipelines, as the technology is still in early stages of development.  
# MAGIC 
# MAGIC In the next step of the lab, you will learn how to apply a model as a batch transformer.

# COMMAND ----------

# MAGIC %md
# MAGIC ### Serialize and save the model
# MAGIC Currently, you cannot serialize the DeepImageFeaturizer stage. Since DeepImageFeaturizer does not have any trainable parameters this is not a major issue. You simply remove DeepImageFeaturizer before serialization and add it explicitly to the pipeline when you load the model at the later time. You also don't need the stage that converts a string label to a numeric one. It is not needed during inference.

# COMMAND ----------

# Remove label conversion stage
model.stages.pop(0)
# Remove DeepImageFeaturizer stage
model.stages.pop(0)
# Serialize and save the model
save_model_path = '/models/landclassifier'
model.write().overwrite().save(save_model_path)
model.stages

# COMMAND ----------

# MAGIC %md
# MAGIC The model is now persisted to a disk. If you use a model management solution like Azure ML you can track it as a configuration management item.
# MAGIC 
# MAGIC If at some later time you want to use the model for scoring (inference) you can load it from the disk.

# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC ### Load the model
# MAGIC 
# MAGIC As noted before, the DeepImageFeaturizer stage has to be added to the restored model pipeline.

# COMMAND ----------

from pyspark.ml import PipelineModel

landclassifier = PipelineModel.read().load(save_model_path)
featurizer = DeepImageFeaturizer(inputCol="image", outputCol="features", modelName="ResNet50")
landclassifier.stages.insert(0, featurizer)
landclassifier.stages

# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC You can now use the loaded model for batch inference.

# COMMAND ----------

test_img_df = ImageSchema.readImages(img_dir + 'test', recursive=True)
scored_img_df = landclassifier.transform(test_img_df)

# COMMAND ----------

display(scored_img_df.select('image', 'predictedLabel').limit(10))

# COMMAND ----------

# MAGIC %md
# MAGIC 
# MAGIC ## THE END

# COMMAND ----------

from examples.dqn import DeepQNetwork
from examples.gym_utils import NormalizedObservationWrapper, CartPoleRewardWrapper
import unittest
from unittest import TestCase
import gym
import tensorflow as tf

#%%

class QLearningTests(TestCase):

    def test_deep_qlearning_cart_pole(self):
        env = CartPoleRewardWrapper(gym.make('CartPole-v1'))
        writer = tf.summary.create_file_writer("/tmp/logdir/deep_q_cart_pole")
        q_learning = DeepQNetwork(env, alpha=1e-3, )
        num_episodes = 10
        episode_lenth = 50
        for episode in range(num_episodes):
            q_learning.training_episode(num_exploration_episodes=int(num_episodes * 2/3), episode_lenght=episode_lenth)
            print("episode: {}, epsilon: {}, everage cumulative reward: {}".format(episode, q_learning.epsilon, q_learning.evaluate_average_cumulative_reward(100)))

        print('Average cumulative reward after episode:{} is: {}'.format(episode, q_learning.evaluate_average_cumulative_reward(100)))

    def test_deep_qlearning_mountain_car(self):
        env = NormalizedObservationWrapper(gym.make('MountainCar-v0'))
        writer = tf.summary.create_file_writer("/tmp/logdir/deep_q_mountain_car")
        q_learning = DeepQNetwork(env, alpha=1e-3, writer=writer)
        num_episodes = 10
        episode_lenth = 50
        for episode in range(num_episodes):
            q_learning.training_episode(num_exploration_episodes=int(num_episodes * 2/3), episode_lenght=episode_lenth)
            print("episode: {}, epsilon: {}, everage cumulative reward: {}".format(episode, q_learning.epsilon, q_learning.evaluate_average_cumulative_reward(100)))

        print('Average cumulative reward after episode:{} is: {}'.format(episode, q_learning.evaluate_average_cumulative_reward(100)))

#%%

if __name__ == "__main__":
    unittest.main()
import logging
from random import randint

import numpy as np

from reflrn.exceptions.EvaluationException import EvaluationException
from reflrn.Interface.Policy import Policy
from reflrn.Interface.State import State


#
# This policy uses a Neural Network as an estimator of QValues. A simple batch randomly experience cache is used
# avoid issues with correlated-states. In addition the learning is only periodic which counteracts issues with
# non-stationary targets.
#
# MSVE = (reward + discount-factor*max(s',a',theta{fixed})-Q(s,a,theta))^2
#

class DeepReplayQNetworkPolicy(Policy):
    #
    # Learning is for all agents of this *type* so q values are at class level, and all
    # methods that select_action on q values are class methods.
    #
    # ToDo: q_vals should not be at class level, should pass in the q_val dicts so it can be shared only if required
    #
    __q_values = None  # key: Agent id + State & Value: (dictionary of key: action -> Value: Q value)
    __n = 0  # number of learning events
    __learning_rate_0 = float(1.0)
    __discount_factor = float(0.8)
    __learning_rate_decay = float(0.05)
    __fixed_games = None  # a class that allows canned games to be played
    __rand_qval_init = True

    #
    # At inti time the only thing needed is the universal set of possible
    # actions for the given Environment
    #
    def __init__(self,
                 lg: logging):
        return

    #
    # Return the learning rate based on number of learning's to date
    #
    @classmethod
    def __q_learning_rate(cls, n: int):
        return cls.__learning_rate_0 / (1 + (n * cls.__learning_rate_decay))

    #
    # Manage q value store
    #
    @classmethod
    def __manage_q_val_store(cls, q_val_state_name: str, action: int):
        if cls.__q_values is None:
            cls.__q_values = dict()
            cls.__n = 0

        if q_val_state_name not in cls.__q_values:
            cls.__q_values[q_val_state_name] = dict()

        if action not in cls.__q_values[q_val_state_name]:
            cls.__q_values[q_val_state_name][action] = cls.__init_qval(cls.__rand_qval_init)

        return

    #
    # Get the given q value for the given agent, curr_coords and action
    #
    @classmethod
    def __get_q_value(cls, state: State, action: int) -> float:
        state_name = state.state_as_string()
        cls.__manage_q_val_store(state.state_as_string(), action)
        return cls.__q_values[state_name][action]

    #
    # Set the q value for the given agent, curr_coords and action
    #
    @classmethod
    def __set_q_value(cls, state: State, action: int, q_value: float) -> None:
        state_name = state.state_as_string()
        cls.__manage_q_val_store(state_name, action)
        cls.__q_values[state_name][action] = q_value

    #
    # Use temporal difference methods to keep q values for the given curr_coords/action plays.
    #
    # prev_state : the previous curr_coords for this Agent; None if no previous curr_coords
    # prev_action : the previous action of this agent; has no meaning is prev_state = None
    # curr_coords : current curr_coords of the environment *after* the given action was played
    # action : the action played by this agent that moved the curr_coords to the curr_coords passed
    # reward : the reward associated with the given curr_coords/action pair.
    # ToDo
    def update_policy(self,
                      agent_name: str,
                      state: State,
                      next_state: State,
                      action: int,
                      reward: float,
                      episode_complete: bool) -> None:

        self.__lg.debug(
            str(
                self.__frame_id) + ":" + agent_name + " : " + state.state_as_string() + " : " + next_state.state_as_string() + " : " + str(
                action))

        lgm = self.vals_and_actions_as_str(state)
        if episode_complete:
            self.__lg.debug(lgm)
            self.__frame_id += 1
            if self.__manage_qval_file:  # Save Q Vals At End Of Every Episode
                self.__save()

        # Update master count of policy learning events
        DeepReplayQNetworkPolicy.__n += 1

        lr = DeepReplayQNetworkPolicy.__q_learning_rate(self.__frame_id)

        # Establish the max (optimal) outcome taken from the target curr_coords.
        #
        qvs, actn = DeepReplayQNetworkPolicy.__get_q_vals_as_np_array(next_state)
        ou = DeepReplayQNetworkPolicy.__greedy_outcome(qvs)
        qvp = self.__discount_factor * ou * lr

        # Update current curr_coords to reflect the reward
        qv = DeepReplayQNetworkPolicy.__get_q_value(state, action)
        qv = (qv * (1 - lr)) + (lr * reward) + qvp
        DeepReplayQNetworkPolicy.__set_q_value(state, action, qv)

        return

    #
    # The optimal action is to take the largest positive gain or the smallest
    # loss. => Maximise Gain & Minimise Loss
    #
    @classmethod
    def __greedy_outcome(cls, q_values: np.array) -> np.float:
        if q_values is not None and q_values.size > 0:
            return np.max(q_values)
        else:
            return np.float(0)

    #
    # get_memories_by_type q values and associated actions as numpy array
    #
    @classmethod
    def __get_q_vals_as_np_array(cls, state: State) -> np.array:
        q_values = None
        q_actions = None

        # If there are no Q values learned yet we cannot predict a greedy action.
        if cls.__q_values is not None:
            state_name = state.state_as_string()

            if state_name in cls.__q_values:
                sz = len(cls.__q_values[state_name])
                q_values = np.full(sz, np.nan)
                q_actions = np.array(sorted(list(cls.__q_values[state_name].keys())))
                i = 0
                for actn in q_actions:
                    q_values[i] = cls.__q_values[state_name][actn]
                    i += 1

        return q_values, q_actions

    #
    # Greedy action; return the action that has the strongest Q value or if there is more
    # than one q value with the same strength, return an arbitrary action from those with
    # equal strength.
    #
    def select_action(self, agent_name: str, state: State, possible_actions: [int]) -> int:

        if self.__fixed_games is not None:
            return self.__fixed_games.next_action()

        qvs, actions = self.__get_q_vals_as_np_array(state)

        # If no Q Values to drive direction then use the fallback policy.
        # the fallback policy will always return an action.
        if qvs is None:
            return self.__fallback_policy.select_action(agent_name, state, possible_actions)

        ou = DeepReplayQNetworkPolicy.__greedy_outcome(qvs)
        greedy_actions = list()
        for v, a in np.vstack([qvs, actions]).T:
            if v == ou and a in possible_actions:
                greedy_actions.append(int(a))
        if len(greedy_actions) == 0:
            raise EvaluationException("No Q Values mapping to possible actions, cannot select greedy action")

        return greedy_actions[randint(0, len(greedy_actions) - 1)]

    #
    # Save with class default filename.
    #
    def __save(self):
        self.save(self.__filename)

    #
    # FileName, return the given file name of the one set as default during
    # class construction
    #
    def file_name(self, filename: str) -> str:
        fn = filename
        if fn is None or len(fn) == 0:
            fn = self.__filename
        return fn

    #
    # Export the current policy to the given file name
    #
    def save(self, filename: str = None):
        fn = self.file_name(filename)
        if fn is not None and len(fn) > 0:
            self.__persistance.save(DeepReplayQNetworkPolicy.__q_values,
                                    DeepReplayQNetworkPolicy.__n,
                                    DeepReplayQNetworkPolicy.__learning_rate_0,
                                    DeepReplayQNetworkPolicy.__discount_factor,
                                    DeepReplayQNetworkPolicy.__learning_rate_decay,
                                    fn)
        else:
            raise FileNotFoundError("File name for TemporalDifferencePolicy save does not exist: [" & fn & "]")

        return

    #
    # Import the current policy to the given file name
    #
    def load(self, filename: str = None):
        fn = self.file_name(filename)
        if fn is not None and len(fn) > 0:
            (DeepReplayQNetworkPolicy.__q_values,
             DeepReplayQNetworkPolicy.__n,
             DeepReplayQNetworkPolicy.__learning_rate_0,
             DeepReplayQNetworkPolicy.__discount_factor,
             DeepReplayQNetworkPolicy.__learning_rate_decay) \
                = self.__persistance.load(filename)
        else:
            raise FileNotFoundError("File name for TemporalDifferencePolicy Load does not exist: [" & fn & "]")

        return (DeepReplayQNetworkPolicy.__q_values,
                DeepReplayQNetworkPolicy.__n,
                DeepReplayQNetworkPolicy.__learning_rate_0,
                DeepReplayQNetworkPolicy.__discount_factor,
                DeepReplayQNetworkPolicy.__learning_rate_decay)

    #
    # Q Values as a string (in grid form). This is just a visual debugger so it is
    # possible to see what q values are being selected from in the way that they
    # relate to the board. (3 x 3)
    #
    def vals_and_actions_as_str(self, state: State) -> str:
        return self.__q_val_render.render(state, self.__q_values)

    #
    # Log curr_coords
    #
    def __log_state(self):
        pass

    #
    # Q Value Initialize
    #
    @classmethod
    def __init_qval(cls, rand_init: bool = True) -> np.float:
        if rand_init:
            return np.random.uniform(-1, 1)
        else:
            return np.float(0)
# -*- coding: utf-8 -*-
# 上采样之后得到的得分，然后通过argmax来得到最后的分类结果
import tensorflow as tf
from DataSet import DataSet
import numpy as np
import gc

IMAGE_SIZE = 224
IMAGE_CHANNAL = 3

CONV1_1_SIZE = 3
CONV1_1_DEEP = 64
CONV1_2_SIZE = 3
CONV1_2_DEEP = 64

CONV2_1_SIZE = 3
CONV2_1_DEEP = 128
CONV2_2_SIZE = 3
CONV2_2_DEEP = 128

CONV3_1_SIZE = 3
CONV3_1_DEEP = 256
CONV3_2_SIZE = 3
CONV3_2_DEEP = 256
CONV3_3_SIZE = 1
CONV3_3_DEEP = 256

CONV4_1_SIZE = 3
CONV4_1_DEEP = 512
CONV4_2_SIZE = 3
CONV4_2_DEEP = 512
CONV4_3_SIZE = 1
CONV4_3_DEEP = 512

CONV5_1_SIZE = 3
CONV5_1_DEEP = 512
CONV5_2_SIZE = 3
CONV5_2_DEEP = 512
CONV5_3_SIZE = 1
CONV5_3_DEEP = 512

UPSAMPLE1_1_SIZE = 5
UPSAMPLE1_1_DEEP = 150


FC1_SIZE = 1
FC1_DEEP = 1

CATEGORY_NUM = 150

FLAGS = tf.flags.FLAGS
tf.flags.DEFINE_integer("batch_size", "50", "batch size for training")
tf.flags.DEFINE_string("logs_dir", "logs/", "path to logs directory")
tf.flags.DEFINE_string("data_dir", "'/home/give/Documents/dataset/ADEChallengeData2016'", "path to dataset")
tf.flags.DEFINE_float("learning_rate", "1e-1", "Learning rate for Adam Optimizer")
tf.flags.DEFINE_string("model_dir", "Model_zoo/", "Path to vgg model mat")
tf.flags.DEFINE_bool('debug', "False", "Debug mode: True/ False")
tf.flags.DEFINE_string('mode', "train", "Mode train/ test/ visualize")
MAX_ITERATION = int(1e5 + 1)
DECAY_LEARNING_RATE = 0.1


def do_conv(name, weight_shape, bias_shape, input_tensor):
    with tf.variable_scope(name):
        weight = tf.get_variable(
            'weight',
            shape=weight_shape,
            initializer=tf.truncated_normal_initializer(stddev=0.02)
        )
        bias = tf.get_variable(
            'bias',
            shape=bias_shape,
            initializer=tf.constant_initializer(0.0)
        )
        conv = tf.nn.conv2d(
            input_tensor,
            weight,
            strides=[1, 1, 1, 1],
            padding='SAME',
        )
        layer = tf.nn.bias_add(conv, bias)
        return tf.nn.relu(layer)


def inference(image, keep_prob):
    with tf.variable_scope('inference'):

        layer11 = do_conv(
            'conv1_1',
            weight_shape=[
                CONV1_1_SIZE,
                CONV1_1_SIZE,
                IMAGE_CHANNAL,
                CONV1_1_DEEP
            ],
            bias_shape=[
                CONV1_1_DEEP
            ],
            input_tensor=image
        )
        print layer11.shape
        layer12 = do_conv(
            'conv1_2',
            weight_shape=[
                CONV1_2_SIZE,
                CONV1_2_SIZE,
                CONV1_1_DEEP,
                CONV1_2_DEEP
            ],
            bias_shape=[
                CONV1_2_DEEP
            ],
            input_tensor=layer11
        )
        print layer12.shape


        with tf.variable_scope('pooling1'):
            pooling1 = tf.nn.max_pool(
                layer12,
                strides=[1, 2, 2, 1],
                padding='SAME',
                ksize=[1, 2, 2, 1]
            )
            print pooling1.shape


        layer21 = do_conv(
            'conv2_1',
            weight_shape=[
                CONV2_1_SIZE,
                CONV2_1_SIZE,
                CONV1_2_DEEP,
                CONV2_1_DEEP
            ],
            bias_shape=[
                CONV2_1_DEEP
            ],
            input_tensor=pooling1
        )
        layer22 = do_conv(
            'conv2_2',
            weight_shape=[
                CONV2_2_SIZE,
                CONV2_2_SIZE,
                CONV2_1_DEEP,
                CONV2_2_DEEP
            ],
            bias_shape=[
                CONV2_2_DEEP
            ],
            input_tensor=layer21
        )


        with tf.variable_scope('pooling2'):
            pooling2 = tf.nn.max_pool(
                layer22,
                strides=[1, 2, 2, 1],
                padding='SAME',
                ksize=[1, 2, 2, 1]
            )
            print pooling2.shape

        layer31 = do_conv(
            'conv3_1',
            weight_shape=[
                CONV3_1_SIZE,
                CONV3_1_SIZE,
                CONV2_2_DEEP,
                CONV3_1_DEEP
            ],
            bias_shape=[
                CONV3_1_DEEP
            ],
            input_tensor=pooling2
        )
        layer32 = do_conv(
            'conv3_2',
            weight_shape=[
                CONV3_2_SIZE,
                CONV3_2_SIZE,
                CONV3_1_DEEP,
                CONV3_2_DEEP
            ],
            bias_shape=[
                CONV3_2_DEEP
            ],
            input_tensor=layer31
        )
        layer33 = do_conv(
            'conv3_3',
            weight_shape=[
                CONV3_3_SIZE,
                CONV3_3_SIZE,
                CONV3_2_DEEP,
                CONV3_3_DEEP
            ],
            bias_shape=[
                CONV3_3_DEEP
            ],
            input_tensor=layer32
        )
        with tf.variable_scope('pooling3'):
            pooling3 = tf.nn.max_pool(
                layer33,
                strides=[1, 2, 2, 1],
                padding='SAME',
                ksize=[1, 2, 2, 1]
            )
            print pooling3.shape
        layer41 = do_conv(
            'conv4_1',
            weight_shape=[
                CONV4_1_SIZE,
                CONV4_1_SIZE,
                CONV3_3_DEEP,
                CONV4_1_DEEP
            ],
            bias_shape=[
                CONV4_1_DEEP
            ],
            input_tensor=pooling3
        )
        layer42 = do_conv(
            'conv4_2',
            weight_shape=[
                CONV4_2_SIZE,
                CONV4_2_SIZE,
                CONV4_1_DEEP,
                CONV4_2_DEEP
            ],
            bias_shape=[
                CONV4_2_DEEP
            ],
            input_tensor=layer41
        )
        layer43 = do_conv(
            'conv4_3',
            weight_shape=[
                CONV4_3_SIZE,
                CONV4_3_SIZE,
                CONV4_2_DEEP,
                CONV4_3_DEEP
            ],
            bias_shape=[
                CONV4_3_DEEP
            ],
            input_tensor=layer42
        )
        with tf.variable_scope('pooling4'):
            pooling4 = tf.nn.max_pool(
                layer43,
                strides=[1, 2, 2, 1],
                padding='SAME',
                ksize=[1, 2, 2, 1]
            )
            print pooling4.shape
        layer51 = do_conv(
            'conv5_1',
            weight_shape=[
                CONV5_1_SIZE,
                CONV5_1_SIZE,
                CONV4_3_DEEP,
                CONV5_1_DEEP
            ],
            bias_shape=[
                CONV5_1_DEEP
            ],
            input_tensor=pooling4
        )
        layer52 = do_conv(
            'conv5_2',
            weight_shape=[
                CONV5_2_SIZE,
                CONV5_2_SIZE,
                CONV5_1_DEEP,
                CONV5_2_DEEP
            ],
            bias_shape=[
                CONV5_2_DEEP
            ],
            input_tensor=layer51
        )
        layer53 = do_conv(
            'conv5_3',
            weight_shape=[
                CONV5_3_SIZE,
                CONV5_3_SIZE,
                CONV5_2_DEEP,
                CONV5_3_DEEP
            ],
            bias_shape=[
                CONV5_3_DEEP
            ],
            input_tensor=layer52
        )
        with tf.variable_scope('pooling5'):
            pooling5 = tf.nn.max_pool(
                layer53,
                strides=[1, 2, 2, 1],
                padding='SAME',
                ksize=[1, 2, 2, 1]
            )
            print pooling5.shape
        with tf.variable_scope('upsampe1'):
            weight = tf.get_variable(
                'weight',
                shape=[
                    UPSAMPLE1_1_SIZE,
                    UPSAMPLE1_1_SIZE,
                    UPSAMPLE1_1_DEEP,
                    CONV5_3_DEEP
                ],
                initializer=tf.truncated_normal_initializer(stddev=0.02)
            )
            upsample1 = tf.nn.conv2d_transpose(
                pooling5,
                weight,
                output_shape=[FLAGS.batch_size, IMAGE_SIZE, IMAGE_SIZE, UPSAMPLE1_1_DEEP],
                strides=[1, 32, 32, 1]
            )
            print 'upsample1 shape is ', upsample1.shape
        return upsample1


def compare2onedimension(x):
    shape = x.get_shape().as_list()
    print shape
    print type(x)
    compared = tf.reshape(
        x, [shape[0] * shape[1] * shape[2]]
    )
    return compared


def conver2onehot(annotation):
    shape = np.shape(annotation)
    res_shape = []
    res_shape.extend(shape)
    res_shape.append(150)
    res = np.zeros(res_shape)
    for i in range(shape[0]):
        for j in range(shape[1]):
            for z in range(shape[2]):
                res[i, j, z, annotation[i, j, z]-1] = 1
    return res


def train(dataset):
    x = tf.placeholder(
        tf.float32,
        [
            FLAGS.batch_size,
            IMAGE_SIZE,
            IMAGE_SIZE,
            IMAGE_CHANNAL
        ],
        name='input-x'
    )
    tf.summary.image(
        'input/image',
        x,
        FLAGS.batch_size
    )
    y_ = tf.placeholder(
        tf.float32,
        [
            FLAGS.batch_size,
            IMAGE_SIZE,
            IMAGE_SIZE,
            CATEGORY_NUM
        ]
    )
    tf.summary.image(
        'input/annotation',
        tf.reshape(
            tf.cast(tf.argmax(y_, dimension=3), tf.uint8),
            [
                FLAGS.batch_size,
                IMAGE_SIZE,
                IMAGE_SIZE,
                1
            ]
        ),
        FLAGS.batch_size
    )
    y = inference(x, 0.5)
    tf.summary.image(
        'output/annotation',
        tf.reshape(
            tf.cast(tf.argmax(y, dimension=3), tf.uint8),
            [
                FLAGS.batch_size,
                IMAGE_SIZE,
                IMAGE_SIZE,
                1
            ]
        ),
        FLAGS.batch_size
    )
    print 'y shape is ', y.shape
    print 'y_ shape is ', y_.shape
    print type(y)
    print type(y_)
    print type(y)
    global_step = tf.Variable(0)
    learning_rate = tf.train.exponential_decay(
        learning_rate=FLAGS.learning_rate,
        global_step=global_step,
        decay_steps=20,
        decay_rate=DECAY_LEARNING_RATE,
        staircase=True
    )

    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(
        logits=y,
        labels=y_,
        name="entropy"
    ))
    # add to scalar
    tf.summary.scalar(
        'loss',
        loss
    )
    # optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)
    # grads = optimizer.compute_gradients(loss, var_list=tf.trainable_variables())
    train_op = tf.train.AdamOptimizer(
        learning_rate=learning_rate
    ).minimize(loss=loss)
    # train_op = tf.train.GradientDescentOptimizer(
    #     learning_rate=FLAGS.learning_rate
    # ).minimize(
    #     loss=loss
    # )
    # 计算准确率
    with tf.name_scope('accuracy'):
        correct_predict = tf.equal(
            tf.cast(tf.argmax(y, dimension=3), tf.int32),
            tf.cast(tf.argmax(y_, dimension=3), tf.int32)
        )
        accuracy_tensor = tf.reduce_mean(tf.cast(correct_predict, tf.float32))
        tf.summary.scalar(
            'accuracy',
            accuracy_tensor
        )
    merged = tf.summary.merge_all()
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        save_path = '/home/give/PycharmProjects/MyFCN/log/FCN_VGG'
        writer = tf.summary.FileWriter(save_path, tf.get_default_graph())
        for i in range(MAX_ITERATION):
            train_image, train_annoation, flag = dataset.next_batch(FLAGS.batch_size)
            # print 'before eye shape is ', np.shape(train_annoation)
            train_annoation_adjust = conver2onehot(np.array(train_annoation))
            # print 'after eye shape is ', np.shape(train_annoation_adjust)
            feed_dict = {
                x: train_image,
                y_: train_annoation_adjust
            }
            _, _, _, summary = sess.run(
                [train_op, loss, accuracy_tensor, merged],
                feed_dict=feed_dict
            )
            writer.add_summary(summary, i)
            if (i % 20) == 0:
                loss_value, accuracy_value, learning_rate_value = sess.run(
                    [loss, accuracy_tensor, learning_rate],
                    feed_dict=feed_dict
                )
                print 'loss value is %g accuracy is %g learning rate is %g ' \
                      % (loss_value, accuracy_value, learning_rate_value)
            del train_annoation_adjust
            gc.collect()
        writer.close()
if __name__ == '__main__':
    # input_image = tf.placeholder(
    #     tf.float32,
    #     [
    #         10,
    #         IMAGE_SIZE,
    #         IMAGE_SIZE,
    #         IMAGE_CHANNAL
    #     ]
    # )
    # print 'input image shape is ', tf.shape(input_image), input_image.shape
    # output_image = inference(input_image, 0.5)
    # output_image.shape
    dataset = DataSet(FLAGS.data_dir)
    train(dataset)# coding: utf-8
"""
    将原始数据集进行划分成训练集、验证集和测试集
    将所有的srcImage和Label分别拷贝到train和label文件夹中，然后就会按照训练集、验证集、测试集的比例划分他们
    但是，当训练集和验证集数据属于不同分布时（训练集为了数据量，使用了非常大量的数据，这些数据可能与验证集、测试集的分布不完全相同），
    而验证集要最接近真实状况，里面都要是最真实的数据，即数据不饿能够随机划分，这时候需要将最接近真实的那部分数据随机抽出一部分给train,
    剩下的那部分作为val和test
"""

import os
import glob
import random
import shutil


import collections
import os.path as osp

import numpy as np
from PIL import Image
import scipy.io
import torch
from torch.utils import data
from torchvision import transforms as T









def makedir(new_dir):
    if not os.path.exists(new_dir):
        os.makedirs(new_dir)



def splitPicture(datasetDir,trainDir,valDir,testDir,trainPer=0.8,valPer=0.2):
    """
    将rootPic路径下的pic和label图片按训练集、验证机和测试集分类，一般语义分割时，rootPic路径下包含label，pic子目录（分别存储语义分割后的标签图片和原图）
        要点：
        1.os.walk()的作用:os.walk后面跟目录的路径(记为主目录)，生成一个生成器
        每次返回是一个tuple,(这次遍历的目录路径是什么(字符串)，这次遍历的目录下的子目录（列表形式），这次遍历的目录下的文件)
        依次遍历主目录下的每个子目录，直到遍历完所有的子目录为止
        对于目录的操作基本都是用os包，如os.path.join进行目录的连接
        2.glob.glob()  后跟字符串，代表想要匹配的字符串形式
        返回一个列表，列表包含了所有和参数匹配的文件的路径

        3.random
        random根据种子的值进行随机，当种子相同时，random的随机值也相同
        """

    for root, dirs, files in os.walk(datasetDir):
        for sDir in dirs:
            imgs_list= []
            imgs_list = glob.glob(os.path.join(root, sDir) + '/*.png')
            imgs_list = imgs_list if imgs_list else glob.glob(os.path.join(root, sDir) + '/*.BMP')
            imgs_list = sorted(imgs_list,key=str.lower)
            random.seed(666)
            random.shuffle(imgs_list)
            imgs_num = len(imgs_list)

            train_point = int(imgs_num * trainPer)
            valid_point = int(imgs_num * (trainPer + valPer))

            for i in range(imgs_num):
                if i < train_point:
                    out_dir = trainDir + sDir + '/'
                elif i < valid_point:
                    out_dir = valDir + sDir + '/'
                else:
                    out_dir = testDir + sDir + '/'

                makedir(out_dir)
                out_path = out_dir + os.path.split(imgs_list[i])[-1]
                shutil.copy(imgs_list[i], out_path)

            print('Class:{}, train:{}, valid:{}, test:{}'.format(sDir, train_point, valid_point - train_point,
                                                                 imgs_num - valid_point))


def gen_txt(txtPath, imgDir):
    """

    :param 给定要产生的txt文件的路径
    :param 给定要遍历的图片的路径
    :结果: 将要遍历的图片路径写入给定的txt文档中
    """
    f = open(txtPath, 'w')

    iDir = os.path.join(imgDir)  # 获取各类的文件夹 绝对路径
    img_list = os.listdir(iDir)  # 获取类别文件夹下所有png图片的路径
    for i in range(len(img_list)):
        if not (img_list[i].endswith('png') or img_list[i].endswith('BMP')):  # 若不是png文件，跳过
            continue
        # label = img_list[i].split('_')[0]
        # img_path = os.path.join(i_dir, img_list[i])
        line = img_list[i] + '\n'
        f.write(line)

    f.close()


def picFulPath(txtPath, rootImg, rootLbl,
               destPath,
               ImgFix = '',
               lblFix = ''
               ):
    '''
    给定只包含图片文件名的txt和图片所在路径
    参数：txtPath  包含图片文件名的txt的路径
         rootImg:图片所在的根文件夹
         rootLbl:标记文件所在的根目录
         destPath:要生成的包含img和lbl完全路径的txt文档
    :return: 包含图片绝对路径和图片文件名、包含标签绝对和标签和的txt文档

    '''
    # 读取txtpath中的每一行，然后加上rootImag和rootLbl后写入新的txt文档
    f = open(destPath, 'w')
    fh = open(txtPath, 'r')
    # 读取txtPath中的每一行，每一行都是图片文件的文件名，在每一行中加上绝对路径
    for line in fh:
        line = line.rstrip()  # 去掉改行最后的回车符号
        line = rootImg + line + ' ' + rootLbl + line.split('.')[0]+'.png'  + '\n'  # 此处最好改为文件名的相加，而不是单纯的字符串相加
        f.write(line)
    f.close()
    fh.close()





if __name__ == '__main__':

    """
    #用法
    指定各个文件夹：
    数据所在文件夹dataset_dir，该文件夹下同时包含了几个文件夹 分别存放原图img和标准图label和可视图vis
    要生成的训练集 验证集 测试集的文件夹 train_dir valid_dir  test_dir
    dataset_dir = '/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/'
    train_dir = '/home/mlxuan/project/DeepLearning/data/image_Segmentation/train/'
    valid_dir = '/home/mlxuan/project/DeepLearning/data/image_Segmentation/valid/'
    test_dir = '/home/mlxuan/project/DeepLearning/data/image_Segmentation/test/'
    
    #制定训练集 验证集 测试集 的划分比例
    train_per = 0.8
    valid_per = 0.2
    
    #图片划分
    splitPicture(dataset_dir, train_dir, valid_dir, test_dir, 0.8, 0.2)
    
    
    train_txt_path = '../Data/train.txt'
    valid_txt_path = '../Data/valid.txt'

    #这些代码只用执行一次，用来生成img lbl的txt文档
    
    """
    """
    dataset_dir = '/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/'
    train_dir = '/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/train/'
    valid_dir = '/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/valid/'
    test_dir =  '/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/test/'
    train_per = 0.9
    valid_per = 0.1
    splitPicture(dataset_dir, train_dir, valid_dir, test_dir, 0.9, 0.1)
    """
    #遍历给定目录下的所有的png文件和BMP文件，生成对应的txt
    gen_txt(txtPath='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/train/train.txt', imgDir='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/train/src')
    gen_txt(txtPath='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/valid/valid.txt', imgDir='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/valid/src')

    #根据目录名 生成img+label的dataAug/完全路径
    picFulPath(txtPath='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/train/train.txt',
               rootImg ='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/train/src/',
               rootLbl='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/train/label/',
               destPath='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/train/trainFull.txt')

    picFulPath(txtPath='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/valid/valid.txt',
               rootImg='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/valid/src/',
               rootLbl='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/valid/label/',
               destPath='/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/valid/validFull.txt')
'''
Created on Jan 10, 2015

@author: Lightning
'''
#from Multi_Layer_Perceptron import multiLayerPerceptron
from Logistic_Regression import sgd_optimization_mnist
#from LeNet import leNetModel
#from Denoising_AutoEncoders import denoisingAutoEncoders
#from Stacked_Denoising_AutoEncoders import stackedDenoisingAutoEncoders
#from Restricted_Boltzmann_Machines import restrictedBoltzmannMachines
#from Deep_Belief_Network import deepBeliefNetwork

if __name__ == '__main__':
    
    #----Logistic Regression Optimization-------------------------------
    
    sgd_optimization_mnist(learning_rate=0.13, n_epochs=1000, 
                           dataset='mnist.pkl.gz', batch_size=600)
                           
    #-----End of the Logistic Regression--------------------------------
    
    #---Begin implementation of Multi-Layer-Perceptron------------------
    
    #multiLayerPerceptron(learning_rate=0.01, L1_reg=0.00, L2_reg=0.0001, n_epochs=1000,
             #dataset='X:\Deep_Learning\mnist.pkl.gz', batch_size=20, n_hidden=500)
             
    #-----End implementation of the MLP----------------------------------

    #------Begin implementing LeNet from here----------------------------
    
    #leNetModel(learning_rate=0.01, L1_reg=0.00, L2_reg=0.0001, n_epochs=1000,
             #dataset='X:\Deep_Learning\mnist.pkl.gz', batch_size=20, n_hidden=500, nkerns=[20,50])
    
    #---------End of LeNet implementation--------------------------------
    
    #-----------Begin implementing the Denoising Auto-Encoders-----------
    
    #denoisingAutoEncoders(learning_rate=0.1, training_epochs=15,
            #dataset='X:\Deep_Learning\mnist.pkl.gz',
            #batch_size=20, output_folder='X:\Deep_Learning\dA_plots')
    
    #--------------------End Implementation of dA------------------------
    
    #---------------Begin implementation of Stacked Auto Encoders--------
    
    #stackedDenoisingAutoEncoders(finetune_lr=0.1, pretraining_epochs=15,
             #pretrain_lr=0.001, training_epochs=1000,
             #dataset='X:\Deep_Learning\mnist.pkl.gz', batch_size=1)
    
    #----------------End of the Stacked Auto Encoders ------------------
    
    #------------Begin implementation of Restricted_Boltzmann_Machines--
    
    #restrictedBoltzmannMachines(learning_rate=0.1, training_epochs=15,
             #dataset='X:\Deep_Learning\mnist.pkl.gz', batch_size=20,
             #n_chains=20, n_samples=10, output_folder='X://Deep_Learning//rbm_plots',
             #n_hidden=500, destination_file='X:\Deep_Learning\samples.png')
     
     #-------End of Restricted_Boltzmann_Machines----------------------
     
     #-------Begin implementation of Deep_Belief_Network---------------
     
     #deepBeliefNetwork(finetune_lr=0.1, pretraining_epochs=100,
             #pretrain_lr=0.01, k=1, training_epochs=1000,
             #dataset='X:\Deep_Learning\mnist.pkl.gz', batch_size=10)
             
    #------End of implementation of Deep_Belief_Network---------------
from tl_controller.qlearning.ControllerAlgorithmQLearning import ControllerAlgorithmQLearning
from tl_controller.qlearning.ControllerAlgorithmDeepQLearning import ControllerAlgorithmDeepQLearning

class QLearningAlgorithmFactory(object):

    qlearning_algorithm = None
    deep_qlearning_algorithm = None

    """docstring for QLearningAlgorithmFactory."""
    def __init__(self):
        super(QLearningAlgorithmFactory, self).__init__()

    @staticmethod
    def getQLearningAlgorithm(epsilon_greedy_rate = 0.7, gamma_value = 0.8, alpha_value = 0.1):

        print(f'Get QLearning algorithm with params: e-greedy-rate {epsilon_greedy_rate}; gamma_value {gamma_value}; alpha_value {alpha_value}.')
        if QLearningAlgorithmFactory.qlearning_algorithm is None:
            QLearningAlgorithmFactory.qlearning_algorithm = ControllerAlgorithmQLearning()

        QLearningAlgorithmFactory.qlearning_algorithm.epsilon_greedy_rate = epsilon_greedy_rate
        QLearningAlgorithmFactory.qlearning_algorithm.gamma_value = gamma_value
        QLearningAlgorithmFactory.qlearning_algorithm.alpha_value = alpha_value

        return QLearningAlgorithmFactory.qlearning_algorithm

    @staticmethod
    def getDeepQLearningAlgorithmLSTM(state_array_length, hidden_neuron_count=40, epsilon_greedy_rate=0.7, learning_rate=1e-05, discounting_rate=0.1, sequence_length=5):

        print(f'Get DeepQLearning algorithm with params:')
        print(f'state_length {state_array_length}; hidden_neuron_count {hidden_neuron_count}; e-greedy-rate {epsilon_greedy_rate};')
        print(f'learning_rate {learning_rate}; discounting_rate {discounting_rate}; sequence_length {sequence_length}.')
        
        if QLearningAlgorithmFactory.deep_qlearning_algorithm is None:
            QLearningAlgorithmFactory.deep_qlearning_algorithm = ControllerAlgorithmDeepQLearning(
                ControllerAlgorithmDeepQLearning.createLSTMApproximator(state_array_length,
                                                     hidden_neuron_count=hidden_neuron_count,
                                                     discounting_rate=discounting_rate,
                                                     learning_rate=learning_rate,
                                                     sequence_length=sequence_length ))

        QLearningAlgorithmFactory.deep_qlearning_algorithm.epsilon_greedy_rate = epsilon_greedy_rate
        # Learning rate.
        QLearningAlgorithmFactory.deep_qlearning_algorithm.alpha_value = learning_rate
        # Discounting rate.
        QLearningAlgorithmFactory.deep_qlearning_algorithm.gamma_value = discounting_rate
        
        return QLearningAlgorithmFactory.deep_qlearning_algorithm

    @staticmethod
    def resetFactory():
        QLearningAlgorithmFactory.deep_qlearning_algorithm = None
        QLearningAlgorithmFactory.qlearning_algorithm = None
# -*- coding: utf-8 -*-
"""
Created on Thu Oct  5 13:03:20 2017

@author: dbn
"""
#import theano

import numpy as np 

import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.contrib.slim as slim
from tensorflow.examples.tutorials.mnist import input_data
import math
import tensorflow as tf
import theano
import scipy.io as sio
import os
import glob
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense,Activation

#VARIABLES
CONV_LAYLENGTH = 5
NUM_CONV_FILTS = 32

def loadMLII_arrythmiaData():
    data = []
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\100m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\101m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\103m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\105m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\106m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\107m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\108m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\109m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\111m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\112m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\113m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\114m.mat').get('val')[1])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\115m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\116m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\117m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\118m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\119m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\121m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\122m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\123m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\124m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\200m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\201m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\202m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\203m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\205m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\207m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\208m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\209m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\210m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\212m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\213m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\214m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\215m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\217m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\219m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\220m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\221m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\222m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\223m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\228m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\230m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\231m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\232m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\233m.mat').get('val')[0])
    data.append(sio.loadmat('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\234m.mat').get('val')[0])
    return data

def windowData(data,windowSize):
    chunks = [data[x:x+windowSize] for x in range(0, len(data), windowSize) if len(data[x:x+windowSize])>=windowSize]
    return chunks
def normalise(X):
    Z = np.array([(y -np.min(X))/(np.max(X)-np.min(X)) for y in X])
    return Z

def convFilterVisualiation(model,layer,path,numX,numY):
    x = model.layers[layer].get_weights()
    xt = np.transpose(x[0])
    fig = plt.figure(figsize=(numX*10,numY*10))
    for i in range(0,np.shape(xt)[0]):
        ax = plt.subplot(numX,numY,i+1)
        ax.set_title('Filter '+str(i))
        ax.plot(xt[i][0])
    plt.savefig(path)
    fig.show()
def ConvolutionalAutoEncoder(chunkSize,CFL1=CONV_LAYLENGTH,CFL2=CONV_LAYLENGTH,CFL3=CONV_LAYLENGTH,CFL4=CONV_LAYLENGTH,CFL5=CONV_LAYLENGTH,CFL6=CONV_LAYLENGTH,CFL7=CONV_LAYLENGTH,numConvFilts1 = NUM_CONV_FILTS,numConvFilts2 = NUM_CONV_FILTS,numConvFilts3 = NUM_CONV_FILTS,numConvFilts4 = NUM_CONV_FILTS,numConvFilts5 = NUM_CONV_FILTS,numConvFilts6 = NUM_CONV_FILTS):
    from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D
    from keras.models import Model    
    input_seq = Input(shape=(chunkSize,1, ))  # 3 sec of 300Hz measurements
    hidden1 = Conv1D(numConvFilts1, CFL1, activation='relu', padding='same')(input_seq)
    pool1 = MaxPooling1D(5, padding='same')(hidden1)
    hidden2 = Conv1D(numConvFilts2, CFL2, activation='relu', padding='same')(pool1)
    pool2 = MaxPooling1D(5, padding='same')(hidden2)
    hidden3 = Conv1D(numConvFilts3, CFL3, activation='relu', padding='same')(pool2)
    encoded = MaxPooling1D(3, padding='same')(hidden3)
    
    hidden4 = Conv1D(numConvFilts4, CFL4, activation='relu', padding='same')(encoded)
    pool4 = UpSampling1D(3)(hidden4)
    hidden5 = Conv1D(numConvFilts5, CFL5, activation='relu', padding='same')(pool4)
    pool5 = UpSampling1D(5)(hidden5)
    hidden6 = Conv1D(numConvFilts6, CFL6, activation='relu', padding='same')(pool5)
    pool6 = UpSampling1D(5)(hidden6)
    decoded = Conv1D(1, CFL7, activation='tanh', padding='same')(pool6)
    
    autoencoder = Model(input_seq, decoded)
    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
    print(autoencoder.summary())
    return autoencoder,hidden1,hidden2,hidden3,hidden4,hidden5,hidden6,encoded,decoded

def Experiments(data,frequency = 300, amountSeconds = 1,numEpochs = 100,CFL1=CONV_LAYLENGTH,CFL2=CONV_LAYLENGTH,CFL3=CONV_LAYLENGTH,CFL4=CONV_LAYLENGTH,CFL5=CONV_LAYLENGTH,CFL6=CONV_LAYLENGTH,CFL7=CONV_LAYLENGTH,numConvFilts1 = NUM_CONV_FILTS,numConvFilts2 = NUM_CONV_FILTS,numConvFilts3 = NUM_CONV_FILTS,numConvFilts4 = NUM_CONV_FILTS,numConvFilts5 = NUM_CONV_FILTS,numConvFilts6 = NUM_CONV_FILTS,filename = '',numX=10,numY=10):
    #reading the data
    #filestrings = glob.glob('C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\Data\\MIT_BIH Arrhythmia Database\\Matlab\\*.mat')
    #labels =  pd.read_csv(ROOT+ '/Data/training2017/labels.csv',header=None)
    chunkSize =  frequency*amountSeconds
    AE,hidden1,hidden2,hidden3,hidden4,hidden5,hidden6,encoded,decoded = ConvolutionalAutoEncoder(chunkSize,CFL1,CFL2,CFL3,CFL4,CFL5,CFL6,CFL7,numConvFilts1,numConvFilts2,numConvFilts3,numConvFilts4,numConvFilts5,numConvFilts6)
    for i in range(0,len(data)):
        chunkedData = windowData(data[i],chunkSize)
        #normalize each chunk
        chunkedData = np.array([normalise(X) for X in chunkedData])
        #chunkedData = np.array([X.reshape(1,chunkSize,1) for X in chunkedData])
        
            
        if len(chunkedData)==len(chunkedData):
            print('equal lengths')
            Xtrain, Xtest, ytrain, ytest = train_test_split(chunkedData,chunkedData,test_size = 0.3)
       
        AE.fit(Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1],1),Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1],1),epochs=numEpochs)
    results = AE.predict(Xtest.reshape(Xtest.shape[0],Xtest.shape[1],1))
    plotrange = 20
    for i in range(0,plotrange):
       plt.figure()
       plt.plot(Xtest[i])
       plt.plot(results[i])
       plt.show()
       
    convFilterVisualiation(AE,1,'C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\images\\'+filename+'_Layer1.png',numX,numY)
    convFilterVisualiation(AE,3,'C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\images\\'+filename+'_Layer3.png',numX,numY)
    convFilterVisualiation(AE,5,'C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\images\\'+filename+'_Layer5.png',numX,numY)
    convFilterVisualiation(AE,7,'C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\images\\'+filename+'_Layer7.png',numX,numY)
    convFilterVisualiation(AE,9,'C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\images\\'+filename+'_Layer9.png',numX,numY)
    convFilterVisualiation(AE,11,'C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\images\\'+filename+'_Layer11.png',numX,numY)
    convFilterVisualiation(AE,13,'C:\\Users\\Dirk\\Desktop\\DeepLearningForSignals\\images\\'+filename+'_Layer13.png',numX,numY)    
           
data = loadMLII_arrythmiaData()
frequency = 300
amountSeconds = 1
numEpochs = 100
#Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =5,CFL2 =5,CFL3 =5,CFL4 =5,CFL5 =5,CFL6 =5,CFL7 =5,numConvFilts1= 25,numConvFilts2= 25,numConvFilts3= 25,numConvFilts4= 25,numConvFilts5= 25,numConvFilts6= 25,filename = 'CFL5_NumFilts25',numX = 5,numY =5)
#Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =5,CFL2 =5,CFL3 =5,CFL4 =5,CFL5 =5,CFL6 =5,CFL7 =5,numConvFilts1= 5,numConvFilts2= 5,numConvFilts3= 5,numConvFilts4= 5,numConvFilts5= 5,numConvFilts6= 5,filename = 'CFL5_NumFilts5',numX = 5,numY =1)
#Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =5,CFL2 =5,CFL3 =5,CFL4 =5,CFL5 =5,CFL6 =5,CFL7 =5,numConvFilts1= 10,numConvFilts2= 10,numConvFilts3= 10,numConvFilts4= 10,numConvFilts5= 10,numConvFilts6= 10,filename = 'CFL5_NumFilts10',numX = 5,numY =2)
#Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =25,CFL2 =25,CFL3 =25,CFL4 =25,CFL5 =25,CFL6 =25,CFL7 =25,numConvFilts1= 25,numConvFilts2= 25,numConvFilts3= 25,numConvFilts4= 25,numConvFilts5= 25,numConvFilts6= 25,filename = 'CFL25_NumFilts25',numX = 5,numY =5)
#Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =25,CFL2 =25,CFL3 =25,CFL4 =25,CFL5 =25,CFL6 =25,CFL7 =25,numConvFilts1= 5,numConvFilts2= 5,numConvFilts3= 5,numConvFilts4= 5,numConvFilts5= 5,numConvFilts6= 5,filename = 'CFL25_NumFilts5',numX = 5,numY =1)
#Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =25,CFL2 =25,CFL3 =25,CFL4 =25,CFL5 =25,CFL6 =25,CFL7 =25,numConvFilts1= 10,numConvFilts2= 10,numConvFilts3= 10,numConvFilts4= 10,numConvFilts5= 10,numConvFilts6= 10,filename = 'CFL25_NumFilts10',numX = 5,numY =2)
#Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =100,CFL2 =100,CFL3 =100,CFL4 =100,CFL5 =100,CFL6 =100,CFL7 =100,numConvFilts1= 25,numConvFilts2= 25,numConvFilts3= 25,numConvFilts4= 25,numConvFilts5= 25,numConvFilts6= 25,filename = 'CFL100_NumFilts25',numX = 5,numY =5)
#Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =100,CFL2 =100,CFL3 =100,CFL4 =100,CFL5 =100,CFL6 =100,CFL7 =100,numConvFilts1= 5,numConvFilts2= 5,numConvFilts3= 5,numConvFilts4= 5,numConvFilts5= 5,numConvFilts6= 5,filename = 'CFL100_NumFilts5',numX = 5,numY =1)
#Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =100,CFL2 =100,CFL3 =100,CFL4 =100,CFL5 =100,CFL6 =100,CFL7 =100,numConvFilts1= 10,numConvFilts2= 10,numConvFilts3= 10,numConvFilts4= 10,numConvFilts5= 10,numConvFilts6= 10,filename = 'CFL100_NumFilts10',numX = 5,numY =2)

Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =5,CFL2 =5,CFL3 =5,CFL4 =5,CFL5 =5,CFL6 =5,CFL7 =5,numConvFilts1= 1,numConvFilts2= 1,numConvFilts3= 1,numConvFilts4= 1,numConvFilts5= 1,numConvFilts6= 1,filename = 'CFL5_NumFilts1',numX = 1,numY =1)
Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =5,CFL2 =5,CFL3 =5,CFL4 =5,CFL5 =5,CFL6 =5,CFL7 =5,numConvFilts1= 300,numConvFilts2= 300,numConvFilts3= 300,numConvFilts4= 300,numConvFilts5= 300,numConvFilts6= 300,filename = 'CFL5_NumFilts300',numX = 15,numY =20)
Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =25,CFL2 =25,CFL3 =25,CFL4 =25,CFL5 =25,CFL6 =25,CFL7 =25,numConvFilts1= 1,numConvFilts2= 1,numConvFilts3= 1,numConvFilts4= 1,numConvFilts5= 1,numConvFilts6= 1,filename = 'CFL25_NumFilts1',numX = 1,numY =1)
Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =25,CFL2 =25,CFL3 =25,CFL4 =25,CFL5 =25,CFL6 =25,CFL7 =25,numConvFilts1= 300,numConvFilts2= 300,numConvFilts3= 300,numConvFilts4= 300,numConvFilts5= 300,numConvFilts6= 300,filename = 'CFL25_NumFilts300',numX = 15,numY =20)
Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =100,CFL2 =100,CFL3 =100,CFL4 =100,CFL5 =100,CFL6 =100,CFL7 =100,numConvFilts1= 1,numConvFilts2= 1,numConvFilts3= 1,numConvFilts4= 1,numConvFilts5= 1,numConvFilts6= 1,filename = 'CFL100_NumFilts1',numX = 1,numY =1)
Experiments(data,frequency = frequency,amountSeconds = amountSeconds,numEpochs = numEpochs,CFL1 =100,CFL2 =100,CFL3 =100,CFL4 =100,CFL5 =100,CFL6 =100,CFL7 =100,numConvFilts1= 300,numConvFilts2= 300,numConvFilts3= 300,numConvFilts4= 300,numConvFilts5= 300,numConvFilts6= 300,filename = 'CFL100_NumFilts300',numX = 15,numY =20)
#from keras import backend as K
#
#inp = AE.input                                           # input placeholder
#outputs = [layer.output for layer in AE.layers]          # all layer outputs
#functors = [K.function([inp]+ [K.learning_phase()], [out]) for out in outputs]  # evaluation functions
#
## Testing
#test = Xtest.reshape(Xtest.shape[0],Xtest.shape[1],1)
#layer_outs = [func([test, 1.]) for func in functors]
#plt.plot(layer_outs[3][0][0])
##[number layer][always 0][testsample number][node number in layer]
#from scipy.interpolate import interp1d
#
##change first[] to change the layer to disp
##layer = 7
##for node in range(0,np.shape(layer_outs[layer][0][0])[1]):
##    x = np.linspace(0,np.shape(layer_outs[layer][0][0][node])[0]-1,num=np.shape(layer_outs[layer][0][0][node])[0],endpoint=True)
##    y = layer_outs[layer][0][0][node]
##    f = interp1d(x,y,kind = 'cubic')
##    xnew = np.linspace(0,np.shape(layer_outs[layer][0][0][node])[0]-1,num = np.shape(layer_outs[0][0][0])[0],endpoint=True)
##    plt.figure();plt.plot(Xtest[0]);plt.plot(f(xnew));plt.show
#
#
#
#def get_activations(model, model_inputs, print_shape_only=False, layer_name=None):
#    print('----- activations -----')
#    activations = []
#    inp = model.input
#
#    model_multi_inputs_cond = True
#    if not isinstance(inp, list):
#        # only one input! let's wrap it in a list.
#        inp = [inp]
#        model_multi_inputs_cond = False
#
#    outputs = [layer.output for layer in model.layers if
#               layer.name == layer_name or layer_name is None]  # all layer outputs
#
#    funcs = [K.function(inp + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions
#
#    if model_multi_inputs_cond:
#        list_inputs = []
#        list_inputs.extend(model_inputs)
#        list_inputs.append(0.)
#    else:
#        list_inputs = [model_inputs, 0.]
#
#    # Learning phase. 0 = Test mode (no dropout or batch normalization)
#    # layer_outputs = [func([model_inputs, 0.])[0] for func in funcs]
#    layer_outputs = [funcs(list_inputs)[0] ]
#    for layer_activations in layer_outputs:
#        activations.append(layer_activations)
#        if print_shape_only:
#            print(layer_activations.shape)
#        else:
#            print(layer_activations)
#    return activations
#
#
#def display_activations(activation_maps,disp1Example=True):
#    for layer in range(0,14):
#        if disp1Example:
#            for ex in range(0,1):
#                print('filters of layer '+str(layer)+' example '+str(ex))
#                plt.figure()
#                plt.plot(a[layer][ex])
#                plt.show()
#        else:
#            for ex in range(0,np.shape(activation_maps[layer])[0]):
#                print('filters of layer '+str(layer)+' example '+str(ex))
#                plt.figure()
#                plt.plot(a[layer][ex])
#                plt.show()
#        print('displaying filters')
#    import seaborn as sb
#    sb.set()
#    for i in range(0,14):
#        plt.figure()
#        sb.heatmap(np.transpose(a[i][0]))
#        plt.show()
#        
#test = Xtest.reshape(Xtest.shape[0],Xtest.shape[1],1)
#a = get_activations(AE,test, print_shape_only=True)  # with just one sample.
#display_activations(a)

import os
import glob
import random
import shutil


import collections
import os.path as osp

import numpy as np
from PIL import Image,ImageEnhance,ImageFilter
import scipy.io
import torch
from torch.utils import data
from torchvision import transforms as T
from torch.utils.data import DataLoader
import fcn
import scipy.misc









def resample(imgPath,lblPath):
    img = Image.open(imgPath)
    imgResized = img.resize((700, 375), Image.ANTIALIAS)
    imgResized.save('./2.JPEG')
    img = Image.open(lblPath)
    lblImmg2 = np.array(img)

    labelImg = np.array(img.resize((700, 375), Image.NEAREST))

    # Image.fromarray(labelImg).save(fp=ds, format='PNG')
    _ = fcn.utils.label2rgb(lbl=labelImg, img = np.asarray(imgResized),label_names=['b', 'R', 'T', 'G', 'A', 'S', 'w', 'W', 'B', 'H'])
    # if dstVisPath not None:
    scipy.misc.imsave('./3.png', _)


def randomResampleTrans(img,lbl):
    ratio = img.size[0]/img.size[1]
    height = random.randint(int(max(350,350/(1.5*ratio))),img.size[1])
    width = random.randint(int(max(0.7*ratio*height,350)),int(min(1.5*ratio*height+1,img.size[0])))
    imgResized = img.resize((width, height), Image.ANTIALIAS)
    labelImg = lbl.resize((width, height), Image.NEAREST)
    return imgResized,labelImg

def randomCropTrans(img,lbl,tw,th):

    w, h = img.size
    assert  w>=tw and h>=th# 确保height 和width大于256，因为256时我们要裁剪的大小
    if w == tw and h == th:
        return 0, 0, h, w

    i = random.randint(0, h - th)
    j = random.randint(0, w - tw)
    imgCrop = img.crop((j,i,j+tw,i+th))
    lblCrop = lbl.crop((j,i,j+tw,i+th))
    return imgCrop,lblCrop

def randomFlipAndRotate(img,lbl):
    if random.random()<0.5:
        img = img.transpose(Image.FLIP_LEFT_RIGHT)
        lbl = lbl.transpose(Image.FLIP_LEFT_RIGHT)
    if random.random()<0.5:
        img = img.transpose(Image.FLIP_TOP_BOTTOM)
        lbl = lbl.transpose(Image.FLIP_TOP_BOTTOM)
    if random.random() < 0.5:
        img = img.transpose(Image.ROTATE_90)
        lbl = lbl.transpose(Image.ROTATE_90)
    if random.random()<0.5:
        img = img.transpose(Image.ROTATE_180)
        lbl = lbl.transpose(Image.ROTATE_180)
    if random.random()<0.5:
        img = img.transpose(Image.ROTATE_270)
        lbl =lbl.transpose(Image.ROTATE_270)
    return img,lbl
def randomHueBrightContrastShap(img,lbl=None):
    if random.random()<0.5:
        hue = random.uniform(0.9,1.2)#控制饱和度
        img = ImageEnhance.Color(img).enhance(hue)
    if random.random() < 0.5:
        bri = random.uniform(0.8,1.2)#控制亮度
        img = ImageEnhance.Brightness(img).enhance(bri)
    if random.random() < 0.5:
        con = random.uniform(0.8,1.2)#控制对比度
        img = ImageEnhance.Contrast(img).enhance(con)
    if random.random() < 0.5:
        shap = random.uniform(0, 2)  # 控制锐度
        img = ImageEnhance.Sharpness(img).enhance(shap)

    return img,lbl

def randomColorChange(img,lbl=None):#最后在做实验查看 感觉随机在某个通道上全部减少只是一种方式，而是要随机在各个像素 各个通道上减少某个很小的值
    # imgArr = np.asarray(img)
    # rVal = random.randint(-20,20)
    # imgArr = [imgArr[i]+rVal for i in range(len(imgArr))]
    if random.random() < 0.25:
        img = img.point(lambda i:i+random.randint(-10,10))
    return img,lbl

def randomJpegCom(img,lbl=None):
    pass

def randomNoise(img,lbl=None):#PIL中没有找到怎么加噪声 所以用cv2实现
    imgArr = np.asarray(img)
    imgArr2 = imgArr.copy()
    if random.random()<0.25:
        for i in range(random.randint(1,100)):  # 添加点噪声
            temp_x = np.random.randint(0, imgArr.shape[0])
            temp_y = np.random.randint(0, imgArr.shape[1])
            imgArr2[temp_x][temp_y] = random.randint(0,255)

    return Image.fromarray(imgArr2),lbl

def randomBlur(img,lbl=None):
    if random.random()<0.1:
        radius = random.randint(1,2)
        img = img.filter(ImageFilter.GaussianBlur(radius))
    return img,lbl


def imageAug(imgPath,lblPath):
    img = Image.open(imgPath)
    lbl = Image.open(lblPath)

    img1, lbl1 = randomResampleTrans(img, lbl)
    img2, lbl2 = randomCropTrans(img1, lbl1, 300, 300)
    img3, lbl3 = randomFlipAndRotate(img2, lbl2)
    img4, lbl4 = randomHueBrightContrastShap(img3, lbl3)
    img5, lbl5 = randomColorChange(img4, lbl4)
    img6, lbl6 = randomNoise(img5, lbl5)
    img7, lbl7 = randomBlur(img6, lbl6)
    return img7,lbl7








class UAVDataClassSeg(data.Dataset):
    """
    class_names = np.array([
        'background',
        'vegetation',
        'building',
        'water',
        'road' ])
        """
    class_names = np.array([
        'background',
        'Road',
        'Tree',
        'Grass',
        'GrassAndSoil',
        'Soil',
        'withered grass',
        'Water',
        'Building',
        'GreenHouse'
    ])
    mean_bgr = np.array([104.00698793, 116.66876762, 122.67891434])


    def __init__(self, txt_path, transforms=None, train=True,test = False):#当train=True时，表示是训练集；ttrain=False且test=False,表示是验证集，test=False而test=True时，是测试集
        '''
         参数：txt_path包含了每张图片的路径和图片的标签的路径（语义分割时就是标记好的图片的路径）
             transforms表示该读取图片后，图片要进行的预处理，如果为None,则使用默认的预处理
         '''

        # 1.指定数据集，常用的方法是给定图片路径的txt文档,将他们读入一个列表
        imgs = []

        self.train = train  # 表示此次时训练集还是数据集，可能需要用来做不同的数据预处理
        self.test = test

        fh = open(txt_path, 'r')
        # 遍历整个txt文档，每张图片的路径作为list的一个元素
        for line in fh:
            line = line.rstrip()  # 去掉改行最后的回车符号
            words = line.split()
            imgs.append((words[0], words[1])if len(words)==2 else(words[0],))  # words[0]是原图片的路径，words[1]是标记好的图片的标签
        self.imgs = imgs

        # 2.指定读入图片后的预处理
        if transforms is None:

            def transforms(img, lbl = None):
                # T.Resize T.CenterCrop将图片保持纵横比缩放裁剪为同一大小，此处图片已经预先裁剪为指定的大小，所以不需要裁剪
                # T.Tensor,T.Normalize 将图片转为[0,1]的Tensor,并归一化
                if self.train == True:#训练集
                    transImg = T.Compose([
                        T.ToTensor(),
                        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])

                    transLbl = T.Compose([T.ToPILImage(),
                                          T.ToTensor()])
                    img = transImg(img)
                    lbl = transLbl(lbl).long()
                elif self.test == False:#验证集
                    transImg = T.Compose([T.ToTensor(),
                                          T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])

                    transLbl = T.Compose([T.ToPILImage(), T.ToTensor()])
                    img = transImg(img)
                    lbl = transLbl(lbl).long()
                else: #测试集
                    transImg = T.Compose([T.ToTensor(),
                                          T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
                    img = transImg(img)
                    lbl = 0
                return img, lbl  # lbl的训练集和验证集都很定时tensor,此处将他们都设计为3维的tensor[1*H*W]

            def untransforms(img, lbl = None):
                # 该trans是对已经归一化的tensor处理，得到归一化之前的Tensor
                trans = T.Compose(
                    [T.Normalize([-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225], [1 / 0.229, 1 / 0.224, 1 / 0.225])])
                imgUntrans = trans(img)
                # for i in range(img.shape[0]):
                #     imgUntrans[i] = trans(img[i])

                return ((255 * imgUntrans).type(torch.ByteTensor).transpose(0, 1).transpose(1, 2)).numpy(), \
                     None if lbl is None else (lbl.squeeze(0)).numpy()

            # 常规的数据操作：（裁剪为统一大小,可选T.scale），（数据增强，如随机裁剪等 语义分割时一般不做这个），ToTensor()后+T.Normalize
            # if self.train:  # 如果此次是训练集（训练集和验证集可能读取数据方法一样，但是预处理的过程不一样）
        self.transforms = transforms
        self.untransform = untransforms
        fh.close()



    def __getitem__(self, index):  # 该方法是给定索引或键值，返回对应的值，常用在enumerate遍历数据集时
        '''返回一张图片的验证集和测试集的数据'''
        # 从list中获取图片的路径
        img_path = self.imgs[index][0]
        lbl_path = self.imgs[index][1] if len(self.imgs[index])==2 else None




        # 读取图片，为numpy格式
        im = Image.open(img_path)


        if self.train ==True:#如果是训练集
            im,lbl =  imageAug(img_path,lbl_path)




        # load label
        if self.test !=True and lbl_path != None:
            if self.train ==False:
                lbl = Image.open(lbl_path)
            lbl = np.array(lbl, dtype=np.int32)
            lbl[lbl == 255] = -1
            lbl = (torch.from_numpy(lbl)).unsqueeze(0)
        else:
            lbl = None
        return self.transforms(im, lbl)


    def __len__(self):
        '''
        返回为数据集中所有图片的个数
        :return:
        '''
        return len(self.imgs)



#标注后的RGBA转单通道Grey 并可视化
def RGBA2Grey(srcPath,dstPath,dstVisPath = None):
    with Image.open(srcPath) as srcImage:
        imgArr = np.array(srcImage)
        labelImg = np.uint8([[imgArr[i][j][0] for j in range(len(imgArr[i]))] for i in range(len(imgArr))])
        Image .fromarray(labelImg).save(fp=dstPath,format='PNG')
        _ = fcn.utils.label2rgb(lbl=labelImg,label_names=['b','R','T','G','A','S','w','W','B','H'])
        # if dstVisPath not None:
        scipy.misc.imsave(dstVisPath,_)














if __name__ == '__main__':

    srcImg = ['0.JPG','1.JPG','2.JPG','3.JPG','DJI_0176.jpg','DJI_0179.jpg','DJI_0202.jpg','DJI_0205.jpg','DJI_0208.jpg','DJI_0209.jpg','DJI_0210.jpg','DJI_0213.jpg','DJI_0242.jpg','DJI_0262.jpg','DJI_0298.jpg','DJI_0300.jpg','DJI_0332.jpg','DJI_0179_2.jpg']
    lblImg = ['0.png','1.png','2.png','3.png','lDJI_0176.png','lDJI_0179.png','lDJI_0202.png','lDJI_0205.png','lDJI_0208.png','lDJI_0209.png','lDJI_0210.png','lDJI_0213.png','lDJI_0242.png','lDJI_0262.png','lDJI_0298.png','lDJI_0300.png','lDJI_0332.png','lDJI_0179_2.png']
    for j in range(len(srcImg)):
        for i in range(1000//len(srcImg)):
            img, lbl = imageAug('./data/' + srcImg[j], './data/' + lblImg[j])
            img.save('./data/valid/' + str(j * (1000//len(srcImg)) + i) + '.JPG')
            lbl.save('./data/valid/' + str(j * (1000//len(srcImg)) + i) + '.png')
            # Image.fromarray(labelImg).save(fp=ds, format='PNG')
            _ = fcn.utils.label2rgb(lbl=np.asarray(lbl), img=np.asarray(img),
                                    label_names=['b', 'R', 'T', 'G', 'A', 'S', 'w', 'W', 'B', 'H'])
            # if dstVisPath not None:
            scipy.misc.imsave('./data/valid/' + str(j * (1000//len(srcImg)) + i) + '_vis.JPG', _)

    RGBA2Grey('/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0176.png',
              '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0176.png', '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0176_vis.png')
    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0179.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0179.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0179_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0179_2.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0179_2.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0179_2_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0202.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0202.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0202_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0205.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0205.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0205_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0208.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0208.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0208_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0208.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0208.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0208_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0209.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0209.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0209_vis.png')
    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0210.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0210.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0210_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0213.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0213.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0213_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0242.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0242.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0242_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0262.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0262.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0262_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0298.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0298.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0298_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0300.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0300.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0300_vis.png')

    RGBA2Grey(
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/DJI_0332.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0332.png',
        '/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/抠图/ktl/grey/DJI_0332_vis.png')



    for j in range(4):
        for i in range(250):
            img,lbl = imageAug('./data/'+str(j)+'.JPG','./data/'+str(j)+'.png')
            img.save('./data/valid/'+str(j*250+i)+'.JPG')
            lbl.save('./data/valid/'+str(j*250+i)+'.png')


    RGBA2Grey('./spliceDJI0200.png',
              './dstDJI0200.png', './dstVisDJI0200.png')

    """
    img = Image.open('/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/DJI_0200.JPG')
    lbl = Image.open('/home/mlxuan/project/DeepLearning/FCN/fcn_mlx/data/dst.png')

    img,lbl = randomResampleTrans(img,lbl)
    img,lbl = randomCropTrans(img,lbl,256,256)
    img,lbl = randomFlipAndRotate(img,lbl)
    img,lbl = randomHueBrightContrastShap(img,lbl)
    img,lbl = randomColorChange(img,lbl)
    img,lbl = randomNoise(img,lbl)
    img,lbl = randomBlur(img,lbl)

    img.save('./1.png')
    lbl.save('2.png')
    resample('./1.png','./2.png')
    _ = fcn.utils.label2rgb(lbl=np.asarray(Image.open('./2.png')), img=np.asarray(Image.open('./1.png')),
                            label_names=['b', 'R', 'T', 'G', 'A', 'S', 'w', 'W', 'B', 'H'])
    # if dstVisPath not None:
    scipy.misc.imsave('./3.png', _)

    resample('/home/mlxuan/project/DeepLearning/data/image_Segmentation/js-segment-annotator-master/data/images/DJI_0200.JPG',
             '/home/mlxuan/project/DeepLearning/FCN/fcn_mlx/data/dst.png')


    RGBA2Grey('/home/mlxuan/project/DeepLearning/FCN/fcn_mlx/utils/PicOperation/splice.png',
              './dst.png','./dstVis.png')
    """
    """
    测试数据集类是否正确，
    初始化
    遍历
    测试其他函数(untransform)
    """
    """
    visualizations = []
    trainDataset = UAVDataClassSeg(txt_path = '/home/mlxuan/project/DeepLearning/data/image_Segmentation/train/trainFull.txt')
    trainloader = DataLoader(trainDataset, batch_size=8, shuffle=True, drop_last=True)
    for batch_idx, (data, target) in enumerate(trainloader):
        for img, lt in zip(data, target):
            img, lt = trainDataset.untransform(img, lt)
            if len(visualizations) < 15:
                 viz = fcn.utils.visualize_segmentation(lbl_pred=lt, lbl_true=lt, img=img, n_class=5)
                 visualizations.append(viz)

    scipy.misc.imsave('./visualization_viz.jpg', fcn.utils.get_tile_image(visualizations))
    """
    """
    测试test集的数据是否可以
    """
    trainDataset = UAVDataClassSeg(txt_path = '/home/mlxuan/project/DeepLearning/data/image_Segmentation/dataAug/valid/validFull.txt',train=False,test=False)
    trainloader = DataLoader(trainDataset, batch_size=1, shuffle=True, drop_last=True)
    for batch_idx, (data, target) in enumerate(trainloader):
        img, lt = trainDataset.untransform(data[0],target[0])#data中包含的图片的数目由Dataloader的batch_size决定，data[0]表示第一张图片
        Image.fromarray(img).save('./1.jpg', 'JPEG')
        _ = fcn.utils.label2rgb(lbl=(np.asarray(lt)), img=np.asarray(img),
                                label_names=['b', 'R', 'T', 'G', 'A', 'S', 'w', 'W', 'B', 'H'])
        # if dstVisPath not None:
        scipy.misc.imsave('./2.png', _)
# import the necessary packages
import os, sys
import cv2
import tkFileDialog
import utility.util as util
import math
import SIFTquery as sift

from Tkinter import *
from colorhistogram.colordescriptor import ColorDescriptor
from colorhistogram.searcher import Searcher
from PIL import Image, ImageTk
from texttags.text_tags import TextTags

class UI_class:
    def __init__(self, master):
        self.master = master
        self.database_image_ids = util.get_image_ids(util.database_path)
        self.limit = 16
        topframe = Frame(self.master, padx=240)
        topframe.pack()

        #query and result img frame
        self.query_img_frame = 0
        self.result_img_frame = 0

        #checkbox variables
        self.color_var = IntVar()
        self.deep_learning_var = IntVar()
        self.visual_words_var = IntVar()
        self.text_tags_var = IntVar()

        #hyper parameter variables
        self.color_parameter = StringVar()
        self.deep_learning_parameter = StringVar()
        self.visual_words_parameter = StringVar()
        self.text_tags_parameter = StringVar()

        #Buttons
        topspace = Label(topframe).grid(row=0, columnspan=2)
        self.bbutton= Button(topframe, text=" Choose an image ", command=self.browse_query_img)
        self.bbutton.grid(row=1, column=2)
        self.cbutton = Button(topframe, text=" Search ", command=self.show_results_imgs)
        self.cbutton.grid(row=1, column=3)

        #CheckBoxes
        self.cbox_color = Checkbutton(topframe, text="Color histogram", variable=self.color_var, onvalue=1, offvalue=0)
        self.cbox_color.grid(row=2, column=1)
        self.cbox_deep_learning = Checkbutton(topframe, text="Deep learning", variable=self.deep_learning_var, onvalue=1, offvalue=0)
        self.cbox_deep_learning.grid(row=2, column=2)
        self.cbox_visual_words = Checkbutton(topframe, text="Visual Words", variable=self.visual_words_var, onvalue=1, offvalue=0)
        self.cbox_visual_words.grid(row=2, column=3)
        self.cbox_text_tags = Checkbutton(topframe, text="Text tags", variable=self.text_tags_var, onvalue=1, offvalue=0)
        self.cbox_text_tags.grid(row=2, column=4)

        #Parameter labels
        self.pbox_color = Entry(topframe, textvariable=self.color_parameter, width=10)
        self.pbox_color.grid(row=3, column=1)
        self.pbox_deep_learning = Entry(topframe, textvariable=self.deep_learning_parameter, width=10)
        self.pbox_deep_learning.grid(row=3, column=2)
        self.pbox_visual_words = Entry(topframe, textvariable=self.visual_words_parameter, width=10)
        self.pbox_visual_words.grid(row=3, column=3)
        self.pbox_text_tags = Entry(topframe, textvariable=self.text_tags_parameter, width=10)
        self.pbox_text_tags.grid(row=3, column=4)

        downspace = Label(topframe).grid(row=5, columnspan=4)

        #Feature objects
        self.color_hist = Searcher("./color_hist.csv")
        if os.name == 'posix':
            from deeplearning.deep_learning import Deep_Learning
            self.deep_learning = Deep_Learning("./deep_learning.csv")
        self.text_tag = TextTags("./tag_text_database.csv", "./tag_text_query.csv")

        self.master.mainloop()

    def browse_query_img(self):
        if (self.query_img_frame != 0):
            self.query_img_frame.destroy()

        if (self.result_img_frame != 0):
            self.result_img_frame.destroy()

        self.query_img_frame = Frame(self.master)
        self.query_img_frame.pack()
        from tkFileDialog import askopenfilename
        self.filename = tkFileDialog.askopenfile(title='Choose an Image File').name

        # find query tags
        query_tags = []
        if self.text_tag.return_query_tags(self.filename):
            query_tags = self.text_tag.return_query_tags(os.path.abspath(self.filename))

        # show query image
        image_file = Image.open(self.filename)
        resized = image_file.resize((100, 100), Image.ANTIALIAS)
        im = ImageTk.PhotoImage(resized)
        image_label = Label(self.query_img_frame, image=im)

        # show query tags
        if query_tags:
            image_tags = Label(self.query_img_frame, text="This image has query tags!")
            image_tags.pack()
        else:
            image_tags = Label(self.query_img_frame, text="This image has no query tags!\n\n Selecting text tags search will not result in a search in text tags")
            image_tags.pack()

        image_label.pack()


        self.query_img_frame.mainloop()

    def show_results_imgs(self):
        if (self.result_img_frame != 0):
            self.result_img_frame.destroy()
        
        self.result_img_frame = Frame(self.master)
        self.result_img_frame.pack()

        results = self.get_search_results()

        # show result pictures
        COLUMNS = 4
        image_count = 0
        image_paths = util.get_image_group_paths(util.database_path)
       
        for (score, resultID) in results:
            # load the result image and display it
            if (score >= 0):
                image_count += 1
                r, c = divmod(image_count - 1, COLUMNS)
                for image in image_paths:
                    if os.path.exists(image + "/" + resultID):
                        im = Image.open(image + "/" + resultID)
                
                resized = im.resize((100, 100), Image.ANTIALIAS)
                tkimage = ImageTk.PhotoImage(resized)
                myvar = Label(self.result_img_frame, image=tkimage)
                myvar.image = tkimage
                myvar.grid(row=r, column=c)
   

        self.result_img_frame.mainloop()

    def check_hyper_parameters(self):
        # perform the search
        # feature 1: color histogram
        # feature 2: deep learning
        # feature 3: text tag
        # feature 4: visual words
        self.hyper_parameter = [0.0, 0.0, 0.0, 0.0]

        if self.color_parameter.get() and self.color_var.get() == 1:
            self.hyper_parameter[0] = float(self.color_parameter.get())
        if self.deep_learning_parameter.get() and self.deep_learning_var.get() == 1:
            self.hyper_parameter[1] = float(self.deep_learning_parameter.get())
        if self.text_tags_parameter.get() and self.text_tags_var.get() == 1:
            self.hyper_parameter[2] = float(self.text_tags_parameter.get())
        if self.visual_words_parameter.get() and self.visual_words_var.get() == 1:
            self.hyper_parameter[3] = float(self.visual_words_parameter.get())

        # if user defined values does not add up to 1, use default values
        if (math.fabs(1 - (self.hyper_parameter[0] + self.hyper_parameter[1] + self.hyper_parameter[2] + self.hyper_parameter[3])) > 0.0000001):     
            self.hyper_parameter[0] = 0.08
            self.hyper_parameter[1] = 0.70
            self.hyper_parameter[2] = 0.19
            self.hyper_parameter[3] = 0.03

    def get_search_results(self):
        results = {}
       
        color_hist_dict = {}
        deep_learning_dict = {}
        text_tags_dict = {}
        visual_words_dict = {}

        self.check_hyper_parameters()
        
        # do dictionary extraction here
        if (self.color_var.get() == 1):
             # process query image to feature vector
            # initialize the image descriptor
            cd = ColorDescriptor((8, 12, 3))
            # load the query image and describe it
            query = cv2.imread(self.filename)
            self.queryfeatures = cd.describe(query)
            color_hist_dict = self.color_hist.search(self.queryfeatures)
        
        if (self.deep_learning_var.get() == 1):
            deep_learning_dict = self.deep_learning.search_deeplearning(os.path.abspath(self.filename))

        # checkbox must be checked and there must be query tags before search is done
        if (self.text_tags_var.get() == 1 and self.text_tag.return_query_tags(self.filename)):
            text_tags_dict = self.text_tag.tags_search(self.filename)

        # run visual words
        if (self.visual_words_var.get() == 1):
            visual_words_dict = sift.newQuery(self.filename)

        #combine feature vectors here in a results array
        # if 0 should, should still be shown since it means they are exactly the same
        # if -1, then should be removed from array
        for name in self.database_image_ids:
            results[name] = -1
            if color_hist_dict:
                if results[name] < 0:
                    results[name] = 0
                results[name] += self.hyper_parameter[0] * color_hist_dict[name]
            if deep_learning_dict and (name in deep_learning_dict):
                if results[name] < 0:
                    results[name] = 0
                results[name] += self.hyper_parameter[1] * deep_learning_dict[name]
            if text_tags_dict:
                if results[name] < 0 and (name in results):
                    results[name] = 0
                results[name] += self.hyper_parameter[2] * text_tags_dict[name]
            if visual_words_dict:
                if results[name] < 0 and (name in results):
                    results[name] = 0
                results[name] += self.hyper_parameter[3] * visual_words_dict[name]


        #sort results and show only top 16
        if (len(results) > 0):
            results = sorted([(v, k) for (k, v) in results.items()])
            results = results[:self.limit]
        
        # makes sure that any element which do not have a valid score is removed from results
        for element in results:
            if element[0] < 0:
                results.remove(element)

        return results

    # return image results from search
    def get_image_search_results(self, file_path, color_var=0, deep_learning_var=0, text_tags_var=0, visual_words_var=0):
        self.filename = file_path
        self.color_var.set(color_var)
        self.deep_learning_var.set(deep_learning_var)
        self.text_tags_var.set(text_tags_var)
        self.visual_words_var.set(visual_words_var)
        return self.get_search_results()
        

root = Tk()
window = UI_class(root)from src.deep_learning.pytorch.models.context_model import ContextModel
from src.deep_learning.pytorch.models.simple_rnn import SimpleRNN
from src.deep_learning.pytorch.models.chrono_net import ChronoNet
from src.deep_learning.pytorch.models.conv_rnn_model import ConvRNN
from src.deep_learning.pytorch.models.fully_connected import FCNet
from src.deep_learning.pytorch.models.split_rnn import SplitRNN
from src.deep_learning.pytorch.models.shallow_fbcsp_net import ShallowFBCSPNet
from src.deep_learning.pytorch.models.shallow_fbcsp_net_multi import ShallowFBCSPNetMulti
from src.deep_learning.pytorch.models.tcn_model import TemporalConvNet
from src.deep_learning.pytorch.models.separate_channel_rnn import SeparateChannelRNN
from src.deep_learning.pytorch.models.separate_tcn_model import SeparateTemporalConvNet
from flask import Flask, render_template, request
from hamlish_jinja import HamlishExtension
from werkzeug import ImmutableDict
#from flask_sqlalchemy import SQLAlchemy
app = Flask(__name__)

json = {
	"id": "http://arxiv.org/abs/1805.08355v1",
	"guidislink": True,
	"updated": "2018-05-22T02:12:33Z",
	"updated_parsed": [
		2018,
		5,
		22,
		2,
		12,
		33,
		1,
		142,
		0
	],
	"published": "2018-05-22T02:12:33Z",
	"published_parsed": [
		2018,
		5,
		22,
		2,
		12,
		33,
		1,
		142,
		0
	],
	"title": "Opening the black box of deep learning",
	"title_detail": {
		"type": "text/plain",
		"language": None,
		"base": "http://export.arxiv.org/api/query?search_query=deep+learning&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending",
		"value": "Opening the black box of deep learning"
	},
	"summary": "The great success of deep learning shows that its technology contains\nprofound truth, and understanding its internal mechanism not only has important\nimplications for the development of its technology and effective application in\nvarious fields, but also provides meaningful insights into the understanding of\nhuman brain mechanism. At present, most of the theoretical research on deep\nlearning is based on mathematics. This dissertation proposes that the neural\nnetwork of deep learning is a physical system, examines deep learning from\nthree different perspectives: microscopic, macroscopic, and physical world\nviews, answers multiple theoretical puzzles in deep learning by using physics\nprinciples. For example, from the perspective of quantum mechanics and\nstatistical physics, this dissertation presents the calculation methods for\nconvolution calculation, pooling, normalization, and Restricted Boltzmann\nMachine, as well as the selection of cost functions, explains why deep learning\nmust be deep, what characteristics are learned in deep learning, why\nConvolutional Neural Networks do not have to be trained layer by layer, and the\nlimitations of deep learning, etc., and proposes the theoretical direction and\nbasis for the further development of deep learning now and in the future. The\nbrilliance of physics flashes in deep learning, we try to establish the deep\nlearning technology based on the scientific theory of physics.",
	"summary_detail": {
		"type": "text/plain",
		"language": None,
		"base": "http://export.arxiv.org/api/query?search_query=deep+learning&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending",
		"value": "The great success of deep learning shows that its technology contains\nprofound truth, and understanding its internal mechanism not only has important\nimplications for the development of its technology and effective application in\nvarious fields, but also provides meaningful insights into the understanding of\nhuman brain mechanism. At present, most of the theoretical research on deep\nlearning is based on mathematics. This dissertation proposes that the neural\nnetwork of deep learning is a physical system, examines deep learning from\nthree different perspectives: microscopic, macroscopic, and physical world\nviews, answers multiple theoretical puzzles in deep learning by using physics\nprinciples. For example, from the perspective of quantum mechanics and\nstatistical physics, this dissertation presents the calculation methods for\nconvolution calculation, pooling, normalization, and Restricted Boltzmann\nMachine, as well as the selection of cost functions, explains why deep learning\nmust be deep, what characteristics are learned in deep learning, why\nConvolutional Neural Networks do not have to be trained layer by layer, and the\nlimitations of deep learning, etc., and proposes the theoretical direction and\nbasis for the further development of deep learning now and in the future. The\nbrilliance of physics flashes in deep learning, we try to establish the deep\nlearning technology based on the scientific theory of physics."
	},
	"authors": [
		"Dian Lei",
		"Xiaoxiao Chen",
		"Jianfei Zhao"
	],
	"author_detail": {
		"name": "Jianfei Zhao"
	},
	"author": "Jianfei Zhao",
	"links": [
		{
			"href": "http://arxiv.org/abs/1805.08355v1",
			"rel": "alternate",
			"type": "text/html"
		},
		{
			"title": "pdf",
			"href": "http://arxiv.org/pdf/1805.08355v1",
			"rel": "related",
			"type": "application/pdf"
		}
	],
	"arxiv_primary_category": {
		"term": "cs.LG",
		"scheme": "http://arxiv.org/schemas/atom"
	},
	"tags": [
		{
			"term": "cs.LG",
			"scheme": "http://arxiv.org/schemas/atom",
			"label": None
		},
		{
			"term": "stat.ML",
			"scheme": "http://arxiv.org/schemas/atom",
			"label": None
		}
	],
	"pdf_url": "http://arxiv.org/pdf/1805.08355v1",
	"affiliation": "None",
	"arxiv_url": "http://arxiv.org/abs/1805.08355v1",
	"arxiv_comment": None,
	"journal_reference": None,
	"doi": None
}

@app.route('/')
def start():
	return render_template('form.html')

@app.route('/form')
def form( ):
	return render_template('form.html')

@app.route('/search', methods=['POST', 'GET'])
def search():
	if request.method == 'POST':
		print(request)
		result = request.form
		print(request)
		return render_template('json_view.html',search_words=request.form['Name'], results_json=json)
#		return render_template('json_view.html',search_words=request.form['Name'])
#		return render_template('search_result.html', search_words=request.form['Name'])

if __name__ == '__main__':
	app.run(host='0.0.0.0', debug=True)
'''
Created on Dec 5, 2016

@author: urishaham
'''

import os.path
from Calibration_Util import DataHandler as dh 
from Calibration_Util import FileIO as io
import numpy as np
import matplotlib
matplotlib.use('TkAgg')
import CostFunctions as cf
from sklearn import decomposition
from keras import backend as K
import ScatterHist as sh
from numpy import genfromtxt
import sklearn.preprocessing as prep
from keras.models import load_model
from keras import initializations
from keras.layers.normalization import BatchNormalization
from keras.layers import Input, Dense, merge, Activation
from keras.regularizers import l2
from keras.models import Model


# configuration hyper parameters
denoise = True # whether or not to train a denoising autoencoder to remover the zeros

######################
###### get data ######
######################
# we load two CyTOF samples 

data1 = 'person2_baseline'
data2 = 'person2_3month'

if data1 =='person1_baseline':
    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_baseline.csv')
    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_baseline.csv')
    sourceLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_baseline_label.csv')
    targetLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_baseline_label.csv')
    autoencoder1 =  load_model(os.path.join(io.DeepLearningRoot(),'savedModels/person1_baseline_DAE.h5'))  
if data1 =='person2_baseline':
    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_baseline.csv')
    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_baseline.csv')
    sourceLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_baseline_label.csv')
    targetLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_baseline_label.csv')
    autoencoder1 =  load_model(os.path.join(io.DeepLearningRoot(),'savedModels/person2_baseline_DAE.h5'))   
if data1 =='person1_3month':
    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_3month.csv')
    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_3month.csv')
    sourceLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_3month_label.csv')
    targetLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_3month_label.csv')
    autoencoder1 =  load_model(os.path.join(io.DeepLearningRoot(),'savedModels/person1_3month_DAE.h5'))  
if data1 =='person2_3month':
    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_3month.csv')
    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_3month.csv')
    sourceLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_3month_label.csv')
    targetLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_3month_label.csv')
    autoencoder1 =  load_model(os.path.join(io.DeepLearningRoot(),'savedModels/person2_3month_DAE.h5'))  
   
source1 = genfromtxt(sourcePath, delimiter=',', skip_header=0)
target1 = genfromtxt(targetPath, delimiter=',', skip_header=0)
sourceLabels1 = genfromtxt(sourceLabelPath, delimiter=',', skip_header=0)
targetLabels1 = genfromtxt(targetLabelPath, delimiter=',', skip_header=0)


if data2 =='person1_baseline':
    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_baseline.csv')
    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_baseline.csv')
    sourceLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_baseline_label.csv')
    targetLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_baseline_label.csv')
    autoencoder2 =  load_model(os.path.join(io.DeepLearningRoot(),'savedModels/person1_baseline_DAE.h5'))   
if data2 =='person2_baseline':
    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_baseline.csv')
    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_baseline.csv')
    sourceLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_baseline_label.csv')
    targetLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_baseline_label.csv')
    autoencoder2 =  load_model(os.path.join(io.DeepLearningRoot(),'savedModels/person2_baseline_DAE.h5'))   
if data2 =='person1_3month':
    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_3month.csv')
    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_3month.csv')
    sourceLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day1_3month_label.csv')
    targetLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person1Day2_3month_label.csv')
    autoencoder2 =  load_model(os.path.join(io.DeepLearningRoot(),'savedModels/person1_3month_DAE.h5'))   
if data2 =='person2_3month':
    sourcePath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_3month.csv')
    targetPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_3month.csv')
    sourceLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day1_3month_label.csv')
    targetLabelPath = os.path.join(io.DeepLearningRoot(),'Data/Person2Day2_3month_label.csv')
    autoencoder2 =  load_model(os.path.join(io.DeepLearningRoot(),'savedModels/person2_3month_DAE.h5'))  
   
source2 = genfromtxt(sourcePath, delimiter=',', skip_header=0)
target2 = genfromtxt(targetPath, delimiter=',', skip_header=0)
sourceLabels2 = genfromtxt(sourceLabelPath, delimiter=',', skip_header=0)
targetLabels2 = genfromtxt(targetLabelPath, delimiter=',', skip_header=0)


# pre-process data: log transformation, a standard practice with CyTOF data
target1 = dh.preProcessCytofData(target1)
source1 = dh.preProcessCytofData(source1) 
target2 = dh.preProcessCytofData(target2)
source2 = dh.preProcessCytofData(source2) 

if denoise:
    source1 = autoencoder1.predict(source1)
    target1 = autoencoder1.predict(target1)
    source2 = autoencoder2.predict(source2)
    target2 = autoencoder2.predict(target2)

# rescale source to have zero mean and unit variance
# apply same transformation to the target
preprocessor1 = prep.StandardScaler().fit(source1)
source1 = preprocessor1.transform(source1) 
target1 = preprocessor1.transform(target1)  

preprocessor2 = prep.StandardScaler().fit(source2)
source2 = preprocessor2.transform(source2) 
target2 = preprocessor2.transform(target2)    

##############################
######## load ResNets ########
##############################
mmdNetLayerSizes = [25, 25]
inputDim = 25
l2_penalty = 1e-2

def my_init (shape, name = None):
    return initializations.normal(shape, scale=.1e-4, name=name)
setattr(initializations, 'my_init', my_init)

calibInput_1 = Input(shape=(inputDim,))
block1_bn1_1 = BatchNormalization()(calibInput_1)
block1_a1_1 = Activation('relu')(block1_bn1_1)
block1_w1_1 = Dense(mmdNetLayerSizes[0], activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block1_a1_1) 
block1_bn2_1 = BatchNormalization()(block1_w1_1)
block1_a2_1 = Activation('relu')(block1_bn2_1)
block1_w2_1 = Dense(inputDim, activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block1_a2_1) 
block1_output_1 = merge([block1_w2_1, calibInput_1], mode = 'sum')
block2_bn1_1 = BatchNormalization()(block1_output_1)
block2_a1_1 = Activation('relu')(block2_bn1_1)
block2_w1_1 = Dense(mmdNetLayerSizes[1], activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block2_a1_1) 
block2_bn2_1 = BatchNormalization()(block2_w1_1)
block2_a2_1 = Activation('relu')(block2_bn2_1)
block2_w2_1 = Dense(inputDim, activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block2_a2_1) 
block2_output_1 = merge([block2_w2_1, block1_output_1], mode = 'sum')
block3_bn1_1 = BatchNormalization()(block2_output_1)
block3_a1_1 = Activation('relu')(block3_bn1_1)
block3_w1_1 = Dense(mmdNetLayerSizes[1], activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block3_a1_1) 
block3_bn2_1 = BatchNormalization()(block3_w1_1)
block3_a2_1 = Activation('relu')(block3_bn2_1)
block3_w2_1 = Dense(inputDim, activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block3_a2_1) 
block3_output_1 = merge([block3_w2_1, block2_output_1], mode = 'sum')

ResNet1 = Model(input=calibInput_1, output=block3_output_1)
ResNet1.compile(optimizer='rmsprop', loss=lambda y_true,y_pred: 
               cf.MMD(block3_output_1,target1,MMDTargetValidation_split=0.1).KerasCost(y_true,y_pred))

if data1 =='person1_baseline': 
    ResNet1.load_weights(os.path.join(io.DeepLearningRoot(),'savedModels/person1_baseline_ResNet_weights.h5'))  
if data1 =='person2_baseline': 
    ResNet1.load_weights(os.path.join(io.DeepLearningRoot(),'savedModels/person2_baseline_ResNet_weights.h5'))  
if data1 =='person1_3month': 
    ResNet1.load_weights(os.path.join(io.DeepLearningRoot(),'savedModels/person1_3month_ResNet_weights.h5'))  
if data1 =='person2_3month':  
    ResNet1.load_weights(os.path.join(io.DeepLearningRoot(),'savedModels/person2_3month_ResNet_weights.h5'))  

calibInput_2 = Input(shape=(inputDim,))
block1_bn1_2 = BatchNormalization()(calibInput_2)
block1_a1_2 = Activation('relu')(block1_bn1_2)
block1_w1_2 = Dense(mmdNetLayerSizes[0], activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block1_a1_2) 
block1_bn2_2 = BatchNormalization()(block1_w1_2)
block1_a2_2 = Activation('relu')(block1_bn2_2)
block1_w2_2 = Dense(inputDim, activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block1_a2_2) 
block1_output_2 = merge([block1_w2_2, calibInput_2], mode = 'sum')
block2_bn1_2 = BatchNormalization()(block1_output_2)
block2_a1_2 = Activation('relu')(block2_bn1_2)
block2_w1_2 = Dense(mmdNetLayerSizes[1], activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block2_a1_2) 
block2_bn2_2 = BatchNormalization()(block2_w1_2)
block2_a2_2 = Activation('relu')(block2_bn2_2)
block2_w2_2 = Dense(inputDim, activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block2_a2_2) 
block2_output_2 = merge([block2_w2_2, block1_output_2], mode = 'sum')
block3_bn1_2 = BatchNormalization()(block2_output_2)
block3_a1_2 = Activation('relu')(block3_bn1_2)
block3_w1_2 = Dense(mmdNetLayerSizes[1], activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block3_a1_2) 
block3_bn2_2 = BatchNormalization()(block3_w1_2)
block3_a2_2 = Activation('relu')(block3_bn2_2)
block3_w2_2 = Dense(inputDim, activation='linear',W_regularizer=l2(l2_penalty), init = my_init)(block3_a2_2) 
block3_output_2 = merge([block3_w2_2, block2_output_2], mode = 'sum')

ResNet2 = Model(input=calibInput_2, output=block3_output_2)
ResNet2.compile(optimizer='rmsprop', loss=lambda y_true,y_pred: 
               cf.MMD(block3_output_2,target2,MMDTargetValidation_split=0.1).KerasCost(y_true,y_pred))

if data2 =='person1_baseline': 
    ResNet2.load_weights(os.path.join(io.DeepLearningRoot(),'savedModels/person1_baseline_ResNet_weights.h5'))  
if data2 =='person2_baseline': 
    ResNet2.load_weights(os.path.join(io.DeepLearningRoot(),'savedModels/person2_baseline_ResNet_weights.h5'))  
if data2 =='person1_3month': 
    ResNet2.load_weights(os.path.join(io.DeepLearningRoot(),'savedModels/person1_3month_ResNet_weights.h5'))  
if data2 =='person2_3month':  
    ResNet2.load_weights(os.path.join(io.DeepLearningRoot(),'savedModels/person2_3month_ResNet_weights.h5'))  

###############################################
######### Train vertical nets ########
###############################################
'''
patient1_source -> patient2_source


patient2_target -> patient1_target
'''
###############################################
######## evaluate generalization ability ######
###############################################

calibration_11 =  ResNet1.predict(source1)
calibration_22 =  ResNet2.predict(source2)
calibration_12 =  ResNet1.predict(source2)
calibration_21 =  ResNet2.predict(source1)

# our hope is that:
#     calibration_b1 is as similar to newTarget1 as calibration_a1
#     calibration_a2 is as similar to newTarget2 as calibration_b2

##################################### qualitative evaluation: PCA #####################################
pca = decomposition.PCA(n_components=2)
pca.fit(target1)
target_sample_pca = np.dot(target1, pca.components_[[0,1]].transpose())
other_target_pca = np.dot(target2, pca.components_[[0,1]].transpose())
projection_before = np.dot(source1, pca.components_[[0,1]].transpose())
projection_org = np.dot(calibration_11, pca.components_[[0,1]].transpose())
projection_cross = np.dot(calibration_21, pca.components_[[0,1]].transpose())

pc1 = 0
pc2 = 1
axis1 = 'PC'+str(pc1)
axis2 = 'PC'+str(pc2)
sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_before[:,pc1], projection_before[:,pc2], axis1, axis2)
sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_org[:,pc1], projection_org[:,pc2], axis1, axis2)
sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_cross[:,pc1], projection_cross[:,pc2], axis1, axis2)
sh.scatterHist(other_target_pca[:,pc1], other_target_pca[:,pc2], projection_cross[:,pc1], projection_cross[:,pc2], axis1, axis2)


pca = decomposition.PCA(n_components=2)
pca.fit(target2)
target_sample_pca = np.dot(target2, pca.components_[[0,1]].transpose())
other_target_pca = np.dot(target1, pca.components_[[0,1]].transpose())
projection_before = np.dot(source2, pca.components_[[0,1]].transpose())
projection_org = np.dot(calibration_22, pca.components_[[0,1]].transpose())
projection_cross = np.dot(calibration_12, pca.components_[[0,1]].transpose())

pc1 = 0
pc2 = 1
axis1 = 'PC'+str(pc1)
axis2 = 'PC'+str(pc2)
sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_before[:,pc1], projection_before[:,pc2], axis1, axis2)
sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_org[:,pc1], projection_org[:,pc2], axis1, axis2)
sh.scatterHist(target_sample_pca[:,pc1], target_sample_pca[:,pc2], projection_cross[:,pc1], projection_cross[:,pc2], axis1, axis2)
sh.scatterHist(other_target_pca[:,pc1], other_target_pca[:,pc2], projection_cross[:,pc1], projection_cross[:,pc2], axis1, axis2)

##################################### quantitative evaluation: MMD #####################################
# MMD with the scales used for training 
sourceInds = np.random.randint(low=0, high = source1.shape[0], size = 1000)
maxTargetInd = np.min([len(target1), len(target2)])
targetInds = np.random.randint(low=0, high = maxTargetInd, size = 1000)


mmd_before1 = K.eval(cf.MMD(source1,target1).cost(K.variable(value=source1[sourceInds]), K.variable(value=target1[targetInds])))
mmd_before2 = K.eval(cf.MMD(source1,target1).cost(K.variable(value=source2[sourceInds]), K.variable(value=target2[targetInds])))
mmd_after_11 = K.eval(cf.MMD(source1,target1).cost(K.variable(value=calibration_11[sourceInds]), K.variable(value=target1[targetInds])))
mmd_after_22 = K.eval(cf.MMD(source1,target1).cost(K.variable(value=calibration_22[sourceInds]), K.variable(value=target2[targetInds])))

mmd_after_12 = K.eval(cf.MMD(source1,target1).cost(K.variable(value=calibration_21[sourceInds]), K.variable(value=target1[targetInds])))
mmd_after_21 = K.eval(cf.MMD(source2,target2).cost(K.variable(value=calibration_12[sourceInds]), K.variable(value=target2[targetInds])))


print('patient 1: MMD to target1 before calibration:        ' + str(mmd_before1))
print('patient 1: MMD to target1 after calibration (net 1): ' + str(mmd_after_11))
print('patient 1: MMD to target1 after calibration (net 2): ' + str(mmd_after_21))
print('patient 2: MMD to target2 before calibration:        ' + str(mmd_before2))
print('patient 2: MMD to target2 after calibration (net 2): ' + str(mmd_after_22))
print('patient 2: MMD to target2 after calibration (net 1): ' + str(mmd_after_12))

'''
p1_base, p1_3month:
patient 1: MMD to target1 before calibration:        0.702666
patient 1: MMD to target1 after calibration (net 1): 0.301217
patient 1: MMD to target1 after calibration (net 2): 0.630393
patient 2: MMD to target2 before calibration:        0.841727
patient 2: MMD to target2 after calibration (net 2): 0.46446
patient 2: MMD to target2 after calibration (net 1): 0.581634




p2_base, p2_3month:






p1_base, p2_base
'''#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Sun Apr  8 09:28:30 2018

@author: lixiaodan
"""

import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import numpy as np
from keras.utils import np_utils
import deep_learning_models
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import confusion_matrix

from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
import plot_precision_recall

wikidata = pd.read_csv('/Users/lixiaodan/Desktop/research/result_3rd_paper/wikipedia_project/dataset/wikipedia_with_all_features.csv')
#wikidata = pd.read_csv('/Users/lixiaodan/Desktop/wikipedia_project/dataset/wikipedia_without_network.csv')
#wikidata = pd.read_csv('/Users/lixiaodan/Desktop/wikipedia_project/dataset/wikipedia_without_hist_net.csv')
colnames = list(wikidata)
class_names = np.array([['Good'], ['Medium'], ['Low']])
labels = wikidata["page_class"]

### good is possitive while bad is negative
for i in range(labels.shape[0]):
    if labels[i] == 'FA' or labels[i] == 'AC':
        labels.loc[i] = 0
    elif labels[i] == 'GA' or labels[i] == 'BC':
        labels.loc[i] = 1
    elif labels[i] == 'ST' or labels[i] == 'SB':
        labels.loc[i] = 2

labels = labels.convert_objects(convert_numeric=True)
onehotlabels = np_utils.to_categorical(labels)

### preprocess features
features = wikidata.iloc[:, 1:]
min_max_scaler = preprocessing.MinMaxScaler()
features_minmax = min_max_scaler.fit_transform(features)

### split data into training set and label set
X_train, X_test, y_train, y_test = train_test_split(features_minmax, onehotlabels, test_size=0.4, random_state=42)
#X_train, X_test, y_train, y_test = train_test_split(features_minmax, labels, test_size=0.4, random_state=42)

### adjust the dataset dimension
# reshape X to be [samples, time steps, features]
X_train_LSTM = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))
X_test_LSTM = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))

### input for CNN
X_train_CNN = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test_CNN = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

### create the deep learning models
epochs = 15
batch_size = 195 #195 best now #190 # 100 # 250
dropoutRate = 0.2
"""
epochs = 200
batch_size = 20
dropoutRate = 0.3
"""
y_test_re = np.argmax(y_test, axis=1)
accuracies = list()
precisions = list()
Fs = list()
TNRs = list()
recalls = list()
transformed_y = deep_learning_models.transformResult(y_test)
transformed_y_train = deep_learning_models.transformResult(y_train) ### one dimention list

### Bidirectional LSTM 
#start_time0 = time.clock()
model0, hist0 = deep_learning_models.Bidirectional_LSTM(X_train_LSTM, y_train, X_test_LSTM, y_test, batch_size, epochs)
prediction0 = model0.predict(X_test_LSTM)
transformed_pre0 = deep_learning_models.transformResult(prediction0)
#end_time0 = time.clock()
#Bi_LSTM_performance = end_time0 - start_time0
prediction0_re = np.argmax(prediction0, axis=1)
Bidirectional_LSTM_accuracy, bi_precision, bi_recall, bi_F1, bi_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre0, transformed_y)
keys = hist0.history.keys()
#print(keys)
print("Precision for bidirectional LSTM")
print(Bidirectional_LSTM_accuracy)
print(bi_precision)
print(bi_recall)
print(bi_fbeta)
print(bi_F1)
accuracy_pair = list()
accuracy_pair.append("bidirectional LSTM")
accuracy_pair.append(Bidirectional_LSTM_accuracy)
accuracies.append(accuracy_pair)
## get Confusion matrix"
cnf_matrix_0 = confusion_matrix(transformed_y, transformed_pre0)
plt.figure()
deep_learning_models.plot_confusion_matrix(cnf_matrix_0, classes=class_names, normalize=True,
                      title='Confusion matrix for bidirectional LSTM accuracy')
plt.savefig('Confusion matrix for bidirectional LSTM accuracy.png', dpi=300)
plt.show()

plot_precision_recall.plot_average_precision(y_test, prediction0, 'bi-LSTM')

#start_time1 = time.clock()
model1, hist1 = deep_learning_models.basic_LSTM(X_train_LSTM, y_train, X_test_LSTM, y_test, batch_size, epochs)
prediction1 = model1.predict(X_test_LSTM)
transformed_pre1 = deep_learning_models.transformResult(prediction1)
#end_time1 = time.clock()
#basic_LSTM_performance = end_time1 - start_time1
prediction1_re = np.argmax(prediction1, axis=1)
basic_LSTM_accuracy, LSTM_precision, LSTM_recall, LSTM_F1, LSTM_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre1, transformed_y)
keys = hist1.history.keys()
#print(keys)
print("Precision for basic LSTM")
print(basic_LSTM_accuracy)
print(LSTM_precision)
print(LSTM_recall)
print(LSTM_fbeta)
print(LSTM_F1)
accuracy_pair = list()
accuracy_pair.append("basic LSTM")
accuracy_pair.append(basic_LSTM_accuracy)
accuracies.append(accuracy_pair)
## get Confusion matrix" 
cnf_matrix_1 = confusion_matrix(transformed_y, transformed_pre1)
plt.figure()
deep_learning_models.plot_confusion_matrix(cnf_matrix_1, classes=class_names, normalize=True,
                      title='Confusion matrix for basic LSTM accuracy')
plt.savefig('Confusion matrix for basic LSTM accuracy.png', dpi=300)
plt.show()

plot_precision_recall.plot_average_precision(y_test, prediction1, 'basic LSTM')

## stacked LSTM with dropout
#start_time2 = time.clock()
model2, hist2 = deep_learning_models.LSTM_with_dropout(X_train_LSTM, y_train, X_test_LSTM, y_test, batch_size, epochs, dropoutRate)
prediction2 = model2.predict(X_test_LSTM)
transformed_pre2 = deep_learning_models.transformResult(prediction2)
#end_time2 = time.clock()
#LSTM_with_dropout_performance = end_time2 - start_time2
prediction2_re = np.argmax(prediction2, axis=1)
LSTM_with_dropout_accuracy, dropout_precision, dropout_recall, dropout_F1, dropout_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre2, transformed_y)
print("Precision for LSTM with dropout")
print(LSTM_with_dropout_accuracy)
print(dropout_precision)
print(dropout_recall)
print(dropout_fbeta)
print(dropout_F1)

accuracy_pair = list()
accuracy_pair.append("LSTM with dropout")
accuracy_pair.append(LSTM_with_dropout_accuracy)
accuracies.append(accuracy_pair)
## get Confusion matrix" 
cnf_matrix_2 = confusion_matrix(transformed_y, transformed_pre2)
plt.figure()
deep_learning_models.plot_confusion_matrix(cnf_matrix_2, classes=class_names, normalize=True,
                      title='Confusion matrix for LSTM with dropout accuracy')
plt.savefig('Confusion matrix for LSTM with dropout accuracy.png', dpi=300)
plt.show()

plot_precision_recall.plot_average_precision(y_test, prediction2, 'LSTM with dropout')

## CNN LSTM
#start_time3 = time.clock()
model3, hist3 = deep_learning_models.CNN_LSTM(X_train_CNN, y_train, y_test, batch_size, epochs, dropoutRate)
prediction3 = model3.predict(X_test_CNN)
transformed_pre3 = deep_learning_models.transformResult(prediction3)
#end_time3 = time.clock()
#CNN_LSTM_performance = end_time3 - start_time3
prediction3_re = np.argmax(prediction3, axis=1)
CNN_LSTM_accuracy, CNN_LSTM_precision, CNN_LSTM_recall, CNN_LSTM_F1, CNN_LSTM_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre3, transformed_y)
print("Precision for CNN LSTM")
print(CNN_LSTM_accuracy)
print(CNN_LSTM_precision)
print(CNN_LSTM_recall)
print(CNN_LSTM_fbeta)
print(CNN_LSTM_F1)

accuracy_pair = list()
accuracy_pair.append("CNN LSTM")
accuracy_pair.append(CNN_LSTM_accuracy)
accuracies.append(accuracy_pair)
## get Confusion matrix" 
cnf_matrix_3 = confusion_matrix(transformed_y, transformed_pre3)
plt.figure()
deep_learning_models.plot_confusion_matrix(cnf_matrix_3, classes=class_names, normalize=True,
                      title='Confusion matrix for CNN LSTM accuracy')
plt.savefig('Confusion matrix for CNN LSTM accuracy.png', dpi=300)
plt.show()
plot_precision_recall.plot_average_precision(y_test, prediction3, 'CNN_LSTM')

## CNN
#start_time4 = time.clock()
model4, hist4 = deep_learning_models.CNN(X_train_CNN, y_train, y_test, batch_size, epochs)
prediction4 = model4.predict(X_test_CNN)
transformed_pre4 = deep_learning_models.transformResult(prediction4)
#end_time4 = time.clock()
#CNN_performance = end_time4 - start_time4
prediction4_re = np.argmax(prediction4, axis=1)
CNN_accuracy, CNN_precision, CNN_recall, CNN_F1, CNN_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre4, transformed_y)
print("Precision for CNN")
print(CNN_accuracy)
print(CNN_precision)
print(CNN_recall)
print(CNN_fbeta)
print(CNN_F1)

accuracy_pair = list()
accuracy_pair.append("CNN")
accuracy_pair.append(CNN_accuracy)
accuracies.append(accuracy_pair)
## get Confusion matrix"
cnf_matrix_4 = confusion_matrix(transformed_y, transformed_pre4)
plt.figure()
deep_learning_models.plot_confusion_matrix(cnf_matrix_4, classes=class_names, normalize=True,
                      title='Confusion matrix for CNN accuracy')
plt.savefig('Confusion matrix for CNN accuracy.png', dpi=300)
plt.show()
plot_precision_recall.plot_average_precision(y_test, prediction4, 'CNN')

## DNN
model5, hist5 = deep_learning_models.DNN(X_train, y_train, batch_size, epochs, dropoutRate)
prediction5 = model5.predict(X_test)
transformed_pre5 = deep_learning_models.transformResult(prediction5)
prediction5_re = np.argmax(prediction5, axis=1)
DNN_accuracy, DNN_precision, DNN_recall, DNN_F1, DNN_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre5, transformed_y)
print("precision for DNN")
print(DNN_accuracy)
print(DNN_precision)
print(DNN_recall)
print(DNN_fbeta)
print(DNN_F1)

accuracy_pair = list()
accuracy_pair.append("DNN")
accuracy_pair.append(DNN_accuracy)
accuracies.append(accuracy_pair)
## get Confusion matrix" 
cnf_matrix_5 = confusion_matrix(transformed_y, transformed_pre5)
plt.figure()
deep_learning_models.plot_confusion_matrix(cnf_matrix_5, classes=class_names, normalize=True,
                      title='Confusion matrix for DNN accuracy')
plt.savefig('Confusion matrix for DNN accuracy.png', dpi=300)
plt.show()
plot_precision_recall.plot_average_precision(y_test, prediction5, 'DNN')

## stacked LSTM
#start_time6 = time.clock()
model6, hist6 = deep_learning_models.stacked_LSTM(X_train_LSTM, y_train, X_test_LSTM, y_test, batch_size, epochs)
prediction6 = model6.predict(X_test_LSTM)
transformed_pre6 = deep_learning_models.transformResult(prediction6)
#end_time6 = time.clock()
#stacked_LSTM_performance = end_time6 - start_time6 
prediction6_re = np.argmax(prediction6, axis=1)
stacked_LSTM_accuracy, stacked_LSTM_precision, stacked_LSTM_recall, stacked_LSTM_F1, stacked_LSTM_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre6, transformed_y)
print("Precision for stacked LSTM")
print(stacked_LSTM_accuracy)
print(stacked_LSTM_precision)
print(stacked_LSTM_recall)
print(stacked_LSTM_fbeta)
print(stacked_LSTM_F1)

accuracy_pair = list()
accuracy_pair.append("stacked LSTM")
accuracy_pair.append(stacked_LSTM_accuracy)
accuracies.append(accuracy_pair)
## get Confusion matrix" 
cnf_matrix_6 = confusion_matrix(transformed_y, transformed_pre6)
plt.figure()
deep_learning_models.plot_confusion_matrix(cnf_matrix_6, classes=class_names, normalize=True,
                      title='Confusion matrix for stacked LSTM accuracy')
plt.savefig('Confusion matrix for stacked LSTM accuracy.png', dpi=300)
plt.show()
plot_precision_recall.plot_average_precision(y_test, prediction6, 'stacked LSTM')

###### Traditional machine learning algorithm #############
### Decision tree ##### predict_proba
dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, transformed_y_train)
dtree_predictions = dtree_model.predict(X_test)
transformed_pre7 = dtree_predictions
# creating a confusion matrix
cm_dt = confusion_matrix(transformed_y, transformed_pre7)
dt_accuracy, dt_precision, dt_recall, dt_F1, dt_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre7, transformed_y)
accuracy_pair = list()
accuracy_pair.append("Decision tree")
accuracy_pair.append(dt_accuracy)
accuracies.append(accuracy_pair)
print("precision for decision tree")
print(dt_accuracy)
print(dt_precision)
print(dt_recall)
print(dt_fbeta)
print(dt_F1)
plt.figure()
deep_learning_models.plot_confusion_matrix(cm_dt, classes=class_names, normalize=True,
                      title='Confusion matrix for decision tree')
plt.savefig('Confusion matrix for decision tree.png', dpi=300)
plt.show()
y_score_dt = dtree_model.predict_proba(X_test)
plot_precision_recall.plot_average_precision(y_test, y_score_dt, 'Decision tree')

### svm ### decision function
svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, transformed_y_train)
svm_predictions = svm_model_linear.predict(X_test)
transformed_pre8 = svm_predictions
# creating a confusion matrix
cm_svm = confusion_matrix(transformed_y, transformed_pre8)
svm_accuracy, svm_precision, svm_recall, svm_F1, svm_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre8, transformed_y)
accuracy_pair = list()
accuracy_pair.append("Support vector machine")
accuracy_pair.append(svm_accuracy)
accuracies.append(accuracy_pair)
print("precision for SVM")
print(svm_accuracy)
print(svm_precision)
print(svm_recall)
print(svm_fbeta)
print(svm_F1)
plt.figure()
deep_learning_models.plot_confusion_matrix(cm_svm, classes=class_names, normalize=True,
                      title='Confusion matrix for SVM')
plt.savefig('Confusion matrix for SVM.png', dpi=300)
plt.show()
y_score_svm = svm_model_linear.decision_function(X_test)
plot_precision_recall.plot_average_precision(y_test, y_score_svm, 'SVM')

### KNN ###
knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, transformed_y_train) 
# creating a confusion matrix
knn_predictions = knn.predict(X_test) 
transformed_pre9 = knn_predictions
cm_knn = confusion_matrix(transformed_y, transformed_pre9)
knn_accuracy, knn_precision, knn_recall, knn_F1, knn_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre9, transformed_y) 
accuracy_pair = list()
accuracy_pair.append("KNN")
accuracy_pair.append(knn_accuracy)
accuracies.append(accuracy_pair)
print("precision for KNN")
print(knn_accuracy)
print(knn_precision)
print(knn_recall)
print(knn_fbeta)
print(knn_F1)
plt.figure()
deep_learning_models.plot_confusion_matrix(cm_knn, classes=class_names, normalize=True,
                      title='Confusion matrix for KNN')
plt.savefig('Confusion matrix for KNN.png', dpi=300)
plt.show()

y_score_knn = knn.predict_proba(X_test)
plot_precision_recall.plot_average_precision(y_test, y_score_knn, 'KNN')


# training a Naive Bayes classifier
gnb = GaussianNB().fit(X_train, transformed_y_train)
gnb_predictions = gnb.predict(X_test)
transformed_pre10 = gnb_predictions
# creating a confusion matrix
gnb_cm = confusion_matrix(transformed_y, transformed_pre10)
gnb_accuracy, gnb_precision, gnb_recall, gnb_F1, gnb_fbeta = deep_learning_models.getAccuracyMulti(transformed_pre10, transformed_y) 
accuracy_pair = list()
accuracy_pair.append("Naive Bayes")
accuracy_pair.append (gnb_accuracy)
accuracies.append(accuracy_pair)
print("precision for Naive Bayes")
print(gnb_accuracy)
print(gnb_precision)
print(gnb_recall)
print(gnb_fbeta)
print(gnb_F1)
plt.figure()
deep_learning_models.plot_confusion_matrix(gnb_cm, classes=class_names, normalize=True,
                      title='Confusion matrix for Naive Bayes')
plt.savefig('Confusion matrix for Naive Bayes.png', dpi=300)
plt.show()
y_score_nb = gnb.predict_proba(X_test)
plot_precision_recall.plot_average_precision(y_test, y_score_nb, 'Naive Bayes')# -*- encoding=utf-8 -*-
BLACK = (0, 0, 0)
WHITE = (255, 255, 255)

SCREEN_SIZE = [160, 200]
BAR_SIZE = [30, 3]
BALL_SIZE = [9, 9]

# 神经网络的输出
MOVE_STAY = [1, 0, 0]
MOVE_LEFT = [0, 1, 0]
MOVE_RIGHT = [0, 0, 1]

# learning_rate
LEARNING_RATE = 0.99
# 更新梯度
INITIAL_EPSILON = 1.0 # 0.5
FINAL_EPSILON = 0.1 # 0.05
# 测试观测次数
EXPLORE = 500000 # 500000
OBSERVE = 10000 # 50000
# 存储过往经验大小
REPLAY_MEMORY = 500000 # 500000

BATCH = 32

GAMMA = 0.99 # decay rate of past observations

'''
版本1：
1、初始化replay memory D 容量为N

2、用一个深度神经网络作为Q值网络，初始化权重参数

3、设定游戏片段总数M

4、初始化网络输入，大小为84*84*4，并且计算网络输出

5、以概率ϵ随机选择动作at或者通过网络输出的Q（max）值选择动作at

6、得到执行at后的奖励rt和下一个网络的输入

7、根据当前的值计算下一时刻网络的输出

8、将四个参数作为此刻的状态一起存入到D中（D中存放着N个时刻的状态）

9、随机从D中取出minibatch个状态

10、计算每一个状态的目标值（通过执行at后的reward来更新Q值作为目标值）

11、通过SGD更新weight

下在的是2015年的版本2：
1、初始化replay memory D，容量是N 用于存储训练的样本

2、初始化action-value function的Q卷积神经网络 ，随机初始化权重参数θ

3、初始化 target action-value function的Q^卷积神经网络，结构以及初始化权重θ和Q相同

4、设定游戏片段总数M

5、初始化网络输入，大小为84*84*4，并且计算网络输出

6、根据概率ϵ（很小）选择一个随机的动作或者根据当前的状态输入到当前的网络中 （用了一次CNN）计算出每个动作的Q值，选择Q值最大的一个动作（最优动作）

7、得到执行at后的奖励rt和下一个网络的输入

8、将四个参数作为此刻的状态一起存入到D中（D中存放着N个时刻的状态）

9、随机从D中取出minibatch个状态

10、计算每一个状态的目标值（通过执行at后的reward来更新Q值作为目标值）

11、通过SGD更新weight

12、每C次迭代后更新target action-value function网络的参数为当前action-value function的参数

参考文献：

    一个 Q-learning 算法的简明教程
    如何用简单例子讲解 Q - learning 的具体过程
    《Code for a painless q-learning tutorial》以及百度网盘地址
    DQN 从入门到放弃4 动态规划与Q-Learning
    DQN从入门到放弃5 深度解读DQN算法
    Deep Reinforcement Learning 基础知识（DQN方面）
    Paper Reading 1 - Playing Atari with Deep Reinforcement Learning
    Playing Atari with Deep Reinforcement Learning 论文及翻译百度网盘地址
    Paper Reading 2:Human-level control through deep reinforcement learning
    Human-level control through deep reinforcement learning 论文及翻译百度网盘地址
    重磅 | 详解深度强化学习，搭建DQN详细指南（附论文）
    Playing Atari with Deep Reinforcement Learning算法解读

'''import data.constants as const
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import Lib.util as util
from Lib.Viz import save_conf_matrix
from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score
from sklearn.metrics import roc_curve,auc


rslt = pd.read_csv("C:\\Users\\Shabdiz\\PycharmProjects\\MasterThesis\\output\\items\\Patch Context\\results.csv", sep=";")
rslt['patch'] = rslt['patch'].astype(str)
# all champions

actual = rslt['actual']
preds = rslt['deep_learning_2']

#
# print("deep_learning_2 Accuracy: " + str(accuracy_score(actual, preds)))
# print("deep_learning_2 Recall: " + str(recall_score(actual, preds)))
# print("deep_learning_2 Precision: " + str(precision_score(actual, preds)))
# df_cm = pd.DataFrame(data=confusion_matrix(actual, preds, labels=list(set().union(actual, preds))),
#                      columns=list(set().union(actual, preds)), index=list(set().union(actual, preds)))
# save_conf_matrix(df_cm, name='Deep Learning 2', path=util.setup("ConfigMatrices"), normalize=True)
#
# preds = rslt['neural_network']
# print("neural_network Accuracy: " + str(accuracy_score(actual, preds)))
# print("neural_network Recall: " + str(recall_score(actual, preds)))
# print("neural_network Precision: " + str(precision_score(actual, preds)))
# save_conf_matrix(df_cm, name='Deep Learning 1', path=util.setup("ConfigMatrices"), normalize=True)
#
#
# preds = rslt['deep_learning_1']
# print("Deep Learning 1 Accuracy: " + str(accuracy_score(actual, preds)))
# print("Deep Learning 1 Recall: " + str(recall_score(actual, preds)))
# print("Deep Learning 1 Precision: " + str(precision_score(actual, preds)))
# save_conf_matrix(df_cm, name='Deep Learning 1', path=util.setup("ConfigMatrices"), normalize=True)
#
# preds = rslt['decision_tree']
# print("decision_tree Accuracy: " + str(accuracy_score(actual, preds)))
# print("decision_tree Recall: " + str(recall_score(actual, preds)))
# print("decision_treePrecision: " + str(precision_score(actual, preds)))
# save_conf_matrix(df_cm, name='Decision Trees', path=util.setup("ConfigMatrices"), normalize=True)
#
# preds = rslt['random_forest']
# print("random_forest Accuracy: " + str(accuracy_score(actual, preds)))
# print("random_forest Recall: " + str(recall_score(actual, preds)))
# print("random_forestPrecision: " + str(precision_score(actual, preds)))



ids = [22, 51, 81, 110, 202]
champ_dict = {
    22: "Ashe",
    51: "Caitlyn",
    81: "Ezreal",
    110: "Varus",
    202: "Jhin"
}

preds = rslt.deep_learning_2.tolist()
actual = rslt.actual.tolist()
acc = accuracy_score(actual, preds)
print("Total Accuracy: " + str(acc))

accuracy_over_time = pd.DataFrame(data={
    "patches": const.PATCHES * 5,
    "champion": [champ_dict[item] for item in ids for i in range(20)],
    "acc": 0
    },
    columns=["patches", "champion", "acc"]
)
for id in ids:
    for patch in const.PATCHES:
        aux = rslt[(rslt.championId == id) & (rslt.patch == patch)]
        preds = aux.deep_learning_2.tolist()
        actual = aux.actual.tolist()
        acc = 0 if math.isnan(accuracy_score(actual, preds)) else accuracy_score(actual, preds)
        accuracy_over_time.loc[(accuracy_over_time.patches == patch) & (accuracy_over_time.champion == champ_dict[id]), "acc"] = acc
        print("Champion : " + str(id) + " accuracy: " + str(acc))

plt.clf()
plt.figure()
patches_b = const.PATCHES
patches_b.remove("7.10")
patches_b.remove("7.1")
accuracy_over_time['acc'] = accuracy_over_time['acc']*100
ax = sns.pointplot(x="patches", y="acc", hue="champion", order=patches_b, data=accuracy_over_time)
ax.set(ylim=(0, 100))
ax.legend(loc='lower left', #bbox_to_anchor=(0.5, 1.05),
          fancybox=True, shadow=True, ncol=2)
plt.ylabel("Test Accuracy in %")
ax.set_xticklabels(rotation=90, labels=patches_b)
plt.tight_layout()
plt.savefig("test_tips.png")

#Ashe
Ashe = rslt[rslt.championId == 22]
actual = Ashe.actual.tolist()
preds = Ashe.deep_learning_2.tolist()
Ashe_acc_all = accuracy_score(actual, preds)

df_cm = pd.DataFrame(data= confusion_matrix(actual, preds, labels=list(set().union(actual, preds))),
                     columns=list(set().union(actual, preds)), index=list(set().union(actual, preds)))

save_conf_matrix(df_cm, path="Ashe", normalize=True, name="Ashe_all_season")

Ashe_pre74 = Ashe[Ashe.patch.isin(["6.23", "6.24", "7.1", "7.2", "7.3", "7.4", "7.5", "7.6", "7.7", "7.8"])]
actual_pre74 = Ashe_pre74.actual.tolist()
preds_pre74 = Ashe_pre74.deep_learning_2.tolist()
Ashe_acc_pre74 = accuracy_score(actual_pre74, preds_pre74)
print("Ashe Acc pre patch 7.4: " + str(Ashe_acc_pre74))
df_cm = pd.DataFrame(data= confusion_matrix(actual_pre74, preds_pre74, labels=list(set().union(actual_pre74, preds_pre74))),
                     columns=list(set().union(actual_pre74, preds_pre74)), index=list(set().union(actual_pre74, preds_pre74)))
save_conf_matrix(df_cm, path="Ashe", normalize=True, name="Ashe_pre_74")


Ashe_post711 = Ashe[~Ashe.patch.isin(["7.8", "7.9", "7.10", "7.11", "7.12", "7.13", "7.14", "7.15", "7.16", "7.17", "7.18"])]
actual_post711 = Ashe_post711.actual.tolist()
preds_post711 = Ashe_post711.deep_learning_2.tolist()
Ashe_acc_post711 = accuracy_score(actual_post711, preds_post711)
print("Ashe Acc post patch 7.11: " + str(Ashe_acc_post711))
df_cm = pd.DataFrame(data= confusion_matrix(actual_post711, preds_post711, labels=list(set().union(actual_post711, preds_post711))),
                     columns=list(set().union(actual_post711, preds_post711)), index=list(set().union(actual_post711, preds_post711)))
save_conf_matrix(df_cm, path="Ashe", normalize=True, name="Ashe_post_711")




# Ezreal
Ezreal = rslt[rslt.championId == 81]
actual = Ezreal.actual.tolist()
preds = Ezreal.deep_learning_2.tolist()
Ezreal_acc_all = accuracy_score(actual, preds)

df_cm = pd.DataFrame(data= confusion_matrix(actual, preds, labels=list(set().union(actual, preds))),
                     columns=list(set().union(actual, preds)), index=list(set().union(actual, preds)))

save_conf_matrix(df_cm, path="Ezreal", normalize=True, name="Ezreal_all_season")

Ezreal_pre74 = Ezreal[Ezreal.patch.isin(["6.23", "6.24", "7.1", "7.2", "7.3", "7.4", "7.5", "7.6", "7.7", "7.8"])]
actual_pre74 = Ezreal_pre74.actual.tolist()
preds_pre74 = Ezreal_pre74.deep_learning_2.tolist()
Ezreal_acc_pre74 = accuracy_score(actual_pre74, preds_pre74)
print("Ezreal Acc pre patch 7.4: " + str(Ezreal_acc_pre74))
df_cm = pd.DataFrame(data= confusion_matrix(actual_pre74, preds_pre74, labels=list(set().union(actual_pre74, preds_pre74))),
                     columns=list(set().union(actual_pre74, preds_pre74)), index=list(set().union(actual_pre74, preds_pre74)))
save_conf_matrix(df_cm, path="Ezreal", normalize=True, name="Ezreal_pre_74")


Ezreal_post711 = Ezreal[~Ezreal.patch.isin(["6.23", "6.24", "7.1", "7.2", "7.3", "7.4", "7.5", "7.6", "7.7", "7.8", "7.9", "7.10", "7.15", "7.16", "7.17", "7.18"])]
actual_post711 = Ezreal_post711.actual.tolist()
preds_post711 = Ezreal_post711.deep_learning_2.tolist()
Ezreal_acc_post711 = accuracy_score(actual_post711, preds_post711)
print("Ezreal Acc post patch 7.11: " + str(Ezreal_acc_post711))
df_cm = pd.DataFrame(data= confusion_matrix(actual_post711, preds_post711, labels=list(set().union(actual_post711, preds_post711))),
                     columns=list(set().union(actual_post711, preds_post711)), index=list(set().union(actual_post711, preds_post711)))
save_conf_matrix(df_cm, path="Ezreal", normalize=True, name="Ezreal_post_711")


# Caitlyn
Caitlyn = rslt[rslt.championId == 51]
actual = Caitlyn.actual.tolist()
preds = Caitlyn.deep_learning_2.tolist()
Caitlyn_acc_all = accuracy_score(actual, preds)

df_cm = pd.DataFrame(data=confusion_matrix(actual, preds, labels=list(set().union(actual, preds))),
                     columns=list(set().union(actual, preds)), index=list(set().union(actual, preds)))

save_conf_matrix(df_cm, path="Caitlyn", normalize=True, name="Caitlyn_all_season")

Caitlyn_pre74 = Caitlyn[Caitlyn.patch.isin(["6.23", "6.24", "7.1", "7.2", "7.3", "7.4", "7.5", "7.6", "7.7", "7.8"])]
actual_pre74 = Caitlyn_pre74.actual.tolist()
preds_pre74 = Caitlyn_pre74.deep_learning_2.tolist()
Caitlyn_acc_pre74 = accuracy_score(actual_pre74, preds_pre74)
print("Caitlyn Acc pre patch 7.4: " + str(Caitlyn_acc_pre74))
df_cm74 = pd.DataFrame(data=confusion_matrix(actual_pre74, preds_pre74, labels=list(set().union(actual_pre74, preds_pre74))),
                     columns=list(set().union(actual_pre74, preds_pre74)), index=list(set().union(actual_pre74, preds_pre74)))
df_cm74.to_csv('Caitlyn_Conf_matrix_pre74.csv', sep=";")
save_conf_matrix(df_cm, path="Caitlyn", normalize=True, name="Caitlyn_pre_74")


Caitlyn_post711 = Caitlyn[~Caitlyn.patch.isin(["6.23", "6.24", "7.1", "7.2", "7.3", "7.4", "7.5", "7.6", "7.7", "7.8", "7.9", "7.10", "7.15", "7.16", "7.17", "7.18"])]
actual_post711 = Caitlyn_post711.actual.tolist()
preds_post711 = Caitlyn_post711.deep_learning_2.tolist()
Caitlyn_acc_post711 = accuracy_score(actual_post711, preds_post711)
print("Caitlyn Acc post patch 7.11: " + str(Caitlyn_acc_post711))
df_cm711 = pd.DataFrame(data=confusion_matrix(actual_post711, preds_post711, labels=list(set().union(actual_post711, preds_post711))),
                        columns=list(set().union(actual_post711, preds_post711)), index=list(set().union(actual_post711, preds_post711)))
df_cm74.to_csv('Caitlyn_Conf_matrix_pre74.csv', sep=";")
save_conf_matrix(df_cm, path="Caitlyn", normalize=True, name="Caitlyn_post_711")

# Jhin
Jhin = rslt[rslt.championId == 202]
actual = Jhin.actual.tolist()
preds = Jhin.deep_learning_2.tolist()
Jhin_acc_all = accuracy_score(actual, preds)

df_cm = pd.DataFrame(data= confusion_matrix(actual, preds, labels=list(set().union(actual, preds))),
                     columns=list(set().union(actual, preds)), index=list(set().union(actual, preds)))

save_conf_matrix(df_cm, path="Jhin", normalize=True, name="Jhin_all_season")

Jhin_pre74 = Jhin[Jhin.patch.isin(["6.23", "6.24", "7.1", "7.2", "7.3", "7.4", "7.5", "7.6", "7.7", "7.8"])]
actual_pre74 = Jhin_pre74.actual.tolist()
preds_pre74 = Jhin_pre74.deep_learning_2.tolist()
Jhin_acc_pre74 = accuracy_score(actual_pre74, preds_pre74)
print("Jhin Acc pre patch 7.4: " + str(Jhin_acc_pre74))
df_cm = pd.DataFrame(data= confusion_matrix(actual_pre74, preds_pre74, labels=list(set().union(actual_pre74, preds_pre74))),
                     columns=list(set().union(actual_pre74, preds_pre74)), index=list(set().union(actual_pre74, preds_pre74)))
save_conf_matrix(df_cm, path="Jhin", normalize=True, name="Jhin_pre_74")


Jhin_post711 = Jhin[~Jhin.patch.isin(["6.23", "6.24", "7.1", "7.2", "7.3", "7.4", "7.5", "7.6", "7.7", "7.8", "7.9", "7.10", "7.15", "7.16", "7.17", "7.18"])]
actual_post711 = Jhin_post711.actual.tolist()
preds_post711 = Jhin_post711.deep_learning_2.tolist()
Jhin_acc_post711 = accuracy_score(actual_post711, preds_post711)
print("Jhin Acc post patch 7.11: " + str(Jhin_acc_post711))
df_cm = pd.DataFrame(data= confusion_matrix(actual_post711, preds_post711, labels=list(set().union(actual_post711, preds_post711))),
                     columns=list(set().union(actual_post711, preds_post711)), index=list(set().union(actual_post711, preds_post711)))
save_conf_matrix(df_cm, path="Jhin", normalize=True, name="Jhin_post_711")





# Varus
Varus = rslt[rslt.championId == 110]
actual = Varus.actual.tolist()
preds = Varus.deep_learning_2.tolist()
varus_acc_all = accuracy_score(actual, preds)

df_cm = pd.DataFrame(data= confusion_matrix(actual, preds, labels=list(set().union(actual, preds))),
                     columns=list(set().union(actual, preds)), index=list(set().union(actual, preds)))

save_conf_matrix(df_cm, path="Varus", normalize=True, name="Varus_all_season")

actual_pre74 = Varus_pre74.actual.tolist()
preds_pre74 = Varus_pre74.deep_learning_2.tolist()
varus_acc_pre74 = accuracy_score(actual_pre74, preds_pre74)
print("Varus Acc pre patch 7.4: " + str(varus_acc_pre74))
df_cm = pd.DataFrame(data= confusion_matrix(actual_pre74, preds_pre74, labels=list(set().union(actual_pre74, preds_pre74))),
                     columns=list(set().union(actual_pre74, preds_pre74)), index=list(set().union(actual_pre74, preds_pre74)))
save_conf_matrix(df_cm, path="Varus", normalize=True, name="Varus_pre_74")


Varus_post711 = Varus[~Varus.patch.isin(["6.23", "6.24", "7.1", "7.2", "7.3", "7.4", "7.5", "7.6", "7.7", "7.8", "7.9", "7.10", "7.15", "7.16", "7.17", "7.18"])]
actual_post711 = Varus_post711.actual.tolist()
preds_post711 = Varus_post711.deep_learning_2.tolist()
varus_acc_post711 = accuracy_score(actual_post711, preds_post711)
print("Varus Acc post patch 7.11: " + str(varus_acc_post711))
df_cm_post711 = pd.DataFrame(data= confusion_matrix(actual_post711, preds_post711, labels=list(set().union(actual_post711, preds_post711))),
                     columns=list(set().union(actual_post711, preds_post711)), index=list(set().union(actual_post711, preds_post711)))
df_cm_post711.to_csv('Varus_Conf_matrix_post711.csv', sep=";")
save_conf_matrix(df_cm, path="Varus", normalize=True, name="Varus_post_711")

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine original batchlist with demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/data/bigbone4/ciriondo/'\n",
    "\n",
    "batchlist_csv = os.path.join(data_root, 'clean_all_path.csv')  # change for server\n",
    "demographic_csv = os.path.join(data_root, 'demographic_data.csv')  # change for server\n",
    "\n",
    "sample_list_csv = os.path.join(data_root, 'sample_list.csv')  # change for server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch = pd.read_csv(batchlist_csv)\n",
    "df_demo = pd.read_csv(demographic_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_batch['patient'] = df_batch['mriFile'].apply(lambda f: os.path.splitext(os.path.basename(f))[0].split('_')[0])\n",
    "df_batch['file_id'] = df_batch['mriFile'].apply(lambda f: os.path.splitext(os.path.basename(f))[0])\n",
    "df_batch = df_batch.loc[df_batch['mriFile'].apply(lambda p: os.path.exists(p))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_batch, df_demo, how='left', on='patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(sample_list_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mriFile',\n",
       " 'segFile',\n",
       " 'mfcWorms',\n",
       " 'lfcWorms',\n",
       " 'mfcBME',\n",
       " 'lfcBME',\n",
       " 'patient',\n",
       " 'file_id',\n",
       " 'GENDER',\n",
       " 'AGE',\n",
       " 'BMI']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mriFile</th>\n",
       "      <th>segFile</th>\n",
       "      <th>mfcWorms</th>\n",
       "      <th>lfcWorms</th>\n",
       "      <th>mfcBME</th>\n",
       "      <th>lfcBME</th>\n",
       "      <th>patient</th>\n",
       "      <th>file_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P052</td>\n",
       "      <td>P052_0_loaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P052</td>\n",
       "      <td>P052_1_loaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P052</td>\n",
       "      <td>P052_2_loaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P052</td>\n",
       "      <td>P052_3_loaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P122</td>\n",
       "      <td>P122_0_loaded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             mriFile  \\\n",
       "0  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "1  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "2  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "3  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "4  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "\n",
       "                                             segFile  mfcWorms  lfcWorms  \\\n",
       "0  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...       0.0       0.0   \n",
       "1  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...       0.0       0.0   \n",
       "2  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...       0.0       0.0   \n",
       "3  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...       0.0       0.0   \n",
       "4  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...       2.5       1.0   \n",
       "\n",
       "   mfcBME  lfcBME patient        file_id  \n",
       "0     0.0     0.0    P052  P052_0_loaded  \n",
       "1     0.0     0.0    P052  P052_1_loaded  \n",
       "2     0.0     0.0    P052  P052_2_loaded  \n",
       "3     0.0     0.0    P052  P052_3_loaded  \n",
       "4     0.0     0.0    P122  P122_0_loaded  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = '/data/bigbone4/ciriondo/'\n",
    "#data_root = os.getcwd()\n",
    "\n",
    "batchlist_csv = os.path.join(data_root, 'clean_all_path.csv') \n",
    "demographic_csv = os.path.join(data_root, 'demographic_data.csv') \n",
    "\n",
    "sample_list_csv = os.path.join(data_root, 'sample_list.csv')  # change for server\n",
    "\n",
    "# Load in dataframe\n",
    "df_batch = pd.read_csv(batchlist_csv)\n",
    "\n",
    "df_batch['patient'] = df_batch['mriFile'].apply(lambda f: os.path.splitext(os.path.basename(f))[0].split('_')[0])\n",
    "df_batch['file_id'] = df_batch['mriFile'].apply(lambda f: os.path.splitext(os.path.basename(f))[0])\n",
    "df_batch = df_batch.loc[df_batch['mriFile'].apply(lambda p: os.path.exists(p))]\n",
    "\n",
    "df_batch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any rows with files that don't exist\n",
    "df_batch = df_batch.loc[df_batch['mriFile'].apply(lambda p: os.path.exists(p))]\n",
    "# df_batch = df_batch.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worms = df_batch.copy().rename(columns={'mfcWorms': 'mfc', 'lfcWorms': 'lfc'}).drop(['lfcBME', 'mfcBME'], axis=1)\n",
    "df_bme = df_batch.copy().rename(columns={'mfcBME': 'mfc', 'lfcBME': 'lfc'}).drop(['lfcWorms', 'mfcWorms'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melting LFC/MFC into seperate rows\n",
    "df_worms_melt = pd.melt(df_worms, \n",
    "                 id_vars=['patient', 'file_id', 'mriFile', 'segFile'], \n",
    "                 value_vars=['lfc', 'mfc'],\n",
    "                 var_name='type',\n",
    "                 value_name='worms')\n",
    "\n",
    "df_bme_melt = pd.melt(df_bme, \n",
    "                 id_vars=['patient', 'file_id', 'mriFile', 'segFile'], \n",
    "                 value_vars=['lfc', 'mfc'],\n",
    "                 var_name='type',\n",
    "                 value_name='bme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3174, 6)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bme_melt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3174, 6)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_worms_melt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3178, 7)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.merge(df_worms_melt, df_bme_melt, \n",
    "                  how='inner', \n",
    "                  on=['patient', 'file_id', 'type', 'mriFile', 'segFile'])\n",
    "df_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>file_id</th>\n",
       "      <th>mriFile</th>\n",
       "      <th>segFile</th>\n",
       "      <th>type</th>\n",
       "      <th>worms</th>\n",
       "      <th>bme</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P052</td>\n",
       "      <td>P052_0_loaded</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>lfc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P052</td>\n",
       "      <td>P052_1_loaded</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>lfc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P052</td>\n",
       "      <td>P052_2_loaded</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>lfc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P052</td>\n",
       "      <td>P052_3_loaded</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>lfc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P122</td>\n",
       "      <td>P122_0_loaded</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>lfc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>62.0</td>\n",
       "      <td>26.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient        file_id                                            mriFile  \\\n",
       "0    P052  P052_0_loaded  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "1    P052  P052_1_loaded  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "2    P052  P052_2_loaded  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "3    P052  P052_3_loaded  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "4    P122  P122_0_loaded  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "\n",
       "                                             segFile type  worms  bme GENDER  \\\n",
       "0  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...  lfc    0.0  0.0      F   \n",
       "1  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...  lfc    0.0  0.0      F   \n",
       "2  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...  lfc    0.0  0.0      F   \n",
       "3  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...  lfc    0.0  0.0      F   \n",
       "4  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...  lfc    1.0  0.0      F   \n",
       "\n",
       "    AGE   BMI  \n",
       "0  49.0  26.3  \n",
       "1  49.0  26.3  \n",
       "2  49.0  26.3  \n",
       "3  49.0  26.3  \n",
       "4  62.0  26.7  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo = pd.read_csv(demographic_csv)\n",
    "df = pd.merge(df_scores, df_demo, how='left', on='patient')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient    465\n",
       "file_id    465\n",
       "mriFile    465\n",
       "segFile    465\n",
       "type       465\n",
       "worms      465\n",
       "bme        464\n",
       "GENDER     465\n",
       "AGE        465\n",
       "BMI        438\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['worms'] > 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(data_root, 'full_sample_list.csv'), index=False)\n",
    "# df_valid.to_csv(os.path.join(data_root, 'valid_batchlist.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/data/bigbone4/ciriondo/'\n",
    "#data_root = os.getcwd()\n",
    "\n",
    "batchlist_csv = os.path.join(data_root, 'clean_all_path.csv') \n",
    "demographic_csv = os.path.join(data_root, 'demographic_data.csv') \n",
    "\n",
    "sample_list_csv = os.path.join(data_root, 'full_batchlist.csv')  # change for server\n",
    "\n",
    "# Load in dataframe\n",
    "df_batch = pd.read_csv(batchlist_csv)\n",
    "\n",
    "df_batch['patient'] = df_batch['mriFile'].apply(lambda f: os.path.splitext(os.path.basename(f))[0].split('_')[0])\n",
    "df_batch['file_id'] = df_batch['mriFile'].apply(lambda f: os.path.splitext(os.path.basename(f))[0])\n",
    "\n",
    "df_batch = df_batch.loc[df_batch['mriFile'].apply(lambda p: os.path.exists(p))]\n",
    "\n",
    "df_worms = df_batch.copy().rename(columns={'mfcWorms': 'mfc', 'lfcWorms': 'lfc'}).drop(['lfcBME', 'mfcBME'], axis=1)\n",
    "df_bme = df_batch.copy().rename(columns={'mfcBME': 'mfc', 'lfcBME': 'lfc'}).drop(['lfcWorms', 'mfcWorms'], axis=1)\n",
    "\n",
    "# melting LFC/MFC into seperate rows\n",
    "df_worms_melt = pd.melt(df_worms, \n",
    "                 id_vars=['patient', 'file_id', 'mriFile', 'segFile'], \n",
    "                 value_vars=['lfc', 'mfc'],\n",
    "                 var_name='type',\n",
    "                 value_name='worms')\n",
    "\n",
    "df_bme_melt = pd.melt(df_bme, \n",
    "                 id_vars=['patient', 'file_id', 'mriFile', 'segFile'], \n",
    "                 value_vars=['lfc', 'mfc'],\n",
    "                 var_name='type',\n",
    "                 value_name='bme')\n",
    "\n",
    "df_scores = pd.merge(df_worms_melt, df_bme_melt, \n",
    "                  how='inner', \n",
    "                  on=['patient', 'file_id', 'type', 'mriFile', 'segFile'])\n",
    "\n",
    "df_demo = pd.read_csv(demographic_csv)\n",
    "df = pd.merge(df_scores, df_demo, how='left', on='patient')\n",
    "\n",
    "df.to_csv(os.path.join(data_root, 'tfrecord_list.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3178, 10)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[None:None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'test/'\n",
    "df['sampleFile'] = save_dir + df['file_id'] + df['type'] + '.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>file_id</th>\n",
       "      <th>mriFile</th>\n",
       "      <th>segFile</th>\n",
       "      <th>type</th>\n",
       "      <th>worms</th>\n",
       "      <th>bme</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BMI</th>\n",
       "      <th>sampleFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P052</td>\n",
       "      <td>P052_0_loaded</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>lfc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>test/P052_0_loadedlfc.tfrecord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P052</td>\n",
       "      <td>P052_1_loaded</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>lfc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>test/P052_1_loadedlfc.tfrecord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P052</td>\n",
       "      <td>P052_2_loaded</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>lfc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>test/P052_2_loadedlfc.tfrecord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P052</td>\n",
       "      <td>P052_3_loaded</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>lfc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>test/P052_3_loadedlfc.tfrecord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P122</td>\n",
       "      <td>P122_0_loaded</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>/data/bigbone4/DeepLearning_temp/Data/all_CUBE...</td>\n",
       "      <td>lfc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>62.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>test/P122_0_loadedlfc.tfrecord</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient        file_id                                            mriFile  \\\n",
       "0    P052  P052_0_loaded  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "1    P052  P052_1_loaded  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "2    P052  P052_2_loaded  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "3    P052  P052_3_loaded  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "4    P122  P122_0_loaded  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...   \n",
       "\n",
       "                                             segFile type  worms  bme GENDER  \\\n",
       "0  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...  lfc    0.0  0.0      F   \n",
       "1  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...  lfc    0.0  0.0      F   \n",
       "2  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...  lfc    0.0  0.0      F   \n",
       "3  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...  lfc    0.0  0.0      F   \n",
       "4  /data/bigbone4/DeepLearning_temp/Data/all_CUBE...  lfc    1.0  0.0      F   \n",
       "\n",
       "    AGE   BMI                      sampleFile  \n",
       "0  49.0  26.3  test/P052_0_loadedlfc.tfrecord  \n",
       "1  49.0  26.3  test/P052_1_loadedlfc.tfrecord  \n",
       "2  49.0  26.3  test/P052_2_loadedlfc.tfrecord  \n",
       "3  49.0  26.3  test/P052_3_loadedlfc.tfrecord  \n",
       "4  62.0  26.7  test/P122_0_loadedlfc.tfrecord  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Apr  6 18:29:49 2017

@author: frankiezeager
"""



import pandas as pd
from sklearn.metrics import roc_curve, auc, roc_auc_score
import matplotlib.pyplot as plt
from itertools import cycle
from sklearn.externals import joblib
#output to local machine on AWS
plt.switch_backend('agg')


# define coverage_curve function
def coverage_curve(df, target_variable_col, predicted_prob_fraud_col, trxn_amount_col):
    df=df.copy(deep=True)
    df = df.sort_values(predicted_prob_fraud_col, ascending=False)
    df['Fraud_Cumulative'] = df[target_variable_col].cumsum()*1.0 / df[target_variable_col].sum( )
    df['TrxnCount'] = 1
    df['Trxn_Cumulative'] = df['TrxnCount'].cumsum()*1.0 / df['TrxnCount'].sum( )

    return df

############### Adversarial Learning #####################################################################################################################################
#read in the validation sets

#load model list
adv_learning_models=joblib.load('adv_learning_models.pkl')

adv_learning_oot=[]

adv_trans_amount = []
for i in range(1,11):
    file=pd.read_csv('adv_learning_test_'+str(i)+'.csv')
    adv_learning_oot.append(file)

    fnr_file = file.copy(deep=True)
    #remove fraud indicator
    fnr_predict=fnr_file.drop('FRD_IND',axis=1)
    #remove index column
    fnr_predict=fnr_predict.drop(fnr_predict.columns[0],axis=1)

    model = adv_learning_models[(i-1)]
    fnr_mod = model.predict(fnr_predict)
    fnr_file['pred'] = fnr_mod

    trans_sum = 0
    fnr_index = fnr_file.where((fnr_file['pred'] == 0) & (fnr_file['FRD_IND'] == 1))
    trans_sum = fnr_index['AUTHZN_AMT'].sum()

    adv_trans_amount.append(trans_sum)

print("the money lost by adversarial learning by round: ",adv_trans_amount)


i_num = 0
fold_n=[1,4,7,10]



### ROC Curve (adversarial learning) ###

lw=2
colors = cycle(['cyan', 'indigo', 'seagreen','darkorange'])
folds_list=[adv_learning_oot[0].copy(deep=True),adv_learning_oot[3].copy(deep=True),adv_learning_oot[6].copy(deep=True),adv_learning_oot[9].copy(deep=True)]
model_list2=[adv_learning_models[0],adv_learning_models[3],adv_learning_models[6],adv_learning_models[9]]
#folds_list=adv_learning_oot
#model_list2=adv_learning_models
for l, color, z in zip(folds_list, colors, model_list2):
    l=l.copy(deep=True)
    #remove fraud indicator
    syntheticdata_test=l.drop('FRD_IND',axis=1)
    #remove index column
    syntheticdata_test=syntheticdata_test.drop(syntheticdata_test.columns[0],axis=1)
    mod_test3 = z.predict_proba(syntheticdata_test)[:,1]
    fpr, tpr, _ = roc_curve(l['FRD_IND'], mod_test3)
    print("The Plot AUC score is:", roc_auc_score(l['FRD_IND'],mod_test3 ))
    aucscore = auc(fpr, tpr )
    plt.plot(fpr, tpr, lw=lw, color=color, label='ROC Round %d (area = %0.2f)' % (fold_n[i_num], aucscore))
    i_num += 1

#adding ROC curve code
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve with Adversarial Learning')
plt.legend(loc="lower right")

#export plot
plt.savefig('adv_learning_roc.png',bbox_inches='tight')
plt.savefig('adv_learning_roc.svg',bbox_inches='tight')
#remove plot
plt.clf()

#print all AUCs
for fold, model in  zip(adv_learning_oot, adv_learning_models):
    fold=fold.copy(deep=True)
    #remove ground truth column
    syntheticdata_test=fold.drop('FRD_IND',axis=1)
    #remove index column
    syntheticdata_test=syntheticdata_test.drop(syntheticdata_test.columns[0],axis=1)
    mod_test3 = model.predict_proba(syntheticdata_test)[:,1]
    fpr, tpr, _ = roc_curve(fold['FRD_IND'], mod_test3)
    print("The All Rounds Adversarial Learning AUC score (model 1) is:", roc_auc_score(fold['FRD_IND'],mod_test3 ))





#### Coverage Curve for Adversarial Learning ####


ilist=[1,4,7,10]

folds_list2=[adv_learning_oot[0].copy(deep=True),adv_learning_oot[3].copy(deep=True),adv_learning_oot[6].copy(deep=True),adv_learning_oot[9].copy(deep=True)]
model_list2=[adv_learning_models[0],adv_learning_models[3],adv_learning_models[6],adv_learning_models[9]]

val=1
#run coverage curve:
for fold,model,color,i in zip(folds_list2,model_list2,colors,ilist):
    fold=fold.copy(deep=True)
    #remove ground truth column
    syntheticdata_test2=fold.drop('FRD_IND',axis=1)
    #remove index column
    syntheticdata_test2=syntheticdata_test2.drop(syntheticdata_test2.columns[0],axis=1)
    model_predictions=model.predict_proba(syntheticdata_test2)[:,1]
    fold['model_pred']=model_predictions
    # create sorted df
    sorted_df = coverage_curve(fold, 'FRD_IND', 'model_pred', fold['AUTHZN_AMT'])
    sorted_df.to_csv('adv_learning_coverage_'+str(val)+'.csv')
    #drop model_pred
    fold=fold.drop('model_pred',axis=1)
    # produce chart
    plt.plot(sorted_df['Trxn_Cumulative'], sorted_df['Fraud_Cumulative'], color=color, label='Round '+str(i))
    plt.xlabel('Cumulative Transactions Examined')
    plt.ylabel('Percent Fraud Caught')
    plt.title('Coverage Curve with Adversarial Learning')
    plt.legend(loc="lower right")
    val=val+1

#save plot
plt.savefig('adv_learn_coverage(1).png',bbox_inches='tight')
plt.savefig('adv_learn_coverage(1).svg',bbox_inches='tight')

#remove plot
plt.clf()




##################### Adversary learns, classifier remains the same (no adv learning)############################################
#load model list
no_learning_mod=joblib.load('no_learning_model.pkl')

no_learning_oot=[]

nolearn_trans_amount = []

for i in range(1,11):
    file=pd.read_csv('no_learning_test_'+str(i)+'.csv')
    no_learning_oot.append(file)

    fnr_file = file.copy(deep=True)
    #remove fraud indicator
    fnr_predict=fnr_file.drop('FRD_IND',axis=1)
    #remove index column
    fnr_predict=fnr_predict.drop(fnr_predict.columns[0],axis=1)

    model = no_learning_mod
    fnr_mod = model.predict(fnr_predict)
    fnr_file['pred'] = fnr_mod

    trans_sum = 0
    fnr_index = fnr_file.where((fnr_file['pred'] == 0) & (fnr_file['FRD_IND'] == 1))
    trans_sum = fnr_index['AUTHZN_AMT'].sum()

    nolearn_trans_amount.append(trans_sum)

print("the money lost without learning by round: ",nolearn_trans_amount)


diff_list = [a_i - b_i for a_i, b_i in zip(adv_trans_amount, nolearn_trans_amount)]

i_num = 0
fold_n=[1,4,7,10]


colors = cycle(['cyan', 'indigo', 'seagreen','darkorange'])
folds_list=[no_learning_oot[0].copy(deep=True),no_learning_oot[3].copy(deep=True),no_learning_oot[6].copy(deep=True),no_learning_oot[9].copy(deep=True)]
firstmod=no_learning_mod

for l, color in zip(folds_list, colors):
    l=l.copy(deep=True)
    syntheticdata_test=l.drop('FRD_IND',axis=1)
    syntheticdata_test=syntheticdata_test.drop(syntheticdata_test.columns[0],axis=1)
    mod_test3 = firstmod.predict_proba(syntheticdata_test)[:,1]
    fpr, tpr, _ = roc_curve(l['FRD_IND'], mod_test3)
    print("The Plot AUC score is:", roc_auc_score(l['FRD_IND'],mod_test3 ))

    aucscore = auc(fpr, tpr )
    plt.plot(fpr, tpr, lw=lw, color=color, label='ROC Round %d (area = %0.2f)' % (fold_n[i_num], aucscore))
    i_num += 1

#adding ROC curve code
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve without Adversarial Learning')
plt.legend(loc="lower right")
#plt.show()

plt.savefig('no_learning_roc.png',bbox_inches='tight')
plt.savefig('no_learning_roc.svg',bbox_inches='tight')

#remove plot
plt.clf()

#print all AUCs
for fold in no_learning_oot:
    fold=fold.copy(deep=True)
    model=firstmod
    syntheticdata_test=fold.drop('FRD_IND',axis=1)
    syntheticdata_test=syntheticdata_test.drop(syntheticdata_test.columns[0],axis=1)
    mod_test3 = model.predict_proba(syntheticdata_test)[:,1]
    fpr, tpr, _ = roc_curve(fold['FRD_IND'], mod_test3)
    print("All Rounds No Learning AUC score is:", roc_auc_score(fold['FRD_IND'],mod_test3 ))

### Coverage Curve ###

ilist=[1,4,7,10]
folds_list4=[no_learning_oot[0].copy(deep=True),no_learning_oot[3].copy(deep=True),no_learning_oot[6].copy(deep=True),no_learning_oot[9].copy(deep=True)]

val=1
#run coverage curve:
for fold,color,i in zip(folds_list4,colors,ilist):
    fold=fold.copy(deep=True)
    model=firstmod
    syntheticdata_test4=fold.drop('FRD_IND',axis=1)
    syntheticdata_test4=syntheticdata_test4.drop(syntheticdata_test4.columns[0],axis=1)
    model_predictions=model.predict_proba(syntheticdata_test4)[:,1]
    new_fold=fold
    new_fold['model_pred']=model_predictions
    # create sorted df
    sorted_df = coverage_curve(new_fold, 'FRD_IND', 'model_pred', new_fold['AUTHZN_AMT'])
    sorted_df.to_csv('no_learning_coverage_'+str(val)+'.csv')
    #drop model_pred
    new_fold=new_fold.drop('model_pred',axis=1)
    # produce chart
    plt.plot(sorted_df['Trxn_Cumulative'], sorted_df['Fraud_Cumulative'], color=color, label='Round '+str(i))
    plt.xlabel('Cumulative Transactions Examined')
    plt.ylabel('Percent Fraud Caught')
    plt.title('Coverage Curve without Adversarial Learning')
    plt.legend(loc="lower right")
    val=val+1
#save plot
plt.savefig('no_adv_coverage.png',bbox_inches='tight')
plt.savefig('no_adv_coverage.svg',bbox_inches='tight')

#remove plot
plt.clf()
# This file was automatically generated by SWIG (http://www.swig.org).
# Version 3.0.8
#
# Do not make changes to this file unless you know what you are doing--modify
# the SWIG interface file instead.





from sys import version_info
if version_info >= (2, 6, 0):
    def swig_import_helper():
        from os.path import dirname
        import imp
        fp = None
        try:
            fp, pathname, description = imp.find_module('_deep_feedback_learning', [dirname(__file__)])
        except ImportError:
            import _deep_feedback_learning
            return _deep_feedback_learning
        if fp is not None:
            try:
                _mod = imp.load_module('_deep_feedback_learning', fp, pathname, description)
            finally:
                fp.close()
            return _mod
    _deep_feedback_learning = swig_import_helper()
    del swig_import_helper
else:
    import _deep_feedback_learning
del version_info
try:
    _swig_property = property
except NameError:
    pass  # Python < 2.2 doesn't have 'property'.


def _swig_setattr_nondynamic(self, class_type, name, value, static=1):
    if (name == "thisown"):
        return self.this.own(value)
    if (name == "this"):
        if type(value).__name__ == 'SwigPyObject':
            self.__dict__[name] = value
            return
    method = class_type.__swig_setmethods__.get(name, None)
    if method:
        return method(self, value)
    if (not static):
        if _newclass:
            object.__setattr__(self, name, value)
        else:
            self.__dict__[name] = value
    else:
        raise AttributeError("You cannot add attributes to %s" % self)


def _swig_setattr(self, class_type, name, value):
    return _swig_setattr_nondynamic(self, class_type, name, value, 0)


def _swig_getattr_nondynamic(self, class_type, name, static=1):
    if (name == "thisown"):
        return self.this.own()
    method = class_type.__swig_getmethods__.get(name, None)
    if method:
        return method(self)
    if (not static):
        return object.__getattr__(self, name)
    else:
        raise AttributeError(name)

def _swig_getattr(self, class_type, name):
    return _swig_getattr_nondynamic(self, class_type, name, 0)


def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)

try:
    _object = object
    _newclass = 1
except AttributeError:
    class _object:
        pass
    _newclass = 0


class DeepFeedbackLearning(_object):
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, DeepFeedbackLearning, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, DeepFeedbackLearning, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        this = _deep_feedback_learning.new_DeepFeedbackLearning(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _deep_feedback_learning.delete_DeepFeedbackLearning
    __del__ = lambda self: None
    backprop = _deep_feedback_learning.DeepFeedbackLearning_backprop
    ico = _deep_feedback_learning.DeepFeedbackLearning_ico

    def doStep(self, *args) -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_doStep(self, *args)

    def getOutput(self, index: 'int') -> "double":
        return _deep_feedback_learning.DeepFeedbackLearning_getOutput(self, index)

    def setLearningRate(self, learningRate: 'double') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_setLearningRate(self, learningRate)

    def setMomentum(self, momentum: 'double') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_setMomentum(self, momentum)

    def setAlgorithm(self, _algorithm: 'DeepFeedbackLearning::Algorithm') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_setAlgorithm(self, _algorithm)

    def getAlgorithm(self) -> "DeepFeedbackLearning::Algorithm":
        return _deep_feedback_learning.DeepFeedbackLearning_getAlgorithm(self)

    def initWeights(self, *args) -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_initWeights(self, *args)

    def seedRandom(self, s: 'int') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_seedRandom(self, s)

    def setBias(self, _bias: 'double') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_setBias(self, _bias)

    def getNumHidLayers(self) -> "int":
        return _deep_feedback_learning.DeepFeedbackLearning_getNumHidLayers(self)

    def getLayer(self, i: 'int') -> "Layer *":
        return _deep_feedback_learning.DeepFeedbackLearning_getLayer(self, i)

    def getOutputLayer(self) -> "Layer *":
        return _deep_feedback_learning.DeepFeedbackLearning_getOutputLayer(self)

    def getLayers(self) -> "Layer **":
        return _deep_feedback_learning.DeepFeedbackLearning_getLayers(self)

    def setUseDerivative(self, useIt: 'int') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_setUseDerivative(self, useIt)

    def saveModel(self, name: 'char const *') -> "bool":
        return _deep_feedback_learning.DeepFeedbackLearning_saveModel(self, name)

    def loadModel(self, name: 'char const *') -> "bool":
        return _deep_feedback_learning.DeepFeedbackLearning_loadModel(self, name)
DeepFeedbackLearning_swigregister = _deep_feedback_learning.DeepFeedbackLearning_swigregister
DeepFeedbackLearning_swigregister(DeepFeedbackLearning)

class Layer(_object):
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, Layer, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, Layer, name)
    __repr__ = _swig_repr

    def __init__(self, _nNeurons: 'int', _nInputs: 'int', _nFilters: 'int'=0, _minT: 'double'=0, _maxT: 'double'=0):
        this = _deep_feedback_learning.new_Layer(_nNeurons, _nInputs, _nFilters, _minT, _maxT)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _deep_feedback_learning.delete_Layer
    __del__ = lambda self: None

    def calcOutputs(self) -> "void":
        return _deep_feedback_learning.Layer_calcOutputs(self)

    def doLearning(self) -> "void":
        return _deep_feedback_learning.Layer_doLearning(self)

    def setError(self, *args) -> "void":
        return _deep_feedback_learning.Layer_setError(self, *args)

    def setErrors(self, _errors: 'double *') -> "void":
        return _deep_feedback_learning.Layer_setErrors(self, _errors)

    def getError(self, i: 'int') -> "double":
        return _deep_feedback_learning.Layer_getError(self, i)

    def setBias(self, _bias: 'double') -> "void":
        return _deep_feedback_learning.Layer_setBias(self, _bias)

    def setUseDerivative(self, useIt: 'int') -> "void":
        return _deep_feedback_learning.Layer_setUseDerivative(self, useIt)

    def setInput(self, inputIndex: 'int', input: 'double') -> "void":
        return _deep_feedback_learning.Layer_setInput(self, inputIndex, input)

    def setInputs(self, _inputs: 'double *') -> "void":
        return _deep_feedback_learning.Layer_setInputs(self, _inputs)

    def setLearningRate(self, _learningRate: 'double') -> "void":
        return _deep_feedback_learning.Layer_setLearningRate(self, _learningRate)

    def setMomentum(self, _momentum: 'double') -> "void":
        return _deep_feedback_learning.Layer_setMomentum(self, _momentum)

    def initWeights(self, *args) -> "void":
        return _deep_feedback_learning.Layer_initWeights(self, *args)

    def getOutput(self, index: 'int') -> "double":
        return _deep_feedback_learning.Layer_getOutput(self, index)

    def getNeuron(self, index: 'int') -> "Neuron *":
        return _deep_feedback_learning.Layer_getNeuron(self, index)

    def getNneurons(self) -> "int":
        return _deep_feedback_learning.Layer_getNneurons(self)

    def getNinputs(self) -> "int":
        return _deep_feedback_learning.Layer_getNinputs(self)

    def setConvolution(self, width: 'int', height: 'int') -> "void":
        return _deep_feedback_learning.Layer_setConvolution(self, width, height)

    def setMaxDetLayer(self, _m: 'int') -> "void":
        return _deep_feedback_learning.Layer_setMaxDetLayer(self, _m)

    def setNormaliseWeights(self, _normaliseWeights: 'int') -> "void":
        return _deep_feedback_learning.Layer_setNormaliseWeights(self, _normaliseWeights)

    def setDebugInfo(self, layerIndex: 'int') -> "void":
        return _deep_feedback_learning.Layer_setDebugInfo(self, layerIndex)

    def setStep(self, step: 'long') -> "void":
        return _deep_feedback_learning.Layer_setStep(self, step)

    def getWeightDistanceFromInitialWeights(self) -> "double":
        return _deep_feedback_learning.Layer_getWeightDistanceFromInitialWeights(self)
Layer_swigregister = _deep_feedback_learning.Layer_swigregister
Layer_swigregister(Layer)

class Neuron(_object):
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, Neuron, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, Neuron, name)
    __repr__ = _swig_repr

    def __init__(self, _nInputs: 'int', _nFilters: 'int'=0, _minT: 'double'=0, _maxT: 'double'=0):
        this = _deep_feedback_learning.new_Neuron(_nInputs, _nFilters, _minT, _maxT)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _deep_feedback_learning.delete_Neuron
    __del__ = lambda self: None

    def calcOutput(self) -> "void":
        return _deep_feedback_learning.Neuron_calcOutput(self)
    __swig_getmethods__["calcOutputThread"] = lambda x: _deep_feedback_learning.Neuron_calcOutputThread
    if _newclass:
        calcOutputThread = staticmethod(_deep_feedback_learning.Neuron_calcOutputThread)

    def doLearning(self) -> "void":
        return _deep_feedback_learning.Neuron_doLearning(self)
    __swig_getmethods__["doLearningThread"] = lambda x: _deep_feedback_learning.Neuron_doLearningThread
    if _newclass:
        doLearningThread = staticmethod(_deep_feedback_learning.Neuron_doLearningThread)

    def doMaxDet(self) -> "void":
        return _deep_feedback_learning.Neuron_doMaxDet(self)
    __swig_getmethods__["doMaxDetThread"] = lambda x: _deep_feedback_learning.Neuron_doMaxDetThread
    if _newclass:
        doMaxDetThread = staticmethod(_deep_feedback_learning.Neuron_doMaxDetThread)
    MAX_OUTPUT_RANDOM = _deep_feedback_learning.Neuron_MAX_OUTPUT_RANDOM
    MAX_WEIGHT_RANDOM = _deep_feedback_learning.Neuron_MAX_WEIGHT_RANDOM
    MAX_OUTPUT_CONST = _deep_feedback_learning.Neuron_MAX_OUTPUT_CONST
    CONST_WEIGHTS = _deep_feedback_learning.Neuron_CONST_WEIGHTS

    def initWeights(self, *args) -> "void":
        return _deep_feedback_learning.Neuron_initWeights(self, *args)

    def getMinWeightValue(self) -> "double":
        return _deep_feedback_learning.Neuron_getMinWeightValue(self)

    def getMaxWeightValue(self) -> "double":
        return _deep_feedback_learning.Neuron_getMaxWeightValue(self)

    def getWeightDistanceFromInitialWeights(self) -> "double":
        return _deep_feedback_learning.Neuron_getWeightDistanceFromInitialWeights(self)

    def getOutput(self) -> "double":
        return _deep_feedback_learning.Neuron_getOutput(self)

    def getSum(self) -> "double":
        return _deep_feedback_learning.Neuron_getSum(self)

    def getWeight(self, _index: 'int', _filter: 'int'=0) -> "double":
        return _deep_feedback_learning.Neuron_getWeight(self, _index, _filter)

    def getWeightChange(self, _index: 'int', _filter: 'int'=0) -> "double":
        return _deep_feedback_learning.Neuron_getWeightChange(self, _index, _filter)

    def getFilteredInput(self, _index: 'int', _filter: 'int'=0) -> "double":
        return _deep_feedback_learning.Neuron_getFilteredInput(self, _index, _filter)

    def setWeight(self, _index: 'int', _weight: 'double', _filter: 'int'=0) -> "void":
        return _deep_feedback_learning.Neuron_setWeight(self, _index, _weight, _filter)

    def setError(self, _error: 'double') -> "void":
        return _deep_feedback_learning.Neuron_setError(self, _error)

    def getError(self) -> "double":
        return _deep_feedback_learning.Neuron_getError(self)

    def setInput(self, _index: 'int', _value: 'double') -> "void":
        return _deep_feedback_learning.Neuron_setInput(self, _index, _value)

    def getInput(self, _index: 'int') -> "double":
        return _deep_feedback_learning.Neuron_getInput(self, _index)

    def setBias(self, _bias: 'double') -> "void":
        return _deep_feedback_learning.Neuron_setBias(self, _bias)

    def setLearningRate(self, _learningrate: 'double') -> "void":
        return _deep_feedback_learning.Neuron_setLearningRate(self, _learningrate)

    def setMomentum(self, _momentum: 'double') -> "void":
        return _deep_feedback_learning.Neuron_setMomentum(self, _momentum)

    def setUseDerivative(self, _useDerivative: 'int') -> "void":
        return _deep_feedback_learning.Neuron_setUseDerivative(self, _useDerivative)

    def getNinputs(self) -> "int":
        return _deep_feedback_learning.Neuron_getNinputs(self)

    def getNfilters(self) -> "int":
        return _deep_feedback_learning.Neuron_getNfilters(self)

    def getAvgWeight(self, _input: 'int') -> "double":
        return _deep_feedback_learning.Neuron_getAvgWeight(self, _input)

    def getAvgWeightCh(self, *args) -> "double":
        return _deep_feedback_learning.Neuron_getAvgWeightCh(self, *args)

    def setGeometry(self, _width: 'int', _height: 'int') -> "void":
        return _deep_feedback_learning.Neuron_setGeometry(self, _width, _height)

    def setMask(self, *args) -> "void":
        return _deep_feedback_learning.Neuron_setMask(self, *args)

    def getMask(self, *args) -> "unsigned char":
        return _deep_feedback_learning.Neuron_getMask(self, *args)

    def normaliseWeights(self) -> "void":
        return _deep_feedback_learning.Neuron_normaliseWeights(self)

    def saveInitialWeights(self) -> "void":
        return _deep_feedback_learning.Neuron_saveInitialWeights(self)

    def setDebugInfo(self, _layerIndex: 'int', _neuronIndex: 'int') -> "void":
        return _deep_feedback_learning.Neuron_setDebugInfo(self, _layerIndex, _neuronIndex)

    def setStep(self, _step: 'long') -> "void":
        return _deep_feedback_learning.Neuron_setStep(self, _step)
Neuron_swigregister = _deep_feedback_learning.Neuron_swigregister
Neuron_swigregister(Neuron)

def Neuron_calcOutputThread(object: 'void *') -> "void *":
    return _deep_feedback_learning.Neuron_calcOutputThread(object)
Neuron_calcOutputThread = _deep_feedback_learning.Neuron_calcOutputThread

def Neuron_doLearningThread(object: 'void *') -> "void *":
    return _deep_feedback_learning.Neuron_doLearningThread(object)
Neuron_doLearningThread = _deep_feedback_learning.Neuron_doLearningThread

def Neuron_doMaxDetThread(object: 'void *') -> "void *":
    return _deep_feedback_learning.Neuron_doMaxDetThread(object)
Neuron_doMaxDetThread = _deep_feedback_learning.Neuron_doMaxDetThread

# This file is compatible with both classic and new-style classes.


import os
from abc import abstractmethod

import numpy as np
from keras import backend as K
from keras.callbacks import ModelCheckpoint
from keras.models import model_from_json

from .dap import DAP, DAPRegr
from . import deep_learning_settings


class DeepLearningDAP(DAP):
    """
    DAP Specialisation for plans using Deep Neural Network Models as Learning models
    """

    # Neural Network Specific Metric Keys
    NN_VAL_ACC = 'NN_val_acc'
    NN_ACC = 'NN_acc'
    NN_VAL_LOSS = 'NN_val_loss'
    NN_LOSS = 'NN_loss'
    HISTORY = 'model_history'
    NETWORK_METRICS = [NN_VAL_ACC, NN_ACC, NN_VAL_LOSS, NN_LOSS]

    def __init__(self, experiment):
        super(DeepLearningDAP, self).__init__(experiment=experiment)

        # Set additional attributes from Deep Learning Specific Settings set.
        self.learning_epochs = deep_learning_settings.epochs
        self.batch_size = deep_learning_settings.batch_size
        self.fit_verbose = deep_learning_settings.fit_verbose
        self.fit_callbacks = deep_learning_settings.callbacks

        # extra fit parameters
        self.extra_fit_params = {
            'validation_split': deep_learning_settings.validation_split,
            'shuffle': deep_learning_settings.shuffle,
        }
        if deep_learning_settings.initial_epoch:
            self.extra_fit_params['initial_epoch'] = deep_learning_settings.initial_epoch
        if deep_learning_settings.sample_weight:
            self.extra_fit_params['sample_weight'] = deep_learning_settings.sample_weight
        if deep_learning_settings.class_weight:
            self.extra_fit_params['class_weight'] = deep_learning_settings.class_weight

        # Compilation Settings, we need to salve the class and
        # configuration since after every experiment we need to call
        # K.clear_session to reduce TensorFlow memory leak. This operation
        # destroy the optimizer and we need to recreate it. To do so we need
        # both the class and the configuration
        self.optimizer = deep_learning_settings.optimizer
        if not isinstance(self.optimizer, str):
            self.optimizer_class = self.optimizer.__class__
            self.optimizer_configuration = self.optimizer.get_config()

        self.loss_function = deep_learning_settings.loss
        self.learning_metrics = deep_learning_settings.metrics
        self.loss_weights = deep_learning_settings.loss_weights
        self.extra_compile_params = deep_learning_settings.extra_compilation_parameters

        # Force the `to_categorical` setting to True for Deep Learning DAP
        # (this is True in the 99% of the cases and avoids to bother in case one forgets
        #  to check and set the corresponding setting)
        self.to_categorical = True

        # Model Cache - one model reference per feature step
        self._model_cache = {}
        self._do_serialisation = True  # Checks whether model serialisation works

    @property
    def ml_model(self):
        """Keras Model to be used in DAP.

        Note: Differently from "standard" DAP, bound to sklearn estimators,
        a **brand new** model (network) must be returned at each call,
        namely with a brand new set of weights each time this property is called.
        """
        # if not self.ml_model_:
        #     self.ml_model_ = self.create_ml_model()
        # else:
        #     pass  # Random Shuffling of Weights

        # Note: the value of self._nb_features attribute is updated during the main DAP loop,
        # during each iteration, before this !

        cache_key = self._nb_features
        if cache_key in self._model_cache:
            if self._do_serialisation:
                try:
                    from_json = self._model_cache[cache_key]
                    model = model_from_json(from_json, custom_objects=self.custom_layers_objects())
                except Exception:
                    self._do_serialisation = False
                    self._model_cache = dict()  #reset cache
                    model = self.create_ml_model()
            else:
                model = self.create_ml_model()
        else:
            model = self.create_ml_model()
            if self._do_serialisation:
                try:
                    self._model_cache[cache_key] = model.to_json()
                except Exception:
                    # Something went wrong during serialisation
                    self._do_serialisation = False

        self.ml_model_ = model
        return self.ml_model_

    @property
    def optimizer_name(self):
        return self._get_label(self.optimizer_class)

    def clear_network_graph(self):
        """
        Method that resets the Keras session at the end of each experiment.
        We need this in order to reduce the memory leak from tensorflow.
        Please note that the optimizer is part of the graph so needs to
        be recreated after this call.
        """
        K.clear_session()

        # If the optimizer is not a string we need to recreate it
        # since the graph is new after calling clear session

        if not isinstance(self.optimizer, str):
            self.optimizer = self.optimizer_class(**self.optimizer_configuration)

    def create_ml_model(self):
        """Instantiate a new Keras Deep Network to be used in the fit-predict step.

        Returns
        -------
        model: keras.models.Model
            The new deep learning Keras model.
        """

        model = self._build_network()

        # Set Compilation Params
        extra_compile_params = {}
        if self.loss_weights:
            extra_compile_params['loss_weights'] = self.loss_weights
        if self.extra_compile_params:
            extra_compile_params.update(**self.extra_compile_params)

        model.compile(loss=self.loss_function, optimizer=self.optimizer,
                      metrics=self.learning_metrics, **extra_compile_params)
        return model

    @staticmethod
    def custom_layers_objects():
        """Utility method to specify references to custom layer objects,
        to be used in de-serialising models.

        Returns
        -------
        dic
            dictionary mapping names (strings) to custom classes or functions to be
            considered during deserialization.
            None by default (no custom layer)
        """
        return None

    @abstractmethod
    def _build_network(self):
        """Abstract method that must be implemented by subclasses to actually
        build the Neural Network graph of layers. This method must return a new
        keras.models.Model object."""

    # ==== Overriding of Utility Methods ====
    #
    def _prepare_metrics_array(self):
        """
        Specialise metrics with extra DNN specific metrics.
        """
        metrics = super(DeepLearningDAP, self)._prepare_metrics_array()

        metrics_shape = (self.iteration_steps, self.feature_steps)
        metrics[self.NN_LOSS] = np.zeros(metrics_shape + (deep_learning_settings.epochs,), dtype=np.float)
        metrics[self.NN_VAL_LOSS] = np.zeros(metrics_shape + (deep_learning_settings.epochs,), dtype=np.float)
        metrics[self.NN_ACC] = np.zeros(metrics_shape + (deep_learning_settings.epochs,), dtype=np.float)
        metrics[self.NN_VAL_ACC] = np.zeros(metrics_shape + (deep_learning_settings.epochs,), dtype=np.float)
        return metrics

    def _compute_extra_step_metrics(self, validation_indices=None, y_true_validation=None,
                                    predictions=None, **extra_metrics):
        """
        Compute extra additional step metrics, specific to Neural Network leaning resulting from
        Keras Models.
        In details, kwargs is expected to contain a key for 'model_history'.

        Parameters
        ----------
        validation_indices: array-like, shape = (n_samples, )
            Indices of validation samples

        y_true_validation: array-like, shape = (n_samples, )
            Array of labels for samples in the validation set

        predictions: array-like, shape = [n_samples] or tuple of array-like objects.
            This parameter contains what has been returned by the `_fit_predict` method.

        extra_metrics: dict
            By default, the list of extra metrics will contain model history resulting after training.
            See Also: `_fit_predict` method.
        """

        # Compute Extra Metrics
        model_history = extra_metrics.get(self.HISTORY, None)
        if model_history:
            standard_metrics = ['loss', 'val_loss', 'acc', 'val_acc']
            metric_keys = [self.NN_LOSS, self.NN_VAL_LOSS, self.NN_ACC, self.NN_VAL_ACC]
            for history_key, metric_name in zip(standard_metrics, metric_keys):
                metric_values = model_history.history.get(history_key, None)
                if metric_values:
                    if len(metric_values) < deep_learning_settings.epochs:  # early stopping case
                        values = np.zeros(shape=deep_learning_settings.epochs)
                        values[:len(metric_values)] = metric_values
                    else:
                        values = np.array(metric_values)
                    self.metrics[metric_name][self._iteration_step_nb, self._feature_step_nb] = values

    def _compute_extra_test_metrics(self, y_true_test=None, predictions=None, **extra_metrics):
        """
        Compute extra additional step metrics, specific to Neural Network leaning resulting from
        Keras Models.
        In details, kwargs is expected to contain a key for 'model_history'.

        Parameters
        ----------

        y_true_test: array-like, shape = (n_samples, )
            Array of labels for samples in the validation set

        predictions: array-like, shape = [n_samples] or tuple of array-like objects.
            This parameter contains what has been returned by the `_predict` method.

        extra_metrics: dict
            By default, the list of extra metrics will contain model history resulting after training.
            See Also: `_predict` method.
        """

        # Compute Extra Metrics
        model_history = extra_metrics.get(self.HISTORY, None)
        if model_history:
            standard_metrics = ['loss', 'val_loss', 'acc', 'val_acc']
            metric_keys = [self.NN_LOSS, self.NN_VAL_LOSS, self.NN_ACC, self.NN_VAL_ACC]
            for history_key, metric_name in zip(standard_metrics, metric_keys):
                metric_values = model_history.history.get(history_key, None)
                if metric_values:
                    if len(metric_values) < deep_learning_settings.epochs:  # early stopping case
                        values = np.zeros(shape=deep_learning_settings.epochs)
                        values[:len(metric_values)] = metric_values
                    else:
                        values = np.array(metric_values)
                    self.metrics[self.TEST_SET][metric_name] = values

    def _save_all_metrics_to_file(self, base_output_folder_path, feature_steps, feature_names, sample_names):
        """
        Specialised implementation for Deep learning models, saving to files also
        Network history losses and accuracy.

        Parameters
        ----------
        base_output_folder_path: str
            Path to the output folder where files will be saved.

        feature_steps: list
            List with all feature steps.

        feature_names: list
            List with all the names of the features

        sample_names: list
            List of all sample names
        """

        # Save Base Metrics and CI Metrics as in the Classical DAP
        super(DeepLearningDAP, self)._save_all_metrics_to_file(base_output_folder_path, feature_steps,
                                                               feature_names, sample_names)

        # Save Deep Learning Specific Metrics
        epochs_names = ['epoch {}'.format(e) for e in range(self.learning_epochs)]
        for i_step, step in enumerate(feature_steps):
            for metric_key in self.NETWORK_METRICS:
                self._save_metric_to_file(os.path.join(base_output_folder_path,
                                                       'metric_{}_fs{}.txt'.format(step, metric_key)),
                                          self.metrics[metric_key][:, i_step, :], epochs_names)

    # ==== Overriding of DAP Ops Methods ====
    #
    def _fit_predict(self, model, X_train, y_train, X_validation, y_validation=None):
        """
        Core method to generate metrics on (feature-step) data by fitting
        the input deep learning model and predicting on validation data.
        on validation data.

        Note: The main difference in the implementation of this method relies on the
        fact that the `_fit` method is provided also with validation data (and targets)
        to be fed into the actual `model.fit` method.

        Parameters
        ----------
        model: keras.models.Model
            Deep Learning network model

        X_train: array-like, shape = (n_samples, n_features)
            Training data of the current feature step

        y_train: array-like, shape = (n_samples, )
            Training targets

        X_validation: array-like, shape = (n_samples, n_features)
            Validation data of the current feature step

        y_validation: array-like, shape = (n_samples, ) - default: None
            Validation targets (None by default as it is not used in predict)

        Returns
        -------
        predictions: array-like, shape = (n_samples, ) or tuple of array-like objects.
            Array containing the predictions generated by the model. What is actually
            contained in the `prediction` array-like object is strongly
            related to the task at hand (see `_predict` method)

        extra_metrics: dict
            List of extra metrics to log during execution. By default, the
            network history will be returned.

        See Also
        --------
        DeepLearningDAP._fit(...)
        """

        # Prepare Data
        X_train = self._prepare_data(X_train, training_data=True)
        y_train = self._prepare_targets(y_train, training_labels=True)
        X_validation = self._prepare_data(X_validation, training_data=False)
        y_validation = self._prepare_targets(y_validation, training_labels=False)

        model, extra_metrics = self._fit(model, X_train, y_train,
                                         X_validation=X_validation, y_validation=y_validation)
        predictions = self._predict(model, X_validation)
        return predictions, extra_metrics

    def _fit(self, model, X_train, y_train, X_validation=None, y_validation=None):
        """
        Default implementation of the training (`fit`) step for an input Keras
        Deep Learning Network model.

        Parameters
        ----------
        model: keras.models.Model
            Deep Learning network model

        X_train: array-like, shape = (n_samples, n_features)
            Training data

        y_train: array-like, shape = (n_samples, )
            Training labels

        X_validation: array-like, shape = (n_samples, n_features) - default: None
            Validation data to be used in combination with Training data.
            This parameter has been included to maintain compatibility with
            keras.models.Model.fit API allowing to pass validation data in `fit`.

        y_validation: array-like, shape = (n_samples, ) - default: None
            Validation labels to be used in combination with validation data.
            This parameter has been included to maintain compatibility with
            keras.models.Model.fit API allowing to pass validation data in `fit`.

        Returns
        -------
        model: the model along with learned weights resulting from the actual training
            process.

        extra_metrics: dict
            List of extra metrics to be logged during execution. Default: `model_history`
        """

        # Setup extra fit parameters from settings
        if X_validation is not None and y_validation is not None:
            self.extra_fit_params['validation_data'] = (X_validation, y_validation)
        else:
            self.extra_fit_params.pop('validation_data', None)

        model_filename = '{}_{}_model.hdf5'.format(self._iteration_step_nb, self._nb_features)
        base_output_folder = self.results_folder
        model_filename = os.path.join(base_output_folder, model_filename)
        callbacks = [ModelCheckpoint(filepath=model_filename, save_best_only=True, save_weights_only=True), ]
        if self.fit_callbacks:
            callbacks.extend(self.fit_callbacks)
            if X_validation is None:
                for callback in callbacks:
                    if hasattr(callback, 'monitor') and callback.monitor == 'val_loss':
                        callback.monitor = 'loss'

        if self.fit_verbose != 0:
            print('Experiment {} - fold {}'.format(self._runstep_nb + 1, self._fold_nb + 1))
            print('Step {}, working with {} features'.format(self._feature_step_nb + 1, self._nb_features))

        model_history = model.fit(X_train, y_train, epochs=self.learning_epochs,
                                  batch_size=self.batch_size, verbose=self.fit_verbose,
                                  callbacks=callbacks, **self.extra_fit_params)
        extra_metrics = {
            self.HISTORY: model_history
        }

        return model, extra_metrics

    def _predict(self, model, X_validation, y_validation=None, **kwargs):
        """
        Default implementation of the inference (`predict`) step of input
        Keras model.

        Parameters
        ----------
        model: keras.models.Model
            Deep Learning network model

        X_validation: array-like, shape = (n_samples, n_features)
            Validation data

        y_validation: array-like, shape = (n_samples, ) - default: None
            Validation labels. None by default as it is not used.

        Other Parameters
        ----------------

        kwargs: dict
            Additional arguments to pass to the inference

        Returns
        -------
        predicted_classes: array-like, shape = (n_samples, )
            Array containing the class predictions generated by the model

        predicted_class_probs: array-like, shape = (n_samples, n_classes)
            Array containing the prediction probabilities estimated by the model
            for each of the considered targets (i.e. classes)
        """

        predicted_class_probs = model.predict(X_validation)
        predicted_classes = predicted_class_probs.argmax(axis=-1)
        return (predicted_classes, predicted_class_probs)

    def run(self, verbose=False):
        dap_model = super(DeepLearningDAP, self).run(verbose)

        if verbose:
            dap_model.summary()

        return dap_model


class DeepLearningDAPRegr(DeepLearningDAP, DAPRegr):
    """Deep Learning DAP Specialisation for Regression Tasks"""

    DAP_REFERENCE_METRIC = DAPRegr.R2_CI
    REF_STEP_METRIC = DAPRegr.R2

    BASE_METRICS = [DAPRegr.EVS, DAPRegr.MAE,
                    DAPRegr.MSE, DAPRegr.MedAE, DAPRegr.R2]

    CI_METRICS = [DAPRegr.EVS_CI, DAPRegr.MAE_CI,
                  DAPRegr.MedAE_CI, DAPRegr.MSE_CI, DAPRegr.R2_CI]

    def __init__(self, experiment):
        DeepLearningDAP.__init__(self, experiment)
        DAPRegr.__init__(self, experiment)

        # ==== Overriding of Utility Methods ====
        #
        def _prepare_metrics_array(self):
            """
            Specialise metrics with extra DNN specific metrics.
            """
            metrics = DAPRegr._prepare_metrics_array(self)

            metrics_shape = (self.iteration_steps, self.feature_steps)
            metrics[self.NN_LOSS] = np.zeros(metrics_shape + (deep_learning_settings.epochs,), dtype=np.float)
            metrics[self.NN_VAL_LOSS] = np.zeros(metrics_shape + (deep_learning_settings.epochs,), dtype=np.float)
            metrics[self.NN_ACC] = np.zeros(metrics_shape + (deep_learning_settings.epochs,), dtype=np.float)
            metrics[self.NN_VAL_ACC] = np.zeros(metrics_shape + (deep_learning_settings.epochs,), dtype=np.float)
            return metrics

        def _compute_step_metrics(self, validation_indices, y_true_validation,
                                  predictions, **extra_metrics):
            DAPRegr._compute_step_metrics(self, validation_indices, y_true_validation, predictions, **extra_metrics)

        def _compute_test_metrics(self, y_true_test, predictions, **extra_metrics):
            DAPRegr._compute_test_metrics(self, y_true_test, predictions, **extra_metrics)


# USAGE
# python deep_learning_with_opencv.py --image images/jemma.png --prototxt bvlc_googlenet.prototxt --model bvlc_googlenet.caffemodel --labels synset_words.txt

# import the necessary packages
import numpy as np
import argparse
import time
import cv2

# construct the argument parse and parse the arguments

ap = argparse.ArgumentParser()
ap.add_argument("-i","--image",help="/home/ajitesh/TCS project/deep/deep-learning-opencv/images/eagle.png")
ap.add_argument("-p","--prototxt",help="/home/ajitesh/TCS project/deep/deep-learning-opencv/bvlc_googlenet.prototxt")
ap.add_argument("-m","--model",help="/home/ajitesh/TCS project/deep/deep-learning-opencv/bvlc_googlenet.caffemodel")
ap.add_argument("-l","--labels",help="/home/ajitesh/TCS project/deep/deep-learning-opencv/synset_words.txt")

args = vars(ap.parse_args())
args["image"] = "/home/ajitesh/TCS project/deep/deep-learning-opencv/images/crocodile.jpg"
args["prototxt"] = "/home/ajitesh/TCS project/deep/deep-learning-opencv/bvlc_googlenet.prototxt"
args["model"] = "/home/ajitesh/TCS project/deep/deep-learning-opencv/bvlc_googlenet.caffemodel"
args["labels"] = "/home/ajitesh/TCS project/deep/deep-learning-opencv/synset_words.txt"
# load the input image from disk
image = cv2.imread(args["image"])

# load the class labels from disk
rows = open(args["labels"]).read().strip().split('\n')
classes = [r[r.find(" ") + 1:].split(",")[0] for r in rows]

# our CNN requires fixed spatial dimensions for our input image(s)
# so we need to ensure it is resized to 224x224 pixels while
# performing mean subtraction (104, 117, 123) to normalize the input;
# after executing this command our "blob" now has the shape:
# (1, 3, 224, 224)
blob = cv2.dnn.blobFromImage(image, 1, (224, 224), (104, 117, 123))

# load our serialized model from disk
print("[INFO] loading model...")
net = cv2.dnn.readNetFromCaffe(args["prototxt"], args["model"])

# set the blob as input to the network and perform a forward-pass to
# obtain our output classification
net.setInput(blob)
start = time.time()
preds = net.forward()
end = time.time()
print("[INFO] classification took {:.5} seconds".format(end - start))

# sort the indexes of the probabilities in descending order (higher
# probabilitiy first) and grab the top-5 predictions
idxs = np.argsort(preds[0])[::-1][:5]

# loop over the top-5 predictions and display them
for (i, idx) in enumerate(idxs):
	# draw the top prediction on the input image
	if i == 0:
		text = "Label: {}, {:.2f}%".format(classes[idx],
			preds[0][idx] * 100)
		cv2.putText(image, text, (5, 25),  cv2.FONT_HERSHEY_SIMPLEX,
			0.7, (0, 0, 255), 2)

	# display the predicted label + associated probability to the
	# console	
	print("[INFO] {}. label: {}, probability: {:.5}".format(i + 1,
		classes[idx], preds[0][idx]))

# display the output image
cv2.imshow("Image", image)
cv2.waitKey(0)
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\singh\\\\Box\\\\Deep Learning Project\\\\Scripts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('C:\\\\Users\\\\singh\\\\Box\\\\Deep Learning Project\\\\Data\\\\trainingdata\\\\trainingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Filename</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000kouqjfnk.mp3</td>\n",
       "      <td>Hmong Daw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000w3fewuqj.mp3</td>\n",
       "      <td>Tektiteko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ylhu4sxl.mp3</td>\n",
       "      <td>Teribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0014x3zvjrl.mp3</td>\n",
       "      <td>Chipaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001xjmtk2wx.mp3</td>\n",
       "      <td>KalmykOirat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample Filename     Language\n",
       "0  000kouqjfnk.mp3    Hmong Daw\n",
       "1  000w3fewuqj.mp3    Tektiteko\n",
       "2  000ylhu4sxl.mp3       Teribe\n",
       "3  0014x3zvjrl.mp3      Chipaya\n",
       "4  001xjmtk2wx.mp3  KalmykOirat"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['Hindi','Korean South','Bhojpuri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_sub = train_df[train_df['Language'].isin(languages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1128, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Filename</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>00ywwvulzwa.mp3</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>01pd0w1exxo.mp3</td>\n",
       "      <td>Bhojpuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>01rjjbm5mtn.mp3</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>04ni1ngt11d.mp3</td>\n",
       "      <td>Bhojpuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>05uipha1itb.mp3</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample Filename  Language\n",
       "58   00ywwvulzwa.mp3     Hindi\n",
       "93   01pd0w1exxo.mp3  Bhojpuri\n",
       "96   01rjjbm5mtn.mp3     Hindi\n",
       "275  04ni1ngt11d.mp3  Bhojpuri\n",
       "355  05uipha1itb.mp3     Hindi"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df_sub.shape)\n",
    "train_df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_sub = train_df_sub.groupby('Language').head(65)\n",
    "train_df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Filename</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>00ywwvulzwa.wav</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>01pd0w1exxo.wav</td>\n",
       "      <td>Bhojpuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>01rjjbm5mtn.wav</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>04ni1ngt11d.wav</td>\n",
       "      <td>Bhojpuri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>05uipha1itb.wav</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample Filename  Language\n",
       "58   00ywwvulzwa.wav     Hindi\n",
       "93   01pd0w1exxo.wav  Bhojpuri\n",
       "96   01rjjbm5mtn.wav     Hindi\n",
       "275  04ni1ngt11d.wav  Bhojpuri\n",
       "355  05uipha1itb.wav     Hindi"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_sub['Sample Filename'] = train_df_sub['Sample Filename'].str.replace('.mp3', '.wav')\n",
    "train_df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"C:\\\\Users\\\\singh\\\\Box\\\\Deep Learning Project\\\\Data\\\\trainingdata\\\\hindi_korean_bhojpuri(wav)\\\\\"\n",
    "dirpath = \"C:\\\\Users\\\\singh\\\\Box\\\\Deep Learning Project\\\\Data\\\\trainingdata\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_op(file):\n",
    "    #Loading train files\n",
    "\n",
    "    s,sr=librosa.load(file, sr=None)\n",
    "    S=librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "\n",
    "    #Taking absolute of input and output of training file\n",
    "    S =  S.T\n",
    "    S_abs = np.abs(S)\n",
    "\n",
    "    #print(S_abs.shape)\n",
    "\n",
    "    return s, S, S_abs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\00ywwvulzwa.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\01pd0w1exxo.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\01rjjbm5mtn.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\04ni1ngt11d.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\05uipha1itb.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0adiw4jd2vh.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0brzbaynfio.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0bwbfbfxvr1.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0ec1nsncnvc.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0fleyjxbw1v.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0iapd2lck0h.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0jzzkllnyli.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0kajiv5vnlh.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0kznowsn4ql.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0mw2tiuqjlf.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0nffepjlfmp.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0ujcc5vsbnh.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\0wmrtwefmwj.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\11uekpvwm22.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\11ycidyh11g.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\121mmfyqbe5.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\12fb5ikeyw3.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1311wyyqphh.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\13afhgg50ub.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\13ddk3dm5oq.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\13oa4ebmzqj.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\15tgxn4hlfh.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\15wx0v40dzx.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1alv0fra4vu.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1b3j0hx1zdr.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1cm4vsulfew.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1fwa0bfo3vs.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1fwlmcgnphl.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1kdl2vnundp.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1lrc2bucups.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1mqlurofzcu.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1nc0wjirijz.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1oyr4dz52g0.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1pjtfhcpdg0.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1qncsun4yrl.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1sj05icgtjh.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1skknmtzfh2.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1smbn4j3qry.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1wifa3dsmpd.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1x0abi1c3tn.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1xxo2awjkb1.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1yyn1gkhmvf.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\1yzw1435jld.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2110d4cxwug.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\21vg4zerfe5.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\22zzsqa1wlc.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\23bkbsxcpgk.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\23hw2wbqume.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\23p4pdegqri.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\244elznv4cw.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\25cunnkzu0g.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\25ddeltl15h.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2a5y0dd4ns1.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2c4fwaqnclb.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2czq3regbma.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2d2x1krrc12.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2d33gnhklg5.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2dpgzj4xxkr.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2f0vht0taxz.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2flc0crdrum.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2gchuwhdgwx.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2gk23agp2hp.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2gt53rgrw3d.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2i2ldczbbas.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2ijrmsw43m1.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2ju5wd5dumr.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2k2lgwuhppf.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2lmgrhwhjsu.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2lx2eyfi4do.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2lx5k3do3uv.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2msjr3tf3oz.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2msowsm0pbr.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2q54l5qscyv.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2qw2zhf4bmj.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2ro0pfyzucj.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2sgpwo1rstm.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2taqiixnnjt.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2trrucsgbod.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2uv5yun0xj0.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2uykq4jfgki.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2vknz0hfmoa.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2wl2q1racvx.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2x4tecw54un.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2y4j5w5yvgn.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2yabznqz1vo.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2zrgzwzzfid.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\2zyeu5y2qn4.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\303i0jxtcgj.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\303tck3ujzp.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\30g1nwk5hxl.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\30kwtoyy3kh.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\30qj50uno3v.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\30wakqpg0ik.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\321dwezqtyp.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\32pesuxa1zk.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\32un2sjlose.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\333lh4wdskf.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\33dv3fbkx3n.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3503wszdsxx.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\35f20wnrbbj.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\35xkqrhilyo.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3ci3abxd1fo.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3ctfpxcyws2.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3cyixevccwg.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3emmoabevvf.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3eq25qnjnw5.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3fet3eip1g3.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3getwxbgulr.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3hjn4cdm4m1.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3hkd0x21ls4.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3hzb05urel2.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3j251v3yy3z.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3kwlqzty5nu.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3n4dvdgr2xl.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3ot1vbptfba.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3piuebekss2.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3q51xcd3ebx.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3rlyeyind0i.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3sfmaqwmjpn.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3sg3c3jgn1u.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3t4o2kxbuch.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3tc5otdvmf5.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3vkq0ud3ox5.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3vpdesgl4f4.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3wfxswk2anj.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3xuval2d5xf.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3yphtsetzjy.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\3zlcjvovbqe.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\400meynwhej.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\40kpxyq04jx.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\41444cl2thw.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\44hhsusdcoj.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\44resubvuct.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\45mfabo2nhn.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4aplyhc11dr.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4axhsvojxia.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4b41wqocpcy.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4c2iozudizb.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4cbidr2n3wg.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4eiqggoemxr.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4gnnswrym3f.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4hwzkdudxzc.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4j1ve5rugls.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4jdw2v3b2fy.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4jwuywy4xrc.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4jz2djsy2ah.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4khy25oflfi.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4kv3rtor552.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4ma2zcahd2c.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4mbjjv1pa1j.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4p5eviwcirv.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4po5vfu4nh2.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4psd4yxutci.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4qj0htvj0ke.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4qm4ji4lvo2.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4re3uw2dst4.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4ryxft1xeff.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4ryxvjo2pth.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4tyart0o2gd.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4yphyvq5d40.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4yqe3vu5sjf.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4zg0fyam2fs.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4zohwg05n5f.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\4ztlvj0qyqi.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\50opr5mjf24.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\513lskr23aa.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\51xuauuvnl4.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\51zh0ncsb15.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\52huplnatks.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\53hbzaux3t3.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\54bap1f30m0.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5bc4e01v4nt.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5blfwdv1q1e.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5c41esw0ct0.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5chliw2ksxi.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5ddxyj5kn2j.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5gsmw5f4l43.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5jqkpeea41j.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5kghm0bjkdl.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5mmfk5lgw0r.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5ns34yssa5w.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5ny1m0xc05b.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5qixiozlp43.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5sanv2lyu4r.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5tktnekdmgc.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5twwedyrcpq.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5ugtfrmac54.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5ulmx0z0h40.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5uv3cnuw0bd.wav\n",
      "C:\\Users\\singh\\Box\\Deep Learning Project\\Data\\trainingdata\\hindi_korean_bhojpuri(wav)\\5vfbugmcczp.wav\n"
     ]
    }
   ],
   "source": [
    "at_list = []\n",
    "spec_list = []\n",
    "spec_abs_list = []\n",
    "labels = []\n",
    "\n",
    "for i in range(train_df_sub.shape[0]):\n",
    "    file = directory+train_df_sub.iloc[i][0]\n",
    "    print(file)\n",
    "    \n",
    "    at, spec, spec_abs = file_op(file)\n",
    "    \n",
    "    at_list.append(at)\n",
    "    spec_list.append(spec)\n",
    "    spec_abs_list.append(spec_abs)\n",
    "    labels.append(train_df_sub.iloc[i][1])\n",
    "    \n",
    "    \n",
    "sound_lists = {'at_list':at_list,\n",
    "               'spec_list': spec_list,\n",
    "               'spec_abs_list': spec_abs_list,\n",
    "               'labels': labels\n",
    "              }\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickling the training data dictionary\n",
    "sound_lists_pkl = open(dirpath+\"train_sound_lists.pkl\",\"wb\")\n",
    "pickle.dump(sound_lists, sound_lists_pkl)\n",
    "sound_lists_pkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(train_df_sub.shape[0]):\n",
    "#     path = path = directory+train_df_sub.iloc[i][0]\n",
    "#     shutil.copy(path,'C:\\\\Users\\\\singh\\\\Box\\\\Deep Learning Project\\\\Data\\\\trainingdata\\\\hindi_korean_bhojpuri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics.regression import r2_score, mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import AdaBoostRegressor
# import GridSearchCV
import xlrd
import math
import matplotlib.pyplot as plt
import logging
import os
import sys
import pandas as pd
from sklearn import svm
# from queue import Queue
from threading import Thread
from multiprocessing import Process, Queue
import os
import datetime

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
# 默认为0：输出所有log信息
# 设置为1：进一步屏蔽INFO信息
# 设置为2：进一步屏蔽WARNING信息
# 设置为3：进一步屏蔽ERROR信息

np.random.seed(1337)  # for reproducibility
logging.basicConfig(level=logging.INFO)


def train_model(learning_rate_rbm, learning_rate, batch_size, x_train, y_trian, x_test, message_queue):
    path_DBN = os.path.join(os.path.join(os.path.dirname(os.path.abspath(__file__)), "models"), "deep-belief-network")
    sys.path.append(path_DBN)
    from dbn.tensorflow import SupervisedDBNRegression

    regressor_DBN = SupervisedDBNRegression(learning_rate_rbm=learning_rate_rbm, learning_rate=learning_rate,
                                            batch_size=batch_size, verbose=False)
    regressor_DBN.fit(x_train, y_trian)
    pred = regressor_DBN.predict(x_test)
    message_queue.put(pred)
    return


def train_model_func(learning_rate_rbm, learning_rate, batch_size, feature, label, path_out_png, pred_num, train_deep,
                     step):
    # X_train, X_test, Y_train, Y_test = train_test_split(feature, label, test_size=0.2, shuffle=False)

    print("Training model...")
    print("RMSE (on training data):")
    root_mean_squared_errors = []
    message_queue = Queue()

    # for deep in range(1, train_deep + 1):
    for _step in range(1, step + 1):
        Feature = np.array([])
        for _start in range(_step, feature.shape[0] + 1):
            Feature=np.append(Feature, feature[_start - _step:_start].values)
        Lable=label[_step-1:]
        Feature = Feature.reshape(Lable.shape[0],math.floor(Feature.size/Lable.shape[0]))

        X_train, X_test, Y_train, Y_test = train_test_split(Feature, Lable, test_size=0.2, shuffle=False)

        deep = train_deep
        RMSE_total = 0

        for i in range(0, pred_num):
            starttime = datetime.datetime.now()

            x_train = np.array(X_train[X_train.shape[0] - i - deep:X_train.shape[0] - i])
            y_trian = np.array(Y_train[Y_train.shape[0] - i - deep:Y_train.shape[0] - i])
            x_test = np.array(X_test)
            y_test = np.array(Y_test)

            _process = Process(target=train_model, args=(
                learning_rate_rbm, learning_rate, batch_size, x_train, y_trian, x_test, message_queue))
            _process.start()
            _process.join()
            predictions = message_queue.get()

            root_mean_squared_error = math.sqrt(mean_squared_error(y_test, predictions))
            endtime = datetime.datetime.now()
            print("\t\ti:\t", root_mean_squared_error, "\t\tusing seconds:\t", (endtime - starttime).seconds)
            RMSE_total += root_mean_squared_error

        RMSE_avg = RMSE_total / pred_num
        root_mean_squared_errors.append(RMSE_avg)
        #print("train_deep:", deep, "\tRMSE_avg:", RMSE_avg)
        print("step:", _step, "\tRMSE_avg:", RMSE_avg)

        # Output a graph of loss metrics over periods.
        # plt.subplot(1, 2, 2)
        plt.ylabel('RMSE')
        plt.xlabel('Step')
        plt.title("Root Mean Squared Error vs. Step")
        plt.tight_layout()
        plt.plot(root_mean_squared_errors)
        plt.savefig(path_out_png)

    print("finished.")


path_data = "data/airdata.csv"
path_out_png = "out/out_test_Step.png"

data = pd.read_csv(path_data, sep=",")

target = data["pm25"]
target = target.drop([0])

data = data.drop([data.shape[0] - 1])
data = data.drop(["date"], axis=1)

learning_rate_rbm = 0.01
learning_rate = 0.00001
batch_size = 1
pred_num = 3
train_deep = 10
step = 200

train_model_func(learning_rate_rbm=learning_rate_rbm, learning_rate=learning_rate, batch_size=batch_size, feature=data,
                 label=target, path_out_png=path_out_png, pred_num=pred_num, train_deep=train_deep, step=step)
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics.regression import r2_score, mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import AdaBoostRegressor
# import GridSearchCV
import xlrd
import math
import matplotlib.pyplot as plt
import logging
import os
import sys
import pandas as pd
from sklearn import svm
# from queue import Queue
from threading import Thread
from multiprocessing import Process, Queue
import os
import datetime

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
# 默认为0：输出所有log信息
# 设置为1：进一步屏蔽INFO信息
# 设置为2：进一步屏蔽WARNING信息
# 设置为3：进一步屏蔽ERROR信息

np.random.seed(1337)  # for reproducibility
logging.basicConfig(level=logging.INFO)


def train_model(learning_rate_rbm, learning_rate, batch_size, x_train, y_trian, x_test, message_queue):
    path_DBN = os.path.join(os.path.join(os.path.dirname(os.path.abspath(__file__)), "models"), "deep-belief-network")
    sys.path.append(path_DBN)
    from dbn.tensorflow import SupervisedDBNRegression

    regressor_DBN = SupervisedDBNRegression(learning_rate_rbm=learning_rate_rbm, learning_rate=learning_rate,
                                            batch_size=batch_size, verbose=False)
    regressor_DBN.fit(x_train, y_trian)
    pred = regressor_DBN.predict(x_test)
    message_queue.put(pred)
    return


def train_model_func(learning_rate_rbm, learning_rate, batch_size, feature, label, path_out_png, pred_num, train_deep):
    X_train, X_test, Y_train, Y_test = train_test_split(feature, label, test_size=0.2, shuffle=False)

    print("Training model...")
    print("RMSE (on training data):")
    root_mean_squared_errors = []
    message_queue = Queue()

    for deep in range(1, train_deep + 1):
        RMSE_total = 0

        for i in range(0, pred_num):
            starttime = datetime.datetime.now()

            x_train = np.array(X_train[X_train.shape[0] - i - deep:X_train.shape[0] - i])
            y_trian = np.array(Y_train[Y_train.shape[0] - i - deep:Y_train.shape[0] - i])
            x_test = np.array(X_test)
            y_test = np.array(Y_test)

            _process = Process(target=train_model, args=(
                learning_rate_rbm, learning_rate, batch_size, x_train, y_trian, x_test, message_queue))
            _process.start()
            _process.join()
            predictions = message_queue.get()

            root_mean_squared_error = math.sqrt(mean_squared_error(y_test, predictions))
            endtime = datetime.datetime.now()
            print("\t\ti:\t", root_mean_squared_error, "\t\tusing seconds:\t", (endtime - starttime).seconds)
            RMSE_total += root_mean_squared_error

        RMSE_avg = RMSE_total / pred_num
        root_mean_squared_errors.append(RMSE_avg)
        print("train_deep:", deep, "\tRMSE_avg:", RMSE_avg)

        # Output a graph of loss metrics over periods.
        # plt.subplot(1, 2, 2)
        plt.ylabel('RMSE')
        plt.xlabel('train_deep')
        plt.title("Root Mean Squared Error vs. Train Deep")
        plt.tight_layout()
        plt.plot(root_mean_squared_errors)
        plt.savefig(path_out_png)

    print("finished.")


path_data = "data/airdata.csv"
path_out_png = "out/out_test_1.png"

data = pd.read_csv(path_data, sep=",")

target = data["pm25"]
target = target.drop([0])

data = data.drop([data.shape[0] - 1])
data = data.drop(["date"], axis=1)
# print(data["date"])


learning_rate_rbm = 0.01
learning_rate = 0.01
batch_size = 16
pred_num = 3
train_deep = 200

train_model_func(learning_rate_rbm=learning_rate_rbm, learning_rate=learning_rate, batch_size=batch_size, feature=data,
                 label=target, path_out_png=path_out_png, pred_num=pred_num, train_deep=train_deep)from itertools import product

import numpy as np
from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
from matplotlib.figure import Figure
from matplotlib import patches, lines

import common

PART_NUM = 6


def generate_fig1():
    fig = Figure(figsize=(8, 4))
    canvas = FigureCanvas(fig)
    ax = fig.add_axes((0.01, 0.01, 0.98, 0.98))
    common.set_ax_params(ax)
    ax.axis([0., 2., 0., 1.])
    
    w = 0.3
    h = 0.2
    for x,y in product([0.3, 1., 1.7], [0.3, 0.7]):
        ax.add_patch(patches.FancyBboxPatch(
            (x - w / 2., y - h / 2.),
            width=w,
            height=h,
            boxstyle="round,pad=0.01",
            facecolor="lightblue",
            edgecolor="darkblue"
        ))

    ax.text(0.3, 0.7, "Q-iteration", ha="center", va="center", size="large")
    ax.text(0.3, 0.3, "P-iteration", ha="center", va="center", size="large")
    ax.text(1., 0.7, "Q-learning", ha="center", va="center", size="large")
    ax.text(1., 0.3, "P-learning", ha="center", va="center", size="large")
    ax.text(1.7, 0.7, "Deep\nQ-learning", ha="center", va="center",
        size="large")
    ax.text(1.7, 0.3, "Deep\nP-learning", ha="center", va="center",
        size="large")

    w = 0.25
    h = 0.1
    for x,y in product([1.3/2., 2.7/2.], [0.3, 0.7]):
        ax.add_patch(patches.FancyBboxPatch(
            (x - w / 2. - 0.02, y - h / 2.),
            width=w,
            height=h,
            boxstyle="rarrow,pad=0.01",
            facecolor="lightgreen",
            edgecolor="darkgreen"
        ))
    
    ax.text(1.3/2., 0.7, "Unknown\nModel", ha="center", va="center",
        size="small")
    ax.text(1.3/2., 0.3, "Unknown\nModel", ha="center", va="center",
        size="small")
    ax.text(2.7/2., 0.7, "Continuous\nState Space", ha="center", va="center",
        size="small")
    ax.text(2.7/2., 0.3, "Continuous\nState Space", ha="center", va="center",
        size="small")

    common.save_next_fig(PART_NUM, fig)


def generate_fig2():
    fig = Figure(figsize=(4, 4))
    canvas = FigureCanvas(fig)
    ax = fig.add_axes((0.01, 0.01, 0.98, 0.98))
    common.set_ax_params(ax)
    ax.set_facecolor("white")
    ax.axis([0., 1., 0., 1.])
    
    ax.add_artist(patches.Rectangle((0.2, 0.1), 0.7, 0.7,
        facecolor="lightgrey", edgecolor="None"))
    
    ax.add_artist(lines.Line2D([0.55, 0.55], [0.1, 0.8], color="red"))
    ax.add_artist(lines.Line2D([0.2, 0.2], [0.1, 0.8], color="black"))
    ax.add_artist(lines.Line2D([0.9, 0.9], [0.1, 0.8], color="black"))
    
    ax.add_artist(lines.Line2D([0.2, 0.9], [0.1, 0.1], color="black"))
    ax.add_artist(lines.Line2D([0.2, 0.9], [0.8, 0.8], color="black"))
    ax.add_artist(lines.Line2D([0.2, 0.9], [0.45, 0.45], color="black"))
    
    ax.text((0.2 + 0.55) / 2., 0.87, "Known\nModel", ha="center", va="center",
        size="medium")
    ax.text((0.9 + 0.55) / 2., 0.87, "Unknown\nModel", ha="center", va="center",
        size="medium")
    
    ax.text(0.1, (0.1 + 0.45) / 2., "Continuous", ha="center", va="center",
        size="medium", rotation=50)
    ax.text(0.1, (0.8 + 0.45) / 2., "Discrete", ha="center", va="center",
        size="medium", rotation=50)
    
    ax.text((0.2 + 0.55) / 2., (0.1 + 0.45) / 2.,
        "Deep-Q-Iteration\n\nDeep-P-Iteration",
        ha="center", va="center", size="small")
    ax.text((0.9 + 0.55) / 2., (0.1 + 0.45) / 2.,
        "Deep-Q-Learning\n\nDeep-P-Learning",
        ha="center", va="center", size="small")
    
    ax.text((0.2 + 0.55) / 2., (0.8 + 0.45) / 2.,
        "Q-Iteration\n\nP-Iteration",
        ha="center", va="center", size="small")
    ax.text((0.9 + 0.55) / 2., (0.8 + 0.45) / 2.,
        "Q-Learning\n\nP-Learning",
        ha="center", va="center", size="small")
    
    common.save_next_fig(PART_NUM, fig)


DATA_FILES = [
    common.DataFile("actor_critic", "Actor Critic", 1000, []),
    common.DataFile("actor_critic_self", "Actor Critic\nSelf-Play Mode", 1000, []),
    common.DataFile("success_learning_critic", "Success Learning with a Critic", 1000, []),
    common.DataFile("success_learning_critic_self", "Success Learning with a Critic\nSelf-Play Mode", 1000, []),
    common.DataFile("deep_p", "Deep-P-Learning", 1000, []),
    common.DataFile("deep_p_self", "Deep-P-Learning\nSelf-Play Mode", 1000, [])
]


if __name__ == "__main__":
    generate_fig1()
    generate_fig2()
    common.generate_plots(DATA_FILES, PART_NUM)
import collections
import os
import pickle
import sys

import bitstring
import h5py
import numpy as np
import theano
import theano.tensor as T
from theano.tensor.shared_randomstreams import RandomStreams

sys.path.append('./')
sys.path.append('./deep_learning/')

from deep_learning.classes_and_functions import Linear_SdA
from deep_learning.logistic_sgd import load_data
from deep_learning.utils import tile_raster_images
from deep_learning.dA import dA
from deep_learning.SdA import SdA


batch_size=128

with h5py.File('deep_learning_data/flickr_32x32_varpatches.hdf5', 'r') as f:
    X = f['X'][:] 

X_std = np.std(X)
X_mean = np.mean(X)
X = (X-X_mean) / X_std

train_set_x = X 
valid_set_x = X[1925000:1975000]
test_set_x = X[1975000:]
numpy_rng = np.random.RandomState(89677)

sda = Linear_SdA(
    numpy_rng=numpy_rng,
    n_ins=112*3,
    hidden_layers_sizes=[1024, 512, 256, 128, 64, 28]
)

# load parameters from previous training 
parameters = pickle.load(open('deep_learning_data/sda_parameters_varpatch.p', 'rb'))
for value, param in zip(parameters, sda.params):
    param.set_value(value)

get_code = theano.function(
            [sda.x],
            [sda.sigmoid_layers[-1].output])

hashing_table = collections.defaultdict(list)
#with h5py.File('./deep_learning_data/varpatch_codes_sda.hdf5') as f:
#    ds = f.create_dataset('X', shape=(25000, 81), dtype='uint')

for i in range(81):
    if i % 9 == 0:
        print(i)
    codes = np.round(get_code(X[i*25000:(i+1)*25000].reshape(-1,336))).reshape(-1,28)

    with h5py.File('./deep_learning_data/varpatch_codes_sda.hdf5') as f:
        #ds = f.create_dataset('X', shape=(25000, 81), dtype='uint')
        ds = f['X']
        for j in range(25000):
            ds[j,i] = bitstring.Bits(codes[j]).uint

    for j in range(25000):
        code = codes[j]
        code_uint = bitstring.Bits(code).uint
        # the way defaultdict behaves, if code_uint already exists as a key, the image index j is appended to the correspoding list,
        #   if not, a new key:value pair (code_uint:[j]) is created
        hashing_table[code_uint].append(j)

    #with h5py.File('./deep_learning_data/varpatch_hashing_table_sda.hdf5') as f:
    #    dtype = h5py.special_dtype(vlen=np.dtype('int32'))
    #    #ds = f.create_dataset('X', (2**28,), dtype=dtype)
    #    ds = f['X']
    #    for j in range(25000):
    #        code = codes[j]
    #        if i == 0
    #        ds[bitstring.Bits(code).uint] = np.append(ds[bitstring.Bits(code).uint], j)
pickle.dump(hashing_table, open('./deep_learning_data/sda_varpatch_hashing_table.p', 'wb'))
# This file was automatically generated by SWIG (http://www.swig.org).
# Version 3.0.8
#
# Do not make changes to this file unless you know what you are doing--modify
# the SWIG interface file instead.





from sys import version_info
if version_info >= (2, 6, 0):
    def swig_import_helper():
        from os.path import dirname
        import imp
        fp = None
        try:
            fp, pathname, description = imp.find_module('_deep_feedback_learning', [dirname(__file__)])
        except ImportError:
            import _deep_feedback_learning
            return _deep_feedback_learning
        if fp is not None:
            try:
                _mod = imp.load_module('_deep_feedback_learning', fp, pathname, description)
            finally:
                fp.close()
            return _mod
    _deep_feedback_learning = swig_import_helper()
    del swig_import_helper
else:
    import _deep_feedback_learning
del version_info
try:
    _swig_property = property
except NameError:
    pass  # Python < 2.2 doesn't have 'property'.


def _swig_setattr_nondynamic(self, class_type, name, value, static=1):
    if (name == "thisown"):
        return self.this.own(value)
    if (name == "this"):
        if type(value).__name__ == 'SwigPyObject':
            self.__dict__[name] = value
            return
    method = class_type.__swig_setmethods__.get(name, None)
    if method:
        return method(self, value)
    if (not static):
        if _newclass:
            object.__setattr__(self, name, value)
        else:
            self.__dict__[name] = value
    else:
        raise AttributeError("You cannot add attributes to %s" % self)


def _swig_setattr(self, class_type, name, value):
    return _swig_setattr_nondynamic(self, class_type, name, value, 0)


def _swig_getattr_nondynamic(self, class_type, name, static=1):
    if (name == "thisown"):
        return self.this.own()
    method = class_type.__swig_getmethods__.get(name, None)
    if method:
        return method(self)
    if (not static):
        return object.__getattr__(self, name)
    else:
        raise AttributeError(name)

def _swig_getattr(self, class_type, name):
    return _swig_getattr_nondynamic(self, class_type, name, 0)


def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)

try:
    _object = object
    _newclass = 1
except AttributeError:
    class _object:
        pass
    _newclass = 0


class DeepFeedbackLearning(_object):
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, DeepFeedbackLearning, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, DeepFeedbackLearning, name)
    __repr__ = _swig_repr

    def __init__(self, *args):
        this = _deep_feedback_learning.new_DeepFeedbackLearning(*args)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _deep_feedback_learning.delete_DeepFeedbackLearning
    __del__ = lambda self: None
    backprop = _deep_feedback_learning.DeepFeedbackLearning_backprop
    ico = _deep_feedback_learning.DeepFeedbackLearning_ico

    def doStep(self, *args) -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_doStep(self, *args)

    def getOutput(self, index: 'int') -> "double":
        return _deep_feedback_learning.DeepFeedbackLearning_getOutput(self, index)

    def setLearningRate(self, learningRate: 'double') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_setLearningRate(self, learningRate)

    def setAlgorithm(self, _algorithm: 'DeepFeedbackLearning::Algorithm') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_setAlgorithm(self, _algorithm)

    def getAlgorithm(self) -> "DeepFeedbackLearning::Algorithm":
        return _deep_feedback_learning.DeepFeedbackLearning_getAlgorithm(self)

    def initWeights(self, *args) -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_initWeights(self, *args)

    def seedRandom(self, s: 'int') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_seedRandom(self, s)

    def setBias(self, _bias: 'double') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_setBias(self, _bias)

    def getNumHidLayers(self) -> "int":
        return _deep_feedback_learning.DeepFeedbackLearning_getNumHidLayers(self)

    def getLayer(self, i: 'int') -> "Layer *":
        return _deep_feedback_learning.DeepFeedbackLearning_getLayer(self, i)

    def getOutputLayer(self) -> "Layer *":
        return _deep_feedback_learning.DeepFeedbackLearning_getOutputLayer(self)

    def getLayers(self) -> "Layer **":
        return _deep_feedback_learning.DeepFeedbackLearning_getLayers(self)

    def setUseDerivative(self, useIt: 'int') -> "void":
        return _deep_feedback_learning.DeepFeedbackLearning_setUseDerivative(self, useIt)
DeepFeedbackLearning_swigregister = _deep_feedback_learning.DeepFeedbackLearning_swigregister
DeepFeedbackLearning_swigregister(DeepFeedbackLearning)

class Layer(_object):
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, Layer, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, Layer, name)
    __repr__ = _swig_repr

    def __init__(self, _nNeurons: 'int', _nInputs: 'int', _nFilters: 'int'=0, _minT: 'double'=0, _maxT: 'double'=0):
        this = _deep_feedback_learning.new_Layer(_nNeurons, _nInputs, _nFilters, _minT, _maxT)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _deep_feedback_learning.delete_Layer
    __del__ = lambda self: None

    def calcOutputs(self) -> "void":
        return _deep_feedback_learning.Layer_calcOutputs(self)

    def doLearning(self) -> "void":
        return _deep_feedback_learning.Layer_doLearning(self)

    def setError(self, *args) -> "void":
        return _deep_feedback_learning.Layer_setError(self, *args)

    def setErrors(self, _errors: 'double *') -> "void":
        return _deep_feedback_learning.Layer_setErrors(self, _errors)

    def getError(self, i: 'int') -> "double":
        return _deep_feedback_learning.Layer_getError(self, i)

    def setBias(self, _bias: 'double') -> "void":
        return _deep_feedback_learning.Layer_setBias(self, _bias)

    def setUseDerivative(self, useIt: 'int') -> "void":
        return _deep_feedback_learning.Layer_setUseDerivative(self, useIt)

    def setInput(self, inputIndex: 'int', input: 'double') -> "void":
        return _deep_feedback_learning.Layer_setInput(self, inputIndex, input)

    def setInputs(self, _inputs: 'double *') -> "void":
        return _deep_feedback_learning.Layer_setInputs(self, _inputs)

    def setLearningRate(self, _learningRate: 'double') -> "void":
        return _deep_feedback_learning.Layer_setLearningRate(self, _learningRate)

    def initWeights(self, *args) -> "void":
        return _deep_feedback_learning.Layer_initWeights(self, *args)

    def getOutput(self, index: 'int') -> "double":
        return _deep_feedback_learning.Layer_getOutput(self, index)

    def getNeuron(self, index: 'int') -> "Neuron *":
        return _deep_feedback_learning.Layer_getNeuron(self, index)

    def getNneurons(self) -> "int":
        return _deep_feedback_learning.Layer_getNneurons(self)

    def getNinputs(self) -> "int":
        return _deep_feedback_learning.Layer_getNinputs(self)

    def setConvolution(self, width: 'int', height: 'int') -> "void":
        return _deep_feedback_learning.Layer_setConvolution(self, width, height)

    def setMaxDetLayer(self, _m: 'int') -> "void":
        return _deep_feedback_learning.Layer_setMaxDetLayer(self, _m)

    def setNormaliseWeights(self, _normaliseWeights: 'int') -> "void":
        return _deep_feedback_learning.Layer_setNormaliseWeights(self, _normaliseWeights)

    def setDebugInfo(self, layerIndex: 'int') -> "void":
        return _deep_feedback_learning.Layer_setDebugInfo(self, layerIndex)

    def setStep(self, step: 'long') -> "void":
        return _deep_feedback_learning.Layer_setStep(self, step)

    def getWeightDistanceFromInitialWeights(self) -> "double":
        return _deep_feedback_learning.Layer_getWeightDistanceFromInitialWeights(self)
Layer_swigregister = _deep_feedback_learning.Layer_swigregister
Layer_swigregister(Layer)

class Neuron(_object):
    __swig_setmethods__ = {}
    __setattr__ = lambda self, name, value: _swig_setattr(self, Neuron, name, value)
    __swig_getmethods__ = {}
    __getattr__ = lambda self, name: _swig_getattr(self, Neuron, name)
    __repr__ = _swig_repr

    def __init__(self, _nInputs: 'int', _nFilters: 'int'=0, _minT: 'double'=0, _maxT: 'double'=0):
        this = _deep_feedback_learning.new_Neuron(_nInputs, _nFilters, _minT, _maxT)
        try:
            self.this.append(this)
        except Exception:
            self.this = this
    __swig_destroy__ = _deep_feedback_learning.delete_Neuron
    __del__ = lambda self: None

    def calcOutput(self) -> "void":
        return _deep_feedback_learning.Neuron_calcOutput(self)
    __swig_getmethods__["calcOutputThread"] = lambda x: _deep_feedback_learning.Neuron_calcOutputThread
    if _newclass:
        calcOutputThread = staticmethod(_deep_feedback_learning.Neuron_calcOutputThread)

    def doLearning(self) -> "void":
        return _deep_feedback_learning.Neuron_doLearning(self)
    __swig_getmethods__["doLearningThread"] = lambda x: _deep_feedback_learning.Neuron_doLearningThread
    if _newclass:
        doLearningThread = staticmethod(_deep_feedback_learning.Neuron_doLearningThread)

    def doMaxDet(self) -> "void":
        return _deep_feedback_learning.Neuron_doMaxDet(self)
    __swig_getmethods__["doMaxDetThread"] = lambda x: _deep_feedback_learning.Neuron_doMaxDetThread
    if _newclass:
        doMaxDetThread = staticmethod(_deep_feedback_learning.Neuron_doMaxDetThread)
    MAX_OUTPUT_RANDOM = _deep_feedback_learning.Neuron_MAX_OUTPUT_RANDOM
    MAX_WEIGHT_RANDOM = _deep_feedback_learning.Neuron_MAX_WEIGHT_RANDOM
    MAX_OUTPUT_CONST = _deep_feedback_learning.Neuron_MAX_OUTPUT_CONST
    CONST_WEIGHTS = _deep_feedback_learning.Neuron_CONST_WEIGHTS

    def initWeights(self, *args) -> "void":
        return _deep_feedback_learning.Neuron_initWeights(self, *args)

    def getMinWeightValue(self) -> "double":
        return _deep_feedback_learning.Neuron_getMinWeightValue(self)

    def getMaxWeightValue(self) -> "double":
        return _deep_feedback_learning.Neuron_getMaxWeightValue(self)

    def getWeightDistanceFromInitialWeights(self) -> "double":
        return _deep_feedback_learning.Neuron_getWeightDistanceFromInitialWeights(self)

    def getOutput(self) -> "double":
        return _deep_feedback_learning.Neuron_getOutput(self)

    def getSum(self) -> "double":
        return _deep_feedback_learning.Neuron_getSum(self)

    def getWeight(self, _index: 'int', _filter: 'int'=0) -> "double":
        return _deep_feedback_learning.Neuron_getWeight(self, _index, _filter)

    def setWeight(self, _index: 'int', _weight: 'double', _filter: 'int'=0) -> "void":
        return _deep_feedback_learning.Neuron_setWeight(self, _index, _weight, _filter)

    def setError(self, _error: 'double') -> "void":
        return _deep_feedback_learning.Neuron_setError(self, _error)

    def getError(self) -> "double":
        return _deep_feedback_learning.Neuron_getError(self)

    def setInput(self, _index: 'int', _value: 'double') -> "void":
        return _deep_feedback_learning.Neuron_setInput(self, _index, _value)

    def getInput(self, _index: 'int') -> "double":
        return _deep_feedback_learning.Neuron_getInput(self, _index)

    def setBias(self, _bias: 'double') -> "void":
        return _deep_feedback_learning.Neuron_setBias(self, _bias)

    def setLearningRate(self, _learningrate: 'double') -> "void":
        return _deep_feedback_learning.Neuron_setLearningRate(self, _learningrate)

    def setUseDerivative(self, _useDerivative: 'int') -> "void":
        return _deep_feedback_learning.Neuron_setUseDerivative(self, _useDerivative)

    def getNinputs(self) -> "int":
        return _deep_feedback_learning.Neuron_getNinputs(self)

    def getAvgWeight(self, _input: 'int') -> "double":
        return _deep_feedback_learning.Neuron_getAvgWeight(self, _input)

    def getAvgWeightCh(self, _input: 'int') -> "double":
        return _deep_feedback_learning.Neuron_getAvgWeightCh(self, _input)

    def setGeometry(self, _width: 'int', _height: 'int') -> "void":
        return _deep_feedback_learning.Neuron_setGeometry(self, _width, _height)

    def setMask(self, *args) -> "void":
        return _deep_feedback_learning.Neuron_setMask(self, *args)

    def getMask(self, *args) -> "unsigned char":
        return _deep_feedback_learning.Neuron_getMask(self, *args)

    def normaliseWeights(self) -> "void":
        return _deep_feedback_learning.Neuron_normaliseWeights(self)

    def saveInitialWeights(self) -> "void":
        return _deep_feedback_learning.Neuron_saveInitialWeights(self)

    def setDebugInfo(self, _layerIndex: 'int', _neuronIndex: 'int') -> "void":
        return _deep_feedback_learning.Neuron_setDebugInfo(self, _layerIndex, _neuronIndex)

    def setStep(self, _step: 'long') -> "void":
        return _deep_feedback_learning.Neuron_setStep(self, _step)
Neuron_swigregister = _deep_feedback_learning.Neuron_swigregister
Neuron_swigregister(Neuron)

def Neuron_calcOutputThread(object: 'void *') -> "void *":
    return _deep_feedback_learning.Neuron_calcOutputThread(object)
Neuron_calcOutputThread = _deep_feedback_learning.Neuron_calcOutputThread

def Neuron_doLearningThread(object: 'void *') -> "void *":
    return _deep_feedback_learning.Neuron_doLearningThread(object)
Neuron_doLearningThread = _deep_feedback_learning.Neuron_doLearningThread

def Neuron_doMaxDetThread(object: 'void *') -> "void *":
    return _deep_feedback_learning.Neuron_doMaxDetThread(object)
Neuron_doMaxDetThread = _deep_feedback_learning.Neuron_doMaxDetThread

# This file is compatible with both classic and new-style classes.


category_dict_icml15 = {
    "Bandit Learning" : [["Bandits"]],
    "Bayesian Nonparametrics" : [["Baysian Nonparametrics"]],
    "Bayesian Optimization" : [["Optimization"], ["Baysian Optimization"]],
    "Causality" : [["Causality"]],
    "Clustering" : [["Clustering"]],
    "Computational Advertising And Social Science" : [["Computational Advertising", "Social Science"]],
    "Deep Learning" : [["Deep Learning"]],
    "Deep Learning And Vision" : [["Deep Learning", "Computer Vision"]],
    "Deep Learning Computations" : [["Deep Learning"]],
    "Distributed Optimization" : [["Optimization"], ["Distributed Optimization"]],
    "Feature Selection" : [["Feature Selection"]],
    "Gaussian Processes" : [["Gaussian Processes"]],
    "Hashing" : [["Hashing"]],
    "Kernel Methods" : [["Kernel Methods"]],
    "Large Scale Learning" : [["Large Scale Learning"]],
    "Learning Theory" : [["Learning Theory"]],
    "Manifold Learning" : [["Manifold Learning"]],
    "Matrix Factorization" : [["Matrix Factorization"]],
    "Monte Carlo Methods" : [["Monte Carlo Methods"]],
    "Natural Language Processing" : [["Natural Language Processing"]],
    "Networks And Graphs" : [["Networks", "Graph Analysis"]],
    "Online Learning" : [["Online Learning"]],
    "Optimization" : [["Optimization"]],
    "Privacy" : [["Privacy"]],
    "Probabilistic Models" : [["Probabilistic Models"]],
    "Ranking Learning" : [["Ranking Learning"]],
    "Reinforcement Learning" : [["Reinforcement Learning"]],
    "Sparse Optimization" : [["Optimization"], ["Sparse Optimization"]],
    "Sparsity" : [["Sparsity"]],
    "Structured Prediction" : [["Structured Prediction"]],
    "Submodularity" : [["Submodularity"]],
    "Supervised Learning" : [["Supervised Learning"]],
    "Time Series Analysis" : [["Time-Series"]],
    "Topic Models" : [["Probabilistic Models"]],
    "Transfer Learning" : [["Transfer Learning"]],
    "Unsupervised Learning" : [["Unsupervised Learning"]],
    "Variational Inference" : [["Approximate Inference"]],
    "Vision" : [["Computer Vision"]]
}

category_dict_icml16 = {
    "Applications and Time-Series Analysis" : [["Applications", "Time-Series"]],
    "Approximate Inference" : [["Approximate Inference"]],
    "Bandit Problems" : [["Bandits"]],
    "Bayesian Nonparametric Methods" : [["Baysian Nonparametrics"]],
    "Causal Inference" : [["Causal Inference"]],
    "Clustering" : [["Clustering"]],
    "Crowdsourcing and Interactive Learning" : [["Crowdsourcing", "Interactive Learning"]],
    "Dimensionality Reduction / Private Learning" : [["Dimensionality Reduction", "Privacy"]],
    "Feature Selection and Dimensionality Reduction" : [["Feature Selection", "Dimensionality Reduction"]],
    "Gaussian Processes" : [["Gaussian Processes"]],
    "Graph Analysis/ Spectral Methods" : [["Graph Analysis", "Spectral Methods"]],
    "Graphical Models" : [["Probabilistic Models"]],
    "Kernel Methods" : [["Kernel Methods"]],
    "Large Scale Learning and Big Data" : [["Large Scale Learning"]],
    "Learning Theory" : [["Learning Theory"]],
    "Machine Learning Applications" : [["Applications"]],
    "Matrix Factorization / Neuroscience Applications" : [["Matrix Factorization", "Neuroscience Applications"]],
    "Matrix Factorization and Related Topics" : [["Matrix Factorization"]],
    "Metric and  Manifold Learning / Kernel Methods" : [["Metric Learning", "Manifold Learning", "Kernel Methods"]],
    "Monte Carlo Methods" : [["Monte Carlo Methods"]],
    "Multi-label, multi-task, and neural networks" : [["Multi-Label Learning", "Multi-Task Learning"], ["Deep Learning"]],
    "Neural Networks and Deep Learning" : [["Deep Learning"]],
    "Neural Networks and Deep Learning&nbsp;I" : [["Deep Learning"]],
    "Neural Networks and Deep Learning&nbsp;II" : [["Deep Learning"]],
    "Neural Networks and Deep Learning&nbsp;II (Computer Vision)" : [["Deep Learning"], ["Computer Vision"]],
    "Online Learning" : [["Online Learning"]],
    "Optimization" : [["Optimization"]],
    "Optimization (Combinatorial)" : [["Optimization"], ["Combinatorial Optimization"]],
    "Optimization (Continuous)" : [["Optimization"], ["Continuous Optimization"]],
    "Optimization / Online Learning" : [["Optimization", "Online Learning"]],
    "Privacy, Anonymity, and Security" : [["Privacy"]],
    "Ranking and Preference Learning" : [["Ranking Learning", "Preference Learning"]],
    "Reinforcement Learning" : [["Reinforcement Learning"]],
    "Sampling / Kernel Methods" : [["Sampling", "Kernel Methods"]],
    "Sparsity and Compressed Sensing" : [["Sparsity", "Compressed Sensing"]],
    "Statistical Learning Theory" : [["Statistical Learning Theory"]],
    "Structured Prediction / Monte Carlo Methods" : [["Structured Prediction", "Monte Carlo Methods"]],
    "Supervised Learning" : [["Supervised Learning"]],
    "Transfer Learning / Learning Theory" : [["Transfer Learning", "Learning Theory"]],
    "Unsupervised Learning / Applications" : [["Unsupervised Learning", "Applications"]],
    "Unsupervised Learning / Representation Learning" : [["Unsupervised Learning", "Representation Learning"]]
}

category_dict_icml17 = {
    "Active Learning" : [["Active Learning"]],
    "Applications" : [["Applications"]],
    "Bayesian Nonparametrics" : [["Baysian Nonparametrics"]],
    "Bayesian Optimization" : [["Optimization"], ["Baysian Optimization"]],
    "Causal Inference" : [["Causal Inference"]],
    "Clustering" : [["Clustering"]],
    "Combinatorial Optimization" : [["Optimization"], ["Combinatorial Optimization"]],
    "Continuous Control" : [["Continuous Control"]],
    "Continuous Optimization" : [["Optimization"], ["Continuous Optimization"]],
    "Deep Generative Models" : [["Deep Learning"], ["Deep Generative Models"]],
    "Deep Learning" : [["Deep Learning"]],
    "Deep Learning : Analysis": [["Deep Learning"]],
    "Deep Learning : Backprop": [["Deep Learning"]],
    "Deep Learning : Fisher Approximations": [["Deep Learning"]],
    "Deep Learning : Hardware": [["Deep Learning"]],
    "Deep Learning : Invariances": [["Deep Learning"]],
    "Deep Learning : Learning To Learn": [["Deep Learning"]],
    "Deep Learning : Metalearning": [["Deep Learning"]],
    "Deep Learning : Probabilistic": [["Deep Learning"], ["Probabilistic Models"]],
    "Deep Learning Theory" : [["Deep Learning"], ["Deep Learning Theory"]],
    "Deep Reinforcement Learning" : [["Deep Reinforcement Learning"], ["Reinforcement Learning"]],
    "Distributed Optimization" : [["Optimization"], ["Distributed Optimization"]],
    "Ensemble Methods" : [["Ensemble Methods"]],
    "Game Theory And Multiagents" : [["Game Theory", "Multi-Agent Learning"]],
    "Gaussian Processes" : [["Gaussian Processes"]],
    "Healthcare" : [["Healthcare"]],
    "High Dimensional Estimation" : [["High Dimensional Estimation"]],
    "Infomation Theory" : [["Information Theory"]],
    "Kernel Methods" : [["Kernel Methods"]],
    "Language" : [["Natural Language Processing"]],
    "Large Scale Learning" : [["Large Scale Learning"]],
    "Latent Feature Models" : [["Latent Feature Models"]],
    "Learning Theory" : [["Learning Theory"]],
    "Matrix Factorization" : [["Matrix Factorization"]],
    "Metric Learning" : [["Metric Learning"]],
    "Ml And Programming" : [["Ml And Programming"]],
    "Monte Carlo Methods" : [["Monte Carlo Methods"]],
    "Networks And Relational Learning" : [["Networks", "Relational Learning"]],
    "Online Learning" : [["Online Learning"]],
    "Privacy And Security" : [["Privacy"]],
    "Probabilistic Inference" : [["Approximate Inference"]],
    "Probabilistic Learning" : [["Probabilistic Models"]],
    "Ranking And Preferences" : [["Ranking Learning", "Preference Learning"]],
    "Recurrent Neural Networks" : [["Recurrent Neural Networks"]],
    "Reinforcement Learning" : [["Reinforcement Learning"]],
    "Robust Estimation" : [["Robustness"]],
    "Semisupervised And Curriculum Learning" : [
            ["Semi-Supervised Learning", "Curriculum Learning"]
        ],
    "Sparsity" : [["Sparsity"]],
    "Spectral Methods" : [["Spectral Methods"]],
    "Structured Prediction" : [["Structured Prediction"]],
    "Supervised Learning" : [["Supervised Learning"]],
    "Time Series" : [["Time-Series"]],
    "Transfer And Multitask Learning": [["Transfer Learning", "Multi-Task Learning"]]
}

category_dict_icml18 = {
    "Active Learning" : [["Active Learning"]],
    "Approximate Inference" : [["Approximate Inference"]],
    "Causal Inference" : [["Causal Inference"]],
    "Clustering" : [["Clustering"]],
    "Computer Vision" : [["Computer Vision"]],
    "Deep Learning (Adversarial)" : [["Deep Learning", "Adversarial"]],
    "Deep Learning (Bayesian)" : [["Deep Learning", "Baysian Deep Learning"]],
    "Deep Learning (Neural Network Architectures)" : [["Deep Learning", "Architectures"]],
    "Deep Learning (Theory)" : [["Deep Learning", "Deep Learning Theory"]],
    "Dimensionality Reduction" : [["Dimensionality Reduction"]],
    "Feature Selection" : [["Feature Selection"]],
    "Gaussian Processes" : [["Gaussian Processes"]],
    "Generative Models" : [["Generative Models"]],
    "Graphical Models" : [["Probabilistic Models"]],
    "Kernel Methods" : [["Kernel Methods"]],
    "Large Scale Learning and Big Data" : [["Large Scale Learning"]],
    "Matrix Factorization" : [["Matrix Factorization"]],
    "Monte Carlo Methods" : [["Monte Carlo Methods"]],
    "Multi-Agent Learning" : [["Multi-Agent Learning"]],
    "Natural Language and Speech Processing" : [["Natural Language Processing", "Speech Processing"]],
    "Networks and Relational Learning" : [["Networks", "Relational Learning"]],
    "Online Learning" : [["Online Learning"]],
    "Optimization (Bayesian)" : [["Optimization"], ["Baysian Optimization"]],
    "Optimization (Combinatorial)" : [["Optimization"], ["Combinatorial Optimization"]],
    "Optimization (Convex)" : [["Optimization"], ["Convex Optimization"]],
    "Optimization (Non-convex)" : [["Optimization"], ["Non-Convex Optimization"]],
    "Other Applications" : [["Applications"]],
    "Other Models and Methods" : [["Other Models and Methods"]],
    "Parallel and Distributed Learning" : [["Optimization"], ["Distributed Optimization"]],
    "Privacy, Anonymity, and Security" : [["Privacy"]],
    "Ranking and Preference Learning" : [["Ranking Learning", "Preference Learning"]],
    "Reinforcement Learning" : [["Reinforcement Learning"]],
    "Representation Learning" : [["Representation Learning"]],
    "Society Impacts of Machine Learning" : [["Society Impacts of Machine Learning"]],
    "Sparsity and Compressed Sensing" : [["Sparsity", "Compressed Sensing"]],
    "Spectral Methods" : [["Spectral Methods"]],
    "Statistical Learning Theory" : [["Statistical Learning Theory"]],
    "Structured Prediction" : [["Structured Prediction"]],
    "Supervised Learning" : [["Supervised Learning"]],
    "Time-Series Analysis" : [["Time-Series"]],
    "Transfer and Multi-Task Learning" : [["Transfer Learning", "Multi-Task Learning"]],
    "Unsupervised Learning" : [["Unsupervised Learning"]]
}

category_dict_icml19 = {
    "Active Learning" : [["Active Learning"]],
    "Adversarial Examples" : [["Adversarial"]],
    "Applications" : [["Applications"]],
    "Applications: Computer Vision" : [["Applications"], ["Computer Vision"]],
    "Applications: Natural Language Processing" : [["Applications"], ["Natural Language Processing"]],
    "Approximate Inference" : [["Approximate Inference"]],
    "Bandits and Multiagent Learning" : [["Bandits", "Multi-Agent Learning"]],
    "Bayesian Deep Learning" : [["Deep Learning"], ["Baysian Deep Learning"]],
    "Bayesian Methods" : [["Baysian Methods"]],
    "Bayesian Non-parametrics" : [["Baysian Nonparametrics"]],
    "Causality" : [["Causality"]],
    "Combinatorial Optimization" : [["Combinatorial Optimization"]],
    "Convex Optimization" : [["Optimization"], ["Convex Optimization"]],
    "Deep Generative Models" : [["Deep Learning"], ["Deep Generative Models"]],
    "Deep Learning" : [["Deep Learning"]],
    "Deep Learning Algorithms" : [["Deep Learning"]],
    "Deep Learning Architectures" : [["Deep Learning"], ["Architectures"]],
    "Deep Learning Optimization" : [["Deep Learning"], ["Optimization"]],
    "Deep Learning Theory" : [["Deep Learning"], ["Deep Learning Theory"]],
    "Deep RL" : [["Deep Learning"], ["Deep Reinforcement Learning"]],
    "Deep Sequence Models" : [["Deep Learning"]],
    "Fairness" : [["Fairness"]],
    "Gaussian Processes" : [["Gaussian Processes"]],
    "General ML" : [["General ML"]],
    "Generative Adversarial Networks" : [["Generative Models"]],
    "Generative Models" : [["Generative Models"]],
    "Information Theory and Estimation" : [["Information Theory", "Estimation"]],
    "Interpretability" : [["Interpretability"]],
    "Kernel Methods" : [["Kernel Methods"]],
    "Large Scale Learning and Systems" : [["Large Scale Learning"]],
    "Learning Theory" : [["Learning Theory"]],
    "Learning Theory: Games" : [["Learning Theory", "Games"]],
    "Monte Carlo Methods" : [["Monte Carlo Methods"]],
    "Networks and Relational Learning" : [["Networks", "Relational Learning"]],
    "Non-convex Optimization" : [["Optimization"], ["Non-Convex Optimization"]],
    "Online Learning" : [["Online Learning"]],
    "Optimization" : [["Optimization"]],
    "Optimization and Graphical Models" : [["Optimization", "Probabilistic Models"]],
    "Optimization: Convex and Non-convex" : [["Optimization"], ["Convex Optimization", "Non-Convex Optimization"]],
    "Privacy" : [["Privacy"]],
    "Privacy and Fairness" : [["Privacy", "Fairness"]],
    "Probabilistic Inference" : [["Probabilistic Inference"]],
    "Ranking and Preference Learning" : [["Ranking Learning", "Preference Learning"]],
    "Reinforcement Learning" : [["Reinforcement Learning"]],
    "Reinforcement Learning Theory" : [["Reinforcement Learning"]],
    "Reinforcement Learning and Bandits" : [["Reinforcement Learning", "Bandits"]],
    "Representation Learning" : [["Representation Learning"]],
    "Robust Statistics and Interpretability" : [["Robustness", "Interpretability"]],
    "Robust Statistics and Machine Learning" : [["Robustness"]],
    "Statistical Learning Theory" : [["Statistical Learning Theory"]],
    "Supervised Learning" : [["Supervised Learning"]],
    "Supervised and Transfer Learning" : [["Supervised Learning", "Transfer Learning"]],
    "Time Series" : [["Time-Series"]],
    "Transfer and Multitask Learning" : [["Transfer Learning", "Multi-Task Learning"]],
    "Unsupervised Learning" : [["Unsupervised Learning"]]
}import random

#random.choice()
#random.sample()
#random.randrange()

beginnings = list()
for line in open("beginnings.txt"):
	line = line.strip()
	if len(line) > 0:
		beginnings.append(line)

deepLearning = list()
for line in open("deepLearning.txt"):
	line = line.strip()
	if len(line) > 0:
		deepLearning.append(line)

for i in range(12):
	rand_beginning = random.choice(beginnings)
	rand_deepLearning = random.choice(deepLearning)

	print rand_beginning + " " + rand_deepLearningimport types
import tempfile
import keras.models
from learning_loader import LearningLoader
#from classic_ml import ClassicMachineLearning
import os
from datetime import datetime
import multiprocessing as mp
import pickle

sample_size = 2000000

def make_keras_picklable():
    '''
    :return: allows keras deep learning model to be saved as pickle for further analysis
    '''
    def __getstate__(self):
        model_str = ""
        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:
            keras.models.save_model(self, fd.name, overwrite=True)
            model_str = fd.read()
        d = { 'model_str': model_str }
        return d

    def __setstate__(self, state):
        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:
            fd.write(state['model_str'])
            fd.flush()
            model = keras.models.load_model(fd.name)
        self.__dict__ = model.__dict__


    cls = keras.models.Model
    cls.__getstate__ = __getstate__
    cls.__setstate__ = __setstate__

def get_learning_loader(dir_path, doi, sample_size):
    '''
    :param dir_path: directory path
    :param doi: domain of intrest to classify
    :param sample_size: requested sample size
    :return: learning loader for train and test
    '''
    leaning_loader = LearningLoader(directory_path=dir_path)
    leaning_loader.load_features_from_directory('degrees_{0}.txt'.format(sample_size),
                                                'kcore_{0}.txt'.format(sample_size),
                                                'page_rank_{0}.txt'.format(sample_size),
                                                'closeness_{0}.txt'.format(sample_size),
                                                'bfs_moments_{0}.txt'.format(sample_size),
                                                'motifs_3_{0}.txt'.format(sample_size),
                                                'propagation_{0}_20/propagation_{1}.txt'.format(sample_size, doi))

    #for 100 DOIs - sample size 20000002
    leaning_loader.load_tags_from_file('/doi_{0}/{1}.txt'.format(2000002, doi))
    #leaning_loader.load_tags_from_file('/doi_{0}/{1}'.format(sample_size, doi))
    leaning_loader.divide_train_test(test_file_path='test_20_{0}.txt'.format(sample_size))
    return leaning_loader

def deep_learning(i):
    '''
    :param i: snapshot to preform deep learning analysis to predict doi based on graph representation of the network
    this function preforms deep learning analysis via keras module
    it creates a Net Attribute Vectors where rows are vertices, and columns are features of the graph
    we use both global and local features
    :return: in the working snap directory, it creates: (A) results path (B) clf pickle
    '''

    i=int(i)
    if i < 10:
        snap = '000' + str(i)
    else:
        snap = '00' + str(i)

    snap_start = datetime.now()
    print snap

    #some boring staff- files and paths
    dir_path = r'./../data/directed/livejournal/snap{}/'.format(snap)

    #dir_path = os.path.dirname(os.getcwd()) + '/data/directed/livejournal/snap{0}/'.format(snap)
    if not os.path.exists('{0}/results'.format(dir_path)):
        os.makedirs('{0}/results'.format(dir_path))
    r_file = 'results/deep_learning.txt'

    #dois = os.listdir(dir_path +'doi_{0}/'.format(sample_size))
    dois = ['Neuroticism', 'Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness']

    if not os.path.exists('{0}/deep_clf_{1}'.format(dir_path, sample_size)):
        os.makedirs('{0}/deep_clf_{1}'.format(dir_path, sample_size))

    with file(dir_path+r_file,'w') as result_file:
        for doi in dois:
            #for each domain of intrest, build FFN, train and evaluate AUC score

            # redundent to learn from
            if doi == 'accountstypes.txt':
                continue

            print doi
            #if os.path.exists('{0}/deep_clf_{1}/{2}_deep.pkl'.format(dir_path, sample_size,doi[:-4])):
            #    print '-skip'
            #    continue

            result_file.writelines('{0}\n'.format(doi[:-4]))

            #innitialize analysis and create NAV
            learning_loader = get_learning_loader(dir_path, doi, sample_size)
            learning_object = learning_loader.get_learning_object(zscoring=True)

            #NAV matrix x = train vertices and features, y= their tags
            ##x = learning_object.train_features_matrix
            ##y = learning_object.train_tags_vector
            ##print x.shape
            ##print y.shape

            from deep_learning import DeepLearning
            learning = DeepLearning(learning_object)

            start = datetime.now()
            clf = learning.run_learning(test_size=0.2)
            auc_train = learning.evaluate_AUC_train()
            end = datetime.now()

            #print '-auc train:', auc_train
            #result_file.writelines('auc train: {0}\n'.format(auc_train))
            auc_test = learning.evaluate_AUC_test()
            result_file.writelines('auc test: {0}\n'.format(auc_test))
            print '-auc test:', auc_test

            #save the module and the AUC results
            result_file.flush()
            with file('{0}/deep_clf_{1}/{2}_deep.pkl'.format(dir_path, sample_size, doi[:-4]), 'w') as pickle_file:
                pickle.dump(clf, file=pickle_file)


            print '-Done, the training took: {}'.format(end-start)
    snap_end = datetime.now()
    print 'Running time for this snap: {}'.format(snap_end-snap_start)

#keras makes troubles with pickle. lines 111-110 solved it
make_keras_picklable()

#for desriptions: lines 24,99 in learning loader,py, line 15 on deep_learning.py
snaps = [2,19,10]
for i in snaps:
    deep_learning(i)

#deep_learning(1)




#validation for a specific snap
# dir_path = r'./../data/directed/livejournal/snap0002/'
# learning_loader2 = get_learning_loader(dir_path)
# learning_object2 = learning_loader2.get_learning_object(zscoring=True)
# print 'auc snap 0002:',learning.evaluate_AUC_general(clf, learning_object2.features_matrix, learning_object2.tags_vector)
#
# dir_path = r'./../data/directed/livejournal/snap0010/'
# learning_loader3 = get_learning_loader(dir_path)
# learning_object3 = learning_loader3.get_learning_object(zscoring=True)
# print 'auc snap 0010:',learning.evaluate_AUC_general(clf, learning_object3.features_matrix, learning_object3.tags_vector)
#
# dir_path = r'./../data/directed/livejournal/snap0019/'
# learning_loader4 = get_learning_loader(dir_path)
# learning_object4 = learning_loader4.get_learning_object(zscoring=True)
# print 'auc snap0019:',learning.evaluate_AUC_general(clf, learning_object4.features_matrix, learning_object4.tags_vector)
import networkx as nx

# words
webpages = ['Big Data 1', 'Big Data 2', 'Machine Learning 1', 'Artificial Intelligence', 'Deep Learning 1',
            'Machine Learning 2', 'Deep Learning 2', 'Big Data 3',
            'Deep Learning 3', 'Econophysics', 'Dow-Jones 1', 'Wall Street', 'Hadoop', 'Spark', 'Dow-Jones 2',
            'Big Data Fake 1', 'Big Data Fake 2', 'Porn 1', 'Porn 2']
links = [('Big Data 1', 'Big Data 2'), ('Big Data 2', 'Big Data 1'), ('Big Data 3', 'Big Data 2'),
         ('Big Data 3', 'Big Data 1'), ('Big Data 3', 'Deep Learning 1'),
         ('Machine Learning 1', 'Artificial Intelligence'), ('Deep Learning 1', 'Artificial Intelligence'),
    ('Deep Learning 1', 'Machine Learning 1'), ('Deep Learning 2', 'Machine Learning 1'),
    ('Deep Learning 1', 'Big Data 1'), ('Big Data 1', 'Deep Learning 1'), ('Big Data 2', 'Deep Learning 1'),
    ('Big Data 3', 'Big Data 1'), ('Big Data 2', 'Econophysics'), ('Econophysics', 'Big Data 2'),
    ('Econophysics', 'Dow-Jones 1'), ('Big Data 2', 'Dow-Jones 1'), ('Big Data 2', 'Dow-Jones 2'), ('Big Data 1', 'Hadoop'),
    ('Big Data 2', 'Hadoop'), ('Big Data 3', 'Hadoop'), ('Big Data 1', 'Spark'), ('Spark', 'Hadoop'), ('Hadoop', 'Spark'),
    ('Hadoop', 'Big Data 1'), ('Spark', 'Big Data 1'), ('Wall Street', 'Big Data 2'), ('Wall Street', 'Spark'),
    ('Dow-Jones 2', 'Dow-Jones 1'), ('Dow-Jones 2', 'Big Data 1'), ('Big Data Fake 1', 'Porn 1'), ('Big Data Fake 2', 'Big Data Fake 1'),
    ('Big Data Fake 2', 'Porn 1'), ('Porn 1', 'Porn 2'), ('Machine Learning 2', 'Machine Learning 1'), ('Machine Learning 2', 'Big Data 1'),
         ('Deep Learning 3', 'Deep Learning 1'), ('Machine Learning 2', 'Artificial Intelligence'), ('Deep Learning 1', 'Machine Learning 2'),
    ('Econophysics', 'Big Data 1'), ('Dow-Jones 2', 'Big Data 1'), ('Big Data 1', 'Dow-Jones 2'), ('Big Data 1', 'Deep Learning 2'),
    ('Porn 1', 'Big Data 3')]

webnet = nx.DiGraph()
webnet.add_nodes_from(webpages)
webnet.add_edges_from(links)# A simple torch style logger
# (C) Wei YANG 2017
from __future__ import absolute_import
import matplotlib.pyplot as plt
import os
import sys
import numpy as np
# plt.switch_backend('agg')

__all__ = ['Logger', 'LoggerMonitor', 'savefig']

def savefig(fname, dpi=None):
    dpi = 150 if dpi == None else dpi
    plt.savefig(fname, dpi=dpi)
    
def plot_overlap(logger, names=None):
    names = logger.names if names == None else names
    numbers = logger.numbers
    for _, name in enumerate(names):
        x = np.arange(len(numbers[name]))
        # np.asarray(numbers[name]) is a str list, convert to float array
        plt.plot(x, np.asarray(numbers[name]).astype(np.float) ) 
    return [logger.title + '(' + name + ')' for name in names]

class Logger(object):
    '''Save training process to log file with simple plot function.'''
    def __init__(self, fpath, title=None, resume=False): 
        self.file = None
        self.resume = resume
        self.title = '' if title == None else title
        if fpath is not None:
            if resume: 
                self.file = open(fpath, 'r') 
                name = self.file.readline()
                # print('name: ', name)
                self.names = name.rstrip().split('\t')
                # print('self.names: ', self.names)
                self.numbers = {}
                for _, name in enumerate(self.names):
                    self.numbers[name] = []

                for numbers in self.file:
                    numbers = numbers.rstrip().split('\t')
                    # print('numbers: ', numbers)
                    for i in range(0, len(numbers)):
                        self.numbers[self.names[i]].append(numbers[i])
                self.file.close()
                self.file = open(fpath, 'a')  
            else:
                self.file = open(fpath, 'w')

    def set_names(self, names):
        if self.resume: 
            pass
        # initialize numbers as empty list
        self.numbers = {}
        self.names = names
        for _, name in enumerate(self.names):
            self.file.write(name)
            self.file.write('\t')
            self.numbers[name] = []
        self.file.write('\n')
        self.file.flush()


    def append(self, numbers):
        assert len(self.names) == len(numbers), 'Numbers do not match names'
        for index, num in enumerate(numbers):
            self.file.write("{0:.6f}".format(num))
            self.file.write('\t')
            self.numbers[self.names[index]].append(num)
        self.file.write('\n')
        self.file.flush()

    def plot(self, names=None):   
        names = self.names if names == None else names
        numbers = self.numbers
        plt.figure(figsize=(18,6))
        plt.subplot(121)
        for _, name in enumerate(names[1:3]):
            # print('namme {} data {} type {}'  .format(name, numbers[name], type(numbers[name])))
            x = np.arange(len(numbers[name]))
            plt.plot(x, np.asarray(numbers[name]))
        plt.legend([self.title + '(' + name + ')' for name in names[1:3]])

        plt.subplot(122)
        for _, name in enumerate(names[3:]):
            # print('namme {} data {} array {} type {}'  .format(name, numbers[name],np.asarray(numbers[name]), type(numbers[name])))
            x = np.arange(len(numbers[name]))
            plt.plot(x, np.asarray(numbers[name]))
        plt.legend([self.title + '(' + name + ')' for name in names[3:]])

        plt.grid(True)

    def close(self):
        if self.file is not None:
            self.file.close()

class LoggerMonitor(object):
    '''Load and visualize multiple logs.'''
    def __init__ (self, paths):
        '''paths is a distionary with {name:filepath} pair'''
        self.loggers = []
        for title, path in paths.items():
            logger = Logger(path, title=title, resume=True)
            self.loggers.append(logger)

    def plot(self, names=None):
        plt.figure(figsize=(18,6))
        plt.subplot(121)
        legend_text = []
        for logger in self.loggers:
            legend_text += plot_overlap(logger, names)             
        plt.legend(legend_text, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
        plt.xlabel('Epoch ')
        plt.ylabel('Acc % ')
        plt.grid(True)
        
                    
if __name__ == '__main__':

    paths1 = {
    'resnet-110' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet-110/log.txt',
    'alexnet' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/alexnet/log.txt',
    'resnet-26' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet-26/log.txt',
    'vgg11' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/vgg11/log.txt',
    'vgg19_bn_q' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/vgg19_bn_q/log.txt',
    'densenet-bc-100-12' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/densenet-bc-100-12/log.txt',
    }
  

    paths2 = {
    'dropout-0.0' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet-110/log.txt',
    'dropout-0.1' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoint/cifar100/dropout/resnet_dropout1-110/log.txt',
    'dropout-0.3' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoint/cifar100/dropout/resnet_dropout3-110/log.txt',
    'dropout-0.5' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoint/cifar100/dropout/resnet_dropout5-110/log.txt',
    'dropout-0.7' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoint/cifar100/dropout/resnet_dropout7-110/log.txt',
    'dropout-0.9' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoint/cifar100/dropout/resnet_dropout9-110/log.txt',
    'dropout2d-0.1' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoint/cifar100/resnet_dropout2D1-110/log.txt',
    'dropout2d-0.3' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoint/cifar100/resnet_dropout2D3-110/log.txt',
    # 'dropout-1' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoint/cifar100/resnet_dropout10-110/log.txt',
    }

    paths3 = {
    'resnet-110' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet-110/log.txt',
    'resnet-110-minus' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet-110-minus/log.txt',
    'resnet-110_dropout-out' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet_dropout-out-110/log.txt',
    # 'resnet-110' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet-110/log.txt',
    }

    paths4 = {
    'resnet-110' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet-110/log.txt',
    'resnet-110-spatialAtt-wo-bn' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet-110-spatialAtt-wo-bn/log.txt',
    'resnet-110-chanelAtt_new' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet-110-chanelAtt_new/log.txt',
    # 'resnet-110' : '/media/jaden/DeepLearningCode/pytorch-classification/checkpoints/cifar100/resnet-110/log.txt',
    }


    # fields = [['Valid Acc.']]
    # FULL comparison
    fields = [['Train Loss'], ['Valid Loss'],  ['Train Acc.'], ['Valid Acc.']]
    monitor = LoggerMonitor(paths4)

    for field in fields:  
        print field    
        monitor.plot(names=field)
        # plt.show()
        savefig('cifar100_all' + field[0] + '.eps')
import socket
import _thread
import time
import datetime as dt
import numpy as np
import tensorflow
from Representation_Keras_MultiAgent_TensorInput import Representation_Keras_MultiAgent_TensorInput
from DeepQNetwork import DeepQNetwork
from DeepQNetwork_PrioritizedReplay import DeepQNetwork_PrioritizedReplay
from DeepQNetwork_PrioritizedReplay_Target import DeepQNetwork_PrioritizedReplay_Target
from DeepQNetwork_PrioritizedReplay_Target_LearnerThread import DeepQNetwork_PrioritizedReplay_Target_LearnerThread
from DeepQNetwork_PrioritizedReplay_Target_LearnerThread_Hybrid import DeepQNetwork_PrioritizedReplay_Target_LearnerThread_Hybrid
from DeepCorrection_base import DeepCorrection_base
from DeepCorrection_Hybrid import DeepCorrection_Hybrid
from Representation_Empty import Representation_Empty
from DeepActorCritic_PrioritizedReplay import DeepActorCritic_PrioritizedReplay
#from DeepActorCritic_PrioritizedReplay_tflearn import DeepActorCritic_PrioritizedReplay_tflearn
from Representation import Representation
from command_parser import command_parser, config_parser
import signal
import sys


#rep = Representation_Tabular([4,12,12])
#rep = Representation_Tensorflow(4,0.1)
# rep = Representation_Tensorflow_Batch(inputs=3,
#                                       hidden_unit=4,
#                                       learning_rate=0.1,
#                                       batch_size=9*4,
#                                       trainpass=5000)

print('tensorflow: %s' % tensorflow.__version__)

def strToValue(str):
    if len(str.split(";")) > 1 :
        try:
            return [int(i) for i in str.split(";")]
        except ValueError:
            return [float(i) for i in str.split(";")]
    else:
        try:
            return int(str)
        except ValueError:
            return float(str)

def init_model(config):
                
    if config["DEEP_ALGO_TYPE"] ==  "DeepQNetwork_PrioritizedReplay":               
        rep = DeepQNetwork_PrioritizedReplay                   (gridsize            = strToValue(config["NUMBER_OF_ROWS"]),
                                                                actionspaceperagent = 5,
                                                                numberofagent       = strToValue(config["NUMBER_OF_AGENTS"]),
                                                                #hidden_unit=[256, 512, 256],
                                                                hidden_unit         = strToValue(config["HIDDEN_LAYERS"]),
                                                                learning_rate       = strToValue(config["ETA_LEARNING_RATE"]),
                                                                batch_size          = strToValue(config["BATCH_SIZE"]),
                                                                trainpass           = strToValue(config["TRAINING_PASS_PER_BATCH"]),
                                                                experiencebuffer    = strToValue(config["EXPERIENCE_REPLAY_BUFFER"]),
                                                                statePreprocessType = 'Vector',
                                                                convolutionLayer    = False,
                                                                modelId             = config["MODEL_ID"],
                                                                logfolder           = config["TIME_STAMP"],
                                                                )

    elif config["DEEP_ALGO_TYPE"] ==  "DeepQNetwork_PrioritizedReplay_Target":
        rep = DeepQNetwork_PrioritizedReplay_Target            (gridsize            = strToValue(config["NUMBER_OF_ROWS"]),
                                                                actionspaceperagent = 5,
                                                                numberofagent       = strToValue(config["NUMBER_OF_AGENTS"]),
                                                                #hidden_unit=[256, 512, 256],
                                                                hidden_unit         = strToValue(config["HIDDEN_LAYERS"]),
                                                                learning_rate       = strToValue(config["ETA_LEARNING_RATE"]),
                                                                batch_size          = strToValue(config["BATCH_SIZE"]),
                                                                trainpass           = strToValue(config["TRAINING_PASS_PER_BATCH"]),
                                                                experiencebuffer    = strToValue(config["EXPERIENCE_REPLAY_BUFFER"]),
                                                                statePreprocessType = 'Vector',
                                                                convolutionLayer    = False,
                                                                modelId             = config["MODEL_ID"],
                                                                logfolder           = config["TIME_STAMP"],
                                                                )

    elif config["DEEP_ALGO_TYPE"] ==  "DeepQNetwork_PrioritizedReplay_Target_LearnerThread":
        rep = DeepQNetwork_PrioritizedReplay_Target_LearnerThread   (gridsize            = strToValue(config["NUMBER_OF_ROWS"]),
                                                                actionspaceperagent = 5,
                                                                numberofagent       = strToValue(config["NUMBER_OF_AGENTS"]),
                                                                #hidden_unit=[256, 512, 256],
                                                                hidden_unit         = strToValue(config["HIDDEN_LAYERS"]),
                                                                learning_rate       = strToValue(config["ETA_LEARNING_RATE"]),
                                                                batch_size          = strToValue(config["BATCH_SIZE"]),
                                                                trainpass           = strToValue(config["TRAINING_PASS_PER_BATCH"]),
                                                                experiencebuffer    = strToValue(config["EXPERIENCE_REPLAY_BUFFER"]),
                                                                statePreprocessType = 'Vector',
                                                                convolutionLayer    = False,
                                                                modelId             = config["MODEL_ID"],
                                                                logfolder           = config["TIME_STAMP"],
                                                                )
    elif config["DEEP_ALGO_TYPE"] ==  "DeepQNetwork_PrioritizedReplay_Target_LearnerThread_Hybrid":
        rep = DeepQNetwork_PrioritizedReplay_Target_LearnerThread_Hybrid   (gridsize            = strToValue(config["NUMBER_OF_ROWS"]),
                                                                actionspaceperagent = 5,
                                                                numberofagent       = strToValue(config["NUMBER_OF_AGENTS"]),
                                                                #hidden_unit=[256, 512, 256],
                                                                hidden_unit         = strToValue(config["HIDDEN_LAYERS"]),
                                                                learning_rate       = strToValue(config["ETA_LEARNING_RATE"]),
                                                                batch_size          = strToValue(config["BATCH_SIZE"]),
                                                                trainpass           = strToValue(config["TRAINING_PASS_PER_BATCH"]),
                                                                experiencebuffer    = strToValue(config["EXPERIENCE_REPLAY_BUFFER"]),
                                                                statePreprocessType = 'Vector',
                                                                convolutionLayer    = False,
                                                                modelId             = config["MODEL_ID"],
                                                                logfolder           = config["TIME_STAMP"],
                                                                )

#   elif config["DEEP_ALGO_TYPE"] ==  "DeepActorCritic_PrioritizedReplay":   
#       rep = DeepActorCritic_PrioritizedReplay_tflearn        (gridsize            = strToValue(config["NUMBER_OF_ROWS"]),
#                                                               actionspaceperagent = 5,
#                                                               numberofagent       = strToValue(config["NUMBER_OF_AGENTS"]),
#                                                               actor_hidden_unit   = strToValue(config["HIDDEN_LAYERS"]),
#                                                               critic_hidden_unit  = strToValue(config["CRITIC_HIDDEN_LAYERS"]),
#                                                               actor_learning_rate  = 0.05,
#                                                               critic_learning_rate = strToValue(config["ETA_LEARNING_RATE"]),                                                        
#                                                               batch_size          = strToValue(config["BATCH_SIZE"]),
#                                                               trainpass           = strToValue(config["TRAINING_PASS_PER_BATCH"]),
#                                                               experiencebuffer    = strToValue(config["EXPERIENCE_REPLAY_BUFFER"]),
#                                                               statePreprocessType = 'Vector',
#                                                               convolutionLayer    = False,
#                                                               modelId             = config["MODEL_ID"],
#                                                               logfolder           = config["TIME_STAMP"],
#                                                               )


    elif config["DEEP_ALGO_TYPE"] ==  "DeepCorrection":
        rep = DeepCorrection_base                               (gridsize            = strToValue(config["NUMBER_OF_ROWS"]),
                                                                actionspaceperagent = 5,
                                                                numberofagent       = strToValue(config["NUMBER_OF_AGENTS"]),
                                                                #hidden_unit=[256, 512, 256],
                                                                hidden_unit         = strToValue(config["HIDDEN_LAYERS"]),
                                                                learning_rate       = strToValue(config["ETA_LEARNING_RATE"]),
                                                                batch_size          = strToValue(config["BATCH_SIZE"]),
                                                                trainpass           = strToValue(config["TRAINING_PASS_PER_BATCH"]),
                                                                experiencebuffer    = strToValue(config["EXPERIENCE_REPLAY_BUFFER"]),
                                                                fusion_model        = config["FUSION_MODEL"],
                                                                correction_model_type = config["CORRECTION_MODEL_TYPE"],
                                                                modelId             = config["MODEL_ID"],
                                                                logfolder           = config["TIME_STAMP"],
                                                                agent_model         = config["AGENT_MODEL"],
                                                                )
    elif config["DEEP_ALGO_TYPE"] ==  "DeepCorrectionHybrid":
        rep = DeepCorrection_Hybrid                               (gridsize            = strToValue(config["NUMBER_OF_ROWS"]),
                                                                actionspaceperagent = 5,
                                                                numberofagent       = strToValue(config["NUMBER_OF_AGENTS"]),
                                                                #hidden_unit=[256, 512, 256],
                                                                hidden_unit         = strToValue(config["HIDDEN_LAYERS"]),
                                                                learning_rate       = strToValue(config["ETA_LEARNING_RATE"]),
                                                                batch_size          = strToValue(config["BATCH_SIZE"]),
                                                                trainpass           = strToValue(config["TRAINING_PASS_PER_BATCH"]),
                                                                experiencebuffer    = strToValue(config["EXPERIENCE_REPLAY_BUFFER"]),
                                                                fusion_model        = config["FUSION_MODEL"],
                                                                correction_model_type = config["CORRECTION_MODEL_TYPE"],
                                                                modelId             = config["MODEL_ID"],
                                                                logfolder           = config["TIME_STAMP"],
                                                                agent_model         = config["AGENT_MODEL"],
                                                                )
            
    elif config["DEEP_ALGO_TYPE"] ==  "Representation_Empty":
        rep = Representation_Empty()     
    
    
    return rep

# rep = Representation_Keras_MultiAgent_TensorInput      (gridsize=3,
#                                                         actionspaceperagent=5,
#                                                         numberofagent=2,
#                                                         hidden_unit=[25,25],
#                                                         learning_rate=0.1,
#                                                         batch_size=32,
#                                                         trainpass=25,
#                                                         experiencebuffer=128)

# rep = Representation_Tensorflow_ExperienceReplay_TypeB(statedimperagent=2,
#                                                         actionspaceperagent=5,
#                                                         numberofagent=2,
#                                                         hidden_unit=[12,6],
#                                                         learning_rate=0.1,
#                                                         batch_size=1,
#                                                         trainpass=1,
#                                                         experiencebuffer=1)



# rep = Representation_Keras_MultiAgent                   (statedimperagent=2,
#                                                         actionspaceperagent=5,
#                                                         numberofagent=3,
#                                                         hidden_unit=[128,256],
#                                                         learning_rate=0.1,
#                                                         batch_size=32,
#                                                         trainpass=10,
#               end                                          experiencebuffer=64)


# rep = Representation_Tensorflow_ExperienceReplay(       inputs=6,
#                                                         actionspaceperagent=5,
#                                                         numberofagent=2,
#                                                         hidden_unit=[12,6],
#                                                         learning_rate=0.1,
#                                                         batch_size=10,
#                                                         trainpass=1,
#                                                         experiencebuffer=20
#                                                         )

HOSTTX   ='127.0.0.1'
PORTRX = 5001
PORTTX = 4001

send_command_type = ''
send_ok = False
flag_continue = True

total_command_persec = 0
total_getval_persec = 0
total_setval_persec = 0
total_getgreedy_persec = 0
total_train_persec = 0
total_train = 0
total_train_old = 0

rep = None


# UDP Receiver
def read():

    # Initialize parameters
    global flag_continue, send_command_type, send_ok,rep, total_command_persec, total_getgreedy_persec, total_setval_persec, total_getval_persec, rep, total_train

    while flag_continue:
        # Read port when available
        data, addr = s.recvfrom(65530)

        # Convert the byte array to string
        rxstr = data.decode('utf-8')
        #print(rxstr)
        
        # Check whether it is config or command            
        params = rxstr.split(",")
        
                
        if params[0] == "command" :
            # Parse Received Command
            command, state, action, value , nextstate, status = command_parser(params[1:])
            
            if command == 'setvalue':
                total_train = rep.Set_Value(state, action, value)
                total_setval_persec += 1
                s.sendto(("OK,setvalue").encode(), (HOSTTX, PORTTX))
    
            elif command == 'getvalue':
                val = rep.Get_Value(state, action)
                total_getval_persec+=1
                s.sendto(("OK,getvalue,"+ str(val) ).encode(), (HOSTTX, PORTTX))
    
    
            elif command == 'getgreedypair':
                #n1 = dt.datetime.now()
                arg, val = rep.Get_Greedy_Pair(state)
                total_getgreedy_persec += 1
                tmp = "OK,getgreedypair," + str(arg) + "," + str(val)
                s.sendto((tmp).encode(), (HOSTTX, PORTTX))
                #n2 = dt.datetime.now()
                #print(((n2-n1).microseconds)/1e3)
    
            elif command == 'experience':
                rep.Add_Experience(state, action, nextstate, value, status)
                total_setval_persec += 1
                s.sendto(("OK,experience").encode(), (HOSTTX, PORTTX))
    
            total_command_persec+=1
    
        elif params[0] == "config" :
            config = config_parser(rxstr[7:].split("|"))
            print("Received Configuration:")
            print(config)
            
            #if rep != None:
            #    rep.Save_Model()
                
            rep = init_model(config)
            s.sendto(("OK,config").encode(), (HOSTTX, PORTTX))

    print("Thread read() stopped.")

# UDP Transmitter
def write():

    # Initialize parameters
    global send_command_type,send_ok,flag_continue

    while flag_continue:

        if send_ok :
            send_ok = False
            s.sendto(("OK," + send_command_type).encode(), (HOSTTX, PORTTX))

        time.sleep(100/1000)

    print("Thread write() stopped.")


# UDP Transmitter
def userinput():

    # Initialize parameters
    global flag_continue

    while flag_continue:
        user_input = input()
        if user_input == "stop":
            rep.Save_Model()
            flag_continue = False
            _thread.exit()
            break
        else:
            print("No User Input.")
            time.sleep(100/1000)

    print("Thread userinput() stopped.")


def signal_handler(sig, frame):
        print('You pressed Ctrl+C!')
        rep.Save_Model()
        flag_continue = False
        _thread.exit()
        sys.exit(0)

s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
s.bind(("", PORTRX))
print ('waiting on port:', PORTRX)
signal.signal(signal.SIGINT, signal_handler)

_thread.start_new_thread(read,())
_thread.start_new_thread(write,())
_thread.start_new_thread(userinput,())

while flag_continue:
    time.sleep(1)
    
    if total_train:
        total_train_persec = total_train - total_train_old
        total_train_old = total_train
    
    print('Total Command Per Sec:{:>5} SetVal:{:>5} GetVal:{:>5} GetGreedy:{:>5} TotalTrain:{:>5} '.format(total_command_persec,total_setval_persec,total_getval_persec,total_getgreedy_persec, total_train_persec))
    total_command_persec=0
    total_setval_persec=0
    total_getval_persec=0
    total_train_persec=0
    total_getgreedy_persec=0





import numpy as np

import learning.FeturesMatrix as features_matrix
from GCN.gcn import myTrain
from graph_features import features as features
from learning import simple_machine_learning as ml, myTrain


def buid_features_importance_dict(map_fetures):
    place = 0
    features_importance_dict = {}
    vertices_algo_dict = features.vertices_algo_dict
    features_list = []
    #
    # for key_feature in map_fetures.keys():
    #     features_list.append(vertices_algo_dict.keys()[vertices_algo_dict.values().index(key_feature)])
    #
    #
    # for k, v in sorted(features.vertices_algo_dict.items(), key=itemgetter(1)):
    #     if k not in features_list:
    #         continue
    #     if k not in features.vertices_algo_feature_directed_length_dict:
    #         features_importance_dict[place] = k
    #         place += 1
    #     else:
    #         for i in range(features.vertices_algo_feature_directed_length_dict[k]):
    #             features_importance_dict[place] = k + '[' + str(i) + ']'
    #             place += 1
    #
    # # print features_importance_dict
    #
    # for k in features_list:
    #     print k
    #     if not features.vertices_algo_feature_directed_length_dict.has_key(k):
    #         place += 1
    #     else:
    #         print k
    #         place += features.vertices_algo_feature_directed_length_dict[k]
    print (place)


def machineLearning(gnx, map_fetures, number_of_learning_for_mean, classifications, ml_algos, tags_loader,
                result_path,edges=False, load_clf_file_name=None, save_clf_file_name=None, test_size=0.3, random_state=None):

    features_importance_dict = buid_features_importance_dict(map_fetures)

    if(edges):
        for classification in classifications:
            edges_to_tags = tags_loader.calssification_to_edge_to_tag[classification]
            [feature_matrix, tags_vector, node_to_zscoringfeatures] = features_matrix.build_matrix_with_tags_edges \
                (gnx, map_fetures, edges_to_tags, zscoring=True)
            tags_vector = np.squeeze(np.asarray(tags_vector))
            l = ml.SimpleMachineLearning(feature_matrix, tags_vector)
            if load_clf_file_name != None:
                load_clf_file_name = load_clf_file_name + classification + '_'
            if save_clf_file_name != None:
                save_clf_file_name = save_clf_file_name + classification + '_'
            if len(set(edges_to_tags.values())) != 2:
                run_multiclass_machine_learning(classification, features_importance_dict, l, ml_algos, edges_to_tags,
                                                node_to_zscoringfeatures, number_of_learning_for_mean, result_path,
                                                load_clf_file_name=load_clf_file_name,
                                                save_clf_file_name=save_clf_file_name,
                                                random_state=random_state,
                                                test_size=test_size)

            else:
                run_binary_machine_learning(classification, features_importance_dict, l, ml_algos, edges_to_tags,
                                            node_to_zscoringfeatures, number_of_learning_for_mean, result_path,
                                            load_clf_file_name=load_clf_file_name
                                            , save_clf_file_name=save_clf_file_name,
                                            random_state=random_state,
                                            test_size=test_size)

    else:
        for classification in classifications:
            print (classification)
            vertex_to_tags = tags_loader.calssification_to_vertex_to_tag[classification]
            [feature_matrix, tags_vector, node_to_zscoringfeatures] = features_matrix.build_matrix_with_tags\
                                                                            (gnx, map_fetures, vertex_to_tags, zscoring=True)
            tags_vector = np.squeeze(np.asarray(tags_vector))
            l = ml.SimpleMachineLearning(feature_matrix, tags_vector)
            if load_clf_file_name != None:
                load_clf_file_name = load_clf_file_name + classification + '_'
            if save_clf_file_name != None:
                save_clf_file_name = save_clf_file_name + classification + '_'
            if len(set(vertex_to_tags.values())) != 2:
                run_multiclass_machine_learning(classification, features_importance_dict, l, ml_algos,vertex_to_tags,
                                                node_to_zscoringfeatures, number_of_learning_for_mean, result_path,
                                                load_clf_file_name=load_clf_file_name
                                                , save_clf_file_name=save_clf_file_name,
                                                random_state=random_state,
                                                test_size=test_size)

            else:
                run_binary_machine_learning(classification, features_importance_dict, l, ml_algos, vertex_to_tags,
                                            node_to_zscoringfeatures, number_of_learning_for_mean, result_path,
                                            load_clf_file_name=load_clf_file_name,
                                            save_clf_file_name=save_clf_file_name,
                                            random_state=random_state,
                                            test_size=test_size)


def run_multiclass_machine_learning(classification, features_importance_dict, l, ml_algos,vertex_to_tags,
                                    node_to_zscoringfeatures, number_of_learning_for_mean, result_path,
                                    load_clf_file_name, save_clf_file_name, test_size , random_state=None):
    confusion_matrix_file_name = result_path + classification + '_confusion_matrix.txt'
    confusion_matrix_file = open(confusion_matrix_file_name, 'a')
    features_importance_file_name = result_path + 'features_importance.csv'
    features_importance_file = open(features_importance_file_name, 'w')
    for algo in ml_algos:
        print (algo)
        sum_confusion_matrix_test = 0
        sum_feature_importance = 0
        for i in range(int(number_of_learning_for_mean)):
            cls = l.implementLearningMethod(algo, load_clf_file_name=load_clf_file_name
                                            , save_clf_file_name=save_clf_file_name, test_size=test_size,
                                            random_state=random_state)
            if i < 2:
                coloring_file_name = result_path + algo +'_coloring.txt'
                l.write_coloring_file(node_to_zscoringfeatures, vertex_to_tags, coloring_file_name)
            # if (algo == 'RF'):
            #     sum_feature_importance += cls.feature_importances_
            #     print len(cls.feature_importances_)
            #     print cls.feature_importances_
            cm = l.evaluate_confusion_metric_test()
            sum_confusion_matrix_test += cm
        confusion_matrix_file.writelines(algo + ',' + str(sum_confusion_matrix_test))
        plot_file_name = result_path + '//' + algo + '_confusion_matrix.png'
        classes = [str(c) for c in set((vertex_to_tags.values()))]
        print (classes)
        l.plot_confusion_matrix(sum_confusion_matrix_test, classes, True,
                                title='Confusion Matrix', plot_file_name=plot_file_name)

        # if algo == 'RF':
        #     for fi in features_importance_dict:
        #         feature_importance_value = sum_feature_importance[fi] / number_of_learning_for_mean
        #         features_importance_file.writelines(
        #             features_importance_dict[fi] + ',' + str(feature_importance_value) + '\n')
    features_importance_file.close()
    confusion_matrix_file.close()


def run_binary_machine_learning(classification, features_importance_dict, l, ml_algos, vertex_to_tags,
                                node_to_zscoringfeatures, number_of_learning_for_mean, result_path,
                                load_clf_file_name, save_clf_file_name,test_size, random_state=None):
    output_file_name = result_path + classification + '_auc.csv'
    auc_file = open(output_file_name, 'a')
    features_importance_file_name = result_path + classification + '_features_importance.csv'
    features_importance_file = open(features_importance_file_name, 'w')
    for algo in ml_algos:
        print (algo)
        sum_auc_test = 0
        sum_auc_train = 0
        sum_f1_test = 0
        sum_feature_importance = 0
        for i in range(int(number_of_learning_for_mean)):
            cls = l.implementLearningMethod(algo, test_size=test_size
                                            ,load_clf_file_name=load_clf_file_name,
                                            save_clf_file_name=save_clf_file_name,
                                            random_state=random_state)
            # if i < 2:
            #     coloring_file_name = result_path + algo +'_coloring.txt'
            #     l.write_coloring_file(node_to_zscoringfeatures, vertex_to_tags, coloring_file_name)
            # if (algo == 'RF'):
            #     sum_feature_importance += cls.feature_importances_
            #     print len(cls.feature_importances_)
            #     print cls.feature_importances_
            auc_test = l.evaluate_AUC_test()
            print ('auc_test', auc_test)
            sum_auc_test += auc_test
            auc_train = l.evaluate_AUC_train()
            print ('auc_train', auc_train)
            sum_auc_train += auc_train
            f1_score = l.evaluate_f1_score()
            print ('f1_score', f1_score)
            sum_f1_test += f1_score
        auc_file.writelines(algo + ',' + str(sum_auc_test / number_of_learning_for_mean) + '\n')
        auc_file.writelines(algo + ' f1,' + str(sum_f1_test / number_of_learning_for_mean) + '\n')
        print ('mean_feature_importance', sum_feature_importance / number_of_learning_for_mean)
        print ('mean_auc_test', sum_auc_test / number_of_learning_for_mean)
        print ('mean_auc_train', sum_auc_train / number_of_learning_for_mean)
        print ('mean_f1_test', sum_f1_test / number_of_learning_for_mean)
        # if algo == 'RF':
        #     for fi in features_importance_dict:
        #         feature_importance_value = sum_feature_importance[fi] / number_of_learning_for_mean
        #         features_importance_file.writelines(
        #             features_importance_dict[fi] + ',' + str(feature_importance_value) + '\n')
    features_importance_file.close()
    auc_file.close()


def deepLearning(gnx, map_fetures, number_of_learning_for_mean, classifications,tags_loader, result_path,edges=False,
                 load_clf_file_name=None, save_clf_file_name=None, test_size=0.2, random_state=None):
    from learning import deep_learning as deep
    if(edges):
        for classification in classifications:
            edge_to_tags = tags_loader.calssification_to_edge_to_tag[classification]
            result = features_matrix.build_matrix_with_tags_edges(gnx, map_fetures, edge_to_tags, zscoring=True)
            feature_matrix = result[0]
            tags_vector = np.squeeze(np.asarray(result[1]))
            deepL = deep.DeepLearning(feature_matrix, tags_vector)
            if load_clf_file_name != None:
                load_clf_file_name = load_clf_file_name + classification + '_'
            if save_clf_file_name != None:
                save_clf_file_name = save_clf_file_name + classification + '_'

            if len(set(edge_to_tags.values())) != 2:
                run_multiclass_deep_learning(classification, deepL, number_of_learning_for_mean, result_path,
                                             load_clf_file_name, save_clf_file_name, test_size=test_size,
                                             random_state=random_state)
            else:
                run_binary_deep_learning(classification, deepL, number_of_learning_for_mean, result_path,
                                         load_clf_file_name, save_clf_file_name, test_size=test_size,
                                         random_state=random_state)
    else:
        for classification in classifications:

            vertex_to_tags = tags_loader.calssification_to_vertex_to_tag[classification]
            result = features_matrix.build_matrix_with_tags(gnx, map_fetures, vertex_to_tags, zscoring=True)
            feature_matrix = result[0]
            tags_vector = np.squeeze(np.asarray(result[1]))
            myTrain.deepLearning(feature_matrix, tags_vector, result[3], gnx)


            # deepL = deep.DeepLearning(feature_matrix, tags_vector)
            # if load_clf_file_name != None:
            #     load_clf_file_name = load_clf_file_name + classification + '_'
            # if save_clf_file_name != None:
            #     save_clf_file_name = save_clf_file_name + classification + '_'
            #
            # if len(set(vertex_to_tags.values())) != 2:
            #     run_multiclass_deep_learning(classification, deepL, number_of_learning_for_mean, result_path,
            #                                  load_clf_file_name, save_clf_file_name,test_size=test_size,
            #                                  random_state=random_state)
            # else:
            #     run_binary_deep_learning(classification, deepL, number_of_learning_for_mean, result_path,
            #                              load_clf_file_name, save_clf_file_name, test_size=test_size,
            #                              random_state=random_state)


def run_multiclass_deep_learning(classification, deepL, number_of_learning_for_mean, result_path,
                                 load_clf_file_name, save_clf_file_name,test_size, random_state = None):
    confusion_matrix_file = result_path + classification + '_confusion_matrix.txt'
    sum_confusion_matrix_test = 0
    for i in range(int(number_of_learning_for_mean)):
        cls = deepL.runNetwork(test_size, output_activation='softmax', output_size=7,
                               load_clf_file_name=load_clf_file_name, save_clf_file_name=save_clf_file_name,
                               random_state=random_state)
        cm = deepL.evaluate_confusion_metric_test()
        sum_confusion_matrix_test += cm
    confusion_matrix_file.writelines('deep,' + str(sum_confusion_matrix_test))
    plot_file_name = result_path + '//deep_confusion_matrix.png'
    deepL.plot_confusion_matrix(sum_confusion_matrix_test, ['0', '1', '2', '3', '4', '5', '6'], True,
                                title='Confusion Matrix', plot_file_name=plot_file_name)
    confusion_matrix_file.close()


def run_binary_deep_learning(classification, deepL, number_of_learning_for_mean, result_path,
                             load_clf_file_name, save_clf_file_name,test_size, random_state=None):
    sum_auc_test = 0
    sum_auc_train = 0
    sum_f1_test = 0
    output_file_name = result_path + classification + '_auc.csv'
    auc_file = open(output_file_name, 'a')
    for i in range(int(number_of_learning_for_mean)):
        cls = deepL.runNetwork(test_size,load_clf_file_name=load_clf_file_name, save_clf_file_name=save_clf_file_name,
                               random_state=random_state)
        auc_test = deepL.evaluate_AUC_test()
        print ('auc_test', auc_test)
        sum_auc_test += auc_test
        auc_train = deepL.evaluate_AUC_train()
        print ('auc_train', auc_train)
        sum_auc_train += auc_train
        f1_score = deepL.evaluate_f1_score()
        print ('f1_score', f1_score)
        sum_f1_test += f1_score
    auc_file.writelines('deep ,' + str(sum_auc_test / number_of_learning_for_mean) + '\n')
    auc_file.writelines('deep f1,' + str(sum_f1_test/number_of_learning_for_mean) + '\n')
    print ('mean_auc_test', sum_auc_test / number_of_learning_for_mean)
    print ('mean_auc_train', sum_auc_train / number_of_learning_for_mean)
    print ('mean_f1_test', sum_f1_test/number_of_learning_for_mean)
    auc_file.close()
# -*- coding: utf-8 -*-

import abc
import os
import sys
import logging

from pathlib import Path
import numpy as np
import logging
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.layers.normalization import BatchNormalization
from keras.optimizers import Adam
from keras.utils import np_utils
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping
from keras import regularizers

from make_tensorboard import make_tensorboard
from util import io


""" log settings    """
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s :%(message)s')


class DeepLearningModeler(object):
    logging.debug('DeepLearningModeler Start')

    # Reproducibility model
    RANDOM_SEED = 1024
    MODEL_LOG_DIR = 'model_log'

    # network and training
    RESHAPED = 784
    NB_TEST = 10000             # テスト用(秘匿)
    NB_TRAIN = 60000            # 学習用(検証用含む)
    NB_EPOCH = 5                # エポック回数
    BATCH_SIZE = 128            # バッチサイズ
    VERBOSE = 1                 # log revel
    NB_CLASSES = 10             # number of outputs = number of digits
    OPTIMIZER = Adam(lr=0.01, beta_1=0.9, beta_2=0.999)  # Adam optimizer
    N_HIDDEN = 128              # 隠れ層のニューロン数
    VALIDATION_SPLIT = 0.2      # how much TRAIN is reserved for VALIDATION
    DROPOUT = 0.3               #
    ACTIVATION = 'relu'         #

    def __init__(self):
        logging.debug('DeepLearningModeler.__init__ Start')

        print(os.path.dirname(__file__))

        self.X_train = None
        self.Y_train = None
        self.X_test = None
        self.Y_test = None
        self.y_train = None
        self.y_test = None

        self.model = None

        try:
            __model_log_dir = r'src/cultivation/' + DeepLearningModeler.MODEL_LOG_DIR
            os.path.isdir(__model_log_dir)
            logging.debug('model_log_dir = {}'.format(__model_log_dir))

        except IOError:
            print('MODEL_LOG_DIR is not found.')
            logging.critical('Fail to load MODEL_LOG_DIR.')
            sys.exit(1)

        logging.debug('DeepLearningModeler.__init__ End')

    def __del__(self):
        logging.debug('DeepLearningModeler End')

    def load_mnist_data(self):
        """ define data set  """

        logging.debug('DeepLearningModeler.load_mnist_data Start')
        # data: shuffled and split between train and test sets
        (self.X_train, self.y_train), (self.X_test, self.y_test) = mnist.load_data()

        # X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784
        self.X_train = self.X_train.reshape(DeepLearningModeler.NB_TRAIN,
                                            DeepLearningModeler.RESHAPED)
        self.X_test = self.X_test.reshape(DeepLearningModeler.NB_TEST,
                                          DeepLearningModeler.RESHAPED)
        self.X_train = self.X_train.astype('float32')
        self.X_test = self.X_test.astype('float32')

        # normalize
        self.X_train /= 255
        self.X_test /= 255
        logging.debug('train samples: {}'.format(self.X_train.shape[0]))
        logging.debug('test samples: {}'.format(self.X_test.shape[0]))

        # convert class vectors to binary class matrices
        self.Y_train = np_utils.to_categorical(
            self.y_train, DeepLearningModeler.NB_CLASSES)
        self.Y_test = np_utils.to_categorical(
            self.y_test, DeepLearningModeler.NB_CLASSES)

        logging.debug('DeepLearningModeler.load_mnist_data End')

    def define_model(self):
        pass

    def define_model_by_sequence(self):
        logging.debug('DeepLearningModeler.define_model_by_sequence Start')
        # 10 outputs
        # final stage is softmax

        self.model = Sequential()
        # l1: 728 -> 128
        self.model.add(Dense(DeepLearningModeler.N_HIDDEN,
                             input_shape=(DeepLearningModeler.RESHAPED,)))
        self.model.add(BatchNormalization())
        self.model.add(Activation(DeepLearningModeler.ACTIVATION))
        self.model.add(Dropout(DeepLearningModeler.DROPOUT))

        # l2: 128 -> 128
        self.model.add(Dense(DeepLearningModeler.N_HIDDEN))
        self.model.add(BatchNormalization())
        self.model.add(Activation(DeepLearningModeler.ACTIVATION))
        self.model.add(Dropout(DeepLearningModeler.DROPOUT))

        # l3: 128 -> 10
        self.model.add(Dense(DeepLearningModeler.NB_CLASSES))
        self.model.add(Activation('softmax'))

        self.model.summary()

        logging.debug('DeepLearningModeler.define_model_by_sequence End')

    def define_model_by_repetition(self):
        pass

    def compile_model(self):
        self.model.compile(loss='categorical_crossentropy',
                           optimizer=DeepLearningModeler.OPTIMIZER,
                           metrics=['accuracy'],
                           )


class MNISTDatasetCNN(object):
    def __init__(self):
        self.image_shape = (28, 28, 1)  # image is 28x28x1 (grayscale)
        self.num_classes = 10

    def get_batch(self):
        (x_train, y_train), (x_test, y_test) = mnist.load_data()

        x_train, x_test = [self.preprocess(d) for d in [x_train, x_test]]
        y_train, y_test = [self.preprocess(d, label_data=True) for d in
                           [y_train, y_test]]

        return x_train, y_train, x_test, y_test

    def preprocess(self, data, label_data=False):
        if label_data:
            # convert class vectors to binary class matrices
            data = to_categorical(data, self.num_classes)
        else:
            data = data.astype("float32")
            data /= 255  # convert the value to 0~1 scale
            shape = (data.shape[0],) + self.image_shape  # add dataset length
            data = data.reshape(shape)

        return data
    
class MNISTDatasetDNN(object):
    def __init__(self):
        self.image_shape = 728  # image is 28x28x1 (grayscale)
        self.num_classes = 10

        self.RESHAPED = 784
        self.NB_TEST = 10000  # テスト用(秘匿)
        self.NB_TRAIN = 60000  # 学習用(検証用含む)

    def get_batch(self):
        # data: shuffled and split between train and test sets
        (x_train, y_train), (x_test, y_test) = mnist.load_data()

        # X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784
        x_train = x_train.reshape(self.NB_TRAIN, self.RESHAPED)
        x_test = x_test.reshape(self.NB_TEST, self.RESHAPED)
        x_train = x_train.astype('float32')
        x_test = x_test.astype('float32')

        # normalize
        x_train /= 255
        x_test /= 255

        # convert class vectors to binary class matrices
        y_train = to_categorical(y_train, self.NB_CLASSES)
        y_test = to_categorical(y_test, self.NB_CLASSES)

        return x_train, y_train, x_test, y_test

    def preprocess(self, data, label_data=False):
        if label_data:
            # convert class vectors to binary class matrices
            data = to_categorical(data, self.num_classes)
        else:
            data = data.astype("float32")
            data /= 255  # convert the value to 0~1 scale
            shape = (data.shape[0],) + self.image_shape  # add dataset length
            data = data.reshape(shape)

        return data


def dnnet(input_shape, num_classes):
    # network and training
    RESHAPED = input_shape
    NB_CLASSES = num_classes    # number of outputs = number of digits
    N_HIDDEN = 128              # 隠れ層のニューロン数
    DROPOUT = 0.3               #
    ACTIVATION = 'relu'         #

    # Sequential design
    model = Sequential()

    # l1: 728 -> 128
    model.add(N_HIDDEN, input_shape=(RESHAPED,))
    model.add(BatchNormalization())
    model.add(Activation(ACTIVATION))
    model.add(Dropout(DROPOUT))

    # l2: 128 -> 128
    model.add(Dense(N_HIDDEN))
    model.add(BatchNormalization())
    model.add(Activation(ACTIVATION))
    model.add(Dropout(DROPOUT))

    # l3: 128 -> 10
    model.add(Dense(NB_CLASSES))
    model.add(Activation('softmax'))

    model.summary()

    return model


class Trainer(object):
    def __init__(self, model, loss, optimizer):
        self._target = model
        self._target.compile(
            loss=loss, optimizer=optimizer, metrics=["accuracy"]
            )
        self.verbose = 1
        logdir = "logdir_lenet"
        self.log_dir = os.path.join(os.path.dirname(__file__), logdir)

    def train(self, x_train, y_train, batch_size, epochs, validation_split):
        if os.path.exists(self.log_dir):
            import shutil
            shutil.rmtree(self.log_dir)  # remove previous execution
        os.mkdir(self.log_dir)

        self._target.fit(
            x_train, y_train,
            batch_size=batch_size, epochs=epochs,
            validation_split=validation_split,
            callbacks=[TensorBoard(log_dir=self.log_dir)],
            verbose=self.verbose
        )




def lenet(input_shape, num_classes):
    model = Sequential()

    # extract image features by convolution and max pooling layers
    model.add(Conv2D(
        20, kernel_size=5, padding="same",
        input_shape=input_shape, activation="relu"
    ))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(50, kernel_size=5, padding="same", activation="relu"))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    # classify the class by fully-connected layers
    model.add(Flatten())
    model.add(Dense(500, activation="relu"))
    model.add(Dense(num_classes))
    model.add(Activation("softmax"))
    return model







#!/usr/bin/python
# -*- coding: utf-8 -*-

import tensorflow as tf
from tensorflow_estimator import estimator


# LR: Predicting Clicks - Estimating the Click-Through Rate for New Ads.
def lr(features, labels, mode, params):

    # --------------- hyper-parameters --------------- #
    feature_size = params["feature_size"]
    field_size = params["field_size"]
    loss_mode = params["loss_mode"]
    optimizer = params["optimizer"]
    learning_rate = params["learning_rate"]
    l2_reg_lambda = params["l2_reg_lambda"]

    # --------------- initial weights ---------------- #
    # [numeric_feature, one-hot categorical_feature]
    coe_b = tf.get_variable(name="coe_b", shape=[1], initializer=tf.constant_initializer(0.0))
    coe_w = tf.get_variable(name="coe_w", shape=[feature_size], initializer=tf.glorot_normal_initializer())

    # --------------- reshape feature ---------------- #
    feat_idx = features["feat_idx"]         # 非零特征位置[batch_size, field_size, 1]
    feat_idx = tf.reshape(feat_idx, shape=[-1, field_size])     # [Batch, Field]
    feat_val = features["feat_val"]         # 非零特征的值[batch_size, field_size, 1]
    feat_val = tf.reshape(feat_val, shape=[-1, field_size])     # [Batch, Field]

    # ------------------ define f(x) ----------------- #
    # LR: y = b + sum<wi,xi>
    with tf.variable_scope("First-Order"):
        feat_wgt = tf.nn.embedding_lookup(coe_w, feat_idx)              # [Batch, Field]
        y_w = tf.reduce_sum(tf.multiply(feat_wgt, feat_val), 1)         # [Batch]

    with tf.variable_scope("LR-Out"):
        y_b = coe_b * tf.ones_like(y_w, dtype=tf.float32)               # [Batch]
        y_hat = y_b + y_w                                               # [Batch]
        y_pred = tf.nn.sigmoid(y_hat)                                   # [Batch]

    # ---------- mode: predict/evaluate/train ---------- #
    # predict: 不计算loss/metric; evaluate: 不进行梯度下降和参数更新

    # Provide an estimator spec for 'ModeKeys.PREDICT'
    predictions = {"prob": y_pred}
    export_outputs = {
        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
            estimator.export.PredictOutput(predictions)}
    if mode == estimator.ModeKeys.PREDICT:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)

    # Provide an estimator spec for 'ModeKeys.EVAL'
    if loss_mode == "log_loss":
        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=y_hat)) +\
               l2_reg_lambda * tf.nn.l2_loss(coe_w)
    else:
        loss = tf.reduce_mean(tf.square(labels-y_pred))
    eval_metric_ops = {"auc": tf.metrics.auc(labels, y_pred)}
    if mode == estimator.ModeKeys.EVAL:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss,
                                       eval_metric_ops=eval_metric_ops)

    # Provide an estimator spec for 'ModeKeys.TRAIN'
    if optimizer == "Adam":
        opt_mode = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)
    elif optimizer == "Adagrad":
        opt_mode = tf.train.AdagradOptimizer(learning_rate=learning_rate, initial_accumulator_value=1e-8)
    elif optimizer == "Momentum":
        opt_mode = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.95)
    elif optimizer == "Ftrl":
        opt_mode = tf.train.FtrlOptimizer(learning_rate)
    else:
        opt_mode = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    train_op = opt_mode.minimize(loss, global_step=tf.train.get_global_step())

    if mode == estimator.ModeKeys.TRAIN:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op)


# FM: Factorization Machines./Factorization Machines with libFM.
# Fast Context-aware Recommendations with Factorization Machines.
def fm(features, labels, mode, params):

    # ---------- hyper-parameters ---------- #
    feature_size = params["feature_size"]
    field_size = params["field_size"]
    embed_size = params["embed_size"]
    loss_mode = params["loss_mode"]
    optimizer = params["optimizer"]
    learning_rate = params["learning_rate"]
    l2_reg_lambda = params["l2_reg_lambda"]

    # ---------- initial weights ----------- #
    # [numeric_feature, one-hot categorical_feature]统一做embedding
    coe_b = tf.get_variable(name="coe_b", shape=[1], initializer=tf.constant_initializer(0.0))
    coe_w = tf.get_variable(name="coe_w", shape=[feature_size], initializer=tf.glorot_normal_initializer())
    coe_v = tf.get_variable(name="coe_v", shape=[feature_size, embed_size],
                            initializer=tf.glorot_normal_initializer())

    # ---------- reshape feature ----------- #
    feat_idx = features["feat_idx"]         # 非零特征位置[batch_size, field_size, 1]
    feat_idx = tf.reshape(feat_idx, shape=[-1, field_size])     # [Batch, Field]
    feat_val = features["feat_val"]         # 非零特征的值[batch_size, field_size, 1]
    feat_val = tf.reshape(feat_val, shape=[-1, field_size])     # [Batch, Field]

    # ------------- define f(x) ------------ #
    # FM: y = b + sum<wi,xi> + sum(<vi,vj>xi*xj)
    with tf.variable_scope("First-Order"):
        feat_wgt = tf.nn.embedding_lookup(coe_w, feat_idx)              # [Batch, Field]
        y_w = tf.reduce_sum(tf.multiply(feat_wgt, feat_val), 1)         # [Batch]

    with tf.variable_scope("Second-Order"):
        embeddings = tf.nn.embedding_lookup(coe_v, feat_idx)            # [Batch, Field, K]
        feat_vals = tf.reshape(feat_val, shape=[-1, field_size, 1])     # [Batch, Field, 1]
        embeddings = tf.multiply(embeddings, feat_vals)                 # [Batch, Field, K]
        sum_square = tf.square(tf.reduce_sum(embeddings, 1))            # [Batch, K]
        square_sum = tf.reduce_sum(tf.square(embeddings), 1)            # [Batch, K]
        y_v = 0.5*tf.reduce_sum(tf.subtract(sum_square, square_sum), 1)     # [Batch]

    with tf.variable_scope("FM-Out"):
        y_b = coe_b * tf.ones_like(y_w, dtype=tf.float32)       # [Batch]
        y_hat = y_b + y_w + y_v                                 # [Batch]
        y_pred = tf.nn.sigmoid(y_hat)                           # [Batch]

    # ----- mode: predict/evaluate/train ----- #
    # predict: 不计算loss/metric; evaluate: 不进行梯度下降和参数更新

    # Provide an estimator spec for 'ModeKeys.PREDICT'
    predictions = {"prob": y_pred}
    export_outputs = {
        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
            estimator.export.PredictOutput(predictions)}
    if mode == estimator.ModeKeys.PREDICT:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)

    # Provide an estimator spec for 'ModeKeys.EVAL'
    if loss_mode == "log_loss":
        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=y_hat)) +\
               l2_reg_lambda * tf.nn.l2_loss(coe_w) + l2_reg_lambda * tf.nn.l2_loss(coe_v)
    else:
        loss = tf.reduce_mean(tf.square(labels-y_pred))
    eval_metric_ops = {"auc": tf.metrics.auc(labels, y_pred)}
    if mode == estimator.ModeKeys.EVAL:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss,
                                       eval_metric_ops=eval_metric_ops)

    # Provide an estimator spec for 'ModeKeys.TRAIN'
    if optimizer == "Adam":
        opt_mode = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)
    elif optimizer == "Adagrad":
        opt_mode = tf.train.AdagradOptimizer(learning_rate=learning_rate, initial_accumulator_value=1e-8)
    elif optimizer == "Momentum":
        opt_mode = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.95)
    elif optimizer == "Ftrl":
        opt_mode = tf.train.FtrlOptimizer(learning_rate)
    else:
        opt_mode = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    train_op = opt_mode.minimize(loss, global_step=tf.train.get_global_step())

    if mode == estimator.ModeKeys.TRAIN:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op)


# Deep Crossing - Web-Scale Modeling without Manually Crafted Combinatorial Features.
def deepcrossing(features, labels, mode, params):

    # ---------- hyper-parameters ---------- #
    feature_size = params["feature_size"]
    field_size = params["field_size"]
    embed_size = params["embed_size"]
    loss_mode = params["loss_mode"]
    optimizer = params["optimizer"]
    learning_rate = params["learning_rate"]
    l2_reg_lambda = params["l2_reg_lambda"]
    layers = list(map(int, params["deep_layers"].split(',')))       # l1神经元数量等于D1长度
    dropout = list(map(float, params["dropout"].split(',')))

    # ---------- initial weights ----------- #
    # [numeric_feature, one-hot categorical_feature]统一做embedding
    coe_v = tf.get_variable(name="coe_v", shape=[feature_size, embed_size],
                            initializer=tf.glorot_normal_initializer())

    # ---------- reshape feature ----------- #
    feat_idx = features["feat_idx"]         # 非零特征位置[batch_size, field_size, 1]
    feat_idx = tf.reshape(feat_idx, shape=[-1, field_size])     # [Batch, Field]
    feat_val = features["feat_val"]         # 非零特征的值[batch_size, field_size, 1]
    feat_val = tf.reshape(feat_val, shape=[-1, field_size])     # [Batch, Field]

    # ------------- define f(x) ------------ #
    with tf.variable_scope("Embed-Layer"):
        embeddings = tf.nn.embedding_lookup(coe_v, feat_idx)            # [Batch, Field, K]
        feat_vals = tf.reshape(feat_val, shape=[-1, field_size, 1])     # [Batch, Field, 1]
        embeddings = tf.multiply(embeddings, feat_vals)                 # [Batch, Field, K]

    with tf.variable_scope("Stack-Layer"):
        deep_inputs = tf.reshape(embeddings, shape=[-1, field_size*embed_size])     # [Batch, Field*K]

    with tf.variable_scope("Deep-Layer"):
        # 论文采用ResNet,代码采用fully connected
        for i in range(len(layers)):
            deep_inputs = tf.contrib.layers.fully_connected(
                inputs=deep_inputs, num_outputs=layers[i], scope="mlp_%d" % i,
                weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda))
            if mode == estimator.ModeKeys.TRAIN:
                deep_inputs = tf.nn.dropout(deep_inputs, keep_prob=dropout[i])

        # output layer
        y_d = tf.contrib.layers.fully_connected(
            inputs=deep_inputs, num_outputs=1, activation_fn=tf.identity,
            weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda), scope='deep_out')

    with tf.variable_scope("DC-Out"):
        y_hat = tf.reshape(y_d, shape=[-1])
        y_pred = tf.nn.sigmoid(y_hat)

    # ----- mode: predict/evaluate/train ----- #
    # predict: 不计算loss/metric; evaluate: 不进行梯度下降和参数更新

    # Provide an estimator spec for 'ModeKeys.PREDICT'
    predictions = {"prob": y_pred}
    export_outputs = {
        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
            estimator.export.PredictOutput(predictions)}
    if mode == estimator.ModeKeys.PREDICT:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)

    # Provide an estimator spec for 'ModeKeys.EVAL'
    if loss_mode == "log_loss":
        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=y_hat)) +\
               l2_reg_lambda * tf.nn.l2_loss(coe_v)
    else:
        loss = tf.reduce_mean(tf.square(labels-y_pred))
    eval_metric_ops = {"auc": tf.metrics.auc(labels, y_pred)}
    if mode == estimator.ModeKeys.EVAL:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss,
                                       eval_metric_ops=eval_metric_ops)

    # Provide an estimator spec for 'ModeKeys.TRAIN'
    if optimizer == "Adam":
        opt_mode = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)
    elif optimizer == "Adagrad":
        opt_mode = tf.train.AdagradOptimizer(learning_rate=learning_rate, initial_accumulator_value=1e-8)
    elif optimizer == "Momentum":
        opt_mode = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.95)
    elif optimizer == "Ftrl":
        opt_mode = tf.train.FtrlOptimizer(learning_rate)
    else:
        opt_mode = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    train_op = opt_mode.minimize(loss, global_step=tf.train.get_global_step())

    if mode == estimator.ModeKeys.TRAIN:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op)


# FNN: Deep Learning over Multi-Field Categorical Data: A Case Study on User Response Prediction.
# PNN: Product-based Neural Networks for User Response Prediction.
def fpnn(features, labels, mode, params):

    # ---------- hyper-parameters ---------- #
    algorithm = params["algorithm"]
    feature_size = params["feature_size"]
    field_size = params["field_size"]
    embed_size = params["embed_size"]
    loss_mode = params["loss_mode"]
    optimizer = params["optimizer"]
    learning_rate = params["learning_rate"]
    l2_reg_lambda = params["l2_reg_lambda"]
    layers = list(map(int, params["deep_layers"].split(',')))       # l1神经元数量等于D1长度
    dropout = list(map(float, params["dropout"].split(',')))

    # ---------- initial weights ----------- #
    # [numeric_feature, one-hot categorical_feature]统一做embedding
    coe_b = tf.get_variable(name="coe_b", shape=[1], initializer=tf.constant_initializer(0.0))
    coe_w = tf.get_variable(name="coe_w", shape=[feature_size], initializer=tf.glorot_normal_initializer())
    coe_v = tf.get_variable(name="coe_v", shape=[feature_size, embed_size],
                            initializer=tf.glorot_normal_initializer())
    coe_line = tf.get_variable(name="coe_line", shape=[layers[0], field_size, embed_size],
                               initializer=tf.glorot_normal_initializer())
    coe_ipnn = tf.get_variable(name="coe_ipnn", shape=[layers[0], field_size],
                               initializer=tf.glorot_normal_initializer())
    coe_opnn = tf.get_variable(name="coe_opnn", shape=[layers[0], embed_size, embed_size],
                               initializer=tf.glorot_normal_initializer())

    # ---------- reshape feature ----------- #
    feat_idx = features["feat_idx"]         # 非零特征位置[batch_size, field_size, 1]
    feat_idx = tf.reshape(feat_idx, shape=[-1, field_size])     # [Batch, Field]
    feat_val = features["feat_val"]         # 非零特征的值[batch_size, field_size, 1]
    feat_val = tf.reshape(feat_val, shape=[-1, field_size])     # [Batch, Field]

    # ------------- define f(x) ------------ #
    with tf.variable_scope("Linear-Part"):
        feat_wgt = tf.nn.embedding_lookup(coe_w, feat_idx)              # [Batch, Field]
        y_linear = tf.reduce_sum(tf.multiply(feat_wgt, feat_val), 1)    # [Batch]

    with tf.variable_scope("Embed-Layer"):
        embeddings = tf.nn.embedding_lookup(coe_v, feat_idx)            # [Batch, Field, K]
        feat_vals = tf.reshape(feat_val, shape=[-1, field_size, 1])     # [Batch, Field, 1]
        embeddings = tf.multiply(embeddings, feat_vals)                 # [Batch, Field, K]

    with tf.variable_scope("Product-Layer"):
        if algorithm == "FNN":
            feat_vec = tf.reshape(embeddings, shape=[-1, field_size*embed_size])
            feat_bias = coe_b * tf.reshape(tf.ones_like(y_linear, dtype=tf.float32), shape=[-1, 1])
            deep_inputs = tf.concat([feat_wgt, feat_vec, feat_bias], 1)     # [Batch, (Field+1)*K+1]
        elif algorithm == "IPNN":
            # linear signal
            z = tf.reshape(embeddings, shape=[-1, field_size*embed_size])   # [Batch, Field*K]
            wz = tf.reshape(coe_line, shape=[-1, field_size*embed_size])    # [D1, Field*K]
            lz = tf.matmul(z, tf.transpose(wz))                             # [Batch, D1]

            # quadratic signal
            row_i = []
            col_j = []
            for i in range(field_size - 1):
                for j in range(i + 1, field_size):
                    row_i.append(i)
                    col_j.append(j)
            fi = tf.gather(embeddings, row_i, axis=1)           # 根据索引从参数轴上收集切片[Batch, num_pairs, K]
            fj = tf.gather(embeddings, col_j, axis=1)           # 根据索引从参数轴上收集切片[Batch, num_pairs, K]

            # p_ij = g(fi,fj)=<fi,fj> 特征i和特征j的隐向量的内积
            p = tf.reduce_sum(tf.multiply(fi, fj), 2)           # p矩阵展成向量[Batch, num_pairs]
            wpi = tf.gather(coe_ipnn, row_i, axis=1)            # 根据索引从参数轴上收集切片[D1, num_pairs]
            wpj = tf.gather(coe_ipnn, col_j, axis=1)            # 根据索引从参数轴上收集切片[D1, num_pairs]
            wp = tf.multiply(wpi, wpj)                          # D1个W矩阵组成的矩阵(每行代表一个W)[D1, num_pairs]
            lp = tf.matmul(p, tf.transpose(wp))                 # [Batch, D1]

            lb = coe_b * tf.reshape(tf.ones_like(y_linear, dtype=tf.float32), shape=[-1, 1])
            deep_inputs = lz + lp + lb                          # [Batch, D1]
        elif algorithm == "OPNN":
            # linear signal
            z = tf.reshape(embeddings, shape=[-1, field_size*embed_size])   # [Batch, Field*K]
            wz = tf.reshape(coe_line, shape=[-1, field_size*embed_size])    # [D1, Field*K]
            lz = tf.matmul(z, tf.transpose(wz))                             # [Batch, D1]

            # quadratic signal
            f_sigma = tf.reduce_sum(embeddings, axis=1)                     # [Batch, K]
            p = tf.matmul(tf.reshape(f_sigma, shape=[-1, embed_size, 1]),
                          tf.reshape(f_sigma, shape=[-1, 1, embed_size]))   # [Batch, K, K]
            p = tf.reshape(p, shape=[-1, embed_size*embed_size])            # [Batch, K*K]
            wp = tf.reshape(coe_opnn, shape=[-1, embed_size*embed_size])    # [D1, K*K]
            lp = tf.matmul(p, tf.transpose(wp))                             # [Batch, D1]

            lb = coe_b * tf.reshape(tf.ones_like(y_linear, dtype=tf.float32), shape=[-1, 1])
            deep_inputs = lz + lp + lb                                      # [Batch, D1]

    with tf.variable_scope("Deep-Layer"):
        # hidden layer
        for i in range(len(layers)):
            deep_inputs = tf.contrib.layers.fully_connected(
                inputs=deep_inputs, num_outputs=layers[i], scope="mlp_%d" % i,
                weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda))
            if mode == estimator.ModeKeys.TRAIN:
                deep_inputs = tf.nn.dropout(deep_inputs, keep_prob=dropout[i])

        # output layer
        y_d = tf.contrib.layers.fully_connected(
            inputs=deep_inputs, num_outputs=1, activation_fn=tf.identity,
            weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda), scope='deep_out')

    with tf.variable_scope("FPNN-Out"):
        y_hat = tf.reshape(y_d, shape=[-1])
        y_pred = tf.nn.sigmoid(y_hat)

    # ----- mode: predict/evaluate/train ----- #
    # predict: 不计算loss/metric; evaluate: 不进行梯度下降和参数更新

    # Provide an estimator spec for 'ModeKeys.PREDICT'
    predictions = {"prob": y_pred}
    export_outputs = {
        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
            estimator.export.PredictOutput(predictions)}
    if mode == estimator.ModeKeys.PREDICT:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)

    # Provide an estimator spec for 'ModeKeys.EVAL'
    if loss_mode == "log_loss":
        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=y_hat)) +\
               l2_reg_lambda * tf.nn.l2_loss(coe_w) + l2_reg_lambda * tf.nn.l2_loss(coe_v)
    else:
        loss = tf.reduce_mean(tf.square(labels-y_pred))
    eval_metric_ops = {"auc": tf.metrics.auc(labels, y_pred)}
    if mode == estimator.ModeKeys.EVAL:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss,
                                       eval_metric_ops=eval_metric_ops)

    # Provide an estimator spec for 'ModeKeys.TRAIN'
    if optimizer == "Adam":
        opt_mode = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)
    elif optimizer == "Adagrad":
        opt_mode = tf.train.AdagradOptimizer(learning_rate=learning_rate, initial_accumulator_value=1e-8)
    elif optimizer == "Momentum":
        opt_mode = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.95)
    elif optimizer == "Ftrl":
        opt_mode = tf.train.FtrlOptimizer(learning_rate)
    else:
        opt_mode = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    train_op = opt_mode.minimize(loss, global_step=tf.train.get_global_step())

    if mode == estimator.ModeKeys.TRAIN:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op)


# Wide&Deep: Wide & Deep Learning for Recommender Systems.
def wd(features, labels, mode, params):

    # ---------- hyper-parameters ---------- #
    feature_size = params["feature_size"]
    field_size = params["field_size"]
    embed_size = params["embed_size"]
    loss_mode = params["loss_mode"]
    optimizer = params["optimizer"]
    learning_rate = params["learning_rate"]
    l2_reg_lambda = params["l2_reg_lambda"]
    layers = list(map(int, params["deep_layers"].split(',')))
    dropout = list(map(float, params["dropout"].split(',')))

    # ---------- initial weights ----------- #
    # [numeric_feature, one-hot categorical_feature]统一做embedding
    coe_b = tf.get_variable(name="coe_b", shape=[1], initializer=tf.constant_initializer(0.0))
    coe_w = tf.get_variable(name="coe_w", shape=[feature_size], initializer=tf.glorot_normal_initializer())
    coe_v = tf.get_variable(name="coe_v", shape=[feature_size, embed_size],
                            initializer=tf.glorot_normal_initializer())

    # ---------- reshape feature ----------- #
    feat_idx = features["feat_idx"]         # 非零特征位置[batch_size, field_size, 1]
    feat_idx = tf.reshape(feat_idx, shape=[-1, field_size])     # [Batch, Field]
    feat_val = features["feat_val"]         # 非零特征的值[batch_size, field_size, 1]
    feat_val = tf.reshape(feat_val, shape=[-1, field_size])     # [Batch, Field]

    # ------------- define f(x) ------------ #
    with tf.variable_scope("Wide-Layer"):
        # 论文里面包含人工组合的特征
        feat_wgt = tf.nn.embedding_lookup(coe_w, feat_idx)              # [Batch, Field]
        y_wide = tf.reduce_sum(tf.multiply(feat_wgt, feat_val), 1)      # [Batch]

    with tf.variable_scope("Embed-Layer"):
        embeddings = tf.nn.embedding_lookup(coe_v, feat_idx)            # [Batch, Field, K]
        feat_vals = tf.reshape(feat_val, shape=[-1, field_size, 1])     # [Batch, Field, 1]
        embeddings = tf.multiply(embeddings, feat_vals)                 # [Batch, Field, K]

    with tf.variable_scope("Deep-Layer"):
        deep_inputs = tf.reshape(embeddings, shape=[-1, field_size * embed_size])
        # hidden layer
        for i in range(len(layers)):
            deep_inputs = tf.contrib.layers.fully_connected(
                inputs=deep_inputs, num_outputs=layers[i], scope="mlp_%d" % i,
                weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda))
            if mode == estimator.ModeKeys.TRAIN:
                deep_inputs = tf.nn.dropout(deep_inputs, keep_prob=dropout[i])

        # output layer
        y_d = tf.contrib.layers.fully_connected(
            inputs=deep_inputs, num_outputs=1, activation_fn=tf.identity,
            weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda), scope='deep_out')

    with tf.variable_scope("W_D-Out"):
        y_deep = tf.reshape(y_d, shape=[-1])
        y_bias = coe_b * tf.ones_like(y_wide, dtype=tf.float32)
        y_hat = y_wide + y_deep + y_bias
        y_pred = tf.nn.sigmoid(y_hat)

    # ----- mode: predict/evaluate/train ----- #
    # predict: 不计算loss/metric; evaluate: 不进行梯度下降和参数更新

    # Provide an estimator spec for 'ModeKeys.PREDICT'
    predictions = {"prob": y_pred}
    export_outputs = {
        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
            estimator.export.PredictOutput(predictions)}
    if mode == estimator.ModeKeys.PREDICT:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)

    # Provide an estimator spec for 'ModeKeys.EVAL'
    if loss_mode == "log_loss":
        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=y_hat)) +\
               l2_reg_lambda * tf.nn.l2_loss(coe_w) + l2_reg_lambda * tf.nn.l2_loss(coe_v)
    else:
        loss = tf.reduce_mean(tf.square(labels-y_pred))
    eval_metric_ops = {"auc": tf.metrics.auc(labels, y_pred)}
    if mode == estimator.ModeKeys.EVAL:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss,
                                       eval_metric_ops=eval_metric_ops)

    # Provide an estimator spec for 'ModeKeys.TRAIN'
    if optimizer == "Adam":
        opt_mode = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)
    elif optimizer == "Adagrad":
        opt_mode = tf.train.AdagradOptimizer(learning_rate=learning_rate, initial_accumulator_value=1e-8)
    elif optimizer == "Momentum":
        opt_mode = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.95)
    elif optimizer == "Ftrl":
        opt_mode = tf.train.FtrlOptimizer(learning_rate)
    else:
        opt_mode = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    train_op = opt_mode.minimize(loss, global_step=tf.train.get_global_step())

    if mode == estimator.ModeKeys.TRAIN:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op)


# DeepFM: A Factorization-Machine based Neural Network for CTR Prediction.
def deepfm(features, labels, mode, params):

    # ---------- hyper-parameters ---------- #
    feature_size = params["feature_size"]
    field_size = params["field_size"]
    embed_size = params["embed_size"]
    loss_mode = params["loss_mode"]
    optimizer = params["optimizer"]
    learning_rate = params["learning_rate"]
    l2_reg_lambda = params["l2_reg_lambda"]
    layers = list(map(int, params["deep_layers"].split(',')))
    dropout = list(map(float, params["dropout"].split(',')))

    # ---------- initial weights ----------- #
    # [numeric_feature, one-hot categorical_feature]统一做embedding
    coe_b = tf.get_variable(name="coe_b", shape=[1], initializer=tf.constant_initializer(0.0))
    coe_w = tf.get_variable(name="coe_w", shape=[feature_size], initializer=tf.glorot_normal_initializer())
    coe_v = tf.get_variable(name="coe_v", shape=[feature_size, embed_size],
                            initializer=tf.glorot_normal_initializer())

    # ---------- reshape feature ----------- #
    feat_idx = features["feat_idx"]         # 非零特征位置[batch_size, field_size, 1]
    feat_idx = tf.reshape(feat_idx, shape=[-1, field_size])     # [Batch, Field]
    feat_val = features["feat_val"]         # 非零特征的值[batch_size, field_size, 1]
    feat_val = tf.reshape(feat_val, shape=[-1, field_size])     # [Batch, Field]

    # ------------- define f(x) ------------ #
    with tf.variable_scope("First-Order"):
        feat_wgt = tf.nn.embedding_lookup(coe_w, feat_idx)              # [Batch, Field]
        y_w = tf.reduce_sum(tf.multiply(feat_wgt, feat_val), 1)         # [Batch]

    with tf.variable_scope("Second-Order"):
        embeddings = tf.nn.embedding_lookup(coe_v, feat_idx)            # [Batch, Field, K]
        feat_vals = tf.reshape(feat_val, shape=[-1, field_size, 1])     # [Batch, Field, 1]
        embeddings = tf.multiply(embeddings, feat_vals)                 # [Batch, Field, K]
        sum_square = tf.square(tf.reduce_sum(embeddings, 1))            # [Batch, K]
        square_sum = tf.reduce_sum(tf.square(embeddings), 1)            # [Batch, K]
        y_v = 0.5*tf.reduce_sum(tf.subtract(sum_square, square_sum), 1)     # [Batch]

    with tf.variable_scope("Deep-Layer"):
        deep_inputs = tf.reshape(embeddings, shape=[-1, field_size * embed_size])
        # hidden layer
        for i in range(len(layers)):
            deep_inputs = tf.contrib.layers.fully_connected(
                inputs=deep_inputs, num_outputs=layers[i], scope="mlp_%d" % i,
                weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda))
            if mode == estimator.ModeKeys.TRAIN:
                deep_inputs = tf.nn.dropout(deep_inputs, keep_prob=dropout[i])

        # output layer
        y_d = tf.contrib.layers.fully_connected(
            inputs=deep_inputs, num_outputs=1, activation_fn=tf.identity,
            weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda), scope='deep_out')

    with tf.variable_scope("DeepFM-Out"):
        y_deep = tf.reshape(y_d, shape=[-1])
        y_bias = coe_b * tf.ones_like(y_w, dtype=tf.float32)    # [Batch]
        y_hat = y_bias + y_w + y_v + y_deep                     # [Batch]
        y_pred = tf.nn.sigmoid(y_hat)                           # [Batch]

    # ----- mode: predict/evaluate/train ----- #
    # predict: 不计算loss/metric; evaluate: 不进行梯度下降和参数更新

    # Provide an estimator spec for 'ModeKeys.PREDICT'
    predictions = {"prob": y_pred}
    export_outputs = {
        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
            estimator.export.PredictOutput(predictions)}
    if mode == estimator.ModeKeys.PREDICT:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)

    # Provide an estimator spec for 'ModeKeys.EVAL'
    if loss_mode == "log_loss":
        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=y_hat)) +\
               l2_reg_lambda * tf.nn.l2_loss(coe_w) + l2_reg_lambda * tf.nn.l2_loss(coe_v)
    else:
        loss = tf.reduce_mean(tf.square(labels-y_pred))
    eval_metric_ops = {"auc": tf.metrics.auc(labels, y_pred)}
    if mode == estimator.ModeKeys.EVAL:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss,
                                       eval_metric_ops=eval_metric_ops)

    # Provide an estimator spec for 'ModeKeys.TRAIN'
    if optimizer == "Adam":
        opt_mode = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)
    elif optimizer == "Adagrad":
        opt_mode = tf.train.AdagradOptimizer(learning_rate=learning_rate, initial_accumulator_value=1e-8)
    elif optimizer == "Momentum":
        opt_mode = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.95)
    elif optimizer == "Ftrl":
        opt_mode = tf.train.FtrlOptimizer(learning_rate)
    else:
        opt_mode = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    train_op = opt_mode.minimize(loss, global_step=tf.train.get_global_step())

    if mode == estimator.ModeKeys.TRAIN:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op)


# DCN: Deep & Cross Network for Ad Click Predictions.
def dcn(features, labels, mode, params):

    # ---------- hyper-parameters ---------- #
    feature_size = params["feature_size"]
    field_size = params["field_size"]
    embed_size = params["embed_size"]
    loss_mode = params["loss_mode"]
    optimizer = params["optimizer"]
    learning_rate = params["learning_rate"]
    l2_reg_lambda = params["l2_reg_lambda"]
    layers = list(map(int, params["deep_layers"].split(',')))
    cross_layers = params["cross_layers"]
    dropout = list(map(float, params["dropout"].split(',')))

    # ---------- initial weights ----------- #
    # [numeric_feature, one-hot categorical_feature]统一做embedding
    coe_b = tf.get_variable(name="coe_b", shape=[1], initializer=tf.constant_initializer(0.0))
    coe_v = tf.get_variable(name="coe_v", shape=[feature_size, embed_size],
                            initializer=tf.glorot_normal_initializer())
    cross_b = tf.get_variable(name="cross_b", shape=[cross_layers, field_size*embed_size],
                              initializer=tf.glorot_uniform_initializer())
    cross_w = tf.get_variable(name="cross_w", shape=[cross_layers, field_size*embed_size],
                              initializer=tf.glorot_uniform_initializer())

    # ---------- reshape feature ----------- #
    feat_idx = features["feat_idx"]         # 非零特征位置[batch_size, field_size, 1]
    feat_idx = tf.reshape(feat_idx, shape=[-1, field_size])     # [Batch, Field]
    feat_val = features["feat_val"]         # 非零特征的值[batch_size, field_size, 1]
    feat_val = tf.reshape(feat_val, shape=[-1, field_size])     # [Batch, Field]

    # ------------- define f(x) ------------ #
    with tf.variable_scope("Embed-Layer"):
        embeddings = tf.nn.embedding_lookup(coe_v, feat_idx)                # [Batch, Field, K]
        feat_vals = tf.reshape(feat_val, shape=[-1, field_size, 1])         # [Batch, Field, 1]
        embeddings = tf.multiply(embeddings, feat_vals)                     # [Batch, Field, K]
        x0 = tf.reshape(embeddings, shape=[-1, field_size*embed_size])      # [Batch, Field*K]

    with tf.variable_scope("Cross-Layer"):
        xl = x0
        for l in range(cross_layers):
            wl = tf.reshape(cross_w[l], shape=[-1, 1])      # [Field*K,1]
            xlw = tf.matmul(xl, wl)                         # [Batch, 1]
            xl = x0 * xlw + cross_b[l]                      # [Batch, Field*K]

    with tf.variable_scope("Deep-Layer"):
        deep_inputs = x0                                    # [Batch, Field*K]
        # hidden layer
        for i in range(len(layers)):
            deep_inputs = tf.contrib.layers.fully_connected(
                inputs=deep_inputs, num_outputs=layers[i], scope="mlp_%d" % i,
                weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda))
            if mode == estimator.ModeKeys.TRAIN:
                deep_inputs = tf.nn.dropout(deep_inputs, keep_prob=dropout[i])

    with tf.variable_scope("DCN-Out"):
        x_stack = tf.concat([xl, deep_inputs], 1)
        y_comb = tf.contrib.layers.fully_connected(
            inputs=x_stack, num_outputs=1, activation_fn=tf.identity,
            weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda), scope="comb_layer")
        y_d = tf.reshape(y_comb, shape=[-1])                    # [Batch]
        y_bias = coe_b * tf.ones_like(y_d, dtype=tf.float32)
        y_hat = y_d + y_bias                                    # [Batch]
        y_pred = tf.nn.sigmoid(y_hat)                           # [Batch]

    # ----- mode: predict/evaluate/train ----- #
    # predict: 不计算loss/metric; evaluate: 不进行梯度下降和参数更新

    # Provide an estimator spec for 'ModeKeys.PREDICT'
    predictions = {"prob": y_pred}
    export_outputs = {
        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
            estimator.export.PredictOutput(predictions)}
    if mode == estimator.ModeKeys.PREDICT:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)

    # Provide an estimator spec for 'ModeKeys.EVAL'
    if loss_mode == "log_loss":
        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=y_hat)) \
               + l2_reg_lambda * tf.nn.l2_loss(coe_v) + l2_reg_lambda * tf.nn.l2_loss(cross_b) \
               + l2_reg_lambda * tf.nn.l2_loss(cross_w)
    else:
        loss = tf.reduce_mean(tf.square(labels-y_pred)) + l2_reg_lambda * tf.nn.l2_loss(coe_v) \
               + l2_reg_lambda * tf.nn.l2_loss(cross_b) + l2_reg_lambda * tf.nn.l2_loss(cross_w)
    eval_metric_ops = {"auc": tf.metrics.auc(labels, y_pred)}
    if mode == estimator.ModeKeys.EVAL:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss,
                                       eval_metric_ops=eval_metric_ops)

    # Provide an estimator spec for 'ModeKeys.TRAIN'
    if optimizer == "Adam":
        opt_mode = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)
    elif optimizer == "Adagrad":
        opt_mode = tf.train.AdagradOptimizer(learning_rate=learning_rate, initial_accumulator_value=1e-8)
    elif optimizer == "Momentum":
        opt_mode = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.95)
    elif optimizer == "Ftrl":
        opt_mode = tf.train.FtrlOptimizer(learning_rate)
    else:
        opt_mode = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    train_op = opt_mode.minimize(loss, global_step=tf.train.get_global_step())

    if mode == estimator.ModeKeys.TRAIN:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op)


# NFM: Neural Factorization Machines for Sparse Predictive Analytics.
def nfm(features, labels, mode, params):

    # ---------- hyper-parameters ---------- #
    feature_size = params["feature_size"]
    field_size = params["field_size"]
    embed_size = params["embed_size"]
    loss_mode = params["loss_mode"]
    optimizer = params["optimizer"]
    learning_rate = params["learning_rate"]
    l2_reg_lambda = params["l2_reg_lambda"]
    layers = list(map(int, params["deep_layers"].split(',')))
    dropout = list(map(float, params["dropout"].split(',')))

    # ---------- initial weights ----------- #
    # [numeric_feature, one-hot categorical_feature]统一做embedding
    coe_b = tf.get_variable(name="coe_b", shape=[1], initializer=tf.constant_initializer(0.0))
    coe_w = tf.get_variable(name="coe_w", shape=[feature_size], initializer=tf.glorot_normal_initializer())
    coe_v = tf.get_variable(name="coe_v", shape=[feature_size, embed_size],
                            initializer=tf.glorot_normal_initializer())

    # ---------- reshape feature ----------- #
    feat_idx = features["feat_idx"]         # 非零特征位置[batch_size, field_size, 1]
    feat_idx = tf.reshape(feat_idx, shape=[-1, field_size])     # [Batch, Field]
    feat_val = features["feat_val"]         # 非零特征的值[batch_size, field_size, 1]
    feat_val = tf.reshape(feat_val, shape=[-1, field_size])     # [Batch, Field]

    # ------------- define f(x) ------------ #
    with tf.variable_scope("First-Order"):
        feat_wgt = tf.nn.embedding_lookup(coe_w, feat_idx)              # [Batch, Field]
        y_w = tf.reduce_sum(tf.multiply(feat_wgt, feat_val), 1)         # [Batch]

    with tf.variable_scope("Bi-Interaction-Layer"):
        embeddings = tf.nn.embedding_lookup(coe_v, feat_idx)            # [Batch, Field, K]
        feat_vals = tf.reshape(feat_val, shape=[-1, field_size, 1])     # [Batch, Field, 1]
        embeddings = tf.multiply(embeddings, feat_vals)                 # [Batch, Field, K]
        sum_square = tf.square(tf.reduce_sum(embeddings, 1))            # [Batch, K]
        square_sum = tf.reduce_sum(tf.square(embeddings), 1)            # [Batch, K]
        bi_out = 0.5*(tf.subtract(sum_square, square_sum))              # [Batch, K]

    with tf.variable_scope("Deep-Layer"):
        deep_inputs = bi_out
        # hidden layer
        for i in range(len(layers)):
            deep_inputs = tf.contrib.layers.fully_connected(
                inputs=deep_inputs, num_outputs=layers[i], scope="mlp_%d" % i,
                weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda))
            if mode == estimator.ModeKeys.TRAIN:
                deep_inputs = tf.nn.dropout(deep_inputs, keep_prob=dropout[i])

        # output layer
        y_d = tf.contrib.layers.fully_connected(
            inputs=deep_inputs, num_outputs=1, activation_fn=tf.identity,
            weights_regularizer=tf.contrib.layers.l2_regularizer(l2_reg_lambda), scope='deep_out')

    with tf.variable_scope("NFM-Out"):
        y_deep = tf.reshape(y_d, shape=[-1])
        y_bias = coe_b * tf.ones_like(y_w, dtype=tf.float32)    # [Batch]
        y_hat = y_bias + y_w + y_deep                           # [Batch]
        y_pred = tf.nn.sigmoid(y_hat)                           # [Batch]

    # ----- mode: predict/evaluate/train ----- #
    # predict: 不计算loss/metric; evaluate: 不进行梯度下降和参数更新

    # Provide an estimator spec for 'ModeKeys.PREDICT'
    predictions = {"prob": y_pred}
    export_outputs = {
        tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:
            estimator.export.PredictOutput(predictions)}
    if mode == estimator.ModeKeys.PREDICT:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs=export_outputs)

    # Provide an estimator spec for 'ModeKeys.EVAL'
    if loss_mode == "log_loss":
        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=y_hat)) +\
               l2_reg_lambda * tf.nn.l2_loss(coe_w) + l2_reg_lambda * tf.nn.l2_loss(coe_v)
    else:
        loss = tf.reduce_mean(tf.square(labels-y_pred))
    eval_metric_ops = {"auc": tf.metrics.auc(labels, y_pred)}
    if mode == estimator.ModeKeys.EVAL:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss,
                                       eval_metric_ops=eval_metric_ops)

    # Provide an estimator spec for 'ModeKeys.TRAIN'
    if optimizer == "Adam":
        opt_mode = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.9, beta2=0.999, epsilon=1e-8)
    elif optimizer == "Adagrad":
        opt_mode = tf.train.AdagradOptimizer(learning_rate=learning_rate, initial_accumulator_value=1e-8)
    elif optimizer == "Momentum":
        opt_mode = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.95)
    elif optimizer == "Ftrl":
        opt_mode = tf.train.FtrlOptimizer(learning_rate)
    else:
        opt_mode = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    train_op = opt_mode.minimize(loss, global_step=tf.train.get_global_step())

    if mode == estimator.ModeKeys.TRAIN:
        return estimator.EstimatorSpec(mode=mode, predictions=predictions, loss=loss, train_op=train_op)
import os

'''
단독실행 시에는 
36_이정재_00,36_이정재_01,36_이정재_02,36_이정재_03,36_이정재_04 0,1,2,3,4 0,0,0,0,0
'''

# import firebase_admin
# from firebase_admin import credentials
# from firebase_admin import firestore
# from preprocess.firebase_manager import FBManager
# import preprocess.if_executor as ie
# from preprocess.aws_manager import AWSManager as am

# from time import sleep
import numpy as np
from PIL import Image
# from datetime import datetime
# from tqdm import tqdm

from preprocess.preprocess_cacd import getMTCNN_result

import sys

a = sys.argv

print(a)

root_path = r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\posts'

target = []
for idx, i in enumerate(a[1].split(',')):
    target.append((i, a[2].split(',')[idx], a[3].split(',')[idx]))

mt_results = []
for idx, (key, category, type2) in enumerate(target):
    filename = os.path.join(root_path, key + ('_1' if type2 == '0' else '_2') + '.jpg')
    if os.path.isdir(filename):
        continue

    img = Image.open(filename)
    image = getMTCNN_result(np.array(img))
    if image:
        mt_results.append((idx, image, filename))


import torch
import torchvision
from model.IPCGANs import IPCGANs
from utils.io import Img_to_zero_center,Reverse_zero_center

class Demo:
    def __init__(self,generator_state_pth):
        self.model = IPCGANs()
        state_dict = torch.load(generator_state_pth)
        self.model.load_generator_state_dict(state_dict)

    def demo(self,image,target=0):
        img_size = 400
        assert target<5 and target>=0, "label shoule be less than 5"

        transforms = torchvision.transforms.Compose([
            torchvision.transforms.Resize((img_size,img_size)),
            torchvision.transforms.ToTensor(),
            Img_to_zero_center()
        ])
        label_transforms = torchvision.transforms.Compose([
            torchvision.transforms.ToTensor(),
        ])
        image=transforms(image).unsqueeze(0)
        full_one = np.ones((img_size, img_size), dtype=np.float32)
        full_zero = np.zeros((img_size, img_size, 5), dtype=np.float32)
        full_zero[:, :, target] = full_one
        label=label_transforms(full_zero).unsqueeze(0)

        img=image.cuda()
        lbl=label.cuda()
        self.model.cuda()

        res=self.model.test_generate(img,lbl)

        res=Reverse_zero_center()(res)
        res_img=res.squeeze(0).cpu().numpy().transpose(1,2,0)
        return Image.fromarray((res_img*255).astype(np.uint8))


# models = {'g_w_90':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\weight65_18_2\gepoch_2_iter_3000.pth'}
# models = {'g_w_90':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\weight65_18_1\gepoch_1_iter_6000.pth'}
models = {
    'w65_18_1_4':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_1_iter_4000.pth',
    'w65_18_1_6':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_1_iter_6000.pth',
    'w65_18_2_4':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_2_iter_4000.pth',
    'w65_18_3_5':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_3_iter_5000.pth',
    'w65_18_3_6':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_3_iter_6000.pth',
    'w65_18_3_7':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_3_iter_7000.pth',
    'w65_18_3_9':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_3_iter_9000.pth',
    'w65_18_3_95':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_3_iter_9500.pth',
    'w65_18_3_10':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_3_iter_10000.pth',
    'w65_18_3_105':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_3_iter_10500.pth',
    'w65_18_3_11':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_3_iter_11000.pth',
    'w65_18_3_115':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\w65_18\gepoch_3_iter_11500.pth',
    'w75_2_0_6':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\weight75_2_0\gepoch_0_iter_6000.pth',
    'g_w_90':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\weight65_18_1\gepoch_1_iter_6000.pth',
    'w65_18_b64_e10':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\weight65_18_b64_e10\depoch_7_iter_6000.pth'
}
# models = {'g_w_90':r'C:\Users\DeepLearning_3\PycharmProjects\ipcgan_clone\preprocess\pretrained_models\weight60_2_0\gepoch_0_iter_9000.pth'}

main_model = 'w65_18_3_9'
isCategoryModel = True

category_main_model = {
    0:('w65_18_3_7', False),
    1:('w65_18_3_115', True),
    2:('w65_18_3_5', False),
    3:('w65_18_b64_e10', False), #7 # 115
    4:('w65_18_b64_e10', False) #95 # 115
}
# with open('model_setting.json') as json_file:
#     json_data = json.load(json_file)
#
#     for k, v in json_data.items():
#         print(k, " : ", v)


if isCategoryModel:
    for idx, image, filename in mt_results:
        target_category = int(target[idx][1])
        target_model = models[category_main_model[target_category][0]]
        D = Demo(target_model)

        print("Demo Start! ==>", target_model)


        # t=  4
        # if target[idx][2] == '1':
        #     t = 2
        result = D.demo(image, target=target_category + (1 if category_main_model[target_category][1] else 0))
        result.save(os.path.join(root_path, target[idx][0] + ('_1' if target[idx][2] == '1' else '_2') + '.jpg'))

        print("Finish! ==> ", category_main_model[target_category][0])

else:
    target_model = models[main_model]
    D = Demo(target_model)

    for idx, image, filename in mt_results:
        target_category = int(target[idx][1])
        print("Demo Start! ==>", target_model)

        # t=  4
        # if target[idx][2] == '1':
        #     t = 2
        result = D.demo(image, target=target_category)
        result.save(os.path.join(root_path, target[idx][0] + ('_1' if target[idx][2] == '1' else '_2') + '.jpg'))

        print("Finish! ==> ", main_model)
# coding:utf-8
import sys
sys.path.append('/home/feixingjian/DeepLearning-OCR/')
from architecture.CNN_LSTM import build_CNN_LSTM
from architecture.vgg_merge import build_vgg_merge
from architecture.shallow import build_shallow
from util import get_char_set, get_maxnb_char, one_hot_decoder, list2str, top_one_prob
from post_correction import get_label_set, correction


class model(object):
    def __init__(self):
        self.char_set = get_char_set(self.train_data_dir)[0]
        self.nb_classes = len(self.char_set)
        self.max_nb_char = get_maxnb_char(self.train_data_dir)
        self.label_set = get_label_set(self.train_data_dir)
        self.pred_probs = None


    def pred(self, X):
        pred_res = self.model.predict(X, batch_size=256)
        self.pred_probs = pred_res
        pred_res = [one_hot_decoder(i, self.char_set) for i in pred_res]
        pred_res = [list2str(i) for i in pred_res]
        # post correction
        if self.post_correction:
            pred_res = correction(pred_res, self.label_set)
        return pred_res


    def get_prob(self):
        probs = [top_one_prob(i) for i in self.pred_probs]
        probs = [i[0] for i in probs] #  TODO  
        return probs



class vgg_merge(model):
    def __init__(self):
        model.__init__(self)
        self.model = build_vgg_merge(self.img_channels, self.img_width, self.img_height, self.max_nb_char, self.nb_classes) # 生成CNN的架构
        self.model.load_weights(self.weights_file_path) # 读取训练好的模型


class cnn_lstm(model):
    def __init__(self):
        model.__init__(self)
        self.model = build_CNN_LSTM(self.img_channels, self.img_width, self.img_height, self.max_nb_char, self.nb_classes) # 生成CNN的架构
        self.model.load_weights(self.weights_file_path) # 读取训练好的模型


class shallow(model):
    def __init__(self):
        model.__init__(self)
        self.model = build_shallow(self.img_channels, self.img_width, self.img_height, self.max_nb_char, self.nb_classes) # 生成CNN的架构
        self.model.load_weights(self.weights_file_path) # 读取训练好的模型   


class single_cha(shallow):
    def __init__(self):
        self.img_width = 48
        self.img_height = 48
        self.img_channels = 1
        self.post_correction = False
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/single_1000000/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-09-13/weights.05-0.09.hdf5'
        shallow.__init__(self)


class jiangxi(shallow):
    def __init__(self):
        self.img_width = 150
        self.img_height = 32
        self.img_channels = 1
        self.post_correction = False
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/jiangxi_train/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-10-12/weights.01-0.00.hdf5'
        shallow.__init__(self)


class shanghai(shallow):
    def __init__(self):
        self.img_width = 160
        self.img_height = 53
        self.img_channels = 1
        self.post_correction = False
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/shanghai/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-10-12/weights.33-0.01.hdf5'
        shallow.__init__(self)


class shandong(shallow):
    def __init__(self):
        self.img_width = 300
        self.img_height = 50
        self.img_channels = 1
        self.post_correction = False
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/shandong_train/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-10-12/weights.29-0.02.hdf5'
        shallow.__init__(self)


class guizhou(vgg_merge):
    def __init__(self):
        self.img_width = 260
        self.img_height = 40
        self.img_channels = 1
        self.post_correction = False
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/guizhou_res/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-08-30/weights.137-0.12.hdf5'
        vgg_merge.__init__(self)


class zhejiang(cnn_lstm):
    def __init__(self):
        self.img_width = 250
        self.img_height = 50
        self.img_channels = 1
        self.post_correction = True
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/zhejiang_real/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-08-24/weights.99-1.44.hdf5'
        cnn_lstm.__init__(self)   


class jiangsu(cnn_lstm):
    def __init__(self):
        self.img_width = 150
        self.img_height = 60
        self.img_channels = 1
        self.post_correction = False
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/jiangsu/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-08-01/weights.491-0.47.hdf5'
        cnn_lstm.__init__(self)        


class beijing(cnn_lstm):
    def __init__(self):
        self.img_width = 150
        self.img_height = 50
        self.img_channels = 3
        self.post_correction = False
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/beijing/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-07-22/weights.66-0.00.hdf5'
        cnn_lstm.__init__(self)


class guangdong(cnn_lstm):
    def __init__(self):
        self.img_width = 180
        self.img_height = 40
        self.img_channels = 1
        self.post_correction = True
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/guangdong/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-08-01/weights.09-0.03.hdf5'
        cnn_lstm.__init__(self)


class hubei(cnn_lstm):
    def __init__(self):
        self.img_width = 150
        self.img_height = 40
        self.img_channels = 1
        self.post_correction = False
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/hubei/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-08-11/weights.32-0.00.hdf5'
        cnn_lstm.__init__(self)


class anhui(cnn_lstm):
    def __init__(self):
        self.img_width = 200
        self.img_height = 50
        self.img_channels = 1
        self.post_correction = True
        self.train_data_dir = '/home/feixingjian/DeepLearning-OCR/train_data/anhui/'
        self.weights_file_path = '/home/feixingjian/DeepLearning-OCR/save_model/2016-10-09/weights.15-0.08.hdf5'
        cnn_lstm.__init__(self)


    import sys
import os

from topoml.mscnn_segmentation import mscnn_segmentation

sys.path.append(os.getcwd())



training_data_path = "/Users/multivax/Documents/PhD/4spring19/DeepLearning/DeepLearning/HW3/datasets/drive/DRIVE/training/images"
#training_data_path = "/Users/multivax/Documents/PhD/4spring19/DeepLearning/DeepLearning/final_project/results/neuron_msc"

testing_data_path = "/Users/multivax/Documents/PhD/4spring19/DeepLearning/DeepLearning/HW3/datasets/drive/DRIVE/test/images"
train_write_path = "/Users/multivax/Documents/PhD/4spring19/DeepLearning/DeepLearning/HW3/datasets/drive/DRIVE/training/" # "/Users/multivax/Documents/PhD/4spring19/DeepLearning/DeepLearning/final_project/results/" #

test_write_path = "/Users/multivax/Documents/PhD/4spring19/DeepLearning/DeepLearning/HW3/datasets/drive/DRIVE/test/"


stare_training_data_path = "/Users/multivax/Documents/PhD/4spring19/DeepLearning/DeepLearning/HW3/datasets/stare/images"

stare_train_write_path = "/Users/multivax/Documents/PhD/4spring19/DeepLearning/DeepLearning/HW3/datasets/stare/"



# iterate over various persistence values and compute the
# morse smale segmentations for a number of images located at data_path
# will create a folder at write path with raw images and another
# fodler with msc segmentations for wach image at each persistence
def msc_segment_images(persistence_values = [1], blur_sigma = 3, data_path = '.', write_path = '.'):
    # check needed folders present else make
    if not os.path.exists(os.path.join(write_path, 'raw_images')):
        os.mkdir(os.path.join(write_path, 'raw_images'))
    # iterate through images and compute msc for each image
    # at various persistence values
    images = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f)) and any(image_type in f.rsplit('.', 1)[1] for image_type in ['tif','gif','jpg','png','ppm'])]
        
    for img in images:
        for pers in persistence_values:

            # construct msc object
            mscnn = mscnn_segmentation()
            mscnn.clear_msc()
            
            msc = mscnn.compute_msc(image =  os.path.join(data_path,img), persistence = pers, blur_sigma=blur_sigma, write_path = write_path)

            mscnn.construct_msc_from_image(image = os.path.join(data_path,img),  write_path = write_path, persistence = pers, blur_sigma = blur_sigma)


persistence_values = [7]#[10, 12, 15, 20 , 23, 25, 30]
blur_sigma = 2.2

#traininig_data_path = "/Users/multivax/Documents/PhD/4spring19/DeepLearning/DeepLearning/final_project/results/neuron_msc"
#train_write_path = "/Users/multivax/Documents/PhD/4spring19/DeepLearning/DeepLearning/final_project/results/"
msc_segment_images(persistence_values = persistence_values, blur_sigma = blur_sigma,
                   data_path = training_data_path, write_path = train_write_path)

#msc_segment_images(persistence_values = persistence_values, blur_sigma = blur_sigma,
#                   data_path = stare_training_data_path, write_path = train_write_path)

#msc_segment_images(persistence_values = persistence_values, blur_sigma = blur_sigma,
#                   data_path = testing_data_path, write_path = test_write_path)
# Download and create the dataset from URLs
# s1 + s2
import requests

def fn_read(path): # Függvény, ami beolvassa az adott txt fájlból a linkeket
    f = open(path, 'r', errors='ignore')  # file megnyitása #errors = ignore nélkül a második hívásnál UnicodeDecodeError: 'charmap' codec can't decode byte 0x98 in position 1447: character maps to <undefined>-t dobott ?!
    list = f.readlines() # Soronként beolvassuk az url-eket egy stringeket tartalmazó listába
    f.close()

    return list

def fn_download(list, type, path):  # Fv, ami letölti a paraméterként megkapott listában lévő linkekről a képeket, olyan típusból amit a name-ben megadtunk és arra a helyre menti amit megadtunk
    error= 0
    for i in range(len(list)):
        #if ("flickr" in list[i]): # A tapasztalatok szerint a flickr.com-ról letöltött képek nagyobb százalékban bizonyulnak használhatónak
        try:
            url = list[i]  # Az adott url amiről letöltünk a listánk i-edik eleme lesz
            r = requests.get(url)  # Megadjuk ezt az url-t a letöltéshez
            fname = type + "{}"
            fpath = path + "\\" + fname.format(i) + ".jpg"
            open(fpath, 'wb').write(r.content)  # Új fájlt hozunk létre, amibe lementjük a letöltött képet
            print(i)
        except IOError:
            error = error + 1
            # Stop in case you reach 100 errors downloading images
            if error > 100:
                break
            else:
                print("File does not exist")
    print('Download is done')


# Person képek 1241 db letöltve, 1146 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\person\person_urls.txt"
# fn_download(fn_read(path), "personb" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\person")

# Bird képek 839 db letöltve 1177 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\bird\bird_urls.txt"
# fn_download(fn_read(path), "birda" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\bird")

# Cat képek 1031 db letöltve 1023 db használható kép # domestic cat-ből

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\cat\cat_urls.txt"
# fn_download(fn_read(path), "catb" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\cat")

# Cow képek 1185 db letöltve 1000 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\cow\cow_urls.txt"
# fn_download(fn_read(path), "cowa" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\cow")

# Dog képek 1020 db letöltve 1000 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\dog\dog_urls.txt"
# fn_download(fn_read(path), "dogc" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\dog")

# Horse képek 1320 db letöltve 1089 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\horse\horse_urls.txt"
# fn_download(fn_read(path), "horsee" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\horse")

# Sheep képek 1026 db letöltve 1009 db használható rohadt bárány

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\sheep\sheep_urls.txt"
# fn_download(fn_read(path), "sheepzzzzz" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\sheep")

# Airplane képek 914 db letöltve 1051 db használható kép aircraft

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\airplane\airplane_urls.txt"
# fn_download(fn_read(path), "airplanez" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\airplane")

# Bicycle képek 1270 db letöltve 788 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\bicycle\bicycle_urls.txt"
# fn_download(fn_read(path), "bicycles" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\bicycle")

# Boat képek 1034 db letöltve 1002 db használható kép (innentől nem a legjobb az annotáció)

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\boat\boat_urls.txt"
# fn_download(fn_read(path), "boatc" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\boat")

# Bus képek 1334 db letöltve 1116 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\bus\bus_urls.txt"
# fn_download(fn_read(path), "busb" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\bus")

# Car képek 1209 db letöltve 1051 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\car\car_urls.txt"
# fn_download(fn_read(path), "carb" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\car")

# Motorbike képek 1199 db letöltve 1000 db használható

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\motorbike\motorbike_urls.txt"
#fn_download(fn_read(path), "motorbikeb" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\motorbike")

# Train képek 1282 db letöltve 1044 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\train\train_urls.txt"
# fn_download(fn_read(path), "trainb" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\train")

# Bottle képek 1177 db letöltve 1002 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\bottle\bottle_urls.txt"
# fn_download(fn_read(path), "bottleb" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\bottle")

# Chair képek 1422 db letöltve 1000 db használható kép
# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\chair\chair_urls.txt"
# fn_download(fn_read(path), "chair" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\chair")

# Table képek (n04379243) (n04379964) (n03063968) (n03090000) (n03201208) (n03231368) 1002 db

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\table\table_urls.txt"
# fn_download(fn_read(path), "tablezs" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\table")

# Plant képek 1261 db letöltve 1008 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\plant\plant_urls.txt"
# fn_download(fn_read(path), "plantc" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\plant")

# Sofa képek 671 db letöltve 1002 db

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\sofa\sofa_urls.txt"
# fn_download(fn_read(path), "sofac" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\sofa")

# TV képek 763 db kép letöltve (tv mappa) 1000 db használható kép

# path = r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\tv\tv_urls.txt"
# fn_download(fn_read(path), "tvb" , r"C:\Users\peisz\Documents\BME\Deep Learning\Temalabor\Dataset\tv")import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics.regression import r2_score, mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import AdaBoostRegressor
# import GridSearchCV
import xlrd
import math
import matplotlib.pyplot as plt
import logging
import os
import sys
import pandas as pd
from sklearn import svm

np.random.seed(1337)  # for reproducibility
logging.basicConfig(level=logging.INFO)


def train_model(learning_rate_rbm, learning_rate, batch_size, x_train, y_trian, x_test):
    path_DBN = os.path.join(os.path.join(os.path.dirname(os.path.abspath(__file__)), "models"), "deep-belief-network")
    sys.path.append(path_DBN)
    from dbn.tensorflow import SupervisedDBNRegression

    regressor_DBN = SupervisedDBNRegression(learning_rate_rbm=learning_rate_rbm, learning_rate=learning_rate,
                                            batch_size=batch_size, verbose=False)
    regressor_DBN.fit(x_train, y_trian)
    pred = regressor_DBN.predict(x_test)
    return pred


def train_model_func(learning_rate_rbm, learning_rate, batch_size, feature, label, path_out_png, pred_num, train_deep):
    X_train, X_test, Y_train, Y_test = train_test_split(feature, label, test_size=0.2, shuffle=False)

    print("Training model...")
    print("RMSE (on training data):")
    root_mean_squared_errors = []
    for deep in range(1, train_deep + 1):
        RMSE_total = 0
        for i in range(0, pred_num):
            x_train = np.array(X_train[X_train.shape[0] - i - deep:X_train.shape[0] - i])
            y_trian = np.array(Y_train[Y_train.shape[0] - i - deep:Y_train.shape[0] - i])
            x_test = np.array(X_test)
            y_test = np.array(Y_test)

            predictions = train_model(learning_rate_rbm=learning_rate_rbm, learning_rate=learning_rate,
                                      batch_size=batch_size, x_train=x_train,
                                      y_trian=y_trian, x_test=x_test)

            root_mean_squared_error = math.sqrt(mean_squared_error(y_test, predictions))
            print("\t\ti:\t", root_mean_squared_error)
            RMSE_total += root_mean_squared_error

        RMSE_avg = RMSE_total / pred_num
        root_mean_squared_errors.append(RMSE_avg)
        print("train_deep:", deep, "\tRMSE_avg:", RMSE_avg)

        # Output a graph of loss metrics over periods.
        # plt.subplot(1, 2, 2)
        plt.ylabel('RMSE')
        plt.xlabel('train_deep')
        plt.title("Root Mean Squared Error vs. Train Deep")
        plt.tight_layout()
        plt.plot(root_mean_squared_errors)
        plt.savefig(path_out_png)

    print("finished.")


path_data = "data/airdata.csv"
path_out_png = "out/out_test_TrianDeep.png"

data = pd.read_csv(path_data, sep=",")

target = data["pm25"]
target = target.drop([0])

data = data.drop([data.shape[0] - 1])
data = data.drop(["date"], axis=1)
# print(data["date"])


learning_rate_rbm = 0.01
learning_rate = 0.00001
batch_size = 1
pred_num = 3
train_deep = 200

train_model_func(learning_rate_rbm=learning_rate_rbm, learning_rate=learning_rate, batch_size=batch_size, feature=data,
                 label=target, path_out_png=path_out_png, pred_num=pred_num, train_deep=train_deep)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import nltk
import LDA_TM


algorithms='Active Learning, Bandit Algorithms, Boosting and Ensemble Methods, Classification, Clustering, Collaborative Filtering, Components Analysis CCA, ICA, LDA, PCA, Density Estimation, Dynamical Systems, Hyperparameter Selection, Kernel Methods, Large Margin Methods, Metric Learning, Missing Data, Model Selection and Structure Learning, Multitask and Transfer Learning, Nonlinear Dimensionality Reduction and Manifold Learning, Online Learning, Ranking and Preference Learning, Regression, Reinforcement Learning, Relational Learning, Representation Learning, Semi-Supervised Learning, Similarity and Distance Learning, Sparse Coding and Dimensionality Expansion, Sparsity and Compressed Sensing, Spectral Methods, Sustainability, Stochastic Methods, Structured Prediction, and Unsupervised Learning'

probabalistic_methods='Bayesian Nonparametrics, Bayesian Theory, Belief Propagation, Causal Inference, Distributed Inference, Gaussian Processes, Graphical Models, Hierarchical Models, Latent Variable Models, MCMC, Topic Models, and Variational Inference.'

optimization='Combinatorial Optimization, Convex Optimization, Non-Convex Optimization, and Submodular Optimization'

Applications='Audio and Speech Processing, Computational Biology and Bioinformatics, Computational Social Science, Computer Vision, Denoising, Dialog- and/or Communication-Based Learning, Fairness Accountability and Transparency, Game Playing, Hardware and Systems, Image Segmentation, Information Retrieval, Matrix and Tensor Factorization, Motor Control, Music Modeling and Analysis, Natural Language Processing, Natural Scene Statistics, Network Analysis, Object Detection, Object Recognition, Privacy Anonymity and Security, Quantitative Finance and Econometrics, Recommender Systems, Robotics, Signal Processing, Source Separation, Speech Recognition, Systems Biology, Text Analysis, Time Series Analysis, Video, Motion and Tracking, Visual Features, Visual Perception, Visual Question Answering, Visual Scene Analysis and Interpretation, and Web Applications and Internet Data'

Reinforcement_learning_and_planning='Decision and Control, Exploration, Hierarchical RL, Markov Decision Processes, Model-Based RL, Multi-Agent RL, Navigation, and Planning'

Theory='Competitive Analysis, Computational Complexity, Control Theory, Frequentist Statistics, Game Theory and Computational Economics, Hardness of Learning and Approximations, Information Theory, Large Deviations and Asymptotic Analysis, Learning Theory, Regularization, Spaces of Functions and Kernels, and Statistical Physics of Learning'

neuroscience='Auditory Perception and Modeling, Brain Imaging, Brain Mapping, Brain Segmentation, Brain--Computer Interfaces and Neural Prostheses, Cognitive Science, Connectomics, Human or Animal Learning, Language for Cognitive Science, Memory, Neural Coding, Neuropsychology, Neuroscience, Perception, Plasticity and Adaptation, Problem Solving, Reasoning, Spike Train Generation, and Synaptic Modulation'

deep_learning= "Adversarial Networks, Attention Models, Biologically Plausible Deep Networks, Deep Autoencoders, Efficient Inference Methods, Efficient Training Methods, Embedding Approaches, Generative Models, Interaction-Based Deep Networks, Learning to Learn, Memory-Augmented Neural Networks, Neural Abstract Machines, One-Shot/Low-Shot Learning Approaches, Optimization for Deep Networks, Predictive Models, Program Induction, Recurrent Networks, Supervised Deep Networks, Virtual Environments, and Visualization Expository Techniques for Deep Networks "

software='Benchmarks, Competitions or Challenges, Data Sets or Data Repositories, and Software Toolkits'

docs=[algorithms,probabalistic_methods,optimization,Applications,Reinforcement_learning_and_planning,Theory,neuroscience,deep_learning,software]
labels=['Algorithms','Probabalistic Methods','optimization','Applications','Reinforcement Learning and Planning','Theory','Neuroscience and Cognitive Science','Deep Learning','Data Competiotions Implemetations and Software']

n_topics=10
Tm=LDA_TM.LDA_TM('LDA'+str(n_topics))
Tm.load_existing_model()
    
"""Init script."""

import gym
import keras
import numpy
from keras import layers
from keras import models
from keras import optimizers

from deep_learning.engine import a3c_impl
from deep_learning.engine import base
from deep_learning.engine import environment_impl
from deep_learning.engine import policy_impl
from deep_learning.engine import qfunc_impl
from deep_learning.engine import runner_extension_impl
from deep_learning.engine import runner_impl
from deep_learning.examples import circular_world_env
from deep_learning.examples import interval_world_env
from deep_learning.examples import shortcut
from deep_learning.experimental import guided_environments
from deep_learning.experimental import model_builder
from deep_learning.experimental import other_runners
from qpylib import logging
from qpylib import numpy_util
from qpylib import running_environment

__will_use = (
  gym,
  keras,
  numpy,

  layers,
  models,
  optimizers,

  logging,
  numpy_util,
  running_environment,

  base,
  a3c_impl,
  environment_impl,
  policy_impl,
  qfunc_impl,
  runner_extension_impl,
  runner_impl,

  circular_world_env,
  interval_world_env,
  model_builder,
  guided_environments,
  other_runners,
  shortcut,
)

# Add this to the first cell of your notebook:
# ReloadProject('deep_learning')
def deeplearning_vignette():
    from tests import pyunit_utils
    story1 = [
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_importfile_example.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_examplerun.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_crossval.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_inspect_model.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_predict.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_varimp.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_gridsearch.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_gridsearch_result.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_gridsearch_random.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_checkpoint.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_savemodel.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_loadmodel_checkpoint.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_getmodel.py"),
        pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_anomaly.py")]
    story2 = [pyunit_utils.locate("DeepLearning_Vignette_code_examples/deeplearning_quantile.py")]

    approved_py_code_examples = story1+story2

    pybooklet_utils.check_code_examples_in_dir(approved_py_code_examples,
                                               pyunit_utils.locate("DeepLearning_Vignette_code_examples"))

    pybooklet_utils.check_story("story1",story1)
    pybooklet_utils.check_story("story2",story2)

deeplearning_vignette()# -*- coding: utf-8 -*-
"""
Created on Fri May 19 14:57:33 2017

@author: L
"""
import numpy as np
from skimage import io

#frames chosen from 4096
START = 0
END = 300
NUMPIC = END-START
#cut 128 pixels out
STARTPXL = 100
ENDPXL = 228
#save data number range
SAVEST = 1000

im = np.array(io.imread('//128.180.65.173/data/Lian/DeepLearning/heartdata/S04/S04labels.tif'))
#a=np.loadtxt('Z:/Lian/DeepLearning/heartdata/1.txt')

im1=im[START:END,STARTPXL:ENDPXL,:,0]

#io.imsave('S02_1.tif',im1)
im1_1=im1/65536
im1_1=im1_1*1.1
im1_1=im1_1.astype(int)
#io.imsave('S01_label_cut.tif',im1_1)

im2=np.array(io.imread('//diskstation2/data/Lian/DeepLearning/heartdata/S04/S04.tiff'))
im2=im2[START:END,STARTPXL:ENDPXL]

#io.imsave('S01_cut.tif',im2)

#im1_1 = io.imread('Z:/Lian/DeepLearning/heartdata/S02_01.tif')
for i in range(0,NUMPIC):
    savenumber=i+SAVEST
    io.imsave('//diskstation2/data/Lian/DeepLearning/heartdata/S04/'+str(savenumber)+'gt.png',np.uint32(im1_1[i]))
    io.imsave('//diskstation2/data/Lian/DeepLearning/heartdata/S04/'+str(savenumber)+'.png',im2[i])
#im2 = io.imread('Z:/Lian/DeepLearning/heartdata/S02_original_1.tif')


    

from PIL import Image

for i in range(SAVEST,SAVEST+NUMPIC):
    im=Image.open('//diskstation2/data/Lian/DeepLearning/heartdata/S04/'+str(i)+'.png')
    imr=im.resize((321,321))
    imr.save('//diskstation2/data/Lian/DeepLearning/heartdata/S04/'+str(i)+'.png')
    
    im=Image.open('//diskstation2/data/Lian/DeepLearning/heartdata/S04/'+str(i)+'gt.png')
    imr=im.resize((321,321))
    imr.save('//diskstation2/data/Lian/DeepLearning/heartdata/S04/'+str(i)+'gt.png')
    '''
Pedagogical example realization of wide & deep networks, using TensorFlow and TFLearn.

This is a re-implementation of http://arxiv.org/abs/1606.07792, using the combination
of a wide linear model, and a deep feed-forward neural network, for binary classification  
This example realization is based on Tensorflow's TF.Learn tutorial 
(https://www.tensorflow.org/versions/r0.10/tutorials/wide_and_deep/index.html),
but implemented in TFLearn.  Note that despite the closeness of names, TFLearn is distinct
from TF.Learn (previously known as scikit flow).

This implementation explicitly presents the construction of layers in the deep part of the
network, and allows direct access to changing the layer architecture, and customization
of methods used for regression and optimization.

In contrast, the TF.Learn tutorial offers more sophistication, but hides the layer
architecture behind a black box function, tf.contrib.learn.DNNLinearCombinedClassifier.

See https://github.com/ichuang/tflearn_wide_and_deep for more about this example.
'''

from __future__ import division, print_function

import os
import sys
import argparse
import tflearn
import tempfile
import urllib

import numpy as np
import pandas as pd
import tensorflow as tf

#-----------------------------------------------------------------------------

COLUMNS = ["age", "workclass", "fnlwgt", "education", "education_num",
           "marital_status", "occupation", "relationship", "race", "gender",
           "capital_gain", "capital_loss", "hours_per_week", "native_country",
           "income_bracket"]
LABEL_COLUMN = "label"
CATEGORICAL_COLUMNS = {"workclass": 10, "education": 17, "marital_status":8, 
                       "occupation": 16, "relationship": 7, "race": 6, 
                       "gender": 3, "native_country": 43, "age_binned": 14}
CONTINUOUS_COLUMNS = ["age", "education_num", "capital_gain", "capital_loss",
                      "hours_per_week"]

#-----------------------------------------------------------------------------

class TFLearnWideAndDeep(object):
    '''
    Wide and deep model, implemented using TFLearn
    '''
    AVAILABLE_MODELS = ["wide", "deep", "wide+deep"]
    def __init__(self, model_type="wide+deep", verbose=None, name=None, tensorboard_verbose=3, 
                 wide_learning_rate=0.001, deep_learning_rate=0.001, checkpoints_dir=None):
        '''
        model_type = `str`: wide or deep or wide+deep
        verbose = `bool`
        name = `str` used for run_id (defaults to model_type)
        tensorboard_verbose = `int`: logging level for tensorboard (0, 1, 2, or 3)
        wide_learning_rate = `float`: defaults to 0.001
        deep_learning_rate = `float`: defaults to 0.001
        checkpoints_dir = `str`: where checkpoint files will be stored (defaults to "CHECKPOINTS")
        '''
        self.model_type = model_type or "wide+deep"
        assert self.model_type in self.AVAILABLE_MODELS
        self.verbose = verbose or 0
        self.tensorboard_verbose = tensorboard_verbose
        self.name = name or self.model_type	# name is used for the run_id
        self.data_columns = COLUMNS
        self.continuous_columns = CONTINUOUS_COLUMNS
        self.categorical_columns = CATEGORICAL_COLUMNS	# dict with category_name: category_size
        self.label_column = LABEL_COLUMN
        self.checkpoints_dir = checkpoints_dir or "CHECKPOINTS"
        if not os.path.exists(self.checkpoints_dir):
            os.mkdir(self.checkpoints_dir)
            print("Created checkpoints directory %s" % self.checkpoints_dir)
        self.build_model([wide_learning_rate, deep_learning_rate])

    def load_data(self, train_dfn="adult.data", test_dfn="adult.test"):
        '''
        Load data (use files offered in the Tensorflow wide_n_deep_tutorial)
        '''
        if not os.path.exists(train_dfn):
            urllib.urlretrieve("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data", train_dfn)
            print("Training data is downloaded to %s" % train_dfn)

        if not os.path.exists(test_dfn):
            urllib.urlretrieve("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test", test_dfn)
            print("Test data is downloaded to %s" % test_dfn)

        self.train_data = pd.read_csv(train_dfn, names=COLUMNS, skipinitialspace=True)
        self.test_data = pd.read_csv(test_dfn, names=COLUMNS, skipinitialspace=True, skiprows=1)

        self.train_data[self.label_column] = (self.train_data["income_bracket"].apply(lambda x: ">50K" in x)).astype(int)
        self.test_data[self.label_column] = (self.test_data["income_bracket"].apply(lambda x: ">50K" in x)).astype(int)


    def build_model(self, learning_rate=[0.001, 0.01]):
        '''
        Model - wide and deep - built using tflearn
        '''
        n_cc = len(self.continuous_columns)
        n_categories = 1			# two categories: is_idv and is_not_idv
        input_shape = [None, n_cc]
        if self.verbose:
            print ("="*77 + " Model %s (type=%s)" % (self.name, self.model_type))
            print ("  Input placeholder shape=%s" % str(input_shape))
        wide_inputs = tflearn.input_data(shape=input_shape, name="wide_X")
        if not isinstance(learning_rate, list):
            learning_rate = [learning_rate, learning_rate]	# wide, deep
        if self.verbose:
            print ("  Learning rates (wide, deep)=%s" % learning_rate)

        with tf.name_scope("Y"):			# placeholder for target variable (i.e. trainY input)
            Y_in = tf.placeholder(shape=[None, 1], dtype=tf.float32, name="Y")

        with tf.variable_op_scope([wide_inputs], None, "cb_unit", reuse=False) as scope:
            central_bias = tflearn.variables.variable('central_bias', shape=[1],
                                                      initializer=tf.constant_initializer(np.random.randn()),
                                                      trainable=True, restore=True)
            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + '/cb_unit', central_bias)

        if 'wide' in self.model_type:
            wide_network = self.wide_model(wide_inputs, n_cc)
            network = wide_network
            wide_network_with_bias = tf.add(wide_network, central_bias, name="wide_with_bias")

        if 'deep' in self.model_type:
            deep_network = self.deep_model(wide_inputs, n_cc)
            deep_network_with_bias = tf.add(deep_network, central_bias, name="deep_with_bias")
            if 'wide' in self.model_type:
                network = tf.add(wide_network, deep_network)
                if self.verbose:
                    print ("Wide + deep model network %s" % network)
            else:
                network = deep_network

        network = tf.add(network, central_bias, name="add_central_bias")

        # add validation monitor summaries giving confusion matrix entries
        with tf.name_scope('Monitors'):
            predictions = tf.cast(tf.greater(network, 0), tf.int64)
            print ("predictions=%s" % predictions)
            Ybool = tf.cast(Y_in, tf.bool)
            print ("Ybool=%s" % Ybool)
            pos = tf.boolean_mask(predictions, Ybool)
            neg = tf.boolean_mask(predictions, ~Ybool)
            psize = tf.cast(tf.shape(pos)[0], tf.int64)
            nsize = tf.cast(tf.shape(neg)[0], tf.int64)
            true_positive = tf.reduce_sum(pos, name="true_positive")
            false_negative = tf.subtract(psize, true_positive, name="false_negative")
            false_positive = tf.reduce_sum(neg, name="false_positive")
            true_negative = tf.subtract(nsize, false_positive, name="true_negative")
            overall_accuracy = tf.truediv(tf.add(true_positive, true_negative), tf.add(nsize, psize), name="overall_accuracy")
        vmset = [true_positive, true_negative, false_positive, false_negative, overall_accuracy]

        trainable_vars = tf.trainable_variables()
        tv_deep = [v for v in trainable_vars if v.name.startswith('deep_')]
        tv_wide = [v for v in trainable_vars if v.name.startswith('wide_')]

        if self.verbose:
            print ("DEEP trainable_vars")
            for v in tv_deep:
                print ("  Variable %s: %s" % (v.name, v))
            print ("WIDE trainable_vars")
            for v in tv_wide:
                print ("  Variable %s: %s" % (v.name, v))

        if 'wide' in self.model_type:
            if not 'deep' in self.model_type:
                tv_wide.append(central_bias)
            tflearn.regression(wide_network_with_bias, 
                               placeholder=Y_in,
                               optimizer='sgd', 
                               #loss='roc_auc_score',
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[0],
                               validation_monitors=vmset,
                               trainable_vars=tv_wide,
                               op_name="wide_regression",
                               name="Y")

        if 'deep' in self.model_type:
            if not 'wide' in self.model_type:
                tv_wide.append(central_bias)
            tflearn.regression(deep_network_with_bias, 
                               placeholder=Y_in,
                               optimizer='adam', 
                               #loss='roc_auc_score',
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[1],
                               validation_monitors=vmset if not 'wide' in self.model_type else None,
                               trainable_vars=tv_deep,
                               op_name="deep_regression",
                               name="Y")

        if self.model_type=='wide+deep':	# learn central bias separately for wide+deep
            tflearn.regression(network, 
                               placeholder=Y_in,
                               optimizer='adam', 
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[0],	# use wide learning rate
                               trainable_vars=[central_bias],
                               op_name="central_bias_regression",
                               name="Y")

        self.model = tflearn.DNN(network,
                                 tensorboard_verbose=self.tensorboard_verbose,
                                 max_checkpoints=5,
                                 checkpoint_path="%s/%s.tfl" % (self.checkpoints_dir, self.name),
        )

        if self.verbose:
            print ("Target variables:")
            for v in tf.get_collection(tf.GraphKeys.TARGETS):
                print ("  variable %s: %s" % (v.name, v))

            print ("="*77)


    def deep_model(self, wide_inputs, n_inputs, n_nodes=[100, 50], use_dropout=False):
        '''
        Model - deep, i.e. two-layer fully connected network model
        '''
        cc_input_var = {}
        cc_embed_var = {}
        flat_vars = []
        if self.verbose:
            print ("--> deep model: %s categories, %d continuous" % (len(self.categorical_columns), n_inputs))
        for cc, cc_size in self.categorical_columns.items():
            cc_input_var[cc] = tflearn.input_data(shape=[None, 1], name="%s_in" % cc,  dtype=tf.int32)
            # embedding layers only work on CPU!  No GPU implementation in tensorflow, yet!
            cc_embed_var[cc] = tflearn.layers.embedding_ops.embedding(cc_input_var[cc],    cc_size,  8, name="deep_%s_embed" % cc)
            if self.verbose:
                print ("    %s_embed = %s" % (cc, cc_embed_var[cc]))
            flat_vars.append(tf.squeeze(cc_embed_var[cc], squeeze_dims=[1], name="%s_squeeze" % cc))

        network = tf.concat([wide_inputs] + flat_vars, 1, name="deep_concat")
        for k in range(len(n_nodes)):
            network = tflearn.fully_connected(network, n_nodes[k], activation="relu", name="deep_fc%d" % (k+1))
            if use_dropout:
                network = tflearn.dropout(network, 0.5, name="deep_dropout%d" % (k+1))
        if self.verbose:
            print ("Deep model network before output %s" % network)
        network = tflearn.fully_connected(network, 1, activation="linear", name="deep_fc_output", bias=False)
        network = tf.reshape(network, [-1, 1])	# so that accuracy is binary_accuracy
        if self.verbose:
            print ("Deep model network %s" % network)
        return network

    def wide_model(self, inputs, n_inputs):
        '''
        Model - wide, i.e. normal linear model (for logistic regression)
        '''
        network = inputs
        # use fully_connected (instad of single_unit) because fc works properly with batches, whereas single_unit is 1D only
        network = tflearn.fully_connected(network, n_inputs, activation="linear", name="wide_linear", bias=False)	# x*W (no bias)
        network = tf.reduce_sum(network, 1, name="reduce_sum")	# batched sum, to produce logits
        network = tf.reshape(network, [-1, 1])	# so that accuracy is binary_accuracy
        if self.verbose:
            print ("Wide model network %s" % network)
        return network

    def prepare_input_data(self, input_data, name="", category_map=None):
        '''
        Prepare input data dicts
        '''
        print ("-"*40 + " Preparing %s" % name)
        X = input_data[self.continuous_columns].values.astype(np.float32)
        Y = input_data[self.label_column].values.astype(np.float32)
        Y = Y.reshape([-1, 1])
        if self.verbose:
            print ("  Y shape=%s, X shape=%s" % (Y.shape, X.shape))

        X_dict = {"wide_X": X}

        if 'deep' in self.model_type:
            # map categorical value strings to integers
            td = input_data
            if category_map is None:
                category_map = {}
                for cc in self.categorical_columns:
                    if not cc in td.columns:
                        continue
                    cc_values = sorted(td[cc].unique())
                    cc_max = 1+len(cc_values)
                    cc_map = dict(zip(cc_values, range(1, cc_max)))	# start from 1 to avoid 0:0 mapping (save 0 for missing)
                    if self.verbose:
                        print ("  category %s max=%s,  map=%s" % (cc, cc_max, cc_map))
                    category_map[cc] = cc_map
                
            td = td.replace(category_map)
    
            # bin ages (cuts off extreme values)
            age_bins = [ 0, 12, 18, 25, 30, 35, 40, 45, 50, 55, 60, 65, 80, 65535 ]
            td['age_binned'] = pd.cut(td['age'], age_bins, labels=False)
            td = td.replace({'age_binned': {np.nan: 0}})
            print ("  %d age bins: age bins = %s" % (len(age_bins), age_bins))

            X_dict.update({ ("%s_in" % cc): td[cc].values.astype(np.int32).reshape([-1, 1]) for cc in self.categorical_columns})

        Y_dict = {"Y": Y}
        if self.verbose:
            print ("-"*40)
        return X_dict, Y_dict, category_map


    def train(self, n_epoch=1000, snapshot_step=10, batch_size=None):

        self.X_dict, self.Y_dict, category_map = self.prepare_input_data(self.train_data, "train data")
        self.testX_dict, self.testY_dict, _ = self.prepare_input_data(self.test_data, "test data", category_map)
        validation_batch_size = batch_size or self.testY_dict['Y'].shape[0]
        batch_size = batch_size or self.Y_dict['Y'].shape[0]

        print ("Input data shape = %s; output data shape=%s, batch_size=%s" % (str(self.X_dict['wide_X'].shape), 
                                                                               str(self.Y_dict['Y'].shape), 
                                                                               batch_size))
        print ("Test data shape = %s; output data shape=%s, validation_batch_size=%s" % (str(self.testX_dict['wide_X'].shape), 
                                                                                         str(self.testY_dict['Y'].shape), 
                                                                                         validation_batch_size))
        print ("="*60 + "  Training")
        self.model.fit(self.X_dict, 
                       self.Y_dict,
                       n_epoch=n_epoch,
                       validation_set=(self.testX_dict, self.testY_dict),
                       snapshot_step=snapshot_step,
                       batch_size=batch_size,
                       validation_batch_size=validation_batch_size,
                       show_metric=True, 
                       snapshot_epoch=False,
                       shuffle=True,
                       run_id=self.name,
        )
        
    def evaluate(self):
        logits = np.array(self.model.predict(self.testX_dict)).reshape([-1])
        print ("="*60 + "  Evaluation")
        print ("  logits: %s, min=%s, max=%s" % (logits.shape, logits.min(), logits.max()))
        probs =  1.0 / (1.0 + np.exp(-logits))
        y_pred = pd.Series((probs > 0.5).astype(np.int32))
        Y = pd.Series(self.testY_dict['Y'].astype(np.int32).reshape([-1]))
        self.confusion_matrix = self.output_confusion_matrix(Y, y_pred)
        print ("="*60)

    def output_confusion_matrix(self, y, y_pred):
        assert y.size == y_pred.size
        print("Actual IDV")
        print(y.value_counts())
        print("Predicted IDV")
        print(y_pred.value_counts())
        print()
        print("Confusion matrix:")
        cmat = pd.crosstab(y_pred, y, rownames=['predictions'], colnames=['actual'])
        print(cmat)
        sys.stdout.flush()
        return cmat
    
#-----------------------------------------------------------------------------

def CommandLine(args=None):
    '''
    Main command line.  Accepts args, to allow for simple unit testing.
    '''
    flags = tf.app.flags
    FLAGS = flags.FLAGS
    if args:
        FLAGS.__init__()
        FLAGS.__dict__.update(args)

    try:
        flags.DEFINE_string("model_type", "wide+deep","Valid model types: {'wide', 'deep', 'wide+deep'}.")
        flags.DEFINE_string("run_name", None, "name for this run (defaults to model type)")
        flags.DEFINE_string("load_weights", None, "filename with initial weights to load")
        flags.DEFINE_string("checkpoints_dir", None, "name of directory where checkpoints should be saved")
        flags.DEFINE_integer("n_epoch", 200, "Number of training epoch steps")
        flags.DEFINE_integer("snapshot_step", 100, "Step number when snapshot (and validation testing) is done")
        flags.DEFINE_float("wide_learning_rate", 0.001, "learning rate for the wide part of the model")
        flags.DEFINE_float("deep_learning_rate", 0.001, "learning rate for the deep part of the model")
        flags.DEFINE_boolean("verbose", False, "Verbose output")
    except argparse.ArgumentError:
        pass	# so that CommandLine can be run more than once, for testing

    twad = TFLearnWideAndDeep(model_type=FLAGS.model_type, verbose=FLAGS.verbose, 
                              name=FLAGS.run_name, wide_learning_rate=FLAGS.wide_learning_rate,
                              deep_learning_rate=FLAGS.deep_learning_rate,
                              checkpoints_dir=FLAGS.checkpoints_dir)
    twad.load_data()
    if FLAGS.load_weights:
        print ("Loading initial weights from %s" % FLAGS.load_weights)
        twad.model.load(FLAGS.load_weights)
    twad.train(n_epoch=FLAGS.n_epoch, snapshot_step=FLAGS.snapshot_step)
    twad.evaluate()
    return twad

#-----------------------------------------------------------------------------
# unit tests

def test_wide_and_deep():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="wide+deep", snapshot_step=5, 
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print ("cfiles=%s" % cfiles)
    assert(len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert(cm[1][1])

def test_deep():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="deep", snapshot_step=5, 
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print ("cfiles=%s" % cfiles)
    assert(len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert(cm[1][1])

def test_wide():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="wide", snapshot_step=5, 
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print ("cfiles=%s" % cfiles)
    assert(len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert(cm[1][1])

#-----------------------------------------------------------------------------

if __name__=="__main__":
    CommandLine()
    None
import csv
import os
import tensorflow as tf

from src.Agent.DeepLearningAgent.DeepLearningAgent import DeepLearningAgent
from src.Agent.Reactive.ReactiveAgent import ReactiveAgent
from src.Entity.Consumer import Consumer
from src.Entity.HotSpot import HotSpot
from src.Entity.Salesman import Salesman
from src.Math.Vector2D import Vector2D
from src.Simulation.Simulation import Simulation
from src.World import World


salesmanA = None
salesmanB = None
simulation = None

def create_simulation_reactive_vs_deep_q():
    global salesmanA, salesmanB, simulation

    tf.reset_default_graph()

    world = World()
    simulation = Simulation(world)

    hotspot = HotSpot(simulation, Vector2D(50, 50), Vector2D(50, 50))
    simulation.addEntity(hotspot)

    hotspot = HotSpot(simulation, Vector2D(200, 650), Vector2D(50, 50))
    simulation.addEntity(hotspot)

    # Consumers
    for i in range(0, 4):
        consumer = Consumer(simulation, simulation.getRandomEmptyPlace(), Vector2D(50, 50))
        simulation.addEntity(consumer)

    # Reactive agent
    salesmanA = Salesman(simulation, simulation.getRandomEmptyPlace(), Vector2D(50, 50))
    agent = ReactiveAgent(salesmanA)
    simulation.addEntity(salesmanA)
    simulation.addAgent(agent)

    # Deep Q Learning Agent
    salesmanB = Salesman(simulation, simulation.getRandomEmptyPlace(), Vector2D(50, 50))
    agent = DeepLearningAgent(salesmanB, model="reactive_vs_deep_learning/episode_136")
    simulation.addEntity(salesmanB)
    simulation.addAgent(agent)

def create_simulation_reactive_vs_reactive():
    global salesmanA, salesmanB, simulation

    tf.reset_default_graph()

    world = World()
    simulation = Simulation(world)

    hotspot = HotSpot(simulation, Vector2D(50, 50), Vector2D(50, 50))
    simulation.addEntity(hotspot)

    hotspot = HotSpot(simulation, Vector2D(200, 650), Vector2D(50, 50))
    simulation.addEntity(hotspot)

    # Consumers
    for i in range(0, 4):
        consumer = Consumer(simulation, simulation.getRandomEmptyPlace(), Vector2D(50, 50))
        simulation.addEntity(consumer)

    # Reactive agent
    salesmanA = Salesman(simulation, simulation.getRandomEmptyPlace(), Vector2D(50, 50))
    agent = ReactiveAgent(salesmanA)
    simulation.addEntity(salesmanA)
    simulation.addAgent(agent)

    # Deep Q Learning Agent
    salesmanB = Salesman(simulation, simulation.getRandomEmptyPlace(), Vector2D(50, 50))
    agent = ReactiveAgent(salesmanB)
    simulation.addEntity(salesmanB)
    simulation.addAgent(agent)

def create_simulation_deep_q_vs_deep_q(iterationA="", iterationB=""):
    global salesmanA, salesmanB, simulation

    tf.reset_default_graph()

    world = World()
    simulation = Simulation(world)

    hotspot = HotSpot(simulation, Vector2D(50, 50), Vector2D(50, 50))
    simulation.addEntity(hotspot)

    hotspot = HotSpot(simulation, Vector2D(200, 650), Vector2D(50, 50))
    simulation.addEntity(hotspot)

    # Consumers
    for i in range(0, 4):
        consumer = Consumer(simulation, simulation.getRandomEmptyPlace(), Vector2D(50, 50))
        simulation.addEntity(consumer)

    # Deep Q Learning Agent
    salesmanA = Salesman(simulation, simulation.getRandomEmptyPlace(), Vector2D(50, 50))
    agent = DeepLearningAgent(salesmanA, model="reactive_vs_deep_learning/episode_"+iterationA)
    simulation.addEntity(salesmanA)
    simulation.addAgent(agent)

    # Deep Q Learning Agent
    salesmanB = Salesman(simulation, simulation.getRandomEmptyPlace(), Vector2D(50, 50))
    agent = DeepLearningAgent(salesmanB, model="reactive_vs_deep_learning/episode_"+iterationB)
    simulation.addEntity(salesmanB)
    simulation.addAgent(agent)



NUM_EPISODES = 10
MAX_EPISODE_SIZE = 2000

# Reactive vs Deep Q Learning
for episode in range(0, NUM_EPISODES):
    create_simulation_reactive_vs_deep_q()

    if not os.path.exists("data/reactive_vs_deep"):
        os.makedirs("data/reactive_vs_deep")

    with open("data/reactive_vs_deep/run_"+str(episode)+".csv", 'w+') as file:
        wr = csv.writer(file, quoting=csv.QUOTE_ALL)
        wr.writerow(["Reactive Agent", "Deep Learning Agent"])

        for index in range(0, MAX_EPISODE_SIZE):
            simulation.update()
            simulation.outputToConsole()
            wr.writerow([salesmanA.getTotalReward(), salesmanB.getTotalReward()])


# Reactive vs Reactive
for episode in range(0, NUM_EPISODES):
    create_simulation_reactive_vs_reactive()

    if not os.path.exists("data/reactive_vs_reactive"):
        os.makedirs("data/reactive_vs_reactive")

    with open("data/reactive_vs_reactive/run_"+str(episode)+".csv", 'w+') as file:
        wr = csv.writer(file, quoting=csv.QUOTE_ALL)
        wr.writerow(["Reactive Agent", "Reactive Agent"])

        for index in range(0, MAX_EPISODE_SIZE):
            simulation.update()
            simulation.outputToConsole()
            wr.writerow([salesmanA.getTotalReward(), salesmanB.getTotalReward()])


# Deep Q Learning (136) vs Deep Q Learning (136)
for episode in range(0, NUM_EPISODES):
    create_simulation_deep_q_vs_deep_q("136", "136")

    if not os.path.exists("data/deep_136_vs_deep_136"):
        os.makedirs("data/deep_136_vs_deep_136")

    with open("data/deep_136_vs_deep_136/run_"+str(episode)+".csv", 'w+') as file:
        wr = csv.writer(file, quoting=csv.QUOTE_ALL)
        wr.writerow(["Deep Learning Agent (136)", "Deep Learning Agent (136)"])

        for index in range(0, MAX_EPISODE_SIZE):
            simulation.update()
            simulation.outputToConsole()
            wr.writerow([salesmanA.getTotalReward(), salesmanB.getTotalReward()])


# Deep Q Learning (50) vs Deep Q Learning (136)
for episode in range(0, NUM_EPISODES):
    create_simulation_deep_q_vs_deep_q("50", "136")

    if not os.path.exists("data/deep_50_vs_deep_136"):
        os.makedirs("data/deep_50_vs_deep_136")

    with open("data/deep_50_vs_deep_136/run_"+str(episode)+".csv", 'w+') as file:
        wr = csv.writer(file, quoting=csv.QUOTE_ALL)
        wr.writerow(["Deep Learning Agent (50)", "Deep Learning Agent (136)"])

        for index in range(0, MAX_EPISODE_SIZE):
            simulation.update()
            simulation.outputToConsole()
            wr.writerow([salesmanA.getTotalReward(), salesmanB.getTotalReward()])


# Deep Q Learning (0) vs Deep Q Learning (136)
for episode in range(0, NUM_EPISODES):
    create_simulation_deep_q_vs_deep_q("0", "136")

    if not os.path.exists("data/deep_0_vs_deep_136"):
        os.makedirs("data/deep_0_vs_deep_136")

    with open("data/deep_0_vs_deep_136/run_"+str(episode)+".csv", 'w+') as file:
        wr = csv.writer(file, quoting=csv.QUOTE_ALL)
        wr.writerow(["Deep Learning Agent (0)", "Deep Learning Agent (136)"])

        for index in range(0, MAX_EPISODE_SIZE):
            simulation.update()
            simulation.outputToConsole()
            wr.writerow([salesmanA.getTotalReward(), salesmanB.getTotalReward()])



# Set Operations


# Set declaration
deep_learning_neuron_set = set(['neuron_solo', 'multi_perceptron', 'multi_perceptron', 'RNN'])
deep_learning_neuron_set_aliter = {'neuron_solo', 'multi_perceptron', 'multi_perceptron', 'RNN'}




deep_learning_neuron_subset = set(['neuron_solo', 'multi_perceptron', 'multi_perceptron'])

deep_learning_neuron_superset = set(['neuron_solo', 'multi_perceptron', 'multi_perceptron', 'RNN', 'neural_network_algorithms'])




print(deep_learning_neuron_subset.issubset(deep_learning_neuron_set))

print(deep_learning_neuron_superset.issuperset(deep_learning_neuron_set))

print(deep_learning_neuron_set)


# -*- coding: utf-8 -*-

# Scrapy settings for deep_learning_task project
#
# For simplicity, this file contains only settings considered important or
# commonly used. You can find more settings consulting the documentation:
#
#     https://doc.scrapy.org/en/latest/topics/settings.html
#     https://doc.scrapy.org/en/latest/topics/downloader-middleware.html
#     https://doc.scrapy.org/en/latest/topics/spider-middleware.html

BOT_NAME = 'deep_learning_task'

SPIDER_MODULES = ['deep_learning_task.spiders']
NEWSPIDER_MODULE = 'deep_learning_task.spiders'


# Crawl responsibly by identifying yourself (and your website) on the user-agent
#USER_AGENT = 'deep_learning_task (+http://www.yourdomain.com)'

# Obey robots.txt rules
ROBOTSTXT_OBEY = False

# Configure maximum concurrent requests performed by Scrapy (default: 16)
#CONCURRENT_REQUESTS = 32

# Configure a delay for requests for the same website (default: 0)
# See https://doc.scrapy.org/en/latest/topics/settings.html#download-delay
# See also autothrottle settings and docs
#DOWNLOAD_DELAY = 3
# The download delay setting will honor only one of:
#CONCURRENT_REQUESTS_PER_DOMAIN = 16
#CONCURRENT_REQUESTS_PER_IP = 16

# Disable cookies (enabled by default)
#COOKIES_ENABLED = False

# Disable Telnet Console (enabled by default)
#TELNETCONSOLE_ENABLED = False

# Override the default request headers:
#DEFAULT_REQUEST_HEADERS = {
#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
#   'Accept-Language': 'en',
#}

# Enable or disable spider middlewares
# See https://doc.scrapy.org/en/latest/topics/spider-middleware.html
#SPIDER_MIDDLEWARES = {
#    'deep_learning_task.middlewares.DeepLearningTaskSpiderMiddleware': 543,
#}

# Enable or disable downloader middlewares
# See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html
#DOWNLOADER_MIDDLEWARES = {
#    'deep_learning_task.middlewares.DeepLearningTaskDownloaderMiddleware': 543,
#}

# Enable or disable extensions
# See https://doc.scrapy.org/en/latest/topics/extensions.html
#EXTENSIONS = {
#    'scrapy.extensions.telnet.TelnetConsole': None,
#}

# Configure item pipelines
# See https://doc.scrapy.org/en/latest/topics/item-pipeline.html
#ITEM_PIPELINES = {
#    'deep_learning_task.pipelines.DeepLearningTaskPipeline': 300,
#}

# Enable and configure the AutoThrottle extension (disabled by default)
# See https://doc.scrapy.org/en/latest/topics/autothrottle.html
#AUTOTHROTTLE_ENABLED = True
# The initial download delay
#AUTOTHROTTLE_START_DELAY = 5
# The maximum download delay to be set in case of high latencies
#AUTOTHROTTLE_MAX_DELAY = 60
# The average number of requests Scrapy should be sending in parallel to
# each remote server
#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0
# Enable showing throttling stats for every response received:
#AUTOTHROTTLE_DEBUG = False

# Enable and configure HTTP caching (disabled by default)
# See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings
#HTTPCACHE_ENABLED = True
#HTTPCACHE_EXPIRATION_SECS = 0
#HTTPCACHE_DIR = 'httpcache'
#HTTPCACHE_IGNORE_HTTP_CODES = []
#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'
try:  
    from setuptools import setup, find_packages
except ImportError:
    from distutils.core import setup

setup(
    name='deep_learning_layer_calculator',
    version='0.1.0',
    description='Calculates layers for deep learning based on user specified input dimensions, output dimensions, and architecture.',
    author='Makenzie Brian',
    author_email='brianm@oregonstate.edu',
    url='',
    classifiers=[
        'License :: OSI Approved :: MIT License',
        'Intended Audience :: Developers',
        'Intended Audience :: Science/Research',
        'Natural Language :: English',
        'Programming Language :: Python :: 2',
    ],
    license='MIT',
    python_requires='>=2',
    zip_safe=False,
    packages=['deep_learning_layer_calculator', 'deep_learning_layer_calculator.tests'],

    package_dir={
        'deep_learning_layer_calculator': 'deep_learning_layer_calculator',
        'deep_learning_layer_calculator.tests': 'deep_learning_layer_calculator/tests',
        },
    include_package_data=True,

)
from PIL import Image
import os


def sliceSpectrograms():
    path_spectrogram_hiphop = r"D:\2018\Deep Learning\termproject_musicgenre\data\spectrogram\hiphop"
    path_spectrogram_jazz = r"D:\2018\Deep Learning\termproject_musicgenre\data\spectrogram\jazz"
    path_spectrogram_rock = r"D:\2018\Deep Learning\termproject_musicgenre\data\spectrogram\rock"
    path_spectrogram_pop = r"D:\2018\Deep Learning\termproject_musicgenre\data\spectrogram\pop"
    path_spectrogram_edm = r"D:\2018\Deep Learning\termproject_musicgenre\data\spectrogram\edm"

    hiphop_files = os.listdir(path_spectrogram_hiphop)
    jazz_files = os.listdir(path_spectrogram_jazz)
    rock_files = os.listdir(path_spectrogram_rock)
    pop_files = os.listdir(path_spectrogram_pop)
    edm_files = os.listdir(path_spectrogram_edm)

    for filename in enumerate(hiphop_files):
        path_sliced_hiphop = r"D:\2018\Deep Learning\termproject_musicgenre\data\sliced_spectrogram\hiphop"
        sliceSpectrogram(filename[1], path_spectrogram_hiphop, path_sliced_hiphop)
    print("Hip-Hop slices saved!")

    for filename in enumerate(jazz_files):
        path_sliced_jazz = r"D:\2018\Deep Learning\termproject_musicgenre\data\sliced_spectrogram\jazz"
        sliceSpectrogram(filename[1], path_spectrogram_jazz, path_sliced_jazz)
    print("Jazz slices saved!")

    for filename in enumerate(rock_files):
        path_sliced_rock = r"D:\2018\Deep Learning\termproject_musicgenre\data\sliced_spectrogram\rock"
        sliceSpectrogram(filename[1], path_spectrogram_rock, path_sliced_rock)
    print("Rock slices saved!")

    for filename in enumerate(pop_files):
        path_sliced_pop = r"D:\2018\Deep Learning\termproject_musicgenre\data\sliced_spectrogram\pop"
        sliceSpectrogram(filename[1], path_spectrogram_pop, path_sliced_pop)
    print("Pop slices saved!")

    for filename in enumerate(edm_files):
        path_sliced_edm = r"D:\2018\Deep Learning\termproject_musicgenre\data\sliced_spectrogram\edm"
        sliceSpectrogram(filename[1], path_spectrogram_edm, path_sliced_edm)
    print("EDM slices saved!")


def sliceSpectrogram(filename, oldpath, newpath):
    path = oldpath + r"\ ".strip() + filename
    img = Image.open(path).convert('LA')

    width, height = img.size
    desired_size = int(width/25)

    for i in range(25):
        print("creating slice: ", (i+1))
        startPixel = i * desired_size
        imgTmp = img.crop((startPixel, 45, startPixel + desired_size, height-45))

        if i < 21 and i > 3:
            imgTmp.save(newpath+"\{}_{}.png".format(filename, i))


#sliceSpectrograms()
path = r'D:\2018\Deep Learning\termproject_musicgenre\data\sliced_spectrogram\hiphop\01 Ambitionz Az A Ridah.wav.png_11.png'
img = Image.open(path)
width, height = img.size
print(width)
print(height)import os
import wave
import pylab
from pydub import AudioSegment
from matplotlib import mlab


def createSpectrogram(filename, oldpath, newpath):
    path = oldpath + r"\ ".strip() + filename
    wav = wave.open(path, 'r')
    frames = wav.readframes(-1)
    sound_info = pylab.fromstring(frames, 'int16')
    frame_rate = wav.getframerate()
    wav.close()

    if wav.getnchannels() == 1:
        pylab.figure(num=None, figsize=(100, 4))
        pylab.subplot(111)
        pylab.specgram(sound_info, Fs=frame_rate, pad_to=None, NFFT=1024)
        pylab.axis('off')
        pylab.box(False)
        pylab.savefig(newpath + r"\ ".strip() + filename + ".png", bbox_inches=None, transparent=True, pad_inches=0, aspect='auto')
        pylab.close()


def createSpectrogramFromAudio():
    path_mono_hiphop = r"D:\2018\Deep Learning\termproject_musicgenre\data\mono\hiphop"
    path_mono_jazz = r"D:\2018\Deep Learning\termproject_musicgenre\data\mono\jazz"
    path_mono_rock = r"D:\2018\Deep Learning\termproject_musicgenre\data\mono\rock"
    path_mono_pop = r"D:\2018\Deep Learning\termproject_musicgenre\data\mono\pop"
    path_mono_edm = r"D:\2018\Deep Learning\termproject_musicgenre\data\mono\edm"

    hiphop_files = os.listdir(path_mono_hiphop)
    jazz_files = os.listdir(path_mono_jazz)
    rock_files = os.listdir(path_mono_rock)
    pop_files = os.listdir(path_mono_pop)
    edm_files = os.listdir(path_mono_edm)

    """hiphop_files = [file for file in hiphop_files if file.endswith(".wav")]
    jazz_files = [file for file in jazz_files if file.endswith(".wav")]"""

    for filename in enumerate(hiphop_files):
        path_spectrogram_hiphop = r"D:\2018\Deep Learning\termproject_musicgenre\data\spectrogram\hiphop"
        createSpectrogram(filename[1], path_mono_hiphop, path_spectrogram_hiphop)
    print("Hip-Hop Spectrogram saved!")

    for filename in enumerate(jazz_files):
        path_spectrogram_jazz = r"D:\2018\Deep Learning\termproject_musicgenre\data\spectrogram\jazz"
        createSpectrogram(filename[1], path_mono_jazz, path_spectrogram_jazz)
    print("Jazz Spectrogram saved!")

    for filename in enumerate(rock_files):
        path_spectrogram_rock = r"D:\2018\Deep Learning\termproject_musicgenre\data\spectrogram\rock"
        createSpectrogram(filename[1], path_mono_rock, path_spectrogram_rock)
    print("Rock Spectrogram saved!")

    for filename in enumerate(pop_files):
        path_spectrogram_pop = r"D:\2018\Deep Learning\termproject_musicgenre\data\spectrogram\pop"
        createSpectrogram(filename[1], path_mono_pop, path_spectrogram_pop)
    print("Pop Spectrogram saved!")

    for filename in enumerate(edm_files):
        path_spectrogram_edm = r"D:\2018\Deep Learning\termproject_musicgenre\data\spectrogram\edm"
        createSpectrogram(filename[1], path_mono_edm, path_spectrogram_edm)
    print("EDM Spectrogram saved!")

def changeToMono():
    path_raw_hiphop = r"D:\2018\Deep Learning\termproject_musicgenre\data\raw\hiphop"
    path_raw_jazz = r"D:\2018\Deep Learning\termproject_musicgenre\data\raw\jazz"
    path_raw_rock = r"D:\2018\Deep Learning\termproject_musicgenre\data\raw\rock"
    path_raw_pop = r"D:\2018\Deep Learning\termproject_musicgenre\data\raw\pop"
    path_raw_edm = r"D:\2018\Deep Learning\termproject_musicgenre\data\raw\edm"

    hiphop_files = os.listdir(path_raw_hiphop)
    jazz_files = os.listdir(path_raw_jazz)
    rock_files = os.listdir(path_raw_rock)
    pop_files = os.listdir(path_raw_pop)
    edm_files = os.listdir(path_raw_edm)

    for filename in enumerate(hiphop_files):
        path_mono_hiphop = r"D:\2018\Deep Learning\termproject_musicgenre\data\mono\hiphop"
        sound = AudioSegment.from_wav(path_raw_hiphop + r"\ ".strip() + filename[1])
        sound = sound.set_channels(1)
        sound.export(path_mono_hiphop + r"\ ".strip() + filename[1], format='wav')
    print("Hip-Hop Mono saved!")

    for filename in enumerate(jazz_files):
        path_mono_jazz = r"D:\2018\Deep Learning\termproject_musicgenre\data\mono\jazz"
        sound = AudioSegment.from_wav(path_raw_jazz + r"\ ".strip() + filename[1])
        sound = sound.set_channels(1)
        sound.export(path_mono_jazz + r"\ ".strip() + filename[1], format='wav')
    print("Jazz Mono saved!")

    for filename in enumerate(rock_files):
        path_mono_rock = r"D:\2018\Deep Learning\termproject_musicgenre\data\mono\rock"
        sound = AudioSegment.from_wav(path_raw_rock + r"\ ".strip() + filename[1])
        sound = sound.set_channels(1)
        sound.export(path_mono_rock + r"\ ".strip() + filename[1], format='wav')
    print("Rock Mono saved!")

    for filename in enumerate(pop_files):
        path_mono_pop = r"D:\2018\Deep Learning\termproject_musicgenre\data\mono\pop"
        sound = AudioSegment.from_wav(path_raw_pop + r"\ ".strip() + filename[1])
        sound = sound.set_channels(1)
        sound.export(path_mono_pop + r"\ ".strip() + filename[1], format='wav')
    print("Pop Mono saved!")

    for filename in enumerate(edm_files):
        path_mono_edm = r"D:\2018\Deep Learning\termproject_musicgenre\data\mono\edm"
        sound = AudioSegment.from_wav(path_raw_edm + r"\ ".strip() + filename[1])
        sound = sound.set_channels(1)
        sound.export(path_mono_edm + r"\ ".strip() + filename[1], format='wav')
    print("EDM Mono saved!")


createSpectrogramFromAudio()
#changeToMono()# always run miniconda for keras:
# ./miniconda3/bin/python

import matplotlib
matplotlib.use('Agg') # this suppresses the console for plotting
import matplotlib.pyplot as plt
import bz2
import numpy as np
from numpy import random
import pandas as pd
import os
import pylab
from importlib import reload
from sklearn.preprocessing import normalize
from keras.layers import Input, Dense
from keras.models import Model
from keras.callbacks import History, TensorBoard
from keras import backend as K
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc, accuracy_score, f1_score, precision_score, recall_score
from sklearn.preprocessing import label_binarize
from sklearn.utils import shuffle

backend = K.backend()

import load_kmer_cnts_jf
import deep_learning_models

#################
# Load the data # 
#################

kmer_size=6

#data_sets_healthy=['HMP', 'Qin_et_al','RA','MetaHIT','Feng','Karlsson_2013','LiverCirrhosis','Zeller_2014']

data_sets_healthy=['Qin_et_al']
allowed_labels=['0']
kmer_cnts_healthy, accessions_healthy, labels_healthy, domain_labels =load_kmer_cnts_jf.load_kmers(kmer_size,data_sets_healthy, allowed_labels)

data_sets_diseased=['Qin_et_al']
allowed_labels=['1']
kmer_cnts_diseased, accessions_diseased, labels_diseased, domain_labels =load_kmer_cnts_jf.load_kmers(kmer_size,data_sets_diseased, allowed_labels)

kmer_cnts=np.concatenate((kmer_cnts_healthy,kmer_cnts_diseased))
accessions=np.concatenate((accessions_healthy,accessions_diseased))
labels=np.concatenate((labels_healthy,labels_diseased))

labels=np.asarray(labels)
labels=labels.astype(np.int)
healthy=np.where(labels==0)
disease=np.where(labels==1)


data=pd.DataFrame(kmer_cnts)
data_normalized = normalize(data, axis = 1, norm = 'l1')

data_normalized, labels = shuffle(data_normalized, labels, random_state=0)

###########################################
# set up a model (supervised learning)    #
###########################################

input_dim=len(data_normalized[0]) # this is the number of input kmers
encoding_dim=200

encoded_activation = 'relu'
#encoded_activation = 'linear'
#decoded_activation = 'softmax'
decoded_activation = 'sigmoid'

loss='binary_crossentropy'

model=deep_learning_models.create_supervised_model(input_dim, encoding_dim, encoded_activation, decoded_activation)

#weightFile = os.environ['HOME'] + '/deep_learning_microbiome/data/weights.txt'

#################
# Fit the model #
#################

numEpochs = 1000
batchSize = 32

history = History()
# history is a dictionary. To get the keys, type print(history.history.keys())

model.fit(data_normalized, labels, epochs=numEpochs, validation_split=0.2, batch_size=batchSize, shuffle=True, callbacks=[history])


y_pred=model.predict(data_normalized)
fpr, tpr, thresholds = roc_curve(labels, y_pred)
y_pred = (y_pred > 0.5)
conf_mat=confusion_matrix(labels, y_pred)
auc= auc(fpr,tpr)
accuracy=accuracy_score(labels, y_pred)
f1 = f1_score(labels, y_pred, pos_label=None, average='weighted')
precision = precision_score(labels, y_pred, pos_label=None, average='weighted')
recall = recall_score(labels, y_pred, pos_label=None, average='weighted')


#############
# plot roc: #
############# 
graph_dir = '~/deep_learning_microbiome/analysis/'
file_name=os.path.expanduser(graph_dir + 'roc.pdf')
deep_learning_models.plot_roc_aucs(fpr, tpr, auc, acc, file_name)

##########################
# Plot accuracy vs epoch #
##########################
graph_dir = '~/deep_learning_microbiome/analysis/'

pylab.figure()
pylab.plot(history.history['acc'])
pylab.plot(history.history['val_acc'])
pylab.legend(['training','test'], loc='upper right')

pylab.title('Model accuracy by epochs')
pylab.ylabel('Accuracy')
pylab.xlabel('Epoch')


pylab.gca().set_position((.1, .6, .8, .6))
pylab.figtext(0.02, .4, 'This graph shows how loss changes with number of epochs for different splits between training and test data.')
pylab.figtext(0.02, .32, 'Backend: ' + backend)
pylab.figtext(0.02, .28, 'Loss function: ' + loss)
pylab.figtext(0.02, .24, 'Number of encoding dimensions: {}'.format(encoding_dim))
pylab.figtext(0.02, .16, 'Number of epochs of training: {}'.format(numEpochs))
pylab.figtext(0.02, .12, 'Batch size used during training: {}'.format(batchSize))
pylab.figtext(0.02, .08, 'Activation function used for encoding: ' + encoded_activation)
pylab.figtext(0.02, .04, 'Activation function used for decoding: ' + decoded_activation)
pylab.savefig(os.path.expanduser(graph_dir + '/accuracy.pdf') , bbox_inches='tight')


##########################
# Plot loss vs epoch #
##########################
graph_dir = '~/deep_learning_microbiome/analysis/'

pylab.figure()
pylab.plot(history.history['loss'])
pylab.plot(history.history['val_loss'])
pylab.legend(['training','test'], loc='upper right')

pylab.title('Model loss by epochs')
pylab.ylabel('Loss')
pylab.xlabel('Epoch')


pylab.gca().set_position((.1, .6, .8, .6))
pylab.figtext(0.02, .4, 'This graph shows how loss changes with number of epochs for different splits between training and test data.')
pylab.figtext(0.02, .32, 'Backend: ' + backend)
pylab.figtext(0.02, .28, 'Loss function: ' + loss)
pylab.figtext(0.02, .24, 'Number of encoding dimensions: {}'.format(encoding_dim))
pylab.figtext(0.02, .16, 'Number of epochs of training: {}'.format(numEpochs))
pylab.figtext(0.02, .12, 'Batch size used during training: {}'.format(batchSize))
pylab.figtext(0.02, .08, 'Activation function used for encoding: ' + encoded_activation)
pylab.figtext(0.02, .04, 'Activation function used for decoding: ' + decoded_activation)
pylab.savefig(os.path.expanduser(graph_dir + '/Loss.pdf') , bbox_inches='tight')



###########################
# Plot a confusion matrix #
###########################
file_name=os.path.expanduser(graph_dir + 'confusion_matrix.pdf')
classes=['0','1']
deep_learning_models.plot_confusion_matrix(conf_mat, classes,file_name)


######################################################
########################################################
# In this part of the code, I will vary different parameters to test how the predictions change
########################################################

############################################################################
# First test: how does number of encoding dimensions change the accuracy?  #
############################################################################  


encoding_dims=[1,2,10,50,100,200,300,400,500]

deep_learning_output={} #store the output in here. 

for encoding_dim in encoding_dims:
    deep_learning_output[encoding_dim]={'fpr':0,'tpr':0,'conf_mat':0, 'auc':0,'acc':0}

for encoding_dim in encoding_dims:
    input_dim=len(data_normalized[0]) # this is the number of input kmers
    #
    encoded_activation = 'relu'
    #encoded_activation = 'linear'
    #decoded_activation = 'softmax'
    decoded_activation = 'sigmoid'
    #
    loss='binary_crossentropy'
    #
    model=deep_learning_models.create_supervised_model(input_dim, encoding_dim, encoded_activation, decoded_activation)
    #
    #weightFile = os.environ['HOME'] + '/deep_learning_microbiome/data/weights.txt'
    #
    #################
    # Fit the model #
    #################
    #
    numEpochs = 1000
    batchSize = 32
    #
    history = History()
    #
    model.fit(data_normalized, labels, epochs=numEpochs, validation_split=0.2, batch_size=batchSize, shuffle=True, callbacks=[history])
    #
    y_pred=model.predict(data_normalized)
    fpr, tpr, thresholds = roc_curve(labels, y_pred)
    y_pred = (y_pred > 0.5)
    conf_mat=confusion_matrix(labels, y_pred)
    #auc= auc(fpr,tpr)
    acc=accuracy_score(labels, y_pred)
    #
    deep_learning_output[encoding_dim]['fpr']=fpr
    deep_learning_output[encoding_dim]['tpr']=tpr
    deep_learning_output[encoding_dim]['conf_mat']=conf_mat
    deep_learning_output[encoding_dim]['auc']=auc
    deep_learning_output[encoding_dim]['acc']=acc




# plot the roc curves for different numbers of encoding dimensions:

colors=['#543005','#8c510a','#bf812d','#dfc27d', '#f6e8c3', '#c7eae5', '#80cdc1', '#35978f', '#01665e']
pylab.figure()

pylab.figure()
pylab.xlim([0.0, 1.0])
pylab.ylim([0.0, 1.05])
pylab.xlabel('False Positive Rate')
pylab.ylabel('True Positive Rate')
title='ROC as function of number of encoding dims'
pylab.title(title)

color_index=0
for encoding_dim in deep_learning_output:
    pylab.plot(deep_learning_output[encoding_dim]['fpr'], deep_learning_output[encoding_dim]['tpr'], color=colors[color_index])
    color_index +=1

pylab.legend(['1','2','10','50','100','200','300','400','500'], loc='upper right')
pylab.plot([0, 1], [0, 1], 'k--')


pylab.gca().set_position((.1, .6, .8, .6))
pylab.figtext(0.02, .4, 'This graph shows how loss changes with number of epochs for different splits between training and test data.')
pylab.figtext(0.02, .32, 'Backend: ' + backend)
pylab.figtext(0.02, .28, 'Loss function: ' + loss)
pylab.figtext(0.02, .16, 'Number of epochs of training: {}'.format(numEpochs))
pylab.figtext(0.02, .12, 'Batch size used during training: {}'.format(batchSize))
pylab.figtext(0.02, .08, 'Activation function used for encoding: ' + encoded_activation)
pylab.figtext(0.02, .04, 'Activation function used for decoding: ' + decoded_activation)
pylab.savefig(os.path.expanduser(graph_dir + '/ROC_vs_encoding_dims.pdf')
              , bbox_inches='tight')


# plot accuracy vs number of encoding dims
pylab.figure()
pylab.xlabel('Number of encoding dimensions')
pylab.ylabel('Accuracy')
title='Accuracy as function of number of encoding dims'
pylab.title(title)

accuracy_vector=[]
for encoding_dim in deep_learning_output:
    accuracy_vector.append(deep_learning_output[encoding_dim]['acc'])

pylab.plot(encoding_dims,accuracy_vector)

pylab.gca().set_position((.1, .6, .8, .6))
pylab.figtext(0.02, .4, 'This graph shows how loss changes with number of epochs for different splits between training and test data.')
pylab.figtext(0.02, .32, 'Backend: ' + backend)
pylab.figtext(0.02, .28, 'Loss function: ' + loss)
pylab.figtext(0.02, .16, 'Number of epochs of training: {}'.format(numEpochs))
pylab.figtext(0.02, .12, 'Batch size used during training: {}'.format(batchSize))
pylab.figtext(0.02, .08, 'Activation function used for encoding: ' + encoded_activation)
pylab.figtext(0.02, .04, 'Activation function used for decoding: ' + decoded_activation)
pylab.savefig(os.path.expanduser(graph_dir + '/Accuracy_vs_encoding_dims.pdf')
              , bbox_inches='tight')



for encoding_dim in deep_learning_output:
    print('\nencoding dim is %s' %encoding_dim)
    print(deep_learning_output[encoding_dim]['conf_mat'])


#################################
# second test: 5 mers vs 3 mers #
################################# 


# note im manually changing variables...
# 200 encoding dims

deep_learning_output={}
for mer in ['5mer','3mer']:
    deep_learning_output[mer]={'fpr':0,'tpr':0,'conf_mat':0, 'auc':0,'acc':0}

mer='3mer'
deep_learning_output[mer]['fpr']=fpr
deep_learning_output[mer]['tpr']=tpr
deep_learning_output[mer]['conf_mat']=conf_mat
deep_learning_output[mer]['acc']=acc



colors=['#8c510a', '#01665e']
pylab.figure()
pylab.xlim([0.0, 1.0])
pylab.ylim([0.0, 1.05])
pylab.xlabel('False Positive Rate')
pylab.ylabel('True Positive Rate')
title='ROC as function of kmer length'
pylab.title(title)

color_index=0
for kmer_len in ['3mer','5mer']:
    pylab.plot(deep_learning_output[kmer_len]['fpr'], deep_learning_output[kmer_len]['tpr'], color=colors[color_index])
    color_index +=1

pylab.legend(['3mer','5mer'], loc='upper right')

pylab.plot([0, 1], [0, 1], 'k--')


pylab.gca().set_position((.1, .6, .8, .6))
pylab.figtext(0.02, .4, 'This graph shows how loss changes with number of epochs for different splits between training and test data.')
pylab.figtext(0.02, .32, 'Backend: ' + backend)
pylab.figtext(0.02, .28, 'Loss function: ' + loss)
pylab.figtext(0.02, .16, 'Number of epochs of training: {}'.format(numEpochs))
pylab.figtext(0.02, .12, 'Batch size used during training: {}'.format(batchSize))
pylab.figtext(0.02, .08, 'Activation function used for encoding: ' + encoded_activation)
pylab.figtext(0.02, .04, 'Activation function used for decoding: ' + decoded_activation)
pylab.savefig(os.path.expanduser(graph_dir + '/ROC_vs_kmer_size.pdf')
              , bbox_inches='tight')




#################################
# One data set vs all data sets #
#################################
# note im manually changing variables...
# 200 encoding dims

deep_learning_output={}
for mer in ['all_datasets','1_dataset']:
    deep_learning_output[mer]={'fpr':0,'tpr':0,'conf_mat':0, 'auc':0,'acc':0}

mer='1_dataset'
deep_learning_output[mer]['fpr']=fpr
deep_learning_output[mer]['tpr']=tpr
deep_learning_output[mer]['conf_mat']=conf_mat
deep_learning_output[mer]['acc']=acc



colors=['#8c510a', '#01665e']
pylab.figure()
pylab.xlim([0.0, 1.0])
pylab.ylim([0.0, 1.05])
pylab.xlabel('False Positive Rate')
pylab.ylabel('True Positive Rate')
title='ROC as function of amount of data used for healthy control'
pylab.title(title)

color_index=0
for kmer_len in ['all_datasets','1_dataset']:
    pylab.plot(deep_learning_output[kmer_len]['fpr'], deep_learning_output[kmer_len]['tpr'], color=colors[color_index])
    color_index +=1

pylab.legend(['all datasets','1 dataset'], loc='upper right')

pylab.plot([0, 1], [0, 1], 'k--')


pylab.gca().set_position((.1, .6, .8, .6))
pylab.figtext(0.02, .32, 'Backend: ' + backend)
pylab.figtext(0.02, .28, 'Loss function: ' + loss)
pylab.figtext(0.02, .16, 'Number of epochs of training: {}'.format(numEpochs))
pylab.figtext(0.02, .12, 'Batch size used during training: {}'.format(batchSize))
pylab.figtext(0.02, .08, 'Activation function used for encoding: ' + encoded_activation)
pylab.figtext(0.02, .04, 'Activation function used for decoding: ' + decoded_activation)
pylab.savefig(os.path.expanduser(graph_dir + '/ROC_vs_datasets.pdf')
              , bbox_inches='tight')




#################################
# type of encoding activation   #
#################################
deep_learning_output={}

encoded_activations=['relu', 'linear', 'softmax', 'tanh', 'elu',  'softplus', 'softsign', 'sigmoid', 'hard_sigmoid']

for encoded_activation in encoded_activations:
    deep_learning_output[encoded_activation]={'fpr':0,'tpr':0,'conf_mat':0, 'auc':0,'acc':0}

for encoded_activation in encoded_activations:

for encoded_activation in ['softplus', 'softsign', 'sigmoid', 'hard_sigmoid']:
    #
    input_dim=len(data_normalized[0]) # this is the number of input kmers
    encoding_dim=200
    #
    decoded_activation = 'sigmoid'
    #
    loss='binary_crossentropy'
    #
    model=deep_learning_models.create_supervised_model(input_dim, encoding_dim, encoded_activation, decoded_activation)
    #
    #weightFile = os.environ['HOME'] + '/deep_learning_microbiome/data/weights.txt'
    #
    #################
    # Fit the model #
    #################
    #
    numEpochs = 1000
    batchSize = 32
    #
    history = History()
    #
    model.fit(data_normalized, labels, epochs=numEpochs, validation_split=0.2, batch_size=batchSize, shuffle=True, callbacks=[history])
    #model.fit(data_normalized, labels, epochs=numEpochs, batch_size=batchSize, shuffle=True, callbacks=[history])
    #
    y_pred=model.predict(data_normalized)
    fpr, tpr, thresholds = roc_curve(labels, y_pred)
    y_pred = (y_pred > 0.5)
    conf_mat=confusion_matrix(labels, y_pred)
    #auc= auc(fpr,tpr)
    acc=accuracy_score(labels, y_pred)
    #
    deep_learning_output[encoded_activation]['fpr']=fpr
    deep_learning_output[encoded_activation]['tpr']=tpr
    deep_learning_output[encoded_activation]['conf_mat']=conf_mat
    deep_learning_output[encoded_activation]['acc']=acc



# plot

#colors=['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a']

pylab.figure()
pylab.xlim([0.0, 1.0])
pylab.ylim([0.0, 1.05])
pylab.xlabel('False Positive Rate')
pylab.ylabel('True Positive Rate')
title='ROC as function of encoding activation function'
pylab.title(title)

color_index=0
for encoded_activation in encoded_activations:
    pylab.plot(deep_learning_output[encoded_activation]['fpr'], deep_learning_output[encoded_activation]['tpr'], color=colors[color_index])
    color_index +=1

pylab.legend(encoded_activations, loc='upper right')
pylab.plot([0, 1], [0, 1], 'k--')


pylab.gca().set_position((.1, .6, .8, .6))
pylab.figtext(0.02, .4, 'This graph shows how loss changes with number of epochs for different splits between training and test data.')
pylab.figtext(0.02, .32, 'Backend: ' + backend)
pylab.figtext(0.02, .28, 'Loss function: ' + loss)
pylab.figtext(0.02, .16, 'Number of epochs of training: {}'.format(numEpochs))
pylab.figtext(0.02, .12, 'Batch size used during training: {}'.format(batchSize))
pylab.figtext(0.02, .08, 'Activation function used for encoding: ' + encoded_activation)
pylab.figtext(0.02, .04, 'Activation function used for decoding: ' + decoded_activation)
pylab.savefig(os.path.expanduser(graph_dir + '/ROC_vs_encoded_activations.pdf')
              , bbox_inches='tight')








###################################
# deep learning vs Random Forest  #
###################################


#################################################
# With and without pre-training for autoencoder #
#################################################

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
import numpy as np
from tensorflow.python.tools import freeze_graph

NUM_FEATURES = 2
NUM_ITER = 2000
learning_rate = 0.01

x = np.array([[0, 0], [1, 0], [1, 1], [0, 1]], np.float32) # 4x2, input
print(x)
y = np.array([0, 0, 1, 0], np.float32) # 4, correct output, AND operation
#y = np.array([0, 1, 1, 1], np.float32) # OR operation
y = np.reshape(y, [4,1]) # convert to 4x1

X = tf.placeholder(tf.float32, shape=[4, 2])
Y = tf.placeholder(tf.float32, shape=[4, 1])

userInputA = tf.placeholder(tf.float32, name="modelInputA")
userInputB = tf.placeholder(tf.float32, name="modelInputB")

W = tf.Variable(tf.zeros([NUM_FEATURES, 1]), tf.float32)
B = tf.Variable(tf.zeros([1, 1]), tf.float32)

yHat = tf.sigmoid(tf.add(tf.matmul(X, W), B))  # 4x1
err = Y - yHat
deltaW = tf.matmul(tf.transpose(X), err)  # have to be 2x1
deltaB = tf.reduce_sum(err, 0)  # 4, have to 1x1. sum all the biases? yes
W_ = W + learning_rate * deltaW
B_ = B + learning_rate * deltaB

step = tf.group(W.assign(W_), B.assign(B_))  # to update the values of weights and biases.

prediction = tf.add(tf.add(tf.multiply(userInputA, W[0]), tf.multiply(userInputB, W[1])), B, name="modelOutput")  # 4x1

init_op = tf.global_variables_initializer()

saver = tf.train.Saver()

with tf.Session() as sess:
    sess.run(init_op)

    for k in range(NUM_ITER):
        sess.run([step], feed_dict={X: x, Y: y})

    #print(sess.run(prediction, feed_dict={userInputA: [0], userInputB: [1]})[0][0])
    #print(sess.run(W[0]) * 1 + sess.run(W[1]) * 1 + sess.run(B[0]))

    out = saver.save(sess, 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/results.ckpt', global_step=1)
    tf.train.write_graph(sess.graph_def, 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/', 'results.pbtxt')
    tf.train.write_graph(sess.graph_def, 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/','results.pb', as_text=False)

# Freeze the graph

# graph definition saved above
input_graph = 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/results.pb'
# any other saver to use other than default
input_saver = ""
# earlier definition file format text or binary
input_binary = True
# checkpoint file to merge with graph definition
input_checkpoint = 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/results.ckpt-1'
# output nodes inn our model
output_node_names = 'modelOutput'
restore_op_name = 'save/restore_all'
filename_tensor_name = 'save/Const:0'
# output path
output_graph = 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/'+'frozen_'+'results'+'.pb'
# default True
clear_devices = True
initializer_nodes = ""
variable_names_blacklist = ""

freeze_graph.freeze_graph(
    input_graph,
    input_saver,
    input_binary,
    input_checkpoint,
    output_node_names,
    restore_op_name,
    filename_tensor_name,
    output_graph,
    clear_devices,
    initializer_nodes,
    variable_names_blacklist
)


"""
w = tf.Variable(10, name="test")
ten = tf.constant(10)
new_var = tf.multiply(w, ten)
update = tf.assign(w, new_var)
new_var2 = tf.add(ten, ten)

pla1 = tf.placeholder(tf.float32)
pla2 = tf.placeholder(tf.float32)
result = tf.multiply(pla1, pla2)

init_op = tf.global_variables_initializer()
with tf.Session() as sess:
    # Run the Op that initializes global variables.
    sess.run(init_op)
    temp = sess.run([new_var, new_var2])
    print(sess.run(result, feed_dict={pla1:[100], pla2:[100]})[0])
    # ...you can now run any Op that uses variable values...
"""

"""
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.python.tools import freeze_graph


NUM_FEATURES = 2
NUM_ITER = 2000
learning_rate = 0.01

x = np.array([[0, 0], [1, 0], [1, 1], [0, 1]], np.float32)  # 4x2, input
y = np.array([0, 0, 1, 0], np.float32)  # 4, correct output, AND operation
# y = np.array([0, 1, 1, 1], np.float32) # OR operation
y = np.reshape(y, [4, 1])  # convert to 4x1

X = tf.placeholder(tf.float32, shape=[4, 2])
Y = tf.placeholder(tf.float32, shape=[4, 1])

W = tf.Variable(tf.zeros([NUM_FEATURES, 1]), tf.float32)
B = tf.Variable(tf.zeros([1, 1]), tf.float32)

yHat = tf.sigmoid(tf.add(tf.matmul(X, W), B), name="modelOutput")  # 4x1
err = Y - yHat
deltaW = tf.matmul(tf.transpose(X), err)  # have to be 2x1
deltaB = tf.reduce_sum(err, 0)  # 4, have to 1x1. sum all the biases? yes
W_ = W + learning_rate * deltaW
B_ = B + learning_rate * deltaB

step = tf.group(W.assign(W_), B.assign(B_))  # to update the values of weights and biases.

A2 = tf.placeholder(tf.float32, shape=[1], name='modelInputA') # input a
B2 = tf.placeholder(tf.float32, shape=[1], name='modelInputB') # input b

sess = tf.Session()
init = tf.global_variables_initializer()
sess.run(init)

saver = tf.train.Saver()

for k in range(NUM_ITER):
    sess.run([step], feed_dict={X: x, Y: y})

out = saver.save(sess, 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/results.ckpt', global_step=1)
tf.train.write_graph(sess.graph_def, 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/', 'results2.pbtxt')
tf.train.write_graph(sess.graph_def, 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/','results3.pb', as_text=False)


# Freeze the graph

# graph definition saved above
input_graph = 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/results3.pb'
# any other saver to use other than default
input_saver = ""
# earlier definition file format text or binary
input_binary = True
# checkpoint file to merge with graph definition
input_checkpoint = 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/results.ckpt-1'
# output nodes inn our model
output_node_names = 'modelOutput'
restore_op_name = 'save/restore_all'
filename_tensor_name = 'save/Const:0'
# output path
output_graph = 'C:/Users/hmeji/Desktop/androidDev/tensorflow_demo/DeepLearningOnAndroid/DeepLearningOnAndroid/savedFiles/'+'frozen_'+'results3'+'.pb'
# default True
clear_devices = True
initializer_nodes = ""
variable_names_blacklist = ""

freeze_graph.freeze_graph(
    input_graph,
    input_saver,
    input_binary,
    input_checkpoint,
    output_node_names,
    restore_op_name,
    filename_tensor_name,
    output_graph,
    clear_devices,
    initializer_nodes,
    variable_names_blacklist
)
"""

"""
# Now plot the fitted line. We need only two points to plot the line
plot_x = np.array([np.min(x[:, 0] - 0.2), np.max(x[:, 1] + 0.2)])
plot_y = - 1 / W[1] * (W[0] * plot_x + b)
plot_y = np.reshape(plot_y, [2, -1])
plot_y = np.squeeze(plot_y)

print('W: ' + str(W))
print('b: ' + str(b))
print('plot_y: ' + str(plot_y))

plt.scatter(x[:, 0], x[:, 1], c=y, s=100, cmap='viridis')
plt.plot(plot_x, plot_y, color='k', linewidth=2)
plt.xlim([-0.2, 1.2]);
plt.ylim([-0.2, 1.25]);
plt.show()
"""

"""
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
print('TensorFlow version: ' + tf.__version__)


from tensorflow.examples.tutorials.mnist import input_data as mnist_data
mnist = mnist_data.read_data_sets("../MNIST_data", one_hot=True, validation_size=0)

x_train = mnist.train.images
y_train = mnist.train.labels
x_test = mnist.test.images
y_test = mnist.test.labels

print ('We have '+str(x_train.shape[0])+' training examples in dataset')
print ('We have '+str(x_train.shape[1])+' feature points(basically pixels) in each input example')

TUTORIAL_NAME = 'Tutorial2'
MODEL_NAME = 'mnistTFonAndroid'
SAVED_MODEL_PATH = '../' + TUTORIAL_NAME+'_Saved_model/'


LEARNING_RATE = 0.1
TRAIN_STEPS = 2000

# Our single node softmax model
X = tf.placeholder(tf.float32, shape=[None, 784], name='modelInput')
Y_ = tf.placeholder(tf.float32, shape=[None, 10])
W = tf.Variable(tf.zeros([784,10]), name='modelWeights')
b = tf.Variable(tf.zeros([10]), name='modelBias')
Y = tf.nn.softmax(tf.matmul(X,W) + b, name='modelOutput')

# Training and performance matrices
cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y_ * tf.log(Y), reduction_indices=[1]))
training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

# Lets initialize the vairables and train our model
sess = tf.Session()
init = tf.global_variables_initializer()

sess.run(init)
saver = tf.train.Saver()


for i in range(TRAIN_STEPS+1):
    sess.run(training, feed_dict={X: x_train, Y_: y_train})
    if i%100 == 0:
        print('Training Step:' + str(i) +
              '  Accuracy =  ' + str(sess.run(accuracy, feed_dict={X: x_test, Y_: y_test})) +
              '  Loss = ' + str(sess.run(cross_entropy, {X: x_train, Y_: y_train}))
             )
    if i%500 == 0:
        out = saver.save(sess, SAVED_MODEL_PATH + MODEL_NAME + '.ckpt', global_step=i)

"""from dilemma import Game
from strategies import *
from collections import Counter

"""
If the machine learning algorithm don't care about future rewards. (decay == 0)
It's the non-iterated version of the game.
The best strategy is to defect (and win 1 or 5).
 
If the machine learning algorithm care about future rewards.
It's the iterated version of the game.
The best strategy is up to the opponant strategy.
"""


def ml_vs_titfortat_non_iterate():
    
    print("Start a non-iterated game between MachineLearning and Titfortat")
    prisoner_a = MachineLearning("A")
    prisoner_a.qlearning.gamma = 0.0 # We don't care about future rewards
    prisoner_b = Titfortat("B")
    game = Game(prisoner_a, prisoner_b)
    game.play(10000)
    print("last 10 moves: ", prisoner_a.actions[-10:])
    print("ml values: ", prisoner_a.qlearning.values)

def ml_vs_titfortat_iterate():
    print("Start an _iterated_ game between MachineLearning and Titfortat")
    prisoner_a = MachineLearning("A")
    prisoner_a.qlearning.gamma = 0.9 # We deeply care about future rewards
    prisoner_b = Titfortat("B")
    game = Game(prisoner_a, prisoner_b)
    game.play(10000)
    print("last 10 moves: ", prisoner_a.actions[-10:])

def ml_vs_ml_non_iterate():
    print("Start a non-iterated game between two MachineLearning bots")
    prisoner_a = MachineLearning("A")
    prisoner_a.qlearning.gamma = 0.0 # We don't care about future rewards
    prisoner_b = MachineLearning("B")
    prisoner_b.qlearning.gamma = 0.0 # We don't care about future rewards
    game = Game(prisoner_a, prisoner_b)
    game.play(10000)
    print("last 10 moves of a: ", prisoner_a.actions[-10:])
    print("last 10 moves of b: ", prisoner_b.actions[-10:])

def ml_vs_ml_iterate():
    print("Start an _iterated_ game between two MachineLearning bots")
    prisoner_a = MachineLearning("A")
    prisoner_a.qlearning.gamma = 0.9 # We care about future rewards
    prisoner_b = MachineLearning("B")
    prisoner_b.qlearning.gamma = 0.9 # We care about future rewards
    game = Game(prisoner_a, prisoner_b)
    game.play(10000)
    print("last 10 moves of a: ", prisoner_a.actions[-10:])
    print("last 10 moves of b: ", prisoner_b.actions[-10:])

def deepqlearning_vs_titfortat_non_iterate():
    print("Start a non-iterated game between DeepQLearning and Titfortat")
    agent_a = DeepQLearnerAdaptater(2, 1, decay=0.0, learning_rate=0.02, scope="dvt_ni_a")
    prisoner_a = MachineLearning("A", agent=agent_a)
    prisoner_b = Titfortat("B")
    game = Game(prisoner_a, prisoner_b)
    game.play(10000)
    print('Last 1000 moves:')
    print('prisoner_a:', Counter(prisoner_a.actions[-1000:]))
    print('prisoner_b:', Counter(prisoner_b.actions[-1000:]))

def deepqlearning_vs_titfortat_iterate():
    print("Start an iterated game between DeepQLearning and Titfortat")
    agent_a = DeepQLearnerAdaptater(2, 1, decay=0.9, learning_rate=0.02, scope="dvt_i_a")
    prisoner_a = MachineLearning("A", agent=agent_a)
    prisoner_b = Titfortat("B")
    game = Game(prisoner_a, prisoner_b)
    game.play(10000)
    print('Last 1000 moves:')
    print('prisoner_a:', Counter(prisoner_a.actions[-1000:]))
    print('prisoner_b:', Counter(prisoner_b.actions[-1000:]))

def deepqlearning_vs_deepqlearning_non_iterate():
    print("Start an non-iterated game between DeepQLearning and DeepQLearning")
    agent_a = DeepQLearnerAdaptater(2, 1, decay=0.0, learning_rate=0.02, scope="dvd_ni_a")
    prisoner_a = MachineLearning("A", agent=agent_a)
    agent_b = DeepQLearnerAdaptater(2, 1, decay=0.0, learning_rate=0.02, scope="dvd_ni_b")
    prisoner_b = MachineLearning("B", agent=agent_b)
    game = Game(prisoner_a, prisoner_b)
    game.play(10000)
    print('Last 1000 moves:')
    print('prisoner_a:', Counter(prisoner_a.actions[-1000:]))
    print('prisoner_b:', Counter(prisoner_b.actions[-1000:]))

def deepqlearning_vs_deepqlearning_iterate():
    print("Start an _iterated_ game between DeepQLearning and Titfortat")
    agent_a = DeepQLearnerAdaptater(2, 1, decay=0.9, learning_rate=0.02, scope="dvd_i_a")
    prisoner_a = MachineLearning("A", agent=agent_a)
    agent_b = DeepQLearnerAdaptater(2, 1, decay=0.9, learning_rate=0.02, scope="dvd_i_b")
    prisoner_b = MachineLearning("B", agent=agent_b)
    game = Game(prisoner_a, prisoner_b)
    game.play(10000)
    print('Last 1000 moves:')
    print('prisoner_a:', Counter(prisoner_a.actions[-1000:]))
    print('prisoner_b:', Counter(prisoner_b.actions[-1000:]))



def main():
    deepqlearning_vs_titfortat_non_iterate()
    deepqlearning_vs_titfortat_iterate()
    deepqlearning_vs_deepqlearning_non_iterate()
    deepqlearning_vs_deepqlearning_iterate()

if __name__ == '__main__':
    main()# -*- coding: utf-8 -*-
"""
describe : 
author : yu_wei
created on : 2019/2/19
version :
refer :
https://github.com/ichuang/tflearn_wide_and_deep/blob/master/tflearn_wide_and_deep.py
"""
import os
import sys
import argparse
import tflearn
import tempfile
import urllib

import numpy as np
import pandas as pd
import tensorflow as tf

# -----------------------------------------------------------------------------

COLUMNS = ["age", "workclass", "fnlwgt", "education", "education_num",
           "marital_status", "occupation", "relationship", "race", "gender",
           "capital_gain", "capital_loss", "hours_per_week", "native_country",
           "income_bracket"]
LABEL_COLUMN = "label"
CATEGORICAL_COLUMNS = {"workclass": 10, "education": 17, "marital_status": 8,
                       "occupation": 16, "relationship": 7, "race": 6,
                       "gender": 3, "native_country": 43, "age_binned": 14}
CONTINUOUS_COLUMNS = ["age", "education_num", "capital_gain", "capital_loss",
                      "hours_per_week"]


# -----------------------------------------------------------------------------

class TFLearnWideAndDeep(object):
    '''
    Wide and deep model, implemented using TFLearn
    '''
    AVAILABLE_MODELS = ["wide", "deep", "wide+deep"]

    def __init__(self, model_type="wide+deep", verbose=None, name=None, tensorboard_verbose=3,
                 wide_learning_rate=0.001, deep_learning_rate=0.001, checkpoints_dir=None):
        '''
        model_type = `str`: wide or deep or wide+deep
        verbose = `bool`
        name = `str` used for run_id (defaults to model_type)
        tensorboard_verbose = `int`: logging level for tensorboard (0, 1, 2, or 3)
        wide_learning_rate = `float`: defaults to 0.001
        deep_learning_rate = `float`: defaults to 0.001
        checkpoints_dir = `str`: where checkpoint files will be stored (defaults to "CHECKPOINTS")
        '''
        self.model_type = model_type or "wide+deep"
        assert self.model_type in self.AVAILABLE_MODELS
        self.verbose = verbose or 0
        self.tensorboard_verbose = tensorboard_verbose
        self.name = name or self.model_type  # name is used for the run_id
        self.data_columns = COLUMNS
        self.continuous_columns = CONTINUOUS_COLUMNS
        self.categorical_columns = CATEGORICAL_COLUMNS  # dict with category_name: category_size
        self.label_column = LABEL_COLUMN
        self.checkpoints_dir = checkpoints_dir or "CHECKPOINTS"
        if not os.path.exists(self.checkpoints_dir):
            os.mkdir(self.checkpoints_dir)
            print("Created checkpoints directory %s" % self.checkpoints_dir)
        self.build_model([wide_learning_rate, deep_learning_rate])

    def load_data(self, train_dfn="adult_train.csv", test_dfn="adult_test.csv"):
        '''
        Load data (use files offered in the Tensorflow wide_n_deep_tutorial)
        '''

        # if not os.path.exists(train_dfn):
        #     urllib.urlretrieve("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data", train_dfn)
        #     print("Training data is downloaded to %s" % train_dfn)
        #
        # if not os.path.exists(test_dfn):
        #     urllib.urlretrieve("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test", test_dfn)
        #     print("Test data is downloaded to %s" % test_dfn)

        self.train_data = pd.read_csv(train_dfn, names=COLUMNS, skipinitialspace=True)
        self.test_data = pd.read_csv(test_dfn, names=COLUMNS, skipinitialspace=True, skiprows=1)

        self.train_data[self.label_column] = (self.train_data["income_bracket"].apply(lambda x: ">50K" in x)).astype(
            int)
        self.test_data[self.label_column] = (self.test_data["income_bracket"].apply(lambda x: ">50K" in x)).astype(int)

    def build_model(self, learning_rate=[0.001, 0.01]):
        '''
        Model - wide and deep - built using tflearn
        '''
        n_cc = len(self.continuous_columns)
        n_categories = 1  # two categories: is_idv and is_not_idv
        input_shape = [None, n_cc]
        if self.verbose:
            print("=" * 77 + " Model %s (type=%s)" % (self.name, self.model_type))
            print("  Input placeholder shape=%s" % str(input_shape))
        wide_inputs = tflearn.input_data(shape=input_shape, name="wide_X")
        if not isinstance(learning_rate, list):
            learning_rate = [learning_rate, learning_rate]  # wide, deep
        if self.verbose:
            print("  Learning rates (wide, deep)=%s" % learning_rate)

        with tf.name_scope("Y"):  # placeholder for target variable (i.e. trainY input)
            Y_in = tf.placeholder(shape=[None, 1], dtype=tf.float32, name="Y")

        with tf.variable_op_scope([wide_inputs], None, "cb_unit", reuse=False) as scope:
            central_bias = tflearn.variables.variable('central_bias', shape=[1],
                                                      initializer=tf.constant_initializer(np.random.randn()),
                                                      trainable=True, restore=True)
            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + '/cb_unit', central_bias)

        if 'wide' in self.model_type:
            wide_network = self.wide_model(wide_inputs, n_cc)
            network = wide_network
            wide_network_with_bias = tf.add(wide_network, central_bias, name="wide_with_bias")

        if 'deep' in self.model_type:
            deep_network = self.deep_model(wide_inputs, n_cc)
            deep_network_with_bias = tf.add(deep_network, central_bias, name="deep_with_bias")
            if 'wide' in self.model_type:
                network = tf.add(wide_network, deep_network)
                if self.verbose:
                    print("Wide + deep model network %s" % network)
            else:
                network = deep_network

        network = tf.add(network, central_bias, name="add_central_bias")

        # add validation monitor summaries giving confusion matrix entries
        with tf.name_scope('Monitors'):
            predictions = tf.cast(tf.greater(network, 0), tf.int64)
            print("predictions=%s" % predictions)
            Ybool = tf.cast(Y_in, tf.bool)
            print("Ybool=%s" % Ybool)
            pos = tf.boolean_mask(predictions, Ybool)
            neg = tf.boolean_mask(predictions, ~Ybool)
            psize = tf.cast(tf.shape(pos)[0], tf.int64)
            nsize = tf.cast(tf.shape(neg)[0], tf.int64)
            true_positive = tf.reduce_sum(pos, name="true_positive")
            false_negative = tf.subtract(psize, true_positive, name="false_negative")  # sub
            false_positive = tf.reduce_sum(neg, name="false_positive")
            true_negative = tf.subtract(nsize, false_positive, name="true_negative")  # sub
            overall_accuracy = tf.truediv(tf.add(true_positive, true_negative), tf.add(nsize, psize),
                                          name="overall_accuracy")
        vmset = [true_positive, true_negative, false_positive, false_negative, overall_accuracy]

        trainable_vars = tf.trainable_variables()
        tv_deep = [v for v in trainable_vars if v.name.startswith('deep_')]
        tv_wide = [v for v in trainable_vars if v.name.startswith('wide_')]

        if self.verbose:
            print("DEEP trainable_vars")
            for v in tv_deep:
                print("  Variable %s: %s" % (v.name, v))
            print("WIDE trainable_vars")
            for v in tv_wide:
                print("  Variable %s: %s" % (v.name, v))

        if 'wide' in self.model_type:
            if not 'deep' in self.model_type:
                tv_wide.append(central_bias)
            tflearn.regression(wide_network_with_bias,
                               placeholder=Y_in,
                               optimizer='sgd',
                               # loss='roc_auc_score',
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[0],
                               validation_monitors=vmset,
                               trainable_vars=tv_wide,
                               op_name="wide_regression",
                               name="Y")

        if 'deep' in self.model_type:
            if not 'wide' in self.model_type:
                tv_wide.append(central_bias)
            tflearn.regression(deep_network_with_bias,
                               placeholder=Y_in,
                               optimizer='adam',
                               # loss='roc_auc_score',
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[1],
                               validation_monitors=vmset if not 'wide' in self.model_type else None,
                               trainable_vars=tv_deep,
                               op_name="deep_regression",
                               name="Y")

        if self.model_type == 'wide+deep':  # learn central bias separately for wide+deep
            tflearn.regression(network,
                               placeholder=Y_in,
                               optimizer='adam',
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[0],  # use wide learning rate
                               trainable_vars=[central_bias],
                               op_name="central_bias_regression",
                               name="Y")

        self.model = tflearn.DNN(network,
                                 tensorboard_verbose=self.tensorboard_verbose,
                                 max_checkpoints=5,
                                 checkpoint_path="%s/%s.tfl" % (self.checkpoints_dir, self.name),
                                 )

        if self.verbose:
            print("Target variables:")
            for v in tf.get_collection(tf.GraphKeys.TARGETS):
                print("  variable %s: %s" % (v.name, v))

            print("=" * 77)

    def deep_model(self, wide_inputs, n_inputs, n_nodes=[100, 50], use_dropout=False):
        '''
        Model - deep, i.e. two-layer fully connected network model
        '''
        cc_input_var = {}
        cc_embed_var = {}
        flat_vars = []
        if self.verbose:
            print("--> deep model: %s categories, %d continuous" % (len(self.categorical_columns), n_inputs))
        for cc, cc_size in self.categorical_columns.items():
            cc_input_var[cc] = tflearn.input_data(shape=[None, 1], name="%s_in" % cc, dtype=tf.int32)
            # embedding layers only work on CPU!  No GPU implementation in tensorflow, yet!
            cc_embed_var[cc] = tflearn.layers.embedding_ops.embedding(cc_input_var[cc], cc_size, 8,
                                                                      name="deep_%s_embed" % cc)
            if self.verbose:
                print("    %s_embed = %s" % (cc, cc_embed_var[cc]))
            flat_vars.append(tf.squeeze(cc_embed_var[cc], squeeze_dims=[1], name="%s_squeeze" % cc))

        network = tf.concat(1, [wide_inputs] + flat_vars, name="deep_concat")
        for k in range(len(n_nodes)):
            network = tflearn.fully_connected(network, n_nodes[k], activation="relu", name="deep_fc%d" % (k + 1))
            if use_dropout:
                network = tflearn.dropout(network, 0.5, name="deep_dropout%d" % (k + 1))
        if self.verbose:
            print("Deep model network before output %s" % network)
        network = tflearn.fully_connected(network, 1, activation="linear", name="deep_fc_output", bias=False)
        network = tf.reshape(network, [-1, 1])  # so that accuracy is binary_accuracy
        if self.verbose:
            print("Deep model network %s" % network)
        return network

    def wide_model(self, inputs, n_inputs):
        '''
        Model - wide, i.e. normal linear model (for logistic regression)
        '''
        network = inputs
        # use fully_connected (instad of single_unit) because fc works properly with batches, whereas single_unit is 1D only
        network = tflearn.fully_connected(network, n_inputs, activation="linear", name="wide_linear",
                                          bias=False)  # x*W (no bias)
        network = tf.reduce_sum(network, 1, name="reduce_sum")  # batched sum, to produce logits
        network = tf.reshape(network, [-1, 1])  # so that accuracy is binary_accuracy
        if self.verbose:
            print("Wide model network %s" % network)
        return network

    def prepare_input_data(self, input_data, name="", category_map=None):
        '''
        Prepare input data dicts
        '''
        print("-" * 40 + " Preparing %s" % name)
        X = input_data[self.continuous_columns].values.astype(np.float32)
        Y = input_data[self.label_column].values.astype(np.float32)
        Y = Y.reshape([-1, 1])
        if self.verbose:
            print("  Y shape=%s, X shape=%s" % (Y.shape, X.shape))

        X_dict = {"wide_X": X}

        if 'deep' in self.model_type:
            # map categorical value strings to integers
            td = input_data
            if category_map is None:
                category_map = {}
                for cc in self.categorical_columns:
                    if not cc in td.columns:
                        continue
                    cc_values = sorted(td[cc].unique())
                    cc_max = 1 + len(cc_values)
                    cc_map = dict(
                        zip(cc_values, range(1, cc_max)))  # start from 1 to avoid 0:0 mapping (save 0 for missing)
                    if self.verbose:
                        print("  category %s max=%s,  map=%s" % (cc, cc_max, cc_map))
                    category_map[cc] = cc_map

            td = td.replace(category_map)

            # bin ages (cuts off extreme values)
            age_bins = [0, 12, 18, 25, 30, 35, 40, 45, 50, 55, 60, 65, 80, 65535]
            td['age_binned'] = pd.cut(td['age'], age_bins, labels=False)
            td = td.replace({'age_binned': {np.nan: 0}})
            print("  %d age bins: age bins = %s" % (len(age_bins), age_bins))

            X_dict.update(
                {("%s_in" % cc): td[cc].values.astype(np.int32).reshape([-1, 1]) for cc in self.categorical_columns})

        Y_dict = {"Y": Y}
        if self.verbose:
            print("-" * 40)
        return X_dict, Y_dict, category_map

    def train(self, n_epoch=1000, snapshot_step=10, batch_size=None):

        self.X_dict, self.Y_dict, category_map = self.prepare_input_data(self.train_data, "train data")
        self.testX_dict, self.testY_dict, _ = self.prepare_input_data(self.test_data, "test data", category_map)
        validation_batch_size = batch_size or self.testY_dict['Y'].shape[0]
        batch_size = batch_size or self.Y_dict['Y'].shape[0]

        print("Input data shape = %s; output data shape=%s, batch_size=%s" % (str(self.X_dict['wide_X'].shape),
                                                                              str(self.Y_dict['Y'].shape),
                                                                              batch_size))
        print("Test data shape = %s; output data shape=%s, validation_batch_size=%s" % (
            str(self.testX_dict['wide_X'].shape),
            str(self.testY_dict['Y'].shape),
            validation_batch_size))
        print("=" * 60 + "  Training")
        self.model.fit(self.X_dict,
                       self.Y_dict,
                       n_epoch=n_epoch,
                       validation_set=(self.testX_dict, self.testY_dict),
                       snapshot_step=snapshot_step,
                       batch_size=batch_size,
                       validation_batch_size=validation_batch_size,
                       show_metric=True,
                       snapshot_epoch=False,
                       shuffle=True,
                       run_id=self.name,
                       )

    def evaluate(self):
        logits = np.array(self.model.predict(self.testX_dict)).reshape([-1])
        print("=" * 60 + "  Evaluation")
        print("  logits: %s, min=%s, max=%s" % (logits.shape, logits.min(), logits.max()))
        probs = 1.0 / (1.0 + np.exp(-logits))
        y_pred = pd.Series((probs > 0.5).astype(np.int32))
        Y = pd.Series(self.testY_dict['Y'].astype(np.int32).reshape([-1]))
        self.confusion_matrix = self.output_confusion_matrix(Y, y_pred)
        print("=" * 60)

    def output_confusion_matrix(self, y, y_pred):
        assert y.size == y_pred.size
        print("Actual IDV")
        print(y.value_counts())
        print("Predicted IDV")
        print(y_pred.value_counts())
        print()
        print("Confusion matrix:")
        cmat = pd.crosstab(y_pred, y, rownames=['predictions'], colnames=['actual'])
        print(cmat)
        sys.stdout.flush()
        return cmat


# -----------------------------------------------------------------------------

def CommandLine(args=None):
    '''
    Main command line.  Accepts args, to allow for simple unit testing.
    '''
    flags = tf.app.flags
    FLAGS = flags.FLAGS
    if args:
        FLAGS.__init__()
        FLAGS.__dict__.update(args)

    try:
        flags.DEFINE_string("model_type", "wide+deep", "Valid model types: {'wide', 'deep', 'wide+deep'}.")
        flags.DEFINE_string("run_name", None, "name for this run (defaults to model type)")
        flags.DEFINE_string("load_weights", None, "filename with initial weights to load")
        flags.DEFINE_string("checkpoints_dir", None, "name of directory where checkpoints should be saved")
        flags.DEFINE_integer("n_epoch", 200, "Number of training epoch steps")
        flags.DEFINE_integer("snapshot_step", 100, "Step number when snapshot (and validation testing) is done")
        flags.DEFINE_float("wide_learning_rate", 0.001, "learning rate for the wide part of the model")
        flags.DEFINE_float("deep_learning_rate", 0.001, "learning rate for the deep part of the model")
        flags.DEFINE_boolean("verbose", False, "Verbose output")
    except argparse.ArgumentError:
        pass  # so that CommandLine can be run more than once, for testing

    twad = TFLearnWideAndDeep(model_type=FLAGS.model_type, verbose=FLAGS.verbose,
                              name=FLAGS.run_name, wide_learning_rate=FLAGS.wide_learning_rate,
                              deep_learning_rate=FLAGS.deep_learning_rate,
                              checkpoints_dir=FLAGS.checkpoints_dir)
    twad.load_data()
    if FLAGS.load_weights:
        print("Loading initial weights from %s" % FLAGS.load_weights)
        twad.model.load(FLAGS.load_weights)
    twad.train(n_epoch=FLAGS.n_epoch, snapshot_step=FLAGS.snapshot_step)
    twad.evaluate()
    return twad


# -----------------------------------------------------------------------------
# unit tests

def test_wide_and_deep():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="wide+deep", snapshot_step=5,
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print("cfiles=%s" % cfiles)
    assert (len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert (cm[1][1])


def test_deep():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="deep", snapshot_step=5,
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print("cfiles=%s" % cfiles)
    assert (len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert (cm[1][1])


def test_wide():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="wide", snapshot_step=5,
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print("cfiles=%s" % cfiles)
    assert (len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert (cm[1][1])


# -----------------------------------------------------------------------------
if __name__ == "__main__":
    CommandLine()
    None

    # ------ debug
    twad = TFLearnWideAndDeep(model_type="wide", verbose=True,
                              # name=FLAGS.run_name,
                              wide_learning_rate=0.00001,
                              deep_learning_rate=0.0001
                              # checkpoints_dir=FLAGS.checkpoints_dir
                              )
    twad.load_data()
    twad.train(n_epoch=20, snapshot_step=20)
    twad.evaluate()
from django.shortcuts import render, redirect , get_object_or_404
from django.contrib.auth.decorators import login_required
from .models import DeepLearning
from django.utils import timezone

# Create your views here.

@login_required(login_url = "accounts/signup")
def dl_create(request):
    if request.method == 'POST':
        if request.POST['title'] and request.POST['body'] and request.POST['url'] and request.POST['code'] and request.FILES['output']:
            project = DeepLearning()
            project.title = request.POST['title']
            project.body = request.POST['body']
            if request.POST['url'].startswith("http://") or request.POST['url'].startswith("https://"):
                project.url = request.POST['url']
            else:
                project.url = "http://" + request.POST['url']
            project.code = request.POST['code']
            project.output = request.FILES['output']
            project.post_date = timezone.datetime.now()
            project.site_user = request.user
            project.save()
            return redirect('/deep_learning/' + str(project.id))
        else:
            return render(request , 'deep_learning/create.html',{'error':'All fields are required.'})
    else:
        return render(request , 'deep_learning/create.html')


def detail2(request , deep_learning_id):
    project = get_object_or_404(DeepLearning , pk = deep_learning_id)
    return render(request,'deep_learning/detail.html', {'project2':project})

def deeplearning(request):
    projects = DeepLearning.objects
    return render(request , 'deep_learning/deep_learning.html', {'projects2':projects})
from Learning.Autoencoder.autoencoder_deep import DeepAutoEncoder
from Learning.CNN.cnn_default import CNNDefault
from Learning.CNN.cnn_edges import CNNEdges
from Learning.CNN.cnn_res import CNNRes
from Learning.CNN.cnn_wide import CNNWide
from Learning.CNN.cnn_4_channels import CNN4Channels
from Learning.CNN.cnn_edges_deep_3 import CNNEdgesDeep3
from Learning.CNN.cnn_default_deep_3 import CNNDefaultDeep3
from enum import Enum
from Learning.PCA_SVM import pca_svm, pca_svm_edges
from Learning.Autoencoder.autoencoder_simple import SimpleAutoEncoder
from Learning.Autoencoder.classifier_deep import ClassifierDeepAutoEncoder
from Learning.Autoencoder.visualization_simple import VisualisationSimpleAutoEncoder
from Learning.Autoencoder.classifier_simple import ClassifierSimpleAutoEncoder


class WhatToRun(Enum):
    cnn_default = CNNDefault
    cnn_edges = CNNEdges
    cnn_4_channels = CNN4Channels
    cnn_wide = CNNWide
    cnn_edges_deep_3 = CNNEdgesDeep3
    cnn_default_deep_3 = CNNDefaultDeep3
    pca_svm = pca_svm.PCA_SVM
    pca_svm_edges = pca_svm_edges
    simple_autoencoder = SimpleAutoEncoder
    deep_autoencoder = DeepAutoEncoder
    visualisation_simple_autoencoder = VisualisationSimpleAutoEncoder
    simple_autoencoder_classifier = ClassifierSimpleAutoEncoder
    deep_autoencoder_classifier = ClassifierDeepAutoEncoder
    cnn_res = CNNRes

    def __init__(self, val):
        self.val = val

    def __call__(self, *args, **kwargs):
        return self.val(*args, **kwargs)
from __future__ import division, print_function

import os
import sys
import argparse
import tflearn
import tempfile
import urllib

import numpy as np
import pandas as pd
import tensorflow as tf

#-----------------------------------------------------------------------------

COLUMNS = ["service_type","is_mix_service","online_time","1_total_fee","2_total_fee",
           "3_total_fee","4_total_fee","month_traffic","many_over_bill","contract_type",
           "contract_time","is_promise_low_consume","net_service","pay_times","pay_num",
           "last_month_traffic","local_trafffic_month","local_caller_time","service1_caller_time",
           "service2_caller_time","gender","age","complaint_level","former_complaint_num",
           "former_complaint_fee","current_service","user_id"]

LABEL_COLUMN = "label"
CATEGORICAL_COLUMNS = {"service_type":3, "is_mix_service":2,
                       "many_over_bill":2,"contract_type":9,
                       "is_promise_low_consume":2,"net_service":4,
                       "gender":3, "complaint_level":4}

CONTINUOUS_COLUMNS = ["online_time","1_total_fee","2_total_fee","3_total_fee","4_total_fee","month_traffic",
                      "contract_time","pay_times","pay_num","last_month_traffic","local_trafffic_month",
                      "local_caller_time","service1_caller_time","service2_caller_time","former_complaint_num","former_complaint_fee"]

#-----------------------------------------------------------------------------

class TFLearnWideAndDeep(object):
    '''
    Wide and deep model, implemented using TFLearn
    '''
    AVAILABLE_MODELS = ["wide", "deep", "wide+deep"]
    def __init__(self, model_type="wide+deep", verbose=None, name=None, tensorboard_verbose=3,
                 wide_learning_rate=0.001, deep_learning_rate=0.001, checkpoints_dir=None):
        '''
        model_type = `str`: wide or deep or wide+deep
        verbose = `bool`
        name = `str` used for run_id (defaults to model_type)
        tensorboard_verbose = `int`: logging level for tensorboard (0, 1, 2, or 3)
        wide_learning_rate = `float`: defaults to 0.001
        deep_learning_rate = `float`: defaults to 0.001
        checkpoints_dir = `str`: where checkpoint files will be stored (defaults to "CHECKPOINTS")
        '''
        self.model_type = model_type or "wide+deep"
        assert self.model_type in self.AVAILABLE_MODELS
        self.verbose = verbose or 0
        self.tensorboard_verbose = tensorboard_verbose
        self.name = name or self.model_type	# name is used for the run_id
        self.data_columns = COLUMNS
        self.continuous_columns = CONTINUOUS_COLUMNS
        self.categorical_columns = CATEGORICAL_COLUMNS	# dict with category_name: category_size
        self.label_column = LABEL_COLUMN
        self.checkpoints_dir = checkpoints_dir or "CHECKPOINTS"
        if not os.path.exists(self.checkpoints_dir):
            os.mkdir(self.checkpoints_dir)
            print("Created checkpoints directory %s" % self.checkpoints_dir)
        self.build_model([wide_learning_rate, deep_learning_rate])

    def load_data(self, train_dfn="adult.data", test_dfn="adult.test"):
        '''
        Load data (use files offered in the Tensorflow wide_n_deep_tutorial)
        '''
        self.train_data = pd.read_csv(train_dfn, names=COLUMNS, skipinitialspace=True)
        self.test_data = pd.read_csv(test_dfn, names=COLUMNS, skipinitialspace=True, skiprows=1)

        self.train_data[self.label_column] = (self.train_data["current_service"].apply(lambda x: ">50K" in x)).astype(int)
        self.test_data[self.label_column] = (self.test_data["current_service"].apply(lambda x: ">50K" in x)).astype(int)


    def build_model(self, learning_rate=[0.001, 0.01]):
        '''
        Model - wide and deep - built using tflearn
        '''
        n_cc = len(self.continuous_columns)
        n_categories = 1			# two categories: is_idv and is_not_idv
        input_shape = [None, n_cc]
        if self.verbose:
            print ("="*77 + " Model %s (type=%s)" % (self.name, self.model_type))
            print ("  Input placeholder shape=%s" % str(input_shape))
        wide_inputs = tflearn.input_data(shape=input_shape, name="wide_X")
        if not isinstance(learning_rate, list):
            learning_rate = [learning_rate, learning_rate]	# wide, deep
        if self.verbose:
            print ("  Learning rates (wide, deep)=%s" % learning_rate)

        with tf.name_scope("Y"):			# placeholder for target variable (i.e. trainY input)
            Y_in = tf.placeholder(shape=[None, 1], dtype=tf.float32, name="Y")

        with tf.variable_op_scope([wide_inputs], None, "cb_unit", reuse=False) as scope:
            central_bias = tflearn.variables.variable('central_bias', shape=[1],
                                                      initializer=tf.constant_initializer(np.random.randn()),
                                                      trainable=True, restore=True)
            tf.add_to_collection(tf.GraphKeys.LAYER_VARIABLES + '/cb_unit', central_bias)

        if 'wide' in self.model_type:
            wide_network = self.wide_model(wide_inputs, n_cc)
            network = wide_network
            wide_network_with_bias = tf.add(wide_network, central_bias, name="wide_with_bias")

        if 'deep' in self.model_type:
            deep_network = self.deep_model(wide_inputs, n_cc)
            deep_network_with_bias = tf.add(deep_network, central_bias, name="deep_with_bias")
            if 'wide' in self.model_type:
                network = tf.add(wide_network, deep_network)
                if self.verbose:
                    print ("Wide + deep model network %s" % network)
            else:
                network = deep_network

        network = tf.add(network, central_bias, name="add_central_bias")

        # add validation monitor summaries giving confusion matrix entries
        with tf.name_scope('Monitors'):
            predictions = tf.cast(tf.greater(network, 0), tf.int64)
            print ("predictions=%s" % predictions)
            Ybool = tf.cast(Y_in, tf.bool)
            print ("Ybool=%s" % Ybool)
            pos = tf.boolean_mask(predictions, Ybool)
            neg = tf.boolean_mask(predictions, ~Ybool)
            psize = tf.cast(tf.shape(pos)[0], tf.int64)
            nsize = tf.cast(tf.shape(neg)[0], tf.int64)
            true_positive = tf.reduce_sum(pos, name="true_positive")
            false_negative = tf.sub(psize, true_positive, name="false_negative")
            false_positive = tf.reduce_sum(neg, name="false_positive")
            true_negative = tf.sub(nsize, false_positive, name="true_negative")
            overall_accuracy = tf.truediv(tf.add(true_positive, true_negative), tf.add(nsize, psize), name="overall_accuracy")
        vmset = [true_positive, true_negative, false_positive, false_negative, overall_accuracy]

        trainable_vars = tf.trainable_variables()
        tv_deep = [v for v in trainable_vars if v.name.startswith('deep_')]
        tv_wide = [v for v in trainable_vars if v.name.startswith('wide_')]

        if self.verbose:
            print ("DEEP trainable_vars")
            for v in tv_deep:
                print ("  Variable %s: %s" % (v.name, v))
            print ("WIDE trainable_vars")
            for v in tv_wide:
                print ("  Variable %s: %s" % (v.name, v))

        if 'wide' in self.model_type:
            if not 'deep' in self.model_type:
                tv_wide.append(central_bias)
            tflearn.regression(wide_network_with_bias,
                               placeholder=Y_in,
                               optimizer='sgd',
                               #loss='roc_auc_score',
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[0],
                               validation_monitors=vmset,
                               trainable_vars=tv_wide,
                               op_name="wide_regression",
                               name="Y")

        if 'deep' in self.model_type:
            if not 'wide' in self.model_type:
                tv_wide.append(central_bias)
            tflearn.regression(deep_network_with_bias,
                               placeholder=Y_in,
                               optimizer='adam',
                               #loss='roc_auc_score',
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[1],
                               validation_monitors=vmset if not 'wide' in self.model_type else None,
                               trainable_vars=tv_deep,
                               op_name="deep_regression",
                               name="Y")

        if self.model_type=='wide+deep':	# learn central bias separately for wide+deep
            tflearn.regression(network,
                               placeholder=Y_in,
                               optimizer='adam',
                               loss='binary_crossentropy',
                               metric="accuracy",
                               learning_rate=learning_rate[0],	# use wide learning rate
                               trainable_vars=[central_bias],
                               op_name="central_bias_regression",
                               name="Y")

        self.model = tflearn.DNN(network,
                                 tensorboard_verbose=self.tensorboard_verbose,
                                 max_checkpoints=5,
                                 checkpoint_path="%s/%s.tfl" % (self.checkpoints_dir, self.name),
                                 )

        if self.verbose:
            print ("Target variables:")
            for v in tf.get_collection(tf.GraphKeys.TARGETS):
                print ("  variable %s: %s" % (v.name, v))

            print ("="*77)


    def deep_model(self, wide_inputs, n_inputs, n_nodes=[100, 50], use_dropout=False):
        '''
        Model - deep, i.e. two-layer fully connected network model
        '''
        cc_input_var = {}
        cc_embed_var = {}
        flat_vars = []
        if self.verbose:
            print ("--> deep model: %s categories, %d continuous" % (len(self.categorical_columns), n_inputs))
        for cc, cc_size in self.categorical_columns.items():
            cc_input_var[cc] = tflearn.input_data(shape=[None, 1], name="%s_in" % cc,  dtype=tf.int32)
            # embedding layers only work on CPU!  No GPU implementation in tensorflow, yet!
            cc_embed_var[cc] = tflearn.layers.embedding_ops.embedding(cc_input_var[cc],    cc_size,  8, name="deep_%s_embed" % cc)
            if self.verbose:
                print ("    %s_embed = %s" % (cc, cc_embed_var[cc]))
            flat_vars.append(tf.squeeze(cc_embed_var[cc], squeeze_dims=[1], name="%s_squeeze" % cc))

        network = tf.concat(1, [wide_inputs] + flat_vars, name="deep_concat")
        for k in range(len(n_nodes)):
            network = tflearn.fully_connected(network, n_nodes[k], activation="relu", name="deep_fc%d" % (k+1))
            if use_dropout:
                network = tflearn.dropout(network, 0.5, name="deep_dropout%d" % (k+1))
        if self.verbose:
            print ("Deep model network before output %s" % network)
        network = tflearn.fully_connected(network, 1, activation="linear", name="deep_fc_output", bias=False)
        network = tf.reshape(network, [-1, 1])	# so that accuracy is binary_accuracy
        if self.verbose:
            print ("Deep model network %s" % network)
        return network

    def wide_model(self, inputs, n_inputs):
        '''
        Model - wide, i.e. normal linear model (for logistic regression)
        '''
        network = inputs
        # use fully_connected (instad of single_unit) because fc works properly with batches, whereas single_unit is 1D only
        network = tflearn.fully_connected(network, n_inputs, activation="linear", name="wide_linear", bias=False)	# x*W (no bias)
        network = tf.reduce_sum(network, 1, name="reduce_sum")	# batched sum, to produce logits
        network = tf.reshape(network, [-1, 1])	# so that accuracy is binary_accuracy
        if self.verbose:
            print ("Wide model network %s" % network)
        return network

    def prepare_input_data(self, input_data, name="", category_map=None):
        '''
        Prepare input data dicts
        '''
        print ("-"*40 + " Preparing %s" % name)
        X = input_data[self.continuous_columns].values.astype(np.float32)
        Y = input_data[self.label_column].values.astype(np.float32)
        Y = Y.reshape([-1, 1])
        if self.verbose:
            print ("  Y shape=%s, X shape=%s" % (Y.shape, X.shape))

        X_dict = {"wide_X": X}

        if 'deep' in self.model_type:
            # map categorical value strings to integers
            td = input_data
            if category_map is None:
                category_map = {}
                for cc in self.categorical_columns:
                    if not cc in td.columns:
                        continue
                    cc_values = sorted(td[cc].unique())
                    cc_max = 1+len(cc_values)
                    cc_map = dict(zip(cc_values, range(1, cc_max)))	# start from 1 to avoid 0:0 mapping (save 0 for missing)
                    if self.verbose:
                        print ("  category %s max=%s,  map=%s" % (cc, cc_max, cc_map))
                    category_map[cc] = cc_map

            td = td.replace(category_map)

            # bin ages (cuts off extreme values)
            age_bins = [ 0, 12, 18, 25, 30, 35, 40, 45, 50, 55, 60, 65, 80, 65535 ]
            td['age_binned'] = pd.cut(td['age'], age_bins, labels=False)
            td = td.replace({'age_binned': {np.nan: 0}})
            print ("  %d age bins: age bins = %s" % (len(age_bins), age_bins))

            X_dict.update({ ("%s_in" % cc): td[cc].values.astype(np.int32).reshape([-1, 1]) for cc in self.categorical_columns})

        Y_dict = {"Y": Y}
        if self.verbose:
            print ("-"*40)
        return X_dict, Y_dict, category_map


    def train(self, n_epoch=1000, snapshot_step=10, batch_size=None):

        self.X_dict, self.Y_dict, category_map = self.prepare_input_data(self.train_data, "train data")
        self.testX_dict, self.testY_dict, _ = self.prepare_input_data(self.test_data, "test data", category_map)
        validation_batch_size = batch_size or self.testY_dict['Y'].shape[0]
        batch_size = batch_size or self.Y_dict['Y'].shape[0]

        print ("Input data shape = %s; output data shape=%s, batch_size=%s" % (str(self.X_dict['wide_X'].shape),
                                                                               str(self.Y_dict['Y'].shape),
                                                                               batch_size))
        print ("Test data shape = %s; output data shape=%s, validation_batch_size=%s" % (str(self.testX_dict['wide_X'].shape),
                                                                                         str(self.testY_dict['Y'].shape),
                                                                                         validation_batch_size))
        print ("="*60 + "  Training")
        self.model.fit(self.X_dict,
                       self.Y_dict,
                       n_epoch=n_epoch,
                       validation_set=(self.testX_dict, self.testY_dict),
                       snapshot_step=snapshot_step,
                       batch_size=batch_size,
                       validation_batch_size=validation_batch_size,
                       show_metric=True,
                       snapshot_epoch=False,
                       shuffle=True,
                       run_id=self.name,
                       )

    def evaluate(self):
        logits = np.array(self.model.predict(self.testX_dict)).reshape([-1])
        print ("="*60 + "  Evaluation")
        print ("  logits: %s, min=%s, max=%s" % (logits.shape, logits.min(), logits.max()))
        probs =  1.0 / (1.0 + np.exp(-logits))
        y_pred = pd.Series((probs > 0.5).astype(np.int32))
        Y = pd.Series(self.testY_dict['Y'].astype(np.int32).reshape([-1]))
        self.confusion_matrix = self.output_confusion_matrix(Y, y_pred)
        print ("="*60)

    def output_confusion_matrix(self, y, y_pred):
        assert y.size == y_pred.size
        print("Actual IDV")
        print(y.value_counts())
        print("Predicted IDV")
        print(y_pred.value_counts())
        print()
        print("Confusion matrix:")
        cmat = pd.crosstab(y_pred, y, rownames=['predictions'], colnames=['actual'])
        print(cmat)
        sys.stdout.flush()
        return cmat

#-----------------------------------------------------------------------------

def CommandLine(args=None):
    '''
    Main command line.  Accepts args, to allow for simple unit testing.
    '''
    flags = tf.app.flags
    FLAGS = flags.FLAGS
    if args:
        FLAGS.__init__()
        FLAGS.__dict__.update(args)

    try:
        flags.DEFINE_string("model_type", "wide+deep","Valid model types: {'wide', 'deep', 'wide+deep'}.")
        flags.DEFINE_string("run_name", None, "name for this run (defaults to model type)")
        flags.DEFINE_string("load_weights", None, "filename with initial weights to load")
        flags.DEFINE_string("checkpoints_dir", None, "name of directory where checkpoints should be saved")
        flags.DEFINE_integer("n_epoch", 200, "Number of training epoch steps")
        flags.DEFINE_integer("snapshot_step", 100, "Step number when snapshot (and validation testing) is done")
        flags.DEFINE_float("wide_learning_rate", 0.001, "learning rate for the wide part of the model")
        flags.DEFINE_float("deep_learning_rate", 0.001, "learning rate for the deep part of the model")
        flags.DEFINE_boolean("verbose", False, "Verbose output")
    except argparse.ArgumentError:
        pass	# so that CommandLine can be run more than once, for testing

    twad = TFLearnWideAndDeep(model_type=FLAGS.model_type, verbose=FLAGS.verbose,
                              name=FLAGS.run_name, wide_learning_rate=FLAGS.wide_learning_rate,
                              deep_learning_rate=FLAGS.deep_learning_rate,
                              checkpoints_dir=FLAGS.checkpoints_dir)
    twad.load_data()
    if FLAGS.load_weights:
        print ("Loading initial weights from %s" % FLAGS.load_weights)
        twad.model.load(FLAGS.load_weights)
    twad.train(n_epoch=FLAGS.n_epoch, snapshot_step=FLAGS.snapshot_step)
    twad.evaluate()
    return twad

#-----------------------------------------------------------------------------
# unit tests

def test_wide_and_deep():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="wide+deep", snapshot_step=5,
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print ("cfiles=%s" % cfiles)
    assert(len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert(cm[1][1])

def test_deep():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="deep", snapshot_step=5,
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print ("cfiles=%s" % cfiles)
    assert(len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert(cm[1][1])

def test_wide():
    import glob
    tf.reset_default_graph()
    cdir = "test_checkpoints"
    if os.path.exists(cdir):
        os.system("rm -rf %s" % cdir)
    twad = CommandLine(args=dict(verbose=True, n_epoch=5, model_type="wide", snapshot_step=5,
                                 wide_learning_rate=0.0001, checkpoints_dir=cdir))
    cfiles = glob.glob("%s/*.tfl-*" % cdir)
    print ("cfiles=%s" % cfiles)
    assert(len(cfiles))
    cm = twad.confusion_matrix.values.astype(np.float32)
    assert(cm[1][1])

#-----------------------------------------------------------------------------

if __name__=="__main__":
    CommandLine()#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Jan 22 22:10:37 2018

@author: lixiaodan
"""

import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
import numpy as np
from keras.utils import np_utils
import deep_learning_models
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
import time

wikidata = pd.read_csv('/Users/lixiaodan/Desktop/research/result_3rd_paper/wikipedia_project/dataset/wikipedia_with_all_features.csv')
#wikidata = pd.read_csv('/Users/lixiaodan/Desktop/wikipedia_project/dataset/wikipedia_without_network.csv')
#wikidata = pd.read_csv('/Users/lixiaodan/Desktop/wikipedia_project/dataset/wikipedia_without_hist_net.csv')
colnames = list(wikidata)
#print(colnames)

labels = wikidata["page_class"]
### good is possitive while bad is negative
for i in range(labels.shape[0]):
    if labels[i] == 'FA' or labels[i] == 'AC' or labels[i] == 'GA':
        labels.loc[i] = '1'
    elif labels[i] == 'BC' or labels[i] == 'ST' or labels[i] == 'SB':
        labels.loc[i] = '0'
    """
    if labels[i] == 'FA' or labels[i] == 'AC':
        labels.loc[i] = '0'
    elif labels[i] == 'GA' or labels[i] == 'BC':
        labels.loc[i] = '1'
    elif labels[i] == 'ST' or labels[i] == 'SB':
        labels.loc[i] = '2'
    """

labels = labels.convert_objects(convert_numeric=True)
onehotlabels = np_utils.to_categorical(labels)

### preprocess features
features = wikidata.iloc[:, 1:]
min_max_scaler = preprocessing.MinMaxScaler()
features_minmax = min_max_scaler.fit_transform(features)

### split data into training set and label set
X_train, X_test, y_train, y_test = train_test_split(features_minmax, onehotlabels, test_size=0.4, random_state=42)
#X_train, X_test, y_train, y_test = train_test_split(features_minmax, labels, test_size=0.4, random_state=42)

### adjust the dataset dimension
# reshape X to be [samples, time steps, features]
X_train_LSTM = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))
X_test_LSTM = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))

### input for CNN
X_train_CNN = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test_CNN = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

### create the deep learning models
epochs = 15
batch_size = 195 #195 best now #190 # 100 # 250
dropoutRate = 0.2
"""
epochs = 200
batch_size = 20
dropoutRate = 0.3
"""
y_test_re = np.argmax(y_test, axis=1)
accuracies = list()
precisions = list()
Fs = list()
TNRs = list()
recalls = list()

### Bidirectional LSTM 
#start_time0 = time.clock()
model0, hist0 = deep_learning_models.Bidirectional_LSTM(X_train_LSTM, y_train, X_test_LSTM, y_test, batch_size, epochs)
prediction0 = model0.predict(X_test_LSTM)
#end_time0 = time.clock()
#Bi_LSTM_performance = end_time0 - start_time0
prediction0_re = np.argmax(prediction0, axis=1)
Bidirectional_LSTM_accuracy, bi_precision, bi_recall, bi_TNR, bi_F = deep_learning_models.getAccuracy(prediction0, y_test)
keys = hist0.history.keys()
print(keys)
print("Precision for bidirectional LSTM")
print(Bidirectional_LSTM_accuracy)
print(bi_precision)
print(bi_recall)
print(bi_TNR)
print(bi_F)
accuracy_pair = list()
accuracy_pair.append("bidirectional LSTM")
accuracy_pair.append(Bidirectional_LSTM_accuracy)
accuracies.append(accuracy_pair)

#start_time1 = time.clock()
model1, hist1 = deep_learning_models.basic_LSTM(X_train_LSTM, y_train, X_test_LSTM, y_test, batch_size, epochs)
prediction1 = model1.predict(X_test_LSTM)
#end_time1 = time.clock()
#basic_LSTM_performance = end_time1 - start_time1
prediction1_re = np.argmax(prediction1, axis=1)
basic_LSTM_accuracy, LSTM_precision, LSTM_recall, LSTM_TNR, LSTM_F= deep_learning_models.getAccuracy(prediction1, y_test)
keys = hist1.history.keys()
print(keys)
print("Precision for basic LSTM")
print(basic_LSTM_accuracy)
print(LSTM_precision)
print(LSTM_recall)
print(LSTM_TNR)
print(LSTM_F)
accuracy_pair = list()
accuracy_pair.append("basic LSTM")
accuracy_pair.append(basic_LSTM_accuracy)
accuracies.append(accuracy_pair)

#deep_learning_models.plotRoc(prediction1_re, y_test_re)
#deep_learning_models.plotTrainingAccuracy(hist1)
#deep_learning_models.plotTrainingLoss(hist1)

## stacked LSTM with dropout
#start_time2 = time.clock()
model2, hist2 = deep_learning_models.LSTM_with_dropout(X_train_LSTM, y_train, X_test_LSTM, y_test, batch_size, epochs, dropoutRate)
prediction2 = model2.predict(X_test_LSTM)
#end_time2 = time.clock()
#LSTM_with_dropout_performance = end_time2 - start_time2
prediction2_re = np.argmax(prediction2, axis=1)
LSTM_with_dropout_accuracy, dropout_precision, dropout_recall, dropout_TNR, dropout_F = deep_learning_models.getAccuracy(prediction2, y_test)
print("Precision for LSTM with dropout")
print(LSTM_with_dropout_accuracy)
print(dropout_precision)
print(dropout_recall)
print(dropout_TNR)
print(dropout_F)
accuracy_pair = list()
accuracy_pair.append("LSTM with dropout")
accuracy_pair.append(LSTM_with_dropout_accuracy)
accuracies.append(accuracy_pair)

#deep_learning_models.plotRoc(prediction2_re, y_test_re)
#deep_learning_models.plotTrainingAccuracy(hist2)
#deep_learning_models.plotTrainingLoss(hist2)

## CNN LSTM
#start_time3 = time.clock()
model3, hist3 = deep_learning_models.CNN_LSTM(X_train_CNN, y_train, y_test, batch_size, epochs, dropoutRate)
prediction3 = model3.predict(X_test_CNN)
#end_time3 = time.clock()
#CNN_LSTM_performance = end_time3 - start_time3
prediction3_re = np.argmax(prediction3, axis=1)
CNN_LSTM_accuracy, CNN_LSTM_precision, CNN_LSTM_recall, CNN_LSTM_TNR, CNN_LSTM_F= deep_learning_models.getAccuracy(prediction3, y_test)
print("Precision for CNN LSTM")
print(CNN_LSTM_accuracy)
print(CNN_LSTM_precision)
print(CNN_LSTM_recall)
print(CNN_LSTM_TNR)
print(CNN_LSTM_F)
accuracy_pair = list()
accuracy_pair.append("CNN LSTM")
accuracy_pair.append(CNN_LSTM_accuracy)
accuracies.append(accuracy_pair)

#deep_learning_models.plotRoc(prediction3_re, y_test_re)
#deep_learning_models.plotTrainingAccuracy(hist3)
#deep_learning_models.plotTrainingLoss(hist3)

## CNN
#start_time4 = time.clock()
model4, hist4 = deep_learning_models.CNN(X_train_CNN, y_train, y_test, batch_size, epochs)
prediction4 = model4.predict(X_test_CNN)
#end_time4 = time.clock()
#CNN_performance = end_time4 - start_time4
prediction4_re = np.argmax(prediction4, axis=1)
CNN_accuracy, CNN_precision, CNN_recall, CNN_TNR, CNN_F = deep_learning_models.getAccuracy(prediction4, y_test)
print("Precision for CNN")
print(CNN_accuracy)
print(CNN_precision)
print(CNN_recall)
print(CNN_TNR)
print(CNN_F)
accuracy_pair = list()
accuracy_pair.append("CNN")
accuracy_pair.append(CNN_accuracy)
accuracies.append(accuracy_pair)

#deep_learning_models.plotRoc(prediction4_re, y_test_re)
#deep_learning_models.plotTrainingAccuracy(hist4)
#deep_learning_models.plotTrainingLoss(hist4)

## DNN
#start_time5 = time.clock()
model5, hist5 = deep_learning_models.DNN(X_train, y_train, batch_size, epochs, dropoutRate)
prediction5 = model5.predict(X_test)
#end_time5 = time.clock()
#DNN_performance = end_time5 - start_time5
prediction5_re = np.argmax(prediction5, axis=1)
DNN_accuracy, DNN_precision, DNN_recall, DNN_TNR, DNN_F = deep_learning_models.getAccuracy(prediction5, y_test)
print("precision for DNN")
print(DNN_accuracy)
print(DNN_precision)
print(DNN_recall)
print(DNN_TNR)
print(DNN_F)
accuracy_pair = list()
accuracy_pair.append("DNN")
accuracy_pair.append(DNN_accuracy)
accuracies.append(accuracy_pair)

#deep_learning_models.plotRoc(prediction5_re, y_test_re)
#deep_learning_models.plotTrainingAccuracy(hist5)
#deep_learning_models.plotTrainingLoss(hist5)

## stacked LSTM
#start_time6 = time.clock()
model6, hist6 = deep_learning_models.stacked_LSTM(X_train_LSTM, y_train, X_test_LSTM, y_test, batch_size, epochs)
prediction6 = model6.predict(X_test_LSTM)
#end_time6 = time.clock()
#stacked_LSTM_performance = end_time6 - start_time6 
prediction6_re = np.argmax(prediction6, axis=1)
stacked_LSTM_accuracy, stacked_LSTM_precision, stacked_LSTM_recall, stacked_LSTM_TNR, stacked_LSTM_F = deep_learning_models.getAccuracy(prediction6, y_test)
print("Precision for stacked LSTM")
print(stacked_LSTM_accuracy)
print(stacked_LSTM_precision)
print(stacked_LSTM_recall)
print(stacked_LSTM_TNR)
print(stacked_LSTM_F)
accuracy_pair = list()
accuracy_pair.append("stacked LSTM")
accuracy_pair.append(stacked_LSTM_accuracy)
accuracies.append(accuracy_pair)

#deep_learning_models.plotRoc(prediction6_re, y_test_re)
#deep_learning_models.plotTrainingAccuracy(hist6)
#deep_learning_models.plotTrainingLoss(hist6)
"""
print("Model accuracy")
plt.plot(hist0.history['acc'], marker = 'v', label = 'Bidirectional LSTM', markersize=10)
plt.plot(hist1.history['acc'], marker = 'o', label='Basic LSTM', markersize=10)
plt.plot(hist2.history['acc'], marker = ',', label = 'LSTM with dropout', markersize=10)
plt.plot(hist3.history['acc'], marker = 's', label = 'CNN_LSTM', markersize=10)
plt.plot(hist4.history['acc'], marker = '*', label = 'CNN', markersize=10)
plt.plot(hist5.history['acc'], marker = '<', label = 'DNN', markersize=10)
plt.plot(hist6.history['acc'], marker = '.', label = 'Stacked LSTM', markersize=10)
plt.title('Model training accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(shadow=False, fontsize='small', loc='lower right')
plt.savefig("Model_accuracy.png", dpi=600)
plt.show()

print("Model loss")
plt.plot(hist0.history['loss'], marker = 'v', label='Bidirectional LSTM', markersize=10)
plt.plot(hist1.history['loss'], marker = 'o', label='Basic LSTM', markersize=10)
plt.plot(hist2.history['loss'], marker = ',', label = 'LSTM with dropout', markersize=10)
plt.plot(hist3.history['loss'], marker = 's', label = 'CNN_LSTM', markersize=10)
plt.plot(hist4.history['loss'], marker = '*', label = 'CNN', markersize=10)
plt.plot(hist5.history['loss'], marker = '<', label = 'DNN', markersize=10)
plt.plot(hist6.history['loss'], marker = '.', label = 'Stacked LSTM', markersize=10)
plt.title('Model training loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(shadow=False, fontsize='small', loc='upper right')
plt.savefig("Model_loss.png", dpi=600)
plt.show()
"""

print("ROC")
fprUni0, tprUni0, _ = roc_curve(prediction0_re, y_test_re)
roc_aucUni0 = auc(fprUni0, tprUni0)

fprUni1, tprUni1, _ = roc_curve(prediction1_re, y_test_re)
roc_aucUni1 = auc(fprUni1, tprUni1)

fprUni2, tprUni2, _ = roc_curve(prediction2_re, y_test_re)
roc_aucUni2 = auc(fprUni2, tprUni2)

fprUni3, tprUni3, _ = roc_curve(prediction3_re, y_test_re)
roc_aucUni3 = auc(fprUni3, tprUni3)

fprUni4, tprUni4, _ = roc_curve(prediction4_re, y_test_re)
roc_aucUni4 = auc(fprUni4, tprUni4)

fprUni5, tprUni5, _ = roc_curve(prediction5_re, y_test_re)
roc_aucUni5 = auc(fprUni5, tprUni5)

fprUni6, tprUni6, _ = roc_curve(prediction6_re, y_test_re)
roc_aucUni6 = auc(fprUni6, tprUni6)

plt.figure()
lw = 2
plt.plot(fprUni0, tprUni0, marker = 'v', markersize=5, linestyle=':',
         lw=lw, label='Bidirectional LSTM (AUC = %0.2f)' % roc_aucUni1)
plt.plot(fprUni1, tprUni1, marker = 'o', markersize=5, linestyle='--',
         lw=lw, label='Basic LSTM (AUC = %0.2f)' % roc_aucUni1)
plt.plot(fprUni2, tprUni2, marker = ',', markersize=5, linestyle='-.',
         lw=lw, label='LSTM with dropout (AUC = %0.2f)' % roc_aucUni2)
plt.plot(fprUni3, tprUni3, marker = 's', markersize=5, linestyle=':',
         lw=lw, label='CNN_LSTM (AUC = %0.2f)' % roc_aucUni3)
plt.plot(fprUni4, tprUni4, marker = '*', markersize=5, linestyle='-',
         lw=lw, label='CNN (AUC = %0.2f)' % roc_aucUni4)
plt.plot(fprUni5, tprUni5, marker = '<', markersize=5, linestyle='-.',
         lw=lw, label='DNN (AUC = %0.2f)' % roc_aucUni5)
plt.plot(fprUni6, tprUni6, marker = 's', markersize=5, linestyle=':',
         lw=lw, label='Stacked LSTM (AUC = %0.2f)' % roc_aucUni6)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic')
plt.legend(loc="lower right")
plt.savefig('Mean_roc.png', dpi=600)
plt.show()
print("Accuracies")
print(accuracies)