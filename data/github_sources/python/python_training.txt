#%% displayHelper
from CrashCourse.displayhelper import *

#%% python modules: https://docs.python.org/3/py-modindex.html
import sys
print(sys.version)


#%% [markdown]

#### Runtime
# - CPython (Python)
# - IPython (Interactive Python)
# - Anaconda (IPython with installed packages)
# - IronPython (Python for dotNet and Mono)

#### IDE
# - Jupyter Notebook
# - VS-Code + Python Extension
# - PyCharm (jetbrains)

#### Package Manager
# - pip
# - Anaconda

#### Important Packages
# - NumPy (large, multi-dimensional arrays)
# - Matplotlib (Plotting library)
# - SciPy (mathematical functions)
# - pandas (csv/excel)

# ML-Stack
# - Scikit Learn (ML-Framewok)
# - Keras (high-level neural networks API; Backend: TensorFlow, CNTK, or Theano)
# - TensorFlow (neural network and deep learning)
# - PyTorch (neural network and deep learning)
import numpy as np
import cv2  # opencv
'''
二、图像基本知识
1、图像是什么：
    图像是客观对象的一种相似性的、生动性的描述或写真，是人类社会活动中最常用的信息载体。或者说图像是客观对象的一种表示，它包含了被描述对象的有关信息。
2、图像基本属性有哪些：
    通道数目、高与宽、像素数据、图像类型
'''
'''
opencv 等pythonlibs 下载网址
https://www.lfd.uci.edu/~gohlke/pythonlibs/

下载完成 opencv_python-3.4.1+contrib-cp35-cp35m-win_amd64.whl
将它放在与pycharm terminal 命令行的同一个文件夹里，如：此处是放置在 0-python 文件夹里，
然后 pip install opencv_python-3.4.1+contrib-cp35-cp35m-win_amd64.whl 即可安装
'''

'''
* [基本的Numpy教程](http://wiki.scipy.org/Tentative_NumPy_Tutorial)
* [Numpy示例列表](http://wiki.scipy.org/Numpy_Example_List)
* [OpenCV文档](http://docs.opencv.org/)
* [OpenCV论坛](http://answers.opencv.org/questions/)

opencv 中图像处理的一般流程——面向对象
https://blog.csdn.net/libin88211/article/details/20860983
图像处理算法工程师面试题
https://blog.csdn.net/ali_dongdong/article/details/74518607

OpenCV常见的优化问题和技巧
https://blog.csdn.net/guyuealian/article/details/78540206



##################

学习这个人的博客，到这各地址的文章
https://blog.csdn.net/maweifei/article/details/53932782
https://blog.csdn.net/wc781708249/article/details/78320644
继续向后翻看


opencv 官方文档
http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html

http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/tutorials.html
http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html#b-rotated-rectangle.

http://www.ruanyifeng.com/blog/2016/07/edge-recognition.html

https://www.cnblogs.com/mymickeyyang1221/p/8141717.html

http://www.guanggua.com/question/11337499-How-to-convert-an-image-from-npuint16-to-npuint8.html

https://github.com/188080501/JQTools

https://blog.csdn.net/u014365862/article/details/52652273

我怎么感觉 photoShop 就是调用的opencv 做的图像处理

CVPR 是IEEE Conference on Computer Vision and Pattern Recognition的缩写，
即IEEE 国际计算机视觉与模式识别会议 。该会议是由IEEE举办的计算机视觉和模式识别领域的顶级会议。- 详情百度百科
'''

'''
CVPR2015一些文章整理
2016年12月13日 22:29:37528人阅读 评论(0) 收藏  举报
 分类： CNN--ANN--Deep Learning（52）   DL_ML_CNN原理（16）
简单看了一部分CVPR2015的文章。整理了一下。其中我决定把精彩的文章加粗。主要是觉得有些文章只读了一遍，没有发现很多很有道理的point（尽管我承认他们的工作都花了很大的功夫，但是没有激起太大的兴趣去follow。也许有机会读第二遍的时候会再highlight）。另外MIT的博士生Zoya Bylinskii也总结了一个list，大家可以看看这里：http://web.mit.edu/zoya/www/CVPR2015brief.pdf
如果有不同看法的我们可以在评论区里讨论。

CNN结构的：
   ---  Fisher Vectors Meet Neural Networks: A Hybrid Classification Architecture，Florent Perronnin and Diane Larlus
         相比于标准的CNN，变化是将卷积层全部变成标准的FV，全连接层的部分做分类层保持不变。比起标准的FV，无疑是把分类器变成了MLP。ACC相比标准的CNN下降，相比标准的FV提高。这种从标准CNN入手，把前面的卷积和后面的全连通隔裂开对待/优化的文章还有arxiv上He Kaiming 的 Object Detection Networks on Convolutional Feature Maps。
    ---- Recurrent Convolutional Neural Network for Object Recognition
          Weichen师兄在讨论班上的推荐。把层次空间想象成序列空间，套上RNN，目的是为了使同一层的节点相互联系从而建模context。这个想法挺有脑洞，但是感觉很不自然（为什么不直接建模相邻节点的依赖关系）。相比之下ION net建模context的方法更直接，以后有机会会讲讲ION。

物体检测与分割：
   ---- Learning to Propose Object， Philipp Krähenbühl, Vladlen Koltun
   ---- Improving Object Proposals with Multi-Thresholding Straddling Expansion， Xiaozhi Chen, Huimin Ma, Xiang Wang, Zhichen Zhao
   ---- Hypercolumns for Object Segmentation and Fine-Grained Localization， Bharath Hariharan, Pablo Arbeláez, Ross Girshick, Jitendra Malik
        这个比较有意思了，明白说CNN每一层都是有用处的。Holistically-Nested Edge Detection的模型跟这个模型有相似的味道。
   ---- Taking a Deeper Look at Pedestrians
         这文章在方法上有啥创新点？好像就是把Cifar-net和Alexnet用在对行人的建模上。
   ---- A Convolutional Neural Network Cascade for Face Detection，Haoxiang Li，Gang Hua
        CNN + Cascade，Calibration层有点意思，模型里还引入了multi-scale。
   ---- Deeply learned face representations are sparse, selective, and robust, Yi Sun, Xiaogang Wang, Xiaoou Tang
        DeepID系列之DeepID2+。在DeepID2之上的改进是增加了网络的规模(feature map数目)，另外每一层都接入一个全连通层加supervision。最精彩的地方应该是后面对神经元性能的分析，发现了三个特点：1.中度稀疏最大化了区分性，并适合二值化；2.身份和attribute选择性；3.对遮挡的鲁棒性。这三个特点在模型训练时都没有显示或隐含地强加了约束，都是CNN自己学的。已经迫不及待要看DeepID3了。
   ---- DeepID3: Face Recognition with Very Deep Neural Networks （顺带提一下吧）
        DeepID3似乎是封山之作，结论是太Deep了在现有数据集上也没什么提升了。反正作者也毕业了。CSDN有一篇对作者的专访，见：http://www.csdn.net/article/2015-11-18/2826241
   ---- Hypercolumns for Object Segmentation and Fine-Grained Localization， Bharath Hariharan, Pablo Arbeláez, Ross Girshick, Jitendra Malik
        这个比较有意思了，明白说CNN每一层都是有用处的。Holistically-Nested Edge Detection的模型跟这个模型有相似的味道。
   ---- Fully Convolutional Networks for Semantic Segmentation (Best Paper Honorable Mention), Jonathan Long, Evan Shelhamer, Trevor Darrell
        文章把全连接层当做卷积层，也用来输出feature map。这样相比于Hypercolumns/HED 这样的模型，可迁移的模型层数（指VGG16/Alexnet等）就更多了。但是从文章来看，因为纯卷积嘛，所以feature map的每个点之间没有位置信息的区分。相较于Hypercolumns的claim，鼻子的点出现在图像的上半部分可以划分为pedestrian类的像素，但是如果出现在下方就应该划分为背景。所以位置信息应该是挺重要需要考虑的。这也许是速度与性能的trade-off?
   ----- Is object localization for free - Weakly-supervised learning with convolutional neural networks
       弱监督做object detection的文章。首先fc layer当做conv layer与上面这篇文章思想一致。同时把最后max pooling之前的feature map看做包含class localization的信息，只不过从第五章“Does adding object-level supervision help classification”的结果看，效果虽好，但是这一物理解释可能不够完善。

（PS. arxiv上有三篇借助CNN做一般物体检测的：
   ---- DeepBox: Learning Objectness with Convolutional Networks，Weicheng Kuo，Bharath Hariharan，Jitendra Malik
        没太大意思，就是把CNN用在所有物体类的训练上。另外证明学到的模型是generic的时候用了IOU-0.5的准确率而不是0.8或者AR是没有很高信服度的。（ICCV2015接收）
   ---- Boosting Convolutional Features for Robust Object Proposals, Nikolaos Karianakis
        把VGG第一层输出当做feature channel然后接boosting做分类。并没有证明算法的一般性。
   ---- Learning to Segment Object Candidates， Pedro O. Pinheiro， Ronan Collobert， Piotr Dollar （NIPS2015接收）
        文章好像没讲明白score那个分支训练集是如何做出标注的（@8.7又读了一遍，如何标注就靠正样本选取时的constraints，自己第一遍的时候没弄明白）。segment相比bounding box在速度上也有点吃亏，所以5秒一个图算慢的（其实5秒就能过一个图还是很快的啊，用的是VGG16的网络）。但比起MCG这速度还是快多了。
        另外Microsoft COCO今年被用起来了。Microsoft COCO也做成竞赛了，好像Detection Task今年在ICCV15要和ILSVR合办workshop。)

CNN做边缘轮廓检测：
   ---- DeepContour： A Deep Convolutional Feature Learned by Positive-sharing Loss for Contour Detection
         二分类变多分类，有点joint learning的意思。
   ---- DeepEdge A Multi-Scale Bifurcated Deep Network for Top-Down Contour Detection
         相当于一种multi-clues做二分类问题。文章里的multi-scale和上面CNN+Cascade那篇文章模型里用到的multi-scale不是同一个东西，用DSP-SIFT一文的总结就是，本文说的multi-scale只是在size-space中选了多个size，并不是CNN+Cascade一文中在scale-space中选择了多个scale。multi-scale是解决真正的不同尺度的多样性，而multi-size更像是引入不同的context以及克服occlusion。个人理解这两点的目标区别于此。

PS. 上面两篇相比传统方法提高并不明显。看来在比较底层的问题上人工特征与end-to-end学习模型相比没有在high-level计算机视觉任务上差距的大。
arxiv上Tu Zhuowen有一篇性能更高的，优势还是很明显的（因为逐像素检测相比全图检测，失去了全局信息。这也隐含了R-CNN的缺点吧）：
   ---- Holistically-Nested Edge Detection
        分析了各种multi-scale model，Wang Naiyan在VALSE的tutorial上也用了这个论文的插图。这个模型很复杂了，除了讨论multi-scale以外，还叠加了cnn multi-layer的区分性，有点Hypercolumns的味道。（ICCV2015接收）


利用CNN的局部性解决计算机视觉问题：
   ---- A Discriminative CNN Video Representation for Event Detection，Zhongwen Xu, Yi Yang, Alex G. Hauptmann
        CNN conv5输出可以作为concept detector。valse上的ppt：这里。
   ---- Exploiting Local Features from Deep Networks for Image Retrieval
        Workshop paper，与上文的思路如出一辙，不过证明了在检索过程中concept概念越抽象不一定越好--因为搜索毕竟是instance-level的，不是class-level的。

图像检索的：
   ---- Query-Adaptive Late Fusion for Image Search and Person Re-Identification
         郑博每年都有CVPR，恭喜。在valse上的ppt：这里。我们在Trecvid2015的竞赛中用了这个方法，很多人当时也觉得这项工作很有意义。
   ---- Early Burst Detection for Memory-Efficient Image Retrieval， Miaojing Shi, Yannis Avrithis, Hervé Jégou
         Hervé Jégou也加入FAIR了
   ---- Pairwise Geometric Matching for Large-scale Object Retrieval
         利用Geometry information做 verification的。速度还挺快。

Eye-fixation:
   ----  Predicting Eye Fixations Using Convolutional Neural Networks, Nian Liu, Junwei Han, Dingwen Zhang, Shifeng Wen, Tianming Liu
         之前没太关注eye-tracking data。这篇文章就是用预测eye fixation的，跟显著性有比较大的联系。这篇文章中利用的multi-resolution的模型，在看过其他文章之后不会觉得有特别特殊的地方，但是从一个contrast导致saliency的角度去结束这里用到的multi-resolution模型，还有点意思。（add@Nov/09/2015: 其实在Naiyan Wang在VALSE上的总结，Saliency和Edge Detection、Segmentation类似，都是做pixel-wise labeling，所以这几个问题都是同质的，所以用相似的模型去解决完全合理。）
   ----  Eye Tracking Assisted Extraction of Attentionally Important Objects From Videos， Karthikeyan Shanmuga Vadivel, Thuyen Ngo, Miguel Eckstein, B.S. Manjunath
        Manj组今年唯一的CVPR论文了，用eye-tracking数据辅助其他（指除了saliency）computer vision task，这里做的是video里的objectness。
   ---- Salient Object Subitizing
        数图像中显著物体的个数。好处是有的图像没有显著物体，而一般的Salient Object Detection方法仍然会检测出几个object。所以事前估计图像显著物体的数目可以作为一个有效的先验（比如没有显著物体的图像就不做检测了）。模型放在caffe的model zoo里了。
   ---- SALICON: Saliency in Context
        一个新库，拿MsCOCO标注的。理由是eye-tracking data的采集需要专门设备，不便于众包，所以她们组用鼠标轨迹代替eye-tracking data采集了human gaze的数据，而且证明了这种采集方法替代eye-tracking很合理。并且她们开放了一个新的竞赛就叫SALICON。还有后续的论文在ICCV2015上，以后专门讲ICCV15的论文时候再说。
   附arxiv上近期放出的论文：
   ---- DeepSaliency：Multi-task deep neural network model for salient object detection
         这里的multi-task是指semantic segmentation + salient object segmentation。不同于joint learning（如DeepID2和Fast RCNN），这里的两个task只是共享了conv layers，输入的训练样本是不一样的。训练的时候两个任务迭代地更新网络的参数。
   ---- DeepFix：A Fully Convolutional Neural Network for predicting Human Eye Fixations
        在MIT的saliency库上排在第二名。很有意思的文章，考虑了Fixation Prediction的Center Bias问题（就是人眼显著性判决时会倾向于图像中心。FCN这类模型因为没有全连接层了，所以输出每个像素的预测值是与位置无关的）。至于怎么解决的，请大家自行去看。

其他不好分类：
   ---- MatchNet Unifying Feature and Metric Learning for Patch-Based Matching，  Xufeng Han， Thomas Leung， Yangqing Jia， Rahul Sukthankar，Alexander C. Berg
         wide-baseline matching，相比与arxiv14年的Descriptor Matching with Convolutional Neural Networks a Comparison to SIFT，这篇文章是监督的，上篇文章是无监督的。patch matching其实和face verification、再辨识的关联挺大的。文中有说到测试的时候采用两步测试的方法：第一步是特征提取（过一个Tower就行），第二步是matching（把两个Tower的特征比较起来），这样先把第一步做完，特征保存起来，做第二步就容易了。联想道Valse上王晓刚老师将NIPS14那篇Joint identification and verification一文，王老师说verification那个网络的时候提到的缺点，不就可以用这个两步测试的方法来解决吗？
   ---- Domain-Size Pooling in Local Descriptors: DSP-SIFT ， Jingming Dong，Stefano Soatto
         wide-baseline matching，相比前面的MatchNet，这篇文章是无监督的。这篇文章Figure8解释了scale-space和size-space的概念，解释的非常好。但是DoG为什么归为size-space？我仍然觉得DoG是属于scale-space的。
   ---- Deep Neural Networks are Easily Fooled    （深度学习对抗样本）
   ---- Age and Gender Classification using Convolutional Neural Networks
         CNN做性别和年龄判决的。年龄判决不是用回归，而是把年龄分组，然后用分类的方法做。有点简单。而且Age和Gender分了两个网络分别做，竟然没有联合起来做。


还在看，慢慢整理吧。

另外这里有其他大神做的CVPR2015年的整理和总结：
CVPR 2015 之深度学习篇(3贴)：
   http://deepnn.net/viewtopic.PHP?f=6&t=31
   http://deepnn.net/viewtopic.php?f=6&t=32
   http://deepnn.net/viewtopic.php?f=6&t=38
武汉大学张觅博士生（原创）：CVPR 2015会议总结报告：
   http://valseonline.org/thread-334-1-1.html
(知乎)CVPR 2015 有什么值得关注的亮点？
   http://www.zhihu.com/question/31300014
Deep down the rabbit hole: CVPR 2015 and beyond:
   http://www.computervisionblog.com/2015/06/deep-down-rabbit-hole-cvpr-2015-and.html

-------
jiang1st
http://jiangwh.weebly.com
'''

'''
 计算机视觉的三大会议
2016年12月13日 22:40:21497人阅读 评论(0) 收藏  举报

1 ICCV 全称 IEEE International Conference on Computer Vision，国际计算机视觉大会

2 ECCV 全称 Europeon Conference on Computer Vision

3 CVRP 国际计算机视觉与模式识别学术会议
    即 International Conference on Computer VisionPattern Recognition
'''
# https://deeplearningcourses.com/c/deep-learning-recurrent-neural-networks-in-python
# https://udemy.com/deep-learning-recurrent-neural-networks-in-python
import json
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, TruncatedSVD

def main(we_file='word_embeddings.npy', w2i_file='wikipedia_word2idx.json', Model=PCA):
    We = np.load(we_file)
    V, D = We.shape
    with open(w2i_file) as f:
        word2idx = json.load(f)
    idx2word = {v:k for k,v in word2idx.iteritems()}

    model = Model()
    Z = model.fit_transform(We)
    plt.scatter(Z[:,0], Z[:,1])
    for i in xrange(V):
        plt.annotate(s=idx2word[i], xy=(Z[i,0], Z[i,1]))
    plt.show()


if __name__ == '__main__':
    # main(Model=TSNE)

    # D=80, M=80
    # main(we_file='gru_nonorm_part1_word_embeddings.npy', w2i_file='gru_nonorm_part1_wikipedia_word2idx.json', Model=TSNE)
    main(we_file='working_files/batch_gru_word_embeddings.npy', w2i_file='working_files/batch_wikipedia_word2idx.json', Model=TSNE)
    from tensorflow.contrib.keras.api.keras.layers import Dropout
    from tensorflow.contrib.keras.api.keras.models import Sequential
    from tensorflow.contrib.keras.api.keras.layers import Conv2D
    from tensorflow.contrib.keras.api.keras.layers import MaxPooling2D
    from tensorflow.contrib.keras.api.keras.layers import Flatten
    from tensorflow.contrib.keras.api.keras.layers import Dense
    from tensorflow.contrib.keras.api.keras.callbacks import Callback
    from tensorflow.contrib.keras.api.keras.preprocessing.image import ImageDataGenerator
    from tensorflow.contrib.keras import backend
    import os


    class LossHistory(Callback):
        def __init__(self):
            super().__init__()
            self.epoch_id = 0
            self.losses = ''

        def on_epoch_end(self, epoch, logs={}):
            self.losses += "Epoch {}: accuracy -> {:.4f}, val_accuracy -> {:.4f}\n"\
                .format(str(self.epoch_id), logs.get('acc'), logs.get('val_acc'))
            self.epoch_id += 1

        def on_train_begin(self, logs={}):
            self.losses += 'Training begins...\n'

    script_dir = os.path.dirname(__file__)
    training_set_path = os.path.join(script_dir, 'G:\\ANALYTICS_WORLD_R_SAS\\python_world\\deep learning\\Convolutional_Neural_Networks\\dataset\\training_set')
    test_set_path = os.path.join(script_dir, 'G:\\ANALYTICS_WORLD_R_SAS\\python_world\\deep learning\\Convolutional_Neural_Networks\\dataset\\test_set')

    # Initialising the CNN
    classifier = Sequential()

    # Step 1 - Convolution
    input_size = (128, 128)
    classifier.add(Conv2D(32, (3, 3), input_shape=(*input_size, 3), activation='relu'))

    # Step 2 - Pooling
    classifier.add(MaxPooling2D(pool_size=(2, 2)))  # 2x2 is optimal

    # Adding a second convolutional layer
    classifier.add(Conv2D(32, (3, 3), activation='relu'))
    classifier.add(MaxPooling2D(pool_size=(2, 2)))

    # Adding a third convolutional layer
    classifier.add(Conv2D(64, (3, 3), activation='relu'))
    classifier.add(MaxPooling2D(pool_size=(2, 2)))

    # Step 3 - Flattening
    classifier.add(Flatten())

    # Step 4 - Full connection
    classifier.add(Dense(units=64, activation='relu'))
    classifier.add(Dropout(0.5))
    classifier.add(Dense(units=1, activation='sigmoid'))

    # Compiling the CNN
    classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # Part 2 - Fitting the CNN to the images
    batch_size = 32
    train_datagen = ImageDataGenerator(rescale=1. / 255,
                                       shear_range=0.2,
                                       zoom_range=0.2,
                                       horizontal_flip=True)

    test_datagen = ImageDataGenerator(rescale=1. / 255)

    training_set = train_datagen.flow_from_directory('G:\\ANALYTICS_WORLD_R_SAS\\python_world\\deep learning\\Convolutional_Neural_Networks\\dataset\\training_set',
                                                     target_size=input_size,
                                                     batch_size=batch_size,
                                                     class_mode='binary')

    test_set = test_datagen.flow_from_directory('G:\\ANALYTICS_WORLD_R_SAS\\python_world\\deep learning\\Convolutional_Neural_Networks\\dataset\\test_set',
                                                target_size=input_size,
                                                batch_size=batch_size,
                                                class_mode='binary')

    # Create a loss history
    history = LossHistory()

    classifier.fit_generator(training_set,
                             steps_per_epoch=8000/batch_size,
                             epochs=90,
                             validation_data=test_set,
                             validation_steps=2000/batch_size,
                             workers=12,
                             #max_q_size=100,
                             callbacks=[history])


    # Save model
    model_backup_path = os.path.join(script_dir, 'G:\\ANALYTICS_WORLD_R_SAS\\python_world\\deep learning\\Convolutional_Neural_Networks\\dataset\\cat_or_dogs_model.h5')
    classifier.save(model_backup_path)
    print("Model saved to", model_backup_path)

    # Save loss history to file
    loss_history_path = os.path.join(script_dir, 'G:\\ANALYTICS_WORLD_R_SAS\\python_world\\deep learning\\Convolutional_Neural_Networks\\dataset\\loss_history.log')
    myFile = open(loss_history_path, 'w+')
    myFile.write(history.losses)
    myFile.close()

    backend.clear_session()
    print("The model class indices are:", training_set.class_indices)
# -*- coding: utf-8 -*-
"""
Created on Sun Jul 23 12:31:55 2017

@author: kaust
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier
from sklearn.calibration import CalibratedClassifierCV
#import xgboost as xgb
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import LogisticRegression
from sklearn import svm
import datetime
from keras.models import Sequential
from keras.layers import Dense, Dropout,Conv1D,GlobalMaxPooling1D
from keras.layers.core import Flatten
from keras.layers.recurrent import LSTM

AfterDate = datetime.date(2012,1,1)

NIFTY = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTY.csv")
NIFTY['Date'] = pd.to_datetime(NIFTY['Date'])
NIFTY = NIFTY[(NIFTY.Date > AfterDate) & (NIFTY.Date < datetime.date(2017,7,25)) ]
NIFTY = NIFTY.as_matrix(["Change %"])

NIFTYAUTO = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTYAUTO.csv")
NIFTYAUTO['Date'] = pd.to_datetime(NIFTYAUTO['Date'])
NIFTYAUTO = NIFTYAUTO[NIFTYAUTO.Date > AfterDate ]
NIFTYAUTO = NIFTYAUTO.as_matrix(["Change %"])

NIFTYBANK = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTYBANK.csv")
NIFTYBANK['Date'] = pd.to_datetime(NIFTYBANK['Date'])
NIFTYBANK = NIFTYBANK[NIFTYBANK.Date > AfterDate ]
NIFTYBANK = NIFTYBANK.as_matrix(["Change %"])

NIFTYFIN = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTYFIN.csv")
NIFTYFIN['Date'] = pd.to_datetime(NIFTYFIN['Date'])
NIFTYFIN = NIFTYFIN[NIFTYFIN.Date > AfterDate ]
NIFTYFIN = NIFTYFIN.as_matrix(["Change %"])

NIFTYFMCG = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTYFMCG.csv")
NIFTYFMCG['Date'] = pd.to_datetime(NIFTYFMCG['Date'])
NIFTYFMCG = NIFTYFMCG[NIFTYFMCG.Date > AfterDate ]
NIFTYFMCG = NIFTYFMCG.as_matrix(["Change %"])

NIFTYIT = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTYIT.csv")
NIFTYIT['Date'] = pd.to_datetime(NIFTYIT['Date'])
NIFTYIT = NIFTYIT[NIFTYIT.Date > AfterDate ]
NIFTYIT = NIFTYIT.as_matrix(["Change %"])

NIFTYMEDIA = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTYMEDIA.csv")
NIFTYMEDIA['Date'] = pd.to_datetime(NIFTYMEDIA['Date'])
NIFTYMEDIA = NIFTYMEDIA[NIFTYMEDIA.Date > AfterDate ]
NIFTYMEDIA = NIFTYMEDIA.as_matrix(["Change %"])

NIFTYMETAL = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTYMETAL.csv")
NIFTYMETAL['Date'] = pd.to_datetime(NIFTYMETAL['Date'])
NIFTYMETAL = NIFTYMETAL[NIFTYMETAL.Date > AfterDate ]
NIFTYMETAL = NIFTYMETAL.as_matrix(["Change %"])

NIFTYPHARMA = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTYPHARMA.csv")
NIFTYPHARMA['Date'] = pd.to_datetime(NIFTYPHARMA['Date'])
NIFTYPHARMA = NIFTYPHARMA[NIFTYPHARMA.Date > AfterDate ]
NIFTYPHARMA = NIFTYPHARMA.as_matrix(["Change %"])

NIFTYPSU = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTYPSU.csv")
NIFTYPSU['Date'] = pd.to_datetime(NIFTYPSU['Date'])
NIFTYPSU = NIFTYPSU[NIFTYPSU.Date > AfterDate ]
NIFTYPSU = NIFTYPSU.as_matrix(["Change %"])

NIFTYREALITY = pd.read_csv("F:\\FinanceRepo\\Deep-Learning-Time-Series-Prediction-using-LSTM-Recurrent-Neural-Networks-master\\NIFTYREALITY.csv")
NIFTYREALITY['Date'] = pd.to_datetime(NIFTYREALITY['Date'])
NIFTYREALITY = NIFTYREALITY[NIFTYREALITY.Date > AfterDate ]
NIFTYREALITY = NIFTYREALITY.as_matrix(["Change %"])


Matrix = np.hstack((NIFTY,NIFTYAUTO,NIFTYBANK,NIFTYFIN,NIFTYFMCG,NIFTYIT,NIFTYMEDIA,NIFTYMETAL,NIFTYPHARMA,NIFTYPSU,NIFTYREALITY))
#data = data.drop(['DATE'],axis=1)
#data.head()
#
#NumpyData = data.as_matrix()
look_back = 8

def convertSeriesToMatrix(vectorSeries, look_back_window):
    matrix=[]
    for i in range(len(vectorSeries)-look_back_window+1):
        A= vectorSeries[i:i+look_back_window]
        A = A.reshape(1,(look_back_window*A.shape[1]))
        matrix.append(A)
    return matrix

Matrix = convertSeriesToMatrix(Matrix,look_back)
Matrix = np.asarray(Matrix)
Matrix = Matrix.reshape(Matrix.shape[0],Matrix.shape[2])

Pandas_Matrix = pd.DataFrame(Matrix)
#for i in range(0,(7*look_back-7),7):
#    Pandas_Matrix = Pandas_Matrix.drop([i,i+1,i+2,i+3,i+4,i+6],axis=1)
#
#Pandas_Matrix = Pandas_Matrix.drop([(7*look_back-7)],axis = 1)
def f(row):
    if row[0] > 0:
        val = 1
    else:
        val = 0
    return val

Pandas_Matrix['Main'] = Pandas_Matrix.apply(f, axis=1)

y = Pandas_Matrix['Main'].values
Pandas_Matrix = Pandas_Matrix.drop(['Main',0,1,2,3,4,5,6,7,8,9,10],axis=1)
X = Pandas_Matrix.values
#Xtrain, Xtest = X[:int(len(X) * 0.90)], X[int(len(X) * 0.90):] 
#ytrain, ytest = y[:int(len(y) * 0.90)], y[int(len(y) * 0.90):] 

Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.10)
Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1],1)
Xtest = Xtest.reshape(Xtest.shape[0],Xtest.shape[1],1)

# build the model
model = Sequential()
# layer 1: LSTM
model.add(LSTM( input_dim=1, output_dim=50, return_sequences=True))
model.add(Dropout(0.2))
# layer 2: LSTM
model.add(LSTM(output_dim=100, return_sequences=False))
model.add(Dropout(0.2))
# layer 3: dense
# linear activation: a(x) = x
model.add(Dense(output_dim=1, activation='sigmoid'))
# compile the model
model.compile(loss="binary_crossentropy", optimizer="adam",metrics=['accuracy'])

model.fit(Xtrain, ytrain,
          
          batch_size=128, validation_data=(Xtest, ytest))
score = model.evaluate(Xtest, ytest, batch_size=32)
target = open('C:\\Users\\kaust\\Downloads\\WinPython-64bit-3.5.2.3Qt5\\myScripts\\out.txt', 'w')
y_pre = model.predict_classes(Xtest)
Total_Trades = 0
Total_Matched_Trades = 0
Total_False_Positives = 0
Total_False_Negatives = 0

for i in range(Xtest.shape[0]):
    line = str(ytest[i])+','+str(y_pre[i])
    target.write(line)
    target.write('\n')
    Total_Trades = Total_Trades + 1
    if(ytest[i] == y_pre[i] ):
        Total_Matched_Trades = Total_Matched_Trades + 1
    if(ytest[i] == 0 and y_pre[i] == 1):
        Total_False_Positives = Total_False_Positives + 1
    if(ytest[i] == 1 and y_pre[i] == 0):
        Total_False_Negatives = Total_False_Negatives + 1
target.close()

print("Total Trades = "+str(Total_Trades))
print("Total Matched Trades = "+str(Total_Matched_Trades))
print("Total False Positive Trades = "+str(Total_False_Positives))
print("Total False Negative Trades = "+str(Total_False_Negatives))

#import numpy as np
#indices = np.argsort(gadaboost.feature_importances_)[::-1]
#
## Print the feature ranking
#print('Feature ranking:')

#for f in range(Pandas_Matrix.shape[1]):
#    print('%d. feature %d %s (%f)' % (f+1 , indices[f], Pandas_Matrix.columns[indices[f]],
#                                      gadaboost.feature_importances_[indices[f]]))from collections import defaultdict, Counter
from typing import List, Dict, Any

users = [
   {"id": 0, "name": "Hero"},
   {"id": 1, "name": "Dunn"},
   {"id": 2, "name": "Sue"},
   {"id": 3, "name": "Chi"},
   {"id": 4, "name": "Thor"},
   {"id": 5, "name": "Clive"},
   {"id": 6, "name": "Hicks"},
   {"id": 7, "name": "Devin"},
   {"id": 8, "name": "Kate"},
   {"id": 9, "name": "Klein"}
]
friendshipPairs = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),
                   (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]
friendShipDict: Dict[int, List[int]] = {user['id']: [] for user in users}

# loop over populate friendship dict
for i, j in friendshipPairs:
   friendShipDict[i].append(j)
   friendShipDict[j].append(i)


def numberOfFriends(user):
   return len(friendShipDict[user['id']])


totalConnections = sum(numberOfFriends(user) for user in users)

numbFriendsById = [(user['id'], numberOfFriends(user)) for user in users]
numbFriendsById.sort(key=lambda pair: pair[1], reverse=True)


def calcFriendOfAFriend(user):
   return {friendOfFriendId for friendId in friendShipDict[user['id']]
           for friendOfFriendId in friendShipDict[friendId]
           if friendOfFriendId != user['id'] and friendOfFriendId not in friendShipDict[user['id']]}


interests = [
   (0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"),
   (0, "Spark"), (0, "Storm"), (0, "Cassandra"),
   (1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"),
   (1, "Postgres"), (2, "Python"), (2, "scikit-learn"), (2, "scipy"),
   (2, "numpy"), (2, "statsmodels"), (2, "pandas"), (3, "R"), (3, "Python"),
   (3, "statistics"), (3, "regression"), (3, "probability"),
   (4, "machine learning"), (4, "regression"), (4, "decision trees"),
   (4, "libsvm"), (5, "Python"), (5, "R"), (5, "Java"), (5, "C++"),
   (5, "Haskell"), (5, "programming languages"), (6, "statistics"),
   (6, "probability"), (6, "mathematics"), (6, "theory"),
   (7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),
   (7, "neural networks"), (8, "neural networks"), (8, "deep learning"),
   (8, "Big Data"), (8, "artificial intelligence"), (9, "Hadoop"),
   (9, "Java"), (9, "MapReduce"), (9, "Big Data")
]


def dataScientistWhoLike(targetInterest):
   return [userId for userId, interest in interests
           if interest == targetInterest]


interest2users = defaultdict(list)
for userId, interest in interests:
   interest2users[interest].append(userId)

user2interests = defaultdict(list)
for userId, interest in interests:
   user2interests[userId].append(interest)


def most_common_interests_with(user):
   return Counter(
      interested_user_id
      for interest in user2interests[user["id"]]
      for interested_user_id in interest2users[interest]
      if interested_user_id != user["id"])


salariesAndTenures = [(83000, 8.7), (88000, 8.1),
                      (48000, 0.7), (76000, 6),
                      (69000, 6.5), (76000, 7.5),
                      (60000, 2.5), (83000, 10),
                      (48000, 1.9), (63000, 4.2)]


def tenureBucket(tenure: float) -> str:
   if tenure < 2:
      return "less than two"
   elif tenure < 5:
      return "between two and five"
   else:
      return "more than five"


bucket2salaries = defaultdict(list)
for salary, tenure in salariesAndTenures:
   bucket2salaries[tenureBucket(tenure)].append(salary)

bucket2avgSalary = {bucket: sum(salaries) / len(salaries) for bucket, salaries in bucket2salaries.items()}

interests = [
   (0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"),
   (0, "Spark"), (0, "Storm"), (0, "Cassandra"),
   (1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"),
   (1, "Postgres"), (2, "Python"), (2, "scikit-learn"), (2, "scipy"),
   (2, "numpy"), (2, "statsmodels"), (2, "pandas"), (3, "R"), (3, "Python"),
   (3, "statistics"), (3, "regression"), (3, "probability"),
   (4, "machine learning"), (4, "regression"), (4, "decision trees"),
   (4, "libsvm"), (5, "Python"), (5, "R"), (5, "Java"), (5, "C++"),
   (5, "Haskell"), (5, "programming languages"), (6, "statistics"),
   (6, "probability"), (6, "mathematics"), (6, "theory"),
   (7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),
   (7, "neural networks"), (8, "neural networks"), (8, "deep learning"),
   (8, "Big Data"), (8, "artificial intelligence"), (9, "Hadoop"),
   (9, "Java"), (9, "MapReduce"), (9, "Big Data")
]

interest2count = Counter([interest for userId, interest in interests])
print(interest2count.most_common())
#coding=utf-8
#E:/Python/workspace/DeepLearning/NeuralNetworks/contact.csv
#多元线性回归
import sys
sys.path[0] = 'E:\Python\Anaconda\Lib\site-packages'
from numpy import genfromtxt
import numpy as np
from sklearn import datasets, linear_model
#英里数	次数  时间
dataPath = r"E:/Python/workspace/DeepLearning/NeuralNetworks/contact.csv"
deliveryData = genfromtxt(dataPath, delimiter=',')

print("data:\r",deliveryData)

X = deliveryData[:, :-1]
Y = deliveryData[:, -1]

print("X:\r",X)
print("Y:\r",Y)

regr = linear_model.LinearRegression()

regr.fit(X, Y)

print('coefficients:', regr.coef_)

print("intercept:",regr.intercept_)

xPred = [[102, 6]]
yPred = regr.predict(xPred)
print("predicted y:",yPred)from setuptools import setup

# Current status: pre-alpha

setup(name='learning_NeuralNetworks',
      version='0.1.0',
      description='Python library for learning about Neural Networks',
      author='Jiovani Ledesma',
      author_email='jiovaniledesmaa@gmail.com',
      license = "MIT",
      keywords=["AI","neural networks", "machine learning", "deep learning"],
      url='https://github.com/JiovaniLedesma/Learning_NeuralNetworks',
      packages=['learning_NeuralNetworks'],
      classifiers=[
      "Development Status :: 2 - Pre-Alpha",
      "Intended Audience :: Education",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: Implementation :: CPython",
      ]
      )
# Simple Recommender system based on what is popular
from collections import Counter

""" i.e. how should a website recommend certain things based off your actions"""

users_interests = [
    ["Hadoop", "Big Data", "HBase", "Java", "Spark", "Storm", "Cassandra"],
    ["NoSQL", "MongoDB", "Cassandra", "HBase", "Postgres"],
    ["Python", "scikit-learn", "scipy", "numpy", "statsmodels", "pandas"],
    ["R", "Python", "statistics", "regression", "probability"],
    ["machine learning", "regression", "decision trees", "libsvm"],
    ["Python", "R", "Java", "C++", "Haskell", "programming languages"],
    ["statistics", "probability", "mathematics", "theory"],
    ["machine learning", "scikit-learn", "Mahout", "neural networks"],
    ["neural networks", "deep learning", "Big Data", "artificial intelligence"],
    ["Hadoop", "Java", "MapReduce", "Big Data"],
    ["statistics", "R", "statsmodels"],
    ["C++", "deep learning", "artificial intelligence", "probability"],
    ["pandas", "R", "Python"],
    ["databases", "HBase", "Postgres", "MySQL", "MongoDB"],
    ["libsvm", "regression", "support vector machines"]
    ]

# Can easily do this by just recommending what is popular that the user does
# not have listed as an interest
popular_interests = Counter(interest
                            for user_interests in users_interests
                            for interest in user_interests).most_common()

def most_popular_new_interests(user_interests, max_results=5):
    suggestions = [(interest, frequency)
                   for interest, frequency in popular_interests
                   if interest not in user_interests]
    return suggestions[:max_results]

# Ex: for user 1
print(most_popular_new_interests(users_interests[1], 5))
import theano
import theano.tensor as T
from theano import pp
import numpy

a = T.dscalar()
b = T.dscalar()
c = a + b
f = theano.function([a,b], c)
assert 4.0 == f(1.5, 2.5)

x = T.dmatrix('x')
s = 1 / (1 + T.exp(-x))
logistic = theano.function([x], s)
print(logistic([[0, 1], [-1, -2]]))

x = T.dmatrix('x')
s = T.sum(1 / (1 + T.exp(-x)))
gs = T.grad(s, x)
dlogistic = theano.function([x], gs)
print(dlogistic([[0, 1], [-1, -2]]))

from sklearn.cross_validation import train_test_split
from sklearn.metrics import classification_report
from sklearn import datasets
from nolearn.dbn import DBN
import numpy as np
# import cv2

print "[X] downloading data..."
dataset = datasets.fetch_mldata("MNIST Original")

(trainX, testX, trainY, testY) = train_test_split(
    dataset.data / 255.0, dataset.target.astype("int0"), test_size = 0.33)

dbn = DBN(
    [trainX.shape[1], 300, 10],
    learn_rates = 0.3,
    learn_rate_decays = 0.9,
    epochs = 10,
    verbose = 1)
dbn.fit(trainX, trainY)

preds = dbn.predict(testX)
print classification_report(testY, preds)

for i in np.random.choice(np.arange(0, len(testY)), size = (10,)):
    pred = dbn.predict(np.atleast_2d(testX[i]))
    image = (testX[i] * 255).reshape((28, 28)).astype("uint8")
    print "Actual digit is {0}, predicted {1}".format(testY[i], pred[0])
#     cv2.imshow("Digit", image)
#     cv2.waitKey(0)



















'''
Theano, Lasagne, nolearn, keras, pylearn2, plato, crino
Only older version of nolearn has DBN. Newer version of nolearn has DNN.
In yaml, pylearn2 has a DBM, RBM
Standard DBN code is not available in python packages. CNNs are readily available.
We must implement a DBN by adapting existing code. Or must trace the dependencies of github packages providing code(like plato). 
More packages to be checked : pylearn2, Torch7, DL4J, H2O, DeepLearnToolbox, MXNet in yaml, lua, Matlab, Java, R 
Alternatves to nolearn in python are Java packages like DL4J, R packages like deepnet
For using GPUs, DL4J consolidates blas into ND4J that has jdk, cuda, nvidia dependencies for switiching backends on linear algebra operations 
ND4J allows portability of deep learning code.  DL4J pipelines also works on both hadoop and spark shell supporting blas, iterative reduce. So main focus is on tuning network hyperparameters and interpreting output in the deep learning model. 
DL4J has both java and scala api docs for building computation graphs and deep learning models. Canova allows us to vectorize and split data input to neural networks. 
DL4J has detailed tutorials for IntelliJ than Eclipse IDE, Maven than SBT build tool
Thus, DL4J is like the Weka of deep learning
https://github.com/Theano/Theano/wiki/Related-projects
http://scikit-learn.org/stable/modules/neural_networks.html
http://scikit-learn.org/dev/modules/neural_networks_supervised.html
https://pythonhosted.org/nolearn/lasagne.html#module-nolearn.lasagne
https://pythonhosted.org/nolearn/lasagne.html
http://www.slideshare.net/roelofp/python-for-image-understanding-deep-learning-with-convolutional-neural-nets
https://github.com/dnouri/nolearn
http://www.pyimagesearch.com/2014/09/22/getting-started-deep-learning-python/
https://github.com/ottogroup/kaggle/blob/master/Otto_Group_Competition.ipynb
http://derekjanni.github.io/Easy-Neural-Nets/
http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/
https://blog.dominodatalab.com/gpu-computing-and-deep-learning/

http://deeplearning.net/software/theano/tutorial/index.html#tutorial
http://deeplearning.net/software/theano/introduction.html#introduction
http://deeplearning.net/software/theano/extending/graphstructures.html
http://deeplearning.net/software/pylearn2/library/index.html
https://wiki.python.org/moin/UsingAssertionsEffectively

https://github.com/petered/plato
https://github.com/petered/plato/wiki/Algorithms-in-Plato
http://blocks.readthedocs.io/en/latest/api/algorithms.html
http://deeplearning.net/software/pylearn2/library/models.html
https://groups.google.com/forum/#!topic/pylearn-dev/cBNms1QEmXc

http://deeplearning4j.org/compare-dl4j-torch7-pylearn.html
http://deeplearning4j.org/deepbeliefnetwork.html
http://deeplearning4j.org/restrictedboltzmannmachine.html
https://github.com/deeplearning4j
http://deeplearning4j.org/
https://www.quora.com/What-are-the-best-packages-for-deep-learning-in-R
'''


'''
== create a penetration testing framework like a password cracker(a decrypter) using ANN  
== decrypting/cracking passwords using ANN idea ; start with a genetic algorithm to learn to print hello world
== decrypting cookies, hashed pswds & bit,SSLs(packet capture app in my phone) and sessions with/without ANN(use python cipher books) 
== create a cipher decoder app(a bruteforcer script from scratch like crunch) using python for my own purposes(decode all ciphers and hashing algos; 
== use python secret cipher books in WOShelf); hack soroush app break the ssl & AES & show them using wireshark concept & turn RSA into bits with/without using ANN
== getting start with ANN(like genetic algo and virus creation) in everything like penjabing and vocfu life-style for the next level of my life => python + raspi + AI(ANN-tensorflow) + vocfu bag
== build ur icfu SlAb(wocfulab) in csr with ur team using AI + use ANN ML DL in MAN project to take them down + build AI projects and cvs with ICFU team(u know who they R!)


TOKNOW: ai health itself (how it know what is it doing like human? try to understand west world movie!)
TOKNOW: lstm vs self-awareness and human memory
TOKNOW: hyper dimensional computnig theaory for AI memory(self-awareness) alternatives to pytorch/tensorflow/keras traditional ann(RIL, SUPL, USUPL)
TOKNOW: ANI-AGI-ASI , all about NLP and its vectors to create a new language!
TOKNOW: openAI RL ppo vs deepNeuroevolution algo vs Hyperdimensional Computing Theory(HBV)
TOKNOW: genetic algorithm as a heuristic search method in all types of AI/ML/DL and all types of neural networks
TOKNOW: ES/GA/DN is an alternative for RL and some algo like DDQN is an improvement algo for DQN(DRL) and other alog like PPO is a RL algo and all NN types like CNN GAN RNN VGG NLP are supervised learning type of ML
TOKNOW: Q-learning algo is a solution to solve the RL issues on MDP env using bellman equation and DQN(DRL/DQL) is a combination of Q-learning algo with neural network
TOKNOW: for all uis of all ur apps just use adobexd and run all ur codes in a parallelism env in python parallel programming


TODO: making ur own anti-virus(statistics, dynamic and heuristic knowledge) stronger than windows defender using AI(AI must detect the all virus signatures and learn to find them)
TODO: make a python flask or django server and a sexy ui in dart flutter(cross platform backdoor all in flutter and dart) for text_classification_Emotion_Detection colab proj with more dataset to prevent the model from underfitting!
TODO: kaggle challenges in raspi 4 or colab on pythonanywhere and zeit with FUD malware creation using AI(pytorch/tensorflow/keras/numpy/matplotlib on google colab) and also malware detection/classification using machine learning
TODO: AI based(pytorch/tensorflow/keras/sonnet/numpy/scipy/matplotlib/opencv/scikit-learn on google colab) airdrone to do some IOT stuff using our own blockchain system for its cryptocurrency based on solidity smart-contract or something like iota tangle system and serverless architecture using dart api(saas, faas, baas, paas) to run airline transportation protocol app(svelte-electron || flutter) built on top of CSR like telecommunication, csa and cryptography stuff
TODO: build ur virus using AI like so: first it'll use ANN to create a cryptographic network(use all articles and pdfs in UT folder for ANN and machine learning) for its ransomware encryption(cL34n 3v3RytH!n9) also for bypassing technique it'll analyze the AV behavior to know the AV detection algorithms such as signature scanning to behavior the opposite of it and hide itself from AV; the virus has two main parts in which the AV behavior analyzing is the first part for bypassing and the main content of virus(ransomware, backdoor) is the second part which will run after a success analyzing job in first part! also it'll use the blockchain for storing vic and AV infos after successfull detection
TODO: use AI in ur MAN project like backdoor creation using AI to bypass et; cause MAN proj is all u got to destroy them
TODO: think about hacking using ANN not a shity hack like iranian hack so build all types of ANN from scratch with ur own language(ur own compiler like dart) and math(derivation) concepts then put it on wocfulab 
TODO: think about to create a bot or anything for person_X to answer every fucking question of her instead of me using AI ANN ML DL
TODO: build ur own framework based on AI and ANN ; you can see the wocfulab.todo and solve all kaggle chalenges with tf.keras
TODO: spoil prevention idea for movies using AI (watch what ur unconscious want! the Agent must access to ur unconscious to surprise u with scenes that ur brain want to see or get what u want to see!)
TODO: solve Artificial Super Intelligence(ASI) dangerous and problems using a two way neuron wave collector which it can put/read thoughts in/from your mind like Doublegainer or Password_Cracker idea(for that we have to build a security protocl like our ASI must prevent those bad thoughts like killing or wars from being happen or no one can hear other thoughts) | implement the abstract of inertia or force for our ASI
TODO: the idea about generating full meaning form of an abbreviation word using nlp and tf.keras
TODO: build a nano robots using Reinforement Learning openAI PPO algo or Deep Neuroevolution or Hyperdimensional Computing theory(HBV) to put them inside our body for two way neuron wave collector device to interact with our neuron waves and send their info waves or thoughts waves to our device for ASI ops 
TODO: create a script for sql injection using ANN; use GyoiThon framework and related below github links ; also build a graph based todo app on top of AI using ~WOCAPP idea(the agent must understand you and tell you what job you have to do it now according to ur mood)
TODO: create a tool to decrypt all passwords algos using ANN(encrypt and crack all algos with ANN) ; create an agent to crack all apps and build the keygen
TODO: build an AI/RL based operating system called AIVO for my hacking and jabing purposes; os create the botnet itself; build a os to control the baseband and more things
TODO: Dapp creation like D-tube and steemit cuase it's new using below links and AI concepts: https://hackernoon.com/blockchain/home, https://storj.io/, https://ipfs.io/, https://github.com/ubirch/, https://sia.tech/, https://maidsafe.net/, https://filecoin.io/, https://www.mix-blockchain.org/, https://eos.io/
TODO: create a system for collage students those who their state is a little bit close to conditional situation but they passed all their courses in that semester; so we can help them by this system in order to give them either a conditional state or passed state by taking a process time for investigating and collecting big data about their manner, behavior, personality, efforts for each semester and other majors of their past life then mine those data using AI and let the AI say us what'll happen! (unixer gdrive slide)
TODO: app for mafia game using AI => it's a bot in which two main roles can randomly choose for the bot : the mafia and the police, if the bot is mafia then it can learn from the behavior of other palyers(mafia, police, nurse and etc...) in first rounds also it can learn the behavior of who are/were mafia too in order to play the best role as a mafia and kill other polices; if it's not mafia the it can learn from the behavior of other polices in couple of last rounds to play the best role as a police and kill the mafia. note: (there is no way to defeat this bot and kill it as a mafia or a police)
TODO: build a suicide bot to produce a noisy voice for ur vic according to the manner, behaviour, past life of vic and all emotions and sences that he/she got before using AI to send a disappinment waves to his ears
TODO: build smt like stem in upgrade movie and AI connect game(its header is below) technology using RL algos to read the mind(implement it in python or nodejs)
TODO: get your hand dirty in dapp(Ethereum dApp) creation and use blockchain in ur vocfu life style in ur wocfulab which is on top of AI
TODO: build ur own cafe(use javad information theory and maximal structure idea) in which u can order anything by thinking through a device(a two way neuron wave collector which it can put thoughts in your mind through its wave) based on blockchain(smart contract) iot(raspi and vocfu bag) and ml(data science and csr ; like using cnn for the surveillance camera of cafee)
TODO: build a civilization lab like west world using RL/ES/DN/simulation then push it in ur wocfulab ; also build THEND idea which is about appdev using AI and client brain(the client think with our device then the whole directory of the app and its structure with the best optimality solution(we can also use our own structure ; a compiler better than the MVC style which combine our logic and all queris in our ui file with our own language) will build for him/her which is either a web and desktop or mobile app ===>> ui framework for all browsers like vuetify or smt like firebase[bricks and typeacid force code] with ui paintintg idea for app ui[cnn(input :  pic of ui or drawing) -> rnn(output : html code with css)])
TODO: extend THEND idea in such a way that when you give a picture of your env to it it'll give the whole code of that env to you! 
TODO: AI based fia/museum smart music player feature using hadoop and parallelism concepts for its big data and data mining(WOCAB idea using nuxt + electron + pytorch + flutter + adobexd for ui) then push it on ur wocfulab
TODO: build an agents as a writer who wirtes drama for theater and give this drama to other agents to take part in it and play their own roles and acts better than human
TODO: build an app/hardware to change the voulume of the music accroding to the env noise using AI and also create a persion OCR to sell the kit in your stomegranate openlab shop
TODO: backdoor creation using ayncio , threading , raw socket , vocfu bag raspi hak5 tools and pytorch(tensorflow) RL blockchain IOT
TODO: Orcus scenarios bypassing using DoubleAgent(see below links for backdoor creation or backdoor bypassing using RL in pytorch)
TODO: all about tensors , graph & tree pathfinding and matrix/tensors in NLA and implement blockchain and iot on raspi(openwrt.org) using pytorch(AI) and a tpu/intel neural stick with a 3D printer on top of data science vs csr
TODO: malware detection using generative adversarial NN and malware training using DQN(DRL algos based on MDP framework and belman equation)
TODO: create a code to destroy and burn the hard and cpu using pytorch , assembly[bash terminal(nasm)] and python rop libs like struct(focus on CSA and OS concepts inside bash terminal through cmd)
TODO: maze , Tic-tac-toe , 2048 , sudoku , N-queens , RL/GA(ES/DN) and data science in health-care , rasol PDE article , smart notebook idea using ANN , poerty agent , sweetheartbot , mafia(implement on raspi stuff tools with blockchain on top of pytorch)
TODO: build an WILAM application on top of ML with python flask backend using keras and pytorch and nuxt electron express flutter dart package for its ui(look wocfulab.todo for more details) also buil AI LCMS(javad idea) using ML algos
TODO: javad maximal structure , echo talar and information theory RL ideas(article) to reinforce the NN to write our virus code based on given input information
TODO: red square , NQAgent.py , sudokuAgent.py , connect game , telbot using DRL(DQN)/RNNLM/NLP , ai.py ideas , wocfulab.todo on top of these goals(data science vs csr)
TODO: implement DQN improvement algorithms and RL algos on MDP based env(DQN.pdf inside AI folder) also use genetic algo(Evolutionary Strategy/Deep Neuroevolution) PPO as an alternative for RL and other RL algos along with probability/statistics concepts
TODO: pygame|arcade|tkinter|openAIgym , CNN VGG and opencv , GAN , SL/USL , DCGAN , DRL(DQN(DNN,DQL)|ES|PPO|DN|GA) , RNNLM , NLP(NLU) , RNN(LSTM)
TODO: IBPS app >> increase the beat of the given song by moving the time using RL eg: 3 beats increase per 30 secs
TODO: an async version of neural networks like each neuron is a Future object(Dart-lang)



use all articles and pdfs in UT folder for ANN and machine learning + create packer/encoder/crypter using ANN + use twitter db to build my dataset for NN in order to create a bot to comment on every post intelligently 
hack all the things(idea) using ANN[tensorflow ANN hacking + raspi] => write ur ideas with above links & AI DL ML ANN concepts
AI ML DL A(D)NN in penetration testing(read/use GyoiThon framework code and use BrainDamage code)
below ideas + wISn tech idea(write it down[hafez fall]) + my idea about blockchain vs cryptography & quantum computing (search on youtube videos)
connect to net without ISP direct connecting using ANN idea(DRL(DQN)) and other wifi radio waves; is more like MAC spoofing but what about the DNS(CCNA-Wireless-** **-Official-Cert-Guide pdfs to know the behaviour of 802.11 waves & signal course & use coding theory in this project & know all about ISP)
getting the neuron waves using quantum tech(quantum computer) or a device which can collect the neuron waves data without any sticking ways for my password cracking idea 
hack pos machine using sp reverse shell concept,teensy payload to upload client file in there and linux python or assembly lang or using ANN
hack trrafic light using my tools or using ANN
all iot projects with nodemcu raspi & raspi ANN tensorflow in hacking & python telbot to scraping websites & upload python code on pythonanywhere
eye ball movement to control computer screen using tensorflow RNN(above links)
nwd pedigree idea tech(search on youtube) => they can see the gift from their parents and we have to collect this big data and mine them to find a pattern between them using AI for creating a virus for a specific generation 
hack all the things(idea) using ANN[tensorflow ANN hacking + raspi] => write ur ideas with above links & AI DL ML ANN concepts
AI ML DL A(D)NN in penetration testing(read/use GyoiThon framework code and use BrainDamage code)
my other ideas in ai.py + wISn tech idea(write it down) + my idea about blockchain vs cryptography & quantum computing (youtube videos)
connect to net without ISP direct connecting using ANN idea and other wifi radios(CCNA-Wireless-** **-Official-Cert-Guide pdfs to know the behaviour of 802.11 waves & signal course)
getting the neuron waves using quantum tech(quantum computer) or a device which can collect the neuron waves data without any sticking ways for my password cracking idea 
hack pos machine using sp reverse shell concept,teensy payload to upload client file in there and linux python or assembly lang or using ANN
hack trrafic light using my tools or using ANN
eye ball movement to control computer screen using tensorflow RNN
dapp creation using ethereum stuffs like truffle and solidity



-example of iot and dapp using blockchain solidity cop and open source kits:
	IBM blockchain, telegram and blockchain based storage, youtube, books in WOShelf folder, pet-shop tutor(testrpc for local developement), ethereum blockchain, public and private blockchain
	pet-shop tutor source: http://truffleframework.com/tutorials/pet-shop
	scripting languages(truffle and ethereum stack => the BlockchainTech folder and CRYPTOGRAPHY_CRYPTANALYSIS section), use IPFS and python => decentralized and distributed storage
-example of iot, fraud detection system of a bank and shopstore or movie org using DB graph neo4j and big data_data mining concept and algorithms:
    youtube, books in WOShelf folder, neo4j browser or its app & scripting languages(nodejs and python), use IPFS and python => decentralized and distributed storage(BlockchainTech folder)
-build your cv using your ideas and their related technology by using p2p technology and its concept, algorithm and iot stuffs & devices
-my ideas using python in everything section:
    proof-of-Dreaming_Flow-idea|Build A Predictable Future Machine + its Dapp with ethereum stack:
    	programming languages: python +‌ ethereum stack
        CONCEPTS: simulation, iot concept, probabilistic 
        TODO: use presentation tools in my phone to control my conferences using the phone + also use airdroid to control the phone with my lap top on LAN
        TODO: find a good app to create my vocfu style slides for all about Machine/deep Learning(ANN) vs data mining in AI and my idearuning
        TOKNOW: understand the graphical computational model of Tensorflow and its ANN
        TOKNOW: data mining and big data concepts and their algorithms + matrices and graph concepts to know the entire algorithm + oneirology
        references: http://web.stanford.edu/class/cs20si/lectures/, http://cs224d.stanford.edu/lectures/, http://tensorflowbook.com/, https://www.youtube.com/watch?v=2Nih24Hy5ng
        references: http://www.tutdl.ir/blog/1396/04/25/%d8%af%d8%a7%d9%86%d9%84%d9%88%d8%af-%d8%a2%d9%85%d9%88%d8%b2%d8%b4-data-science-deep-learning-in-python/, 
        references: http://www.tutdl.ir/blog/1396/05/13/%d8%af%d8%a7%d9%86%d9%84%d9%88%d8%af-%d8%a2%d9%85%d9%88%d8%b2%d8%b4-python-for-data-science-and-machine-learning-bootcamp/, 
        references: http://www.tutdl.ir/blog/1396/08/12/%d8%af%d8%a7%d9%86%d9%84%d9%88%d8%af-%d8%a2%d9%85%d9%88%d8%b2%d8%b4-complete-guide-to-tensorflow-for-deep-learning-with-python/, 
        references: http://www.tutdl.ir/blog/1396/09/17/%d8%af%d8%a7%d9%86%d9%84%d9%88%d8%af-%d8%a2%d9%85%d9%88%d8%b2%d8%b4-the-complete-machine-learning-course-with-python/,
        references: https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html, https://www.pyimagesearch.com/2017/11/27/image-hashing-opencv-python/ 
        references: https://www.kdnuggets.com/2015/05/top-10-data-mining-algorithms-explained.html, https://www.springboard.com/blog/data-mining-python-tutorial/
        references: https://www.youtube.com/watch?v=DJjPzyo3osg, https://www.youtube.com/watch?v=XYk4Xtad0Bg, https://www.youtube.com/watch?v=AYhHJIAbNIg
        references: WOShelf books and TensorFlow For Machine Intelligence book, https://www.youtube.com/watch?v=BSpAWkQLlgM, https://www.youtube.com/watch?v=w1xNTLH1zlA
        tools: open source kits and hardwares(Raspberry Pi) to fire up the machine or maybe we want to use quantum computing machine
        tools: blockchain truffle COP to create contracts between dreams using their public address key 
        tools: ANN tensorFlow(python) for its machine(deep) learning in AI section to create images of objects and events in dream using recorded brain waves and reverse engineering 
        tools: graph DB neo4j(nodejs/python) to store all objects in every dream or we can use IPFS or storj => decentralized and distributed storage(BlockchainTech folder)
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    proof-of-Brain's_Password_Cracker-idea => Build A Device Like Specific Neurons Using ANN To Detect The Words & Phrases Or Read Whole Things Of Mind And Save Them In A Safe TXT File Or We Can Send Them By Wifi Or A New Protocol In A Second When User Is Typing The Credentials; User's Brain Must Know This Device As Our Arbitary(Specific) Neuron To Give The Data To Our
    Device Using Brain's And Device's Synapses, Maybe We Have To Use Quantum Computing Machine; we can use IPFS or storj => decentralized and distributed storage(BlockchainTech folder)
    	CONCEPTS: simulation, iot concept, probabilistic
    	programming languages: python + ethereum stack
	AI-TYPE : Artificial Super Intelligence
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    proof-of-Telegram_Sloving_Question_Bot-idea => Build A Telegram Bot To Solve An Specific Question From Its Picture And Send Us The Answer In A picture
    xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    proof-of-Doublegainer-idea => Build A Virtual Brain From The Real One Which Is The Human Brain In Order To Do All Remaining Stuffs And Works Of Human Life That Is related To Another BlockchainTechs + its Dapp with ethereum stack:
        CONCEPTS: simulation, iot concept, probabilistic
        TO NEED: we need a blockchain based storage like sia for our contracts between the human brain and the virtual one to store rapidly the data and transactions in blockchain
        programming languages: python + ethereum stack
        references: https://blog.sia.tech/how-to-put-data-on-the-sia-network-784499a65b, http://simpy.readthedocs.io/en/latest/simpy_intro/, https://pypi.python.org/pypi/simpy
        TODO: we can use IPFS or storj => decentralized and distributed storage(BlockchainTech folder)
        TODO: build a device to act like neuron to get the data from real brain using its synapses and send them to the virtual brain
        TODO: virtual brain must check the ownership of neuron device using its UUID or a unique behaviour address
        TODO: the virtual brain collect data into different categories like emotion works; logical works; anger works and so on using ANN or AI
        TODO: then virtual brain stores all categories which every category has its own works in our blockchain and all works have a public address in order to interact with each others and 		other categories using smart contracts with truffle and COP concept
        TODO: create your neural networks
        TODO: add citizen ship idea(AI blockchain based using smart contract with validithum as its crypto crurrency money to create a smart citizen and change the constitution)
        TODO: for its proof of work we have some systems for our users which are the nodes in our entire network and check two rules for the incoming data from our neuron device:
              check the ownership of virtual brain so every real brain must hav UUID(or a unique address of our neuron device stuck(later on we can use brain waves to detect the thoughts of real brain and send those waves to our virtual brain without using a neuron device) on users brain)
              either is a new or old data if is new it will added to the blockchain with its category and real brain info like its address and its waves; if is old the virtual brain must detect the rest of work or what was the final result of that using ANN or AI
        PURPOSE: we want to build another human not a robot ofcourse but a virtual brain which it will do all human works and make all human decisions according to the order of human real
        	     brain; the human brain must active the virtual mode with a kind of signal or some orders or some thoughts(brain waves thoughts)
        PURPOSE: this technology is usefull for interacting with other blockchain and distributed systems to have copy of a human brain and make presence of human less in computer world
        		 we can use it in mental payment system, book writing & create movie or make a new language from user's mind using ANN or AI concept to show the right concept of what he/she is thinking or imagining to the other people or other blockchain system finally write your about-me book!





---------------
SOURCES
---------------

medium.com/deep-math-machine-learning-ai/ch-13-deep-reinforcement-learning-deep-q-learning-and-policy-gradients-towards-agi-a2a0b611617e

pythonhealthcare.org/2018/10/01/94-genetic-algorithms-a-simple-genetic-algorithm/

heartbeat.fritz.ai/the-5-algorithms-for-efficient-deep-learning-inference-on-small-devices-bcc2d18aa806

infoworld.com/article/3394399/machine-learning-algorithms-explained.html

medium.com/@SmartLabAI/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc

medium.com/datadriveninvestor/math-neural-network-from-scratch-in-python-d6da9f29ce65

freecodecamp.org/news/building-a-neural-network-from-scratch/

mikulskibartosz.name/understanding-the-keras-layer-input-shapes/

mc.ai/lstm-with-keras/

stackoverflow.com/questions/44273249/in-keras-what-exactly-am-i-configuring-when-i-create-a-stateful-lstm-layer-wi

intellipaat.com/community/21811/multi-dimensional-input-for-lstm-in-keras

towardsdatascience.com/understanding-lstm-and-its-quick-implementation-in-keras-for-sentiment-analysis-af410fd85b47

towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45?source=post_recirc---------1------------------

towardsdatascience.com/machine-learning-recurrent-neural-networks-and-long-short-term-memory-lstm-python-keras-example-86001ceaaebc

machinelearningmastery.com/tutorial-first-neural-network-python-keras/

victorzhou.com/blog/intro-to-neural-networks/

github.com/PacktPublishing

github.com/makeyourownneuralnetwork/makeyourownneuralnetwork

github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing

digitalocean.com/community/tutorials/how-to-build-a-neural-network-to-recognize-handwritten-digits-with-tensorflow

cs231n.github.io/convolutional-networks/

missinglink.ai/guides/neural-network-concepts/convolutional-neural-network-build-one-keras-pytorch/

missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/

victorzhou.com/blog/intro-to-cnns-part-1/

victorzhou.com/blog/intro-to-cnns-part-2/

youtube.com/watch?v=IUn8k5zSI6g

youtube.com/watch?v=kE5QZ8G_78c

youtube.com/watch?v=EQZaSuK-PHs

youtube.com/watch?v=8dqdDEyzkFA

youtube.com/watch?v=sgL7RrqhGKI

medium.com/intuitive-deep-learning/intuitive-deep-learning-part-2-cnns-for-computer-vision-24992d050a27

medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8

deeplearningbook.org/

medium.com/intuitive-deep-learning/intuitive-deep-learning-part-4-deep-reinforcement-learning-d3b57f246bd8?source=collection_home---4------0-----------------------

stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw

towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e

towardsdatascience.com/understanding-neural-networks-19020b758230

youtube.com/watch?v=6g4O5UOH304

youtube.com/watch?v=wQ8BIBpya2k

youtube.com/watch?v=RznKVRTFkBY&list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL

youtube.com/watch?v=5qCDzaOUCWA

youtube.com/watch?v=7wy0jqJU8ts

youtube.com/watch?v=jJaG2ytJVQU

youtube.com/watch?v=nVvhkVLh60o&list=PLc2rvfiptPSR3iwFp1VHVJFK4yAMo0wuF

youtube.com/watch?v=OhIa2cnGD8Y

becominghuman.ai/cheat-sheets-for-ai-neural-networks-machine-learning-deep-learning-big-data-678c51b4b463

ml-cheatsheet.readthedocs.io/en/latest/

python-course.eu/neural_networks_with_python_numpy.php

neuralnetworksanddeeplearning.com/chap1.html

towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace

towardsdatascience.com/how-to-build-a-simple-neural-network-from-scratch-with-python-9f011896d2f3

towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d

towardsdatascience.com/feed-forward-neural-networks-c503faa46620

towardsdatascience.com/deep-learning-feedforward-neural-network-26a6705dbdc7

medium.com/beyond-intelligence/reinforcement-learning-or-evolutionary-strategies-nature-has-a-solution-both-8bc80db539b3

openai.com/blog/evolution-strategies/

github.com/harvitronix/neural-network-genetic-algorithm

medium.com/sigmoid/https-medium-com-rishabh-anand-on-the-origin-of-genetic-algorithms-fc927d2e11e0

groundai.com/project/unsupervised-user-identity-linkage-via-factoid-embedding/

towardsdatascience.com/build-a-handwritten-text-recognition-system-using-tensorflow-2326a3487cd5

arxiv.org/abs/1909.02487

emfexplained.info/?ID=25916

medium.com/@aallan/hands-on-with-the-coral-usb-accelerator-a37fcb323553

blog.hackster.io/getting-started-with-the-intel-neural-compute-stick-2-and-the-raspberry-pi-6904ccfe963

towardsdatascience.com/malware-detection-using-deep-learning-6c95dd235432

youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A

towardsdatascience.com/spiking-neural-networks-the-next-generation-of-machine-learning-84e167f4eb2b

youtube.com/watch?v=z8DY5DndmxI

appliedmachinelearning.blog/2019/03/04/state-of-the-art-text-classification-using-bert-model-predict-the-happiness-hackerearth-challenge/

kaggle.com/httpwwwfszyc/bert-keras-with-warmup-and-excluding-wd-parameters

youtube.com/watch?v=ycXWAtm22-w

medium.com/predict/creating-a-chatbot-from-scratch-using-keras-and-tensorflow-59e8fc76be79

towardsdatascience.com/deep-learning-for-nlp-creating-a-chatbot-with-keras-da5ca051e051

towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270

blog.cambridgespark.com/tutorial-build-your-own-embedding-and-use-it-in-a-neural-network-e9cde4a81296

jjallaire.github.io/deep-learning-with-r-notebooks/notebooks/6.1-using-word-embeddings.nb.html

analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/

medium.com/@sabber/classifying-yelp-review-comments-using-cnn-lstm-and-pre-trained-glove-word-embeddings-part-3-53fcea9a17fa

machinelearningmastery.com/use-different-batch-sizes-training-predicting-python-keras/

youtube.com/watch?v=1XRahNzA5bE

youtube.com/watch?v=VO1mCjHvzlo

youtube.com/watch?v=WxQfQW48A4A

youtube.com/watch?v=3begG_s9lzg

youtube.com/watch?v=lehLSoMPmcM&t=2s

youtube.com/watch?v=UvdWDcbAY7M

towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-part-ii-trpo-ppo-87f2c5919bb9

github.com/openai/baselines

towardsdatascience.com/paper-repro-deep-neuroevolution-756871e00a66

aqibsaeed.github.io/2017-08-11-genetic-algorithm-for-optimizing-rnn/

adventuresinmachinelearning.com/gensim-word2vec-tutorial/

adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/

adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/

sciencedaily.com/releases/2019/07/190701163827.htm

sciencedaily.com/releases/2019/07/190702160115.htm

sciencedaily.com/releases/2019/06/190625093304.htm

machinelearningmastery.com/5-step-life-cycle-long-short-term-memory-models-keras/

machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/

machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/

medium.com/@shivajbd/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e

medium.com/@ageitgey/natural-language-processing-is-fun-part-3-explaining-model-predictions-486d8616813c

machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/

medium.com/appening-io/emotion-classification-2d4ed93bf4e2

machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/

missinglink.ai/guides/deep-learning-frameworks/keras-conv1d-working-1d-convolutional-neural-networks-keras/

kdnuggets.com/2018/04/implementing-deep-learning-methods-feature-engineering-text-data-skip-gram.html

github.com/saitejdandge/Sentimental_Analysis_LSTM_Conv1D/

kaggle.com/eray1yildiz/using-lstms-with-attention-for-emotion-recognition/notebook

towardsdatascience.com/word2vec-made-easy-139a31a4b8ae

towardsdatascience.com/sentiment-analysis-for-text-with-deep-learning-2f0a0c6472b5

medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714

medium.com/mlreview/the-intuition-behind-adversarial-attacks-on-neural-networks-71fdd427a33b

towardsdatascience.com/sentiment-analysis-using-lstm-step-by-step-50d074f09948

towardsdatascience.com/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456

machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/

liip.ch/en/blog/sentiment-detection-with-keras-word-embeddings-and-lstm-deep-learning-networks

medium.com/coinmonks/text-classifier-with-keras-tensorflow-using-recurrent-neural-networks-ad63dd5fc316

realpython.com/python-keras-text-classification/

medium.com/explore-artificial-intelligence/

word2vec-a-baby-step-in-deep-learning-but-a-giant-leap-towards-natural-language-processing-40fe4e8602ba

towardsdatascience.com/understanding-neural-networks-from-neuron-to-rnn-cnn-and-deep-learning-cd88e90e0a90

medium.com/@jonathan_hui/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b

medium.com/sciforce/nlp-vs-nlu-from-understanding-a-language-to-its-processing-1bf1f62453c1

medium.com/@jatinmandav3/digit-recognition-using-tensorflow-a3eb186a28d3

medium.com/machine-learning-algorithms/mnist-using-recurrent-neural-network-2d070a5915a2

towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b

mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/

medium.com/@jayeshbahire/introduction-to-word-vectors-ea1d4e4b84bf

medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148

medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09

towardsdatascience.com/word2vec-a-baby-step-in-deep-learning-but-a-giant-leap-towards-natural-language-processing-40fe4e8602ba

medium.com/explore-artificial-intelligence/an-introduction-to-recurrent-neural-networks-72c97bf0912

towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa

towardsdatascience.com/recurrent-neural-networks-for-language-understanding-10c649f8ac15

towardsdatascience.com/natural-language-processing-from-basics-to-using-rnn-and-lstm-ef6779e4ae66

blog.goodaudience.com/artificial-neural-networks-explained-436fcf36e75

medium.com/datadriveninvestor/neural-networks-explained-6e21c70d7818

towardsdatascience.com/first-neural-network-for-beginners-explained-with-code-4cfd37e06eaf

towardsdatascience.com/what-are-the-types-of-machine-learning-e2b9e5d1756f

towardsdatascience.com/recurrent-neural-networks-and-natural-language-processing-73af640c2aa1

sas.com/en_us/insights/analytics/what-is-natural-language-processing-nlp.html

towardsdatascience.com/natural-language-processing-nlp-for-machine-learning-d44498845d5b

machinelearningmastery.com/natural-language-processing/

medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e

blog.algorithmia.com/introduction-natural-language-processing-nlp/

searchbusinessanalytics.techtarget.com/definition/natural-language-processing-NLP

becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32

kdnuggets.com/2018/03/5-things-reinforcement-learning.html

mc.ai/understanding-input-and-output-shape-in-lstm-keras/

medium.com/analytics-vidhya/understanding-genetic-algorithms-in-the-artificial-intelligence-spectrum-7021b7cc25e7

ai.stackexchange.com/questions/7721/how-does-lstm-in-deep-reinforcement-learning-differ-from-experience-replay

colab.research.google.com/drive/1p51HFDExl7XagWfSQE5leDQwBC6I_e3D

colab.research.google.com/drive/14I-31WuynLg1B0RQHWwwRgBmqTlDgkwV

microsoft.com/developerblog/2015/11/29/emotion-detection-and-recognition-from-text-using-deep-learning/

psychologytoday.com/us/blog/the-future-brain/201904/neuroscientists-transform-brain-activity-speech-ai

theregister.co.uk/2019/01/30/ai_brain_reader/

wired.com/story/ml-brain-boost/

infoq.com/news/2019/03/deep-learning-speech-brain/

newatlas.com/brain-signals-into-speech-algorithm/58253/

digitaltrends.com/cool-tech/ai-thought-to-speech/

towardsdatascience.com/a-beginners-guide-to-brain-computer-interface-and-convolutional-neural-networks-9f35bd4af948

towardsdatascience.com/from-brain-waves-to-arm-movements-with-deep-learning-an-introduction-3c2a8b535ece

sciencemag.org/news/2019/01/artificial-intelligence-turns-brain-activity-speech

eng.umd.edu/release/helping-robots-remember-hyperdimensional-computing-theory-could-change-the-way-ai-works

futurity.org/brain-computer-interface-robotic-arm-2088502/

futurity.org/deepfake-videos-detection-computer-vision-2088302/

becominghuman.ai/neural-networks-for-solving-differential-equations-fa230ac5e04c

scialert.net/fulltextmobile/?doi=jas.2007.2812.2817

techworld.com/tech-innovation/what-is-catastrophic-forgetting-how-does-it-affect-ai-development-3687007/

medium.com/@AIerusalem/catastrophic-importance-of-catastrophic-forgetting-c1c2a245a662

forbes.com/sites/federicoguerrini/2017/05/08/new-deep-learning-system-allows-ai-to-solve-catastrophic-forgetting-problem/

pnas.org/content/114/13/3521

qz.com/933223/deepmind-developed-an-artificial-intelligence-algorithm-to-tackle-catastrophic-forgetting/

telegraph.co.uk/technology/2017/03/15/googles-deepmind-ai-learns-like-human-overcome-catastrophic/

indico.io/blog/recognizing-emotion-in-text-machine-learning-no-code/

paulvangent.com/2016/04/01/emotion-recognition-with-python-opencv-and-a-face-dataset/

kdnuggets.com/2018/08/emotion-sentiment-analysis-practitioners-guide-nlp-5.html

tensorflow.org/tutorials/non-ml/pdes

csirtgadgets.com/commits/2018/8/17/hunting-for-malicious-connections-using-python-and-tensorflow

medium.com/@radicalrafi/untitled-document-md-87f85d658a9a

github.com/PacktPublishing/Mastering-Machine-Learning-for-Penetration-Testing

github.com/AFAgarap/malware-classification

dzone.com/articles/malware-detection-with-convolutional-neural-networ

github.com/AFAgarap/malware-classification

evilsocket.net/2019/05/22/How-to-create-a-Malware-detection-system-with-Machine-Learning/

towardsdatascience.com/understanding-generative-adversarial-networks-4dafc963f2ef

becominghuman.ai/genetic-algorithm-for-reinforcement-learning-a38a5612c4dc

pastebin.com/ZZmSNaHX

analytics-link.com/single-post/2019/02/14/Password-Cracking-with-a-Genetic-Algorithm

onlinelibrary.wiley.com/doi/abs/10.1002/cjce.23350

towardsdatascience.com/evolution-of-a-salesman-a-complete-genetic-algorithm-tutorial-for-python-6fe5d2b3ca35

youtube.com/watch?v=Pls_q2aQzHg

medium.com/predict/a-step-towards-agi-the-story-of-alphago-e0fafd83e6b9

deepmind.com/research/alphago/

towardsdatascience.com/gas-and-nns-6a41f1e8146d

towardsdatascience.com/artificial-neural-networks-optimization-using-genetic-algorithm-with-python-1fe8ed17733e

blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164

medium.com/analytics-vidhya/the-scuffle-between-two-algorithms-neural-network-vs-support-vector-machine-16abe0eb4181

youtube.com/watch?v=1NxnPkZM9bc

youtube.com/watch?v=j_pJmXJwMLA

colah.github.io/posts/2015-08-Understanding-LSTMs/

skymind.ai/wiki/lstm

towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0

medium.com/datadriveninvestor/recurrent-neural-networks-and-long-short-term-memory-5d17bdbdfc00

analyticsvidhya.com/blog/2018/07/evolutionary-algorithm-perfect-useful-alternative-neural-network/

innovationtoronto.com/2019/02/engineers-create-a-robot-that-can-imagine-itself/

techxplore.com/news/2019-05-recreate-human-like-machines.html

techxplore.com/news/2019-05-robots-hyperdimensional-theory-ai.html

techxplore.com/news/2019-05-ai-taught-video-game-beatinghumans.html

robotics.sciencemag.org/content/4/30/eaaw6736

sciencedaily.com/releases/2019/05/190515165455.htm

techxplore.com/news/2019-05-algorithm-people-pictures-videos-faster.html

techxplore.com/news/2018-10-developmental-framework-robots-optimize-hyper-parameters.html

techxplore.com/news/2018-10-brain-inspired-algorithm-ai-multitask.html

techxplore.com/news/2019-03-memory-approach-enable-lifelong.html

sri.com/work/projects/artificial-intelligence-system-continually-learns

techxplore.com/news/2019-03-memory-approach-enable-lifelong.html

techxplore.com/news/2019-05-framework-artificial-intelligence.html

phys.org/news/2019-06-machine-sensors.html

youtube.com/watch?v=zUCoxhExe0o

nanowerk.com/news2/robotics/newsid=52814.php?utm_source=feedblitz&utm_medium=FeedBlitzRss&utm_campaign=nanowerkemergingtechnologiesnews

scitecheuropa.eu/hyperdimensional-computing-theory-robots-memory/95060/

bigthink.com/technology-innovation/discovery-ai-robots-create-memories

innovationtoronto.com/2019/05/hyperdimensional-computing-theory-could-change-the-way-ai-works-by-helping-robots-to-remember/

thenextweb.com/artificial-intelligence/2019/05/17/hyperdimensional-computing-theory-could-lead-to-ai-with-memories-and-reflexes/

allaboutcircuits.com/news/artificial-intelligence-memory-basics-of-hyperdimensional-computing/

enlight.nyc/projects/neural-network/

youtube.com/watch?v=2rDkQWi-RA4&t=666s

youtube.com/watch?v=DWsJc1xnOZo

theverge.com/2019/1/28/18194816/ai-artificial-intelligence-issue

app.sndbox.com/login

youtu.be/kqSzLo9fenk

towardsdatascience.com/an-easy-introduction-to-unsupervised-learning-with-4-basic-techniques-897cb81979fd

blog.openai.com/evolution-strategies/

medium.com/@benjamin.phillips22/evolution-strategies-as-a-scalable-alternative-to-reinforcement-learning-paper-summary-691161b52ddd

flyyufelix.github.io/2018/06/11/sonic-rl.html

towardsdatascience.com/deploying-a-keras-deep-learning-model-as-a-web-application-in-p-fc0f2354a7ff

towardsdatascience.com/deep-neuroevolution-genetic-algorithms-are-a-competitive-alternative-for-training-deep-neural-822bfe3291f5

github.com/topics/unsupervised-learning

github.com/mindis/002_MachineLearning_eBook

analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/

stats.stackexchange.com/questions/184657/what-is-the-difference-between-off-policy-and-on-policy-learning

pytorch.org

leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/

youtube.com/watch?v=nSxaG_Kjw_w 

datascience.stackexchange.com/questions/38845/what-is-the-relationship-between-mdp-and-rl

stats.stackexchange.com/questions/34357/q-learning-in-a-stochastic-environment

github.com/CodeReclaimers/neat-python/tree/master/examples/single-pole-balancing

cs.cmu.edu/~avrim/courses.html

cs.cmu.edu/~avrim/

stats.stackexchange.com/questions/336974/when-are-monte-carlo-methods-preferred-over-temporal-difference-ones

datascience.stackexchange.com/questions/26471/is-my-understanding-of-on-policy-and-off-policy-td-algorithms-correct

quora.com/Does-Deep-Q-learning-use-Monte-Carlo-tree-search

medium.com/deep-math-machine-learning-ai/ch-12-1-model-free-reinforcement-learning-algorithms-monte-carlo-sarsa-q-learning-65267cb8d1b4

becominghuman.ai/machines-demonstrate-self-awareness-8bd08ceb1694

github.com/13o-bbr-bbq/machine_learning_security/tree/master/DeepExploit

github.com/cchio/deep-pwning

github.com/13o-bbr-bbq/machine_learning_security

github.com/gyoisamurai/GyoiThon

github.com/src-d/awesome-machine-learning-on-source-code

github.com/jivoi/awesome-ml-for-cybersecurity

github.com/zhexxian/From-Machine-Learning-To-Zero-Day-Exploits

github.com/philipperemy/deep-learning-bitcoin

github.com/RandomAdversary/Awesome-AI-Security

github.com/Hack-with-Github/Awesome-Hacking

python-course.eu/graphs_python.php

jeremyjordan.me/rl-learning-methods/

en.wikibooks.org/wiki/Artificial_Intelligence/AI_Agents_and_their_Environments

youtube.com/watch?v=CIfsB_EYsVI

youtube.com/watch?v=IxQtK2SjWWM

youtube.com/watch?v=lvoHnicueoE&t=88s

youtube.com/watch?v=OYhFoMySoVs

youtube.com/watch?v=fIKkhoI1kF4

youtube.com/watch?v=iLNHVwSu9EA

youtube.com/watch?v=C14VDpGAbSE

youtube.com/watch?v=1g1HCYTX3Rg

youtube.com/watch?v=miPyFmr4iCc

quora.com/What-are-the-different-types-of-Machine-Learning-Algorithms

stackoverflow.com/questions/26182980/can-anyone-give-a-real-life-example-of-supervised-learning-and-unsupervised-lear

towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d

analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/

github.com/Kyushik/DRL

github.com/Kaixhin/Rainbow

outlace.com/rlpart3.html

github.com/keras-rl/keras-rl

github.com/endgameinc/gym-malware

github.com/keras-team/keras/tree/master/examples

yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html

pastebin.com/ZZmSNaHX

gym.openai.com/evaluations/eval_ujFWHmoqSniDh8cErKCVpA/

github.com/mymultiverse/GeneticAlgo_OpenAIGymCartPole

github.com/HackerShackOfficial/OpenAI-NEAT

towardsdatascience.com/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0

medium.com/@xbno/openai-gym-and-evolutionary-models-5232fd94226d

becominghuman.ai/genetic-algorithm-for-reinforcement-learning-a38a5612c4dc

github.com/vmayoral/basic_reinforcement_learning/blob/master/tutorial5/evolutionary-ann-cartpole.py

github.com/topics/genetic-algorithm?l=python&o=desc&s=stars

dzone.com/articles/beating-atari-games-with-openais-evolutionary-stra

youtube.com/watch?v=RznKVRTFkBY&list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL

youtube.com/watch?v=edIMMTL2jlw&list=PLVBorYCcu-xX3Ppjb_sqBd_Xf6GqagQyl

becominghuman.ai/lets-build-an-atari-ai-part-1-dqn-df57e8ff3b26

medium.com/@jonathan_hui/rl-dqn-deep-q-network-e207751f7ae4

towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c

medium.freecodecamp.org/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682

skymind.ai/wiki/generative-adversarial-network-gan

towardsdatascience.com/generative-adversarial-networks-explained-34472718707a

medium.freecodecamp.org/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394

lexalytics.com/lexablog/machine-learning-vs-natural-language-processing-part-1

medium.com/machine-learning-in-practice/over-200-of-the-best-machine-learning-nlp-and-python-tutorials-2018-edition-dd8cf53cb7dc

medium.com/cityai/deep-learning-for-natural-language-processing-part-i-8369895ffb98

machinelearningmastery.com/deep-learning-for-nlp/

towardsdatascience.com/using-nlp-and-deep-learning-to-predict-the-stock-market-64eb9229e102

studywolf.wordpress.com/2013/07/01/reinforcement-learning-sarsa-vs-q-learning/

cse.unsw.edu.au/~cs9417ml/RL1/index.html

studywolf.wordpress.com/2012/11/25/reinforcement-learning-q-learning-and-exploration/

medium.com/swlh/introduction-to-reinforcement-learning-coding-sarsa-part-4-2d64d6e37617

yanpanlau.github.io/2016/10/11/Torcs-Keras.html

medium.freecodecamp.org/how-to-build-an-ai-game-bot-using-openai-gym-and-universe-f2eb9bfbb40a

medium.com/@jonathan_hui/rl-basics-algorithms-and-terms-ae98314851d7

towardsdatascience.com/reinforcement-learning-demystified-markov-decision-processes-part-1-bf00dda41690

sandipanweb.wordpress.com/2017/03/24/solving-4-puzzles-with-reinforcement-learning-q-learning-in-python/

medium.com/@asierarranz/decentralized-supervised-neural-network-on-the-blockchain-giving-mining-a-good-purpose-3e64888caa

medium.com/beyond-intelligence/reinforcement-learning-or-evolutionary-strategies-nature-has-a-solution-both-8bc80db539b3

towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287

medium.freecodecamp.org/using-machine-learning-to-predict-the-quality-of-wines-9e2e13d7480d

blog.openai.com/openai-baselines-ppo/

medium.com/@m.alzantot/deep-reinforcement-learning-demysitifed-episode-2-policy-iteration-value-iteration-and-q-978f9e89ddaa

towardsdatascience.com/build-your-own-convolution-neural-network-in-5-mins-4217c2cf964f

studywolf.wordpress.com/2013/07/01/reinforcement-learning-sarsa-vs-q-learning/

medium.com/@AdrienLE/lets-build-an-atari-ai-part-0-intro-to-rl-9b2c5336e0ec

towardsdatascience.com/using-nlp-and-deep-learning-to-predict-the-stock-market-64eb9229e102

machinelearningmastery.com/deep-learning-for-nlp/

medium.com/cityai/deep-learning-for-natural-language-processing-part-i-8369895ffb98

medium.com/machine-learning-in-practice/over-200-of-the-best-machine-learning-nlp-and-python-tutorials-2018-edition-dd8cf53cb7dc

lexalytics.com/lexablog/machine-learning-vs-natural-language-processing-part-1

medium.freecodecamp.org/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394

towardsdatascience.com/generative-adversarial-networks-explained-34472718707a

skymind.ai/wiki/generative-adversarial-network-gan

researchgate.net/publication/224089748_Malware_detection_using_machine_learning

github.com/Kaixhin/Rainbow

github.com/endgameinc/gym-malware

github.com/Kyushik/DRL 

medium.com/@jonathan_hui/rl-dqn-deep-q-network-e207751f7ae4

becominghuman.ai/lets-build-an-atari-ai-part-1-dqn-df57e8ff3b26

becominghuman.ai/beat-atari-with-deep-reinforcement-learning-part-2-dqn-improvements-d3563f665a2c

blog.google/technology/ai/alphago-machine-learning-game-go/

nature.com/articles/nature16961

medium.freecodecamp.org/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682

sigmoidal.io/boosting-your-solutions-with-nlp/

github.com/JannesKlaas/sometimes_deep_sometimes_learning/blob/master/reinforcement.ipynb

youtube.com/watch?v=3bhP7zulFfY

medium.freecodecamp.org/deep-reinforcement-learning-where-to-start-291fb0058c01

magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning

github.com/MattChanTK/gym-maze

github.com/ChintanTrivedi/DeepGamingAI_FIFARL

github.com/keon/deep-q-learning/blob/master/dqn.py

youtube.com/watch?v=FmpDIaiMIeA

blog.coast.ai/lets-evolve-a-neural-network-with-a-genetic-algorithm-code-included-8809bece164

medium.com/@gtnjuvin/my-journey-into-deep-q-learning-with-keras-and-gym-3e779cc12762

medium.com/@yashpatel_86510/reinforcement-learning-w-keras-openai-698add10b4eb

github.com/keon/deep-q-learning

keon.io/deep-q-learning/

yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html

youtube.com/watch?v=A5eihauRQvo

youtube.com/watch?v=79pmNdyxEGo

medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3

youtube.com/watch?v=0Zuqytgf6yY

medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721

youtube.com/watch?v=pieI7rOXELI&list=PLXO45tsB95cIplu-fLMpUEEZTwrDNh6Ba

youtube.com/watch?v=2pWv7GOvuf0&list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT

youtube.com/watch?v=wQ8BIBpya2k&list=PLQVvvaa0QuDfhTox0AjmQ6tvTgMBZBEXN

medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0

ml-cheatsheet.readthedocs.io/en/latest/forwardpropagation.html#dynamic-resizing

datascience.stackexchange.com/questions/27421/when-are-weights-updated-in-cnn

towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795

medium.freecodecamp.org/diving-deeper-into-reinforcement-learning-with-q-learning-c18d0db58efe

adventuresinmachinelearning.com/keras-lstm-tutorial/

medium.com/deep-learning-101/how-to-generate-a-video-of-a-neural-network-learning-in-python-62f5c520e85c

blog.coast.ai/using-reinforcement-learning-in-python-to-teach-a-virtual-car-to-avoid-obstacles-6e782cc7d4c6

blog.coast.ai/reinforcement-learning-in-python-to-teach-a-virtual-car-to-avoid-obstacles-part-2-93e614fcd238

blog.coast.ai/reinforcement-learning-in-python-to-teach-an-rc-car-to-avoid-obstacles-part-3-a1d063ac962f

adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/

adventuresinmachinelearning.com/reinforcement-learning-tutorial-python-keras/

activestate.com/blog/2017/05/building-game-ai-using-machine-learning-working-tensorflow-keras-and-intel-mkl-python

pyimagesearch.com/2017/12/18/keras-deep-learning-raspberry-pi/

medium.com/@datamonsters/artificial-neural-networks-for-natural-language-processing-part-1-64ca9ebfa3b2

medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0

github.com/yanpanlau/Keras-FlappyBird

ai.intel.com/demystifying-deep-reinforcement-learning/

github.com/yenchenlin/DeepLearningFlappyBird

medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8

youtube.com/watch?v=Aut32pR5PQA => genetic algorithm

stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc

medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0

towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f

blog.goodaudience.com/artificial-neural-networks-explained-436fcf36e75

becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8

youtube.com/watch?v=JcI5Vnw0b2c&index=2&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v

youtube.com/watch?v=wQ8BIBpya2k

youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=1

towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6

quora.com/How-do-artificial-neural-networks-work

medium.freecodecamp.org/an-introduction-to-reinforcement-learning-4339519de419

enlight.nyc/projects/neural-network/

appdividend.com/2018/07/23/prepare-dataset-for-machine-learning-in-python/

github.com/SpiderLabs/social_mapper => read its code to build smt like social_mapper with AI but more powerfull than that

theverge.com/2018/8/8/17663640/socialmapper-facial-recognition-open-source-intelligence

thehackernews.com/2018/08/artificial-intelligence-malware.html

thehackernews.com/2018/08/social-mapper-osint.html

github.com/tensorflow/cleverhans

youtube.com/watch?v=fm8MGPKgUPk

youtube.com/watch?v=_U146hWhDhM

youtube.com/watch?v=m2w_FCba8TY&list=PLnNF__MXrUQy7Stv8sc4U7pyjf7oNk0tl

youtube.com/watch?v=XZkiuWOf8TI&list=PLVRZqxcZ5vU9J0Wh4Lsh3mGguZuJm7hKw

youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A/playlists

youtube.com/watch?v=b81Ib_oYbFk

youtube.com/watch?v=F0njE7D22SI

stackoverflow.com/questions/44429742/need-reference-of-opencv-python-for-age-and-gender-detection-on-video-stream

github.com/BoyuanJiang/Age-Gender-Estimate-TF

github.com/dpressel/rude-carnie

gizmodo.com/hackers-have-already-started-to-weaponize-artificial-in-1797688425

aitrends.com/ai-insider/ai-deep-learning-backdoor-security-holes-self-driving-cars-detection-prevention/

theregister.co.uk/2017/12/20/fool_ai_facial_recognition_poison/

forbes.com/sites/ajagrawal/2017/08/01/how-to-use-artificial-intelligence-to-growth-hack-social-engagement/#4cb592f318c9

resources.infosecinstitute.com/criminals-can-exploit-ai/

analyticsvidhya.com/blog/2017/02/6-deep-learning-applications-beginner-python/

oscaralsing.com/automated-tinder-using-artificial-intelligence/

hackernoon.com/what-leading-artificial-intelligence-course-should-you-take-and-what-should-you-do-after-261a933bb3da

motherboard.vice.com/en_us/article/ev8gx4/were-teaming-up-with-the-plug-a-daily-newsletter-on-black-entrepreneurs-in-tech

letzgro.net/blog/creating-ai-using-python/

aibusiness.com/ai-researchers-develop-backdoor-security-threat/

ieeexplore.ieee.org/document/6086325/

wired.com/story/machine-learning-backdoors/

bleepingcomputer.com/news/security/ai-training-algorithms-susceptible-to-backdoors-manipulation/

qz.com/1061560/researchers-built-an-invisible-back-door-to-hack-ais-decisions/

contest-2017.korelogic.com/

medium.com/@curiousily/tensorflow-for-hackers-part-i-basics-2c46bc99c930

medium.com/mindorks/detection-on-android-using-tensorflow-a3f6fe423349

hackernoon.com/finding-the-genre-of-a-song-with-deep-learning-da8f59a61194

mentalhealthdaily.com/2014/04/15/5-types-of-brain-waves-frequencies-gamma-beta-alpha-theta-delta/

hackernoon.com/everything-you-need-to-know-about-neural-networks-8988c3ee4491

cointelegraph.com/news/blockchain-based-artificial-neural-networks-to-save-thousands-of-lives-from-medical-errors

youtube.com/results?search_query=ANN+exploiting+in+python

youtube.com/watch?v=gWfVwnOyG78&list=PLnjEM1fs09cE7SAFuvU1URVgbBgXZnNmF

youtube.com/watch?v=hENZrj0qxqg&list=PLnjEM1fs09cGQvwi-HQGB9hz-v-cWJBv3

youtube.com/watch?v=oxf3o8IbCk4

youtube.com/watch?v=gplTc2F5Wvk

quora.com/Is-it-possible-to-access-the-Internet-without-an-ISP?share=1

quora.com/How-can-you-access-the-internet-without-an-ISP?share=1

abovetopsecret.com/forum/thread1021068/pg1

youtube.com/watch?v=PWLffkqw_yY

medium.com/ethereum-dapp-builder/blockchain-and-how-to-create-a-dapp-daa1a548ff51

hackernoon.com/7-blockchain-web-development-tools-that-will-grow-your-stack-3d854f1cb9bf

medium.com/@reputaction/decentralized-application-dapp-platform-selection-c7790ea74bce

youtu.be/6g4O5UOH304

youtu.be/45MbmHQ5iMY

youtube.com/playlist?list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN

youtu.be/Y1-hQdgftMQ

youtube.com/playlist?list=PLVBorYCcu-xX3Ppjb_sqBd_Xf6GqagQyl

youtu.be/XNKeayZW4dY

youtu.be/2-Ol7ZB0MmU

youtu.be/umGJ30-15_A

youtu.be/H-HVZJ7kGI0

youtube.com/playlist?list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL

youtu.be/8HyCNIVRbSU

youtu.be/Vz5l886eptw

youtube.com/playlist?list=PLQVvvaa0QuDezJFIOU5wDdfy4e9vdnx-7

youtu.be/yMk_XtIEzH8

youtu.be/nSxaG_Kjw_w

youtube.com/playlist?list=PLZbbT5o_s2xoWNVdDudn51XM8lOuZ_Njv

youtu.be/LzaWrmKL1Z4

youtu.be/ELE2_Mftqoc

youtu.be/iMIWee_PXl8

youtu.be/z-EtmaFJieY

youtu.be/VB1ZLvgHlYs

youtu.be/y7qrilE-Zlc

youtu.be/6g4O5UOH304

youtu.be/FmpDIaiMIeA

youtu.be/fv6Qll3laUU

youtu.be/vpc35rBs_Bc

youtu.be/WCUNPb-5EYI

youtu.be/GvQwE2OhL8I

youtu.be/ILsA4nyG7I0

youtu.be/YRhxdVk_sIs

youtube.com/playlist?list=PL-XeOa5hMEYz7xMckkUL8w2EKzM3TDrON

youtu.be/5WPSecXkQ3U

youtu.be/9f-GarcDY58

youtu.be/b2q5OFtxm6A

youtu.be/mWxhsBFatvA

youtu.be/EWmCkVfPnJ8

youtu.be/5B_aWK_MSi0

youtu.be/O5sx1PSG8oU

youtu.be/8v383l45PZs

youtu.be/7aknmJMEXK4

youtu.be/9dFhZFUkzuQ

youtu.be/xtOg44r6dsE
'''#!/usr/bin/env python
# -*- coding: utf-8 -*-
r"""Provide Bayesian Neural Networks.

This file provides Bayesian neural networks which add uncertainty to the the prediction of NNs. In a bayesian neural
network, the weights and biases have a prior probability distribution attached to them. The posterior distribution on
these parameters is computed after training the model on some data.

Several approaches to learning Bayesian neural networks have been proposed in the literature:
- Laplace approximation [5,4]
- Monte Carlo
- MC Dropout [8,9]
- Variational Inference (Bayes by Backprop [7,10])

References:
    [1] "Deep Learning" (http://www.deeplearningbook.org/), Goodfellow et al., 2016
    [2] PyTorch: https://pytorch.org/
    [3] Pyro: https://pyro.ai/
    [4] "Pattern Recognition and Machine Learning" (section 5.7), Bishop, 2006
    [5] "Practical Bayesian Framework for Backpropagation Networks", MacKay, 1992
        (https://authors.library.caltech.edu/13793/1/MACnc92b.pdf)
    [6] "Bayesian Learning for Neural Networks" (PhD thesis), Neal, 1995
        (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&rep=rep1&type=pdf)
    [7] "Weight Uncertainty in Neural Networks", Blundell et al., 2015 (https://arxiv.org/abs/1505.05424)
    [8] "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning", Gal et al., 2015
        (https://arxiv.org/abs/1506.02142  and   appendix: https://arxiv.org/abs/1506.02157)
    [9] "Uncertainty in Deep Learning" (PhD thesis), Gal, 2016
    [10] "A Comprehensive guide to Bayesian Convolutional Neural Network with Variational Inference", Shridhar et al.,
        2019 (https://arxiv.org/pdf/1901.02731.pdf)
    [11] Blog post: "Making your Neural Network Say 'I Don't Know' - Bayesian NNs using Pyro and PyTorch":
        https://towardsdatascience.com/making-your-neural-network-say-i-dont-know-bayesian-nns-using-pyro-and-pytorch\
        -b1c24e6ab8cd

Interesting implementations:
- https://github.com/kumar-shridhar/PyTorch-BayesianCNN
- https://github.com/anassinator/bnn
- https://github.com/paraschopra/bayesian-neural-network-mnist
"""

import torch

from pyrobolearn.models.nn.dnn import NN

__author__ = "Brian Delhaisse"
__copyright__ = "Copyright 2018, PyRoboLearn"
__credits__ = ["Brian Delhaisse"]
__license__ = "GNU GPLv3"
__version__ = "1.0.0"
__maintainer__ = "Brian Delhaisse"
__email__ = "briandelhaisse@gmail.com"
__status__ = "Development"


# TODO: implement
class BNN(NN):
    r"""Bayesian Neural Networks"""
    pass
# -*- coding: utf-8 -*-
import yaml
from collections import defaultdict
from jinja2 import Template
import codecs  # enforce "utf-8" coding when reading files
import os


def dict_from_collection(collection):
    """
    This function is purely for debugging purpose, and is not used in this python script.

    extract a menu dict from the Jekyll yaml collection
    example input:  {'ReadingNotes_Book_NeuralNetworksAndDeepLearning': {'output': True,
    'permalink': '/ReadingNotes/Book_NeuralNetworksAndDeepLearning/:path'},
    'ReadingNotes_test': {'output': True, 'permalink': '/ReadingNotes/test/:path'}}
    example output: {'ReadingNotes': ['Book_NeuralNetworksAndDeepLearning', 'test']}
    """
    menus = defaultdict(list)
    menu_name_en = ""
    menu_iterm = ""
    for k, v in collection.iteritems():
        menu_name_en = v['permalink'].split('/')[1]
        menu_iterm = v['permalink'].split('/')[2]
        menus[menu_name_en].append(menu_iterm)
    return menus


# menus=dict_from_collection(yold['collections'])
# print menus
def collections_from_dict(dic):
    """
    construct a Jekyll yaml collection (a dictionary) from a menu dict
    example input:  {'ReadingNotes': ['Book_NeuralNetworksAndDeepLearning', 'test']}
    example output:  {'ReadingNotes_Book_NeuralNetworksAndDeepLearning': {'output': True,
    'permalink': '/ReadingNotes/Book_NeuralNetworksAndDeepLearning/:path'},
    'ReadingNotes_test': {'output': True, 'permalink': '/ReadingNotes/test/:path'}}
    """
    collection = {}
    for k, v in dic.iteritems():
        menu_name_en = k
        for collection_directory in v:
            menu_iterm = 'collection_' + menu_name_en + '_' + collection_directory
            permalink = '/{0}/{1}/:path'.format(menu_name_en, collection_directory)
            collection[menu_iterm] = {'output': True, 'permalink': permalink}
    return collection


# collection=collections_from_dict({'ReadingNotes': ['Book_NeuralNetworksAndDeepLearning', 'test']})
# print collection
def defaults_from_dict(dic):
    """
    construct a Jekyll yaml defaults （a list） from a menu dict
    example input:  {'ReadingNotes': ['Book_NeuralNetworksAndDeepLearning', 'test']}
    example output:  [{'scope': {'path': '', 'type': 'ReadingNotes_test'},  'values': {'layout': 'page'}},
                     {'scope': {'path': '',   'type': 'ReadingNotes_Book_NeuralNetworksAndDeepLearning'},
                      'values': {'layout': 'page'}}]
    """
    defaults = []
    for k, v in dic.iteritems():
        menu_name_en = k
        for collection_directory in v:
            menu_iterm = 'collection_' + menu_name_en + '_' + collection_directory
            tmp_dict = eval("""{'scope': {'path': '', 'type': %s},'values': {'layout': 'page'}}""" % "menu_iterm")
            defaults.append(tmp_dict)
    return defaults


# defaults=defaults_from_dict({'ReadingNotes': ['Book_NeuralNetworksAndDeepLearning', 'test']})
def directories_from_dict(dic):
    pass


if __name__ == '__main__':
    # related files for setting up our blog menus
    yamlMenuFile = r"./menu_config.yml"
    yamlConfigFile = r"../_config.yml"
    yaml_template_ConfigFile = r"./template_config.yml"
    template_header_file = r"./template_header.html"
    template_index_file = r"./template_index.html"
    header_file = r"../_includes/header.html"

    # extract menus from menu_config.yml
    menu_config = yaml.load(file(yamlMenuFile, 'r'))
    menus = menu_config['menus']
    # menus is a list of menu dictionaries:
    # [
    # {'menu_name_en': 'ReadingNotes', 'menu_name_cn': u'\u9605\u8bfb\u7b14\u8bb0',
    # 'menu_list': ['Book_NeuralNetworksAndDeepLearning', 'test']},
    # {'menu_name_en': 'ScholarThings', 'menu_name_cn': u'\u5b66\u672f\u79ef\u7d2f', 'menu_list': []}
    # ]
    # menus is essential in the following configureation.

    # construct the menus_dict to update collections in yamlConfigFile and also for other use.
    menus_dict = {}
    for menu in menus:
        menus_dict[menu['menu_name_en']] = menu['menu_list']

    print "/.....................The configuration process begins...................../"

    # update collections related configurations in yamlConfigFile, so Jekyll knows who are collections
    h_yamlConfigFile = yaml.load(file(yaml_template_ConfigFile, 'r'))
    streamyamlConfigFile = file(yamlConfigFile, 'w')
    # note that the initial collections are overwritten, change the following two lines if you don't want this.
    h_yamlConfigFile['collections'] = collections_from_dict(menus_dict)
    h_yamlConfigFile['defaults'] = defaults_from_dict(menus_dict)
    yaml.dump(h_yamlConfigFile, streamyamlConfigFile, default_flow_style=False, allow_unicode=True)
    streamyamlConfigFile.close()
    print "File:(%s) is updated succefully!"%yamlConfigFile

    # update header_file in the _includes directory, so the menus are shown in the header of our blog.
    h_template_header_file = codecs.open(template_header_file, "r", "utf-8")
    h_header_file = codecs.open(header_file, "w", "utf-8")
    jinja_template = Template(h_template_header_file.read())
    h_header_file.write(jinja_template.render(menus=menus))
    h_header_file.close()
    h_template_header_file.close()
    print "File:(%s) is updated succefully!"%header_file

    # now create an index.html in the dictory of each collection.
    # if the directory does not exist, then create it and
    # place there an index.html, which lists the content of that directory.
    collection_iterm_path = ""
    for k, v in menus_dict.iteritems():
        menu_name_en = k
        for collection_iterm_name in v:
            collection_name = 'collection_' + menu_name_en + '_' + collection_iterm_name
            collection_iterm_path = '../_collection_' + menu_name_en + '_' + collection_iterm_name
            try:
                os.makedirs(collection_iterm_path)
                h_template_index_file = codecs.open(template_index_file, "r", "utf-8")
                h_index_file = codecs.open(collection_iterm_path + '/index.html', "w", "utf-8")
                jinja_template = Template(h_template_index_file.read())
                h_index_file.write(
                    jinja_template.render(collection_iterm_name=collection_iterm_name, collection_name=collection_name))
                h_index_file.close()
                h_template_index_file.close()
                print "an index.html is generated in your new directory:(%s)"%collection_iterm_path
            except OSError:  # the directory already exists or it's a file name
                if not os.path.isdir(collection_iterm_path):
                    raise  # it's a file name
                else:
                    h_template_index_file = codecs.open(template_index_file, "r", "utf-8")
                    h_index_file = codecs.open(collection_iterm_path + '/index.html', "w", "utf-8")
                    jinja_template = Template(h_template_index_file.read())
                    h_index_file.write(
                        jinja_template.render(collection_iterm_name=collection_iterm_name, collection_name=collection_name))
                    h_index_file.close()
                    h_template_index_file.close()
                    print "Dictory (%s) already exists. The index.html in it is overwritten!."%collection_iterm_path
            pass
        pass       

    print "/.....................The configuration process ends...................../"
    print "Your menus are configured succefully! You can run: " \
          "jekyll serve -w to see the effects if you have configured jekyll locally" \
          "or you can simply push the changes to github pages to see the effects."
    print "/.............................................................../"
courses taken:
    Machine Learning Nanodegree
        Model Evaluation and Validation
             Predicting Boston Housing Prices
        Supervised Learning
            Find Donors for CharityML
        Unsupervised Learning
            Creating Customer Segments

    Deep Learning Nanodegree
    Deep Reinforcement Learning Nanodegree
    Data Analyst Nanodegree
        Introduction to Data Analysis
            Investigate a Dataset
        Data Wrangling
            Wrangle and Analyze Data
    Data Scientist Nanodegree
        Supervised Learning
            Find Donors for CharityML with Kaggle
        Unsupervised Learning
             Creating Customer Segments

courses to: take
    Machine Learning Nanodegree
        Deep Learning
            Dog Breed Classifier
        Reinforcement Learning
            Train a Quadcopter to Fly
        Project 6: Capstone Proposal
        Project 7: Capstone Project

    Deep Learning Nanodegree
        Neural Networks
            Predicting Bike-Sharing Patterns
        Convolutional Neural Networks
            Dog Breed Classifier
        Recurrent Neural Networks
             Generate TV Scripts
        Generative Adversarial Networks
            Generate Faces
        Model Deployment
            Deploy a Sentiment Analysis Model

    Deep Reinforcement Learning Nanodegree
        Foundations of Reinforcement Learning
        Value-Based Methods
            Navigation
        Policy-Based Methods
            Continuous Control
        Multi-Agent Reinforcement Learning
            Collaboration and Competition

    Data Analyst Nanodegree
        Practical Statistics
            Analyze Experiment Results
        Data Visualization with Python
            Communicate Data Findings

    Data Scientist Nanodegree
        Introduction to Deep Learning
            Create an Image Classifier
        Solving Problems with Data Science
            Write a Data Science Blog Post
        Software Engineering for Data Scientists
        Data Engineering for Data Scientists
            Build Pipelines to Classify Messages with Figure Eight
        Experiment Design
        Recommendations
            Design a Recommendation Engine with IBM
        Data Science Projects
            Project 7: Data Science Capstone Project

    Data Engineer nanodegree
        Data Modeling
            Data Modeling with Postgres 
            Data Modeling with Apache Cassandra
         Cloud Data Warehouses
            Data Infrastructure on the Cloud
         Data Lakes with Spark
             Big Data with Spark
        Automate Data Pipelines
            Data Pipelines with Airflow
         Capstone Project
str1 = """
python

Touchstone - Clojure A/B testing library. [Deprecated]
Clojush - The Push programming language and the PushGP genetic programming system implemented in Clojure.
Infer - Inference and machine learning in Clojure. [Deprecated]
Clj-ML - A machine learning library for Clojure built on top of Weka and friends. [Deprecated]
DL4CLJ - Clojure wrapper for Deeplearning4j.
Encog - Clojure wrapper for Encog (v3) (Machine-Learning framework that specializes in neural-nets). [Deprecated]
Fungp - A genetic programming library for Clojure. [Deprecated]
Statistiker - Basic Machine Learning algorithms in Clojure. [Deprecated]
clortex - General Machine Learning library using Numenta’s Cortical Learning Algorithm. [Deprecated]
comportex - Functionally composable Machine Learning library using Numenta’s Cortical Learning Algorithm. [Deprecated]
cortex - Neural networks, regression and feature learning in Clojure.
lambda-ml - Simple, concise implementations of machine learning techniques and utilities in Clojure.

Data Analysis / Data Visualization
Incanter - Incanter is a Clojure-based, R-like platform for statistical computing and graphics.
PigPen - Map-Reduce for Clojure.
Envision - Clojure Data Visualisation library, based on Statistiker and D3.

Crystal

General-Purpose Machine Learning
machine - Simple machine learning algorithm.
crystal-fann - FANN (Fast Artificial Neural Network) binding.

Elixir

General-Purpose Machine Learning
Simple Bayes - A Simple Bayes / Naive Bayes implementation in Elixir.
emel - A simple and functional machine learning library written in Elixir.

Natural Language Processing
Stemmer - An English (Porter2) stemming implementation in Elixir.

Erlang

General-Purpose Machine Learning
Disco - Map Reduce in Erlang. [Deprecated]
Yanni - ANN neural networks using Erlangs leightweight processes.

Go

Natural Language Processing
go-porterstemmer - A native Go clean room implementation of the Porter Stemming algorithm. [Deprecated]
paicehusk - Golang implementation of the Paice/Husk Stemming Algorithm.
snowball - Snowball Stemmer for Go.
Textbox - Natural language processing SDK from Machine Box
go-ngram - In-memory n-gram index with compression.
word-embedding - Word Embeddings: the full implementation of word2vec, GloVe in Go.
sentences - Golang implementation of Punkt sentence tokenizer.

General-Purpose Machine Learning
eaopt - An evolutionary optimization library.
Go Learn - Machine Learning for Go. [Deprecated]
go-pr - Pattern recognition package in Go lang. [Deprecated]
go-ml - Linear / Logistic regression, Neural Networks, Collaborative Filtering and Gaussian Multivariate Distribution. [Deprecated]
bayesian - Naive Bayesian Classification for Golang. [Deprecated]
go-galib - Genetic Algorithms library written in Go / Golang. [Deprecated]
Cloudforest - Ensembles of decision trees in Go/Golang. [Deprecated]
gobrain - Neural Networks written in Go.
GoNN - GoNN is an implementation of Neural Network in Go Language, which includes BPNN, RBF, PCN. [Deprecated]
go-mxnet-predictor - Go binding for MXNet c_predict_api to do inference with pre-trained model.
neat - Plug-and-play, parallel Go framework for NeuroEvolution of Augmenting Topologies (NEAT). [Deprecated]
go-ml-transpiler - An open source Go transpiler for machine learning models.
therfoo - An embedded deep learning library for Go.

Data Analysis / Data Visualization
go-graph - Graph library for Go/Golang language. [Deprecated]
SVGo - The Go Language library for SVG generation.
RF - Random forests implementation in Go. [Deprecated]
Glot - Glot is a plotting library for Golang built on top of gnuplot.

Facial Detection and Recognition
Facebox - Facial detection and recognition SDK with one-shot teaching from Machine Box

Image Classification
Tagbox - Image classification SDK with one-shot teaching from Machine Box
Nudebox - Nudity detection from Machine Box

Haskell

General-Purpose Machine Learning
haskell-ml - Haskell implementations of various ML algorithms. [Deprecated]
HLearn - a suite of libraries for interpreting machine learning models according to their algebraic structure. [Deprecated]
hnn - Haskell Neural Network library.
hopfield-networks - Hopfield Networks for unsupervised learning in Haskell. [Deprecated]
DNNGraph - A DSL for deep neural networks. [Deprecated]
LambdaNet - Configurable Neural Networks in Haskell. [Deprecated]

Java

Natural Language Processing
Cortical.io - Retina: an API performing complex NLP operations (disambiguation, classification, streaming text filtering, etc...) as quickly and intuitively as the brain.
IRIS - Cortical.io's FREE NLP, Retina API Analysis Tool (written in JavaFX!) - See the Tutorial Video.
CoreNLP - Stanford CoreNLP provides a set of natural language analysis tools which can take raw English language text input and give the base forms of words.
Stanford Parser - A natural language parser is a program that works out the grammatical structure of sentences.
Stanford POS Tagger - A Part-Of-Speech Tagger (POS Tagger).
Stanford Name Entity Recognizer - Stanford NER is a Java implementation of a Named Entity Recognizer.
Stanford Word Segmenter - Tokenization of raw text is a standard pre-processing step for many NLP tasks.
Tregex, Tsurgeon and Semgrex - Tregex is a utility for matching patterns in trees, based on tree relationships and regular expression matches on nodes (the name is short for "tree regular expressions").
Stanford Phrasal: A Phrase-Based Translation System
Stanford English Tokenizer - Stanford Phrasal is a state-of-the-art statistical phrase-based machine translation system, written in Java.
Stanford Tokens Regex - A tokenizer divides text into a sequence of tokens, which roughly correspond to "words".
Stanford Temporal Tagger - SUTime is a library for recognizing and normalizing time expressions.
Stanford SPIED - Learning entities from unlabeled text starting with seed sets using patterns in an iterative fashion.
Stanford Topic Modeling Toolbox - Topic modeling tools to social scientists and others who wish to perform analysis on datasets.
Twitter Text Java - A Java implementation of Twitter's text processing library.
MALLET - A Java-based package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text.
OpenNLP - a machine learning based toolkit for the processing of natural language text.
LingPipe - A tool kit for processing text using computational linguistics.
ClearTK - ClearTK provides a framework for developing statistical natural language processing (NLP) components in Java and is built on top of Apache UIMA. [Deprecated]
Apache cTAKES - Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) is an open-source natural language processing system for information extraction from electronic medical record clinical free-text.
NLP4J - The NLP4J project provides software and resources for natural language processing. The project started at the Center for Computational Language and EducAtion Research, and is currently developed by the Center for Language and Information Research at Emory University. [Deprecated]
CogcompNLP - This project collects a number of core libraries for Natural Language Processing (NLP) developed in the University of Illinois' Cognitive Computation Group, for example illinois-core-utilities which provides a set of NLP-friendly data structures and a number of NLP-related utilities that support writing NLP applications, running experiments, etc, illinois-edison a library for feature extraction from illinois-core-utilities data structures and many other packages.

General-Purpose Machine Learning
aerosolve - A machine learning library by Airbnb designed from the ground up to be human friendly.
AMIDST Toolbox - A Java Toolbox for Scalable Probabilistic Machine Learning.
Datumbox - Machine Learning framework for rapid development of Machine Learning and Statistical applications.
ELKI - Java toolkit for data mining. (unsupervised: clustering, outlier detection etc.)
Encog - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks.
FlinkML in Apache Flink - Distributed machine learning library in Flink.
H2O - ML engine that supports distributed learning on Hadoop, Spark or your laptop via APIs in R, Python, Scala, REST/JSON.
htm.java - General Machine Learning library using Numenta’s Cortical Learning Algorithm.
liblinear-java - Java version of liblinear.
Mahout - Distributed machine learning.
Meka - An open source implementation of methods for multi-label classification and evaluation (extension to Weka).
MLlib in Apache Spark - Distributed machine learning library in Spark
Hydrosphere Mist - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.
Neuroph - Neuroph is lightweight Java neural network framework
ORYX - Lambda Architecture Framework using Apache Spark and Apache Kafka with a specialization for real-time large-scale machine learning.
Samoa SAMOA is a framework that includes distributed machine learning for data streams with an interface to plug-in different stream processing platforms.
RankLib - RankLib is a library of learning to rank algorithms. [Deprecated]
rapaio - statistics, data mining and machine learning toolbox in Java.
RapidMiner - RapidMiner integration into Java code.
Stanford Classifier - A classifier is a machine learning tool that will take data items and place them into one of k classes.
SmileMiner - Statistical Machine Intelligence & Learning Engine.
SystemML - flexible, scalable machine learning (ML) language.
Weka - Weka is a collection of machine learning algorithms for data mining tasks.
LBJava - Learning Based Java is a modeling language for the rapid development of software systems, offers a convenient, declarative syntax for classifier and constraint definition directly in terms of the objects in the programmer's application.

Speech Recognition
CMU Sphinx - Open Source Toolkit For Speech Recognition purely based on Java speech recognition library.

Data Analysis / Data Visualization
Flink - Open source platform for distributed stream and batch data processing.
Hadoop - Hadoop/HDFS.
Onyx - Distributed, masterless, high performance, fault tolerant data processing. Written entirely in Clojure.
Spark - Spark is a fast and general engine for large-scale data processing.
Storm - Storm is a distributed realtime computation system.
Impala - Real-time Query for Hadoop.
DataMelt - Mathematics software for numeric computation, statistics, symbolic calculations, data analysis and data visualization.
Dr. Michael Thomas Flanagan's Java Scientific Library [Deprecated]

Deep Learning
Deeplearning4j - Scalable deep learning for industry with parallel GPUs.
Keras Beginner Tutorial - Friendly guide on using Keras to implement a simple Neural Network in Python

Javascript

Natural Language Processing
Twitter-text - A JavaScript implementation of Twitter's text processing library.
natural - General natural language facilities for node.
Knwl.js - A Natural Language Processor in JS.
Retext - Extensible system for analyzing and manipulating natural language.
NLP Compromise - Natural Language processing in the browser.
nlp.js - An NLP library built in node over Natural, with entity extraction, sentiment analysis, automatic language identify, and so more

Data Analysis / Data Visualization
D3.js
High Charts
NVD3.js
dc.js
chartjs
dimple
amCharts
D3xter - Straight forward plotting built on D3. [Deprecated]
statkit - Statistics kit for JavaScript. [Deprecated]
datakit - A lightweight framework for data analysis in JavaScript
science.js - Scientific and statistical computing in JavaScript. [Deprecated]
Z3d - Easily make interactive 3d plots built on Three.js [Deprecated]
Sigma.js - JavaScript library dedicated to graph drawing.
C3.js - customizable library based on D3.js for easy chart drawing.
Datamaps - Customizable SVG map/geo visualizations using D3.js. [Deprecated]
ZingChart - library written on Vanilla JS for big data visualization.
cheminfo - Platform for data visualization and analysis, using the visualizer project.
Learn JS Data
AnyChart
FusionCharts
Nivo - built on top of the awesome d3 and Reactjs libraries

General-Purpose Machine Learning
Auto ML - Automated machine learning, data formatting, ensembling, and hyperparameter optimization for competitions and exploration- just give it a .csv file!
Convnet.js - ConvNetJS is a Javascript library for training Deep Learning models[DEEP LEARNING] [Deprecated]
Clusterfck - Agglomerative hierarchical clustering implemented in Javascript for Node.js and the browser. [Deprecated]
Clustering.js - Clustering algorithms implemented in Javascript for Node.js and the browser. [Deprecated]
Decision Trees - NodeJS Implementation of Decision Tree using ID3 Algorithm. [Deprecated]
DN2A - Digital Neural Networks Architecture. [Deprecated]
figue - K-means, fuzzy c-means and agglomerative clustering.
Gaussian Mixture Model - Unsupervised machine learning with multivariate Gaussian mixture model.
Node-fann - FANN (Fast Artificial Neural Network Library) bindings for Node.js [Deprecated]
Keras.js - Run Keras models in the browser, with GPU support provided by WebGL 2.
Kmeans.js - Simple Javascript implementation of the k-means algorithm, for node.js and the browser. [Deprecated]
LDA.js - LDA topic modeling for Node.js
Learning.js - Javascript implementation of logistic regression/c4.5 decision tree [Deprecated]
machinelearn.js - Machine Learning library for the web, Node.js and developers
mil-tokyo - List of several machine learning libraries.
Node-SVM - Support Vector Machine for Node.js
Brain - Neural networks in JavaScript [Deprecated]
Brain.js - Neural networks in JavaScript - continued community fork of Brain.
Bayesian-Bandit - Bayesian bandit implementation for Node and the browser. [Deprecated]
Synaptic - Architecture-free neural network library for Node.js and the browser.
kNear - JavaScript implementation of the k nearest neighbors algorithm for supervised learning.
NeuralN - C++ Neural Network library for Node.js. It has advantage on large dataset and multi-threaded training. [Deprecated]
kalman - Kalman filter for Javascript. [Deprecated]
shaman - Node.js library with support for both simple and multiple linear regression. [Deprecated]
ml.js - Machine learning and numerical analysis tools for Node.js and the Browser!
ml5 - Friendly machine learning for the web!
Pavlov.js - Reinforcement learning using Markov Decision Processes.
MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.
TensorFlow.js - A WebGL accelerated, browser based JavaScript library for training and deploying ML models.
JSMLT - Machine learning toolkit with classification and clustering for Node.js; supports visualization (see visualml.io).
xgboost-node - Run XGBoost model and make predictions in Node.js.
Netron - Visualizer for machine learning models.
WebDNN - Fast Deep Neural Network Javascript Framework. WebDNN uses next generation JavaScript API, WebGPU for GPU execution, and WebAssembly for CPU execution.

Misc
stdlib - A standard library for JavaScript and Node.js, with an emphasis on numeric computing. The library provides a collection of robust, high performance libraries for mathematics, statistics, streams, utilities, and more.
sylvester - Vector and Matrix math for JavaScript. [Deprecated]
simple-statistics - A JavaScript implementation of descriptive, regression, and inference statistics. Implemented in literate JavaScript with no dependencies, designed to work in all modern browsers (including IE) as well as in Node.js.
regression-js - A javascript library containing a collection of least squares fitting methods for finding a trend in a set of data.
Lyric - Linear Regression library. [Deprecated]
GreatCircle - Library for calculating great circle distance.
MLPleaseHelp - MLPleaseHelp is a simple ML resource search engine. You can use this search engine right now at https://jgreenemi.github.io/MLPleaseHelp/, provided via Github Pages.

Demos and Scripts
The Bot - Example of how the neural network learns to predict the angle between two points created with Synaptic.
Half Beer - Beer glass classifier created with Synaptic.

Julia

General-Purpose Machine Learning
MachineLearning - Julia Machine Learning library. [Deprecated]
MLBase - A set of functions to support the development of machine learning algorithms.
PGM - A Julia framework for probabilistic graphical models.
DA - Julia package for Regularized Discriminant Analysis.
Regression - Algorithms for regression analysis (e.g. linear regression and logistic regression). [Deprecated]
Local Regression - Local regression, so smooooth!
Naive Bayes - Simple Naive Bayes implementation in Julia. [Deprecated]
Mixed Models - A Julia package for fitting (statistical) mixed-effects models.
Simple MCMC - basic mcmc sampler implemented in Julia. [Deprecated]
Distances - Julia module for Distance evaluation.
Decision Tree - Decision Tree Classifier and Regressor.
Neural - A neural network in Julia.
MCMC - MCMC tools for Julia. [Deprecated]
Mamba - Markov chain Monte Carlo (MCMC) for Bayesian analysis in Julia.
GLM - Generalized linear models in Julia.
Gaussian Processes - Julia package for Gaussian processes.
Online Learning [Deprecated]
GLMNet - Julia wrapper for fitting Lasso/ElasticNet GLM models using glmnet.
Clustering - Basic functions for clustering data: k-means, dp-means, etc.
SVM - SVM's for Julia. [Deprecated]
Kernel Density - Kernel density estimators for julia.
MultivariateStats - Methods for dimensionality reduction.
NMF - A Julia package for non-negative matrix factorization.
ANN - Julia artificial neural networks. [Deprecated]
Mocha - Deep Learning framework for Julia inspired by Caffe. [Deprecated]
XGBoost - eXtreme Gradient Boosting Package in Julia.
ManifoldLearning - A Julia package for manifold learning and nonlinear dimensionality reduction.
MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.
Merlin - Flexible Deep Learning Framework in Julia.
ROCAnalysis - Receiver Operating Characteristics and functions for evaluation probabilistic binary classifiers.
GaussianMixtures - Large scale Gaussian Mixture Models.
ScikitLearn - Julia implementation of the scikit-learn API.
Knet - Koç University Deep Learning Framework.
Flux - Relax! Flux is the ML library that doesn't make you tensor

Natural Language Processing
Topic Models - TopicModels for Julia. [Deprecated]
Text Analysis - Julia package for text analysis.
Word Tokenizers - Tokenizers for Natural Language Processing in Julia
Corpus Loaders - A julia package providing a variety of loaders for various NLP corpora.
Embeddings - Functions and data dependencies for loading various word embeddings
Languages - Julia package for working with various human languages
WordNet - A Julia package for Princeton's WordNet

Data Analysis / Data Visualization
Graph Layout - Graph layout algorithms in pure Julia.
LightGraphs - Graph modeling and analysis.
Data Frames Meta - Metaprogramming tools for DataFrames.
Julia Data - library for working with tabular data in Julia. [Deprecated]
Data Read - Read files from Stata, SAS, and SPSS.
Hypothesis Tests - Hypothesis tests for Julia.
Gadfly - Crafty statistical graphics for Julia.
Stats - Statistical tests for Julia.
RDataSets - Julia package for loading many of the data sets available in R.
DataFrames - library for working with tabular data in Julia.
Distributions - A Julia package for probability distributions and associated functions.
Data Arrays - Data structures that allow missing values. [Deprecated]
Time Series - Time series toolkit for Julia.
Sampling - Basic sampling algorithms for Julia.

Misc Stuff / Presentations
DSP - Digital Signal Processing (filtering, periodograms, spectrograms, window functions).
JuliaCon Presentations - Presentations for JuliaCon.
SignalProcessing - Signal Processing tools for Julia.
Images - An image library for Julia.
DataDeps - Reproducible data setup for reproducible science.

Lua

General-Purpose Machine Learning
Torch7
cephes - Cephes mathematical functions library, wrapped for Torch. Provides and wraps the 180+ special mathematical functions from the Cephes mathematical library, developed by Stephen L. Moshier. It is used, among many other places, at the heart of SciPy. [Deprecated]
autograd - Autograd automatically differentiates native Torch code. Inspired by the original Python version.
graph - Graph package for Torch. [Deprecated]
randomkit - Numpy's randomkit, wrapped for Torch. [Deprecated]
signal - A signal processing toolbox for Torch-7. FFT, DCT, Hilbert, cepstrums, stft.
nn - Neural Network package for Torch.
torchnet - framework for torch which provides a set of abstractions aiming at encouraging code re-use as well as encouraging modular programming.
nngraph - This package provides graphical computation for nn library in Torch7.
nnx - A completely unstable and experimental package that extends Torch's builtin nn library.
rnn - A Recurrent Neural Network library that extends Torch's nn. RNNs, LSTMs, GRUs, BRNNs, BLSTMs, etc.
dpnn - Many useful features that aren't part of the main nn package.
dp - A deep learning library designed for streamlining research and development using the Torch7 distribution. It emphasizes flexibility through the elegant use of object-oriented design patterns. [Deprecated]
optim - An optimization library for Torch. SGD, Adagrad, Conjugate-Gradient, LBFGS, RProp and more.
unsup - A package for unsupervised learning in Torch. Provides modules that are compatible with nn (LinearPsd, ConvPsd, AutoEncoder, ...), and self-contained algorithms (k-means, PCA). [Deprecated]
manifold - A package to manipulate manifolds.
svm - Torch-SVM library. [Deprecated]
lbfgs - FFI Wrapper for liblbfgs. [Deprecated]
vowpalwabbit - An old vowpalwabbit interface to torch. [Deprecated]
OpenGM - OpenGM is a C++ library for graphical modeling, and inference. The Lua bindings provide a simple way of describing graphs, from Lua, and then optimizing them with OpenGM. [Deprecated]
spaghetti - Spaghetti (sparse linear) module for torch7 by @MichaelMathieu [Deprecated]
LuaSHKit - A lua wrapper around the Locality sensitive hashing library SHKit [Deprecated]
kernel smoothing - KNN, kernel-weighted average, local linear regression smoothers. [Deprecated]
cutorch - Torch CUDA Implementation.
cunn - Torch CUDA Neural Network Implementation.
imgraph - An image/graph library for Torch. This package provides routines to construct graphs on images, segment them, build trees out of them, and convert them back to images. [Deprecated]
videograph - A video/graph library for Torch. This package provides routines to construct graphs on videos, segment them, build trees out of them, and convert them back to videos. [Deprecated]
saliency - code and tools around integral images. A library for finding interest points based on fast integral histograms. [Deprecated]
stitch - allows us to use hugin to stitch images and apply same stitching to a video sequence. [Deprecated]
sfm - A bundle adjustment/structure from motion package. [Deprecated]
fex - A package for feature extraction in Torch. Provides SIFT and dSIFT modules. [Deprecated]
OverFeat - A state-of-the-art generic dense feature extractor. [Deprecated]
wav2letter - a simple and efficient end-to-end Automatic Speech Recognition (ASR) system from Facebook AI Research.
Numeric Lua
Lunatic Python
SciLua
Lua - Numerical Algorithms [Deprecated]
Lunum [Deprecated]

Demos and Scripts
Core torch7 demos repository.
linear-regression, logistic-regression
face detector (training and detection as separate demos)
mst-based-segmenter
train-a-digit-classifier
train-autoencoder
optical flow demo
train-on-housenumbers
train-on-cifar
tracking with deep nets
kinect demo
filter-bank visualization
saliency-networks
Training a Convnet for the Galaxy-Zoo Kaggle challenge(CUDA demo)
Music Tagging - Music Tagging scripts for torch7.
torch-datasets - Scripts to load several popular datasets including:
BSR 500
CIFAR-10
COIL
Street View House Numbers
MNIST
NORB
Atari2600 - Scripts to generate a dataset with static frames from the Arcade Learning Environment.

Matlab

Computer Vision
Contourlets - MATLAB source code that implements the contourlet transform and its utility functions.
Shearlets - MATLAB code for shearlet transform.
Curvelets - The Curvelet transform is a higher dimensional generalization of the Wavelet transform designed to represent images at different scales and different angles.
Bandlets - MATLAB code for bandlet transform.
mexopencv - Collection and a development kit of MATLAB mex functions for OpenCV library.

Natural Language Processing
NLP - An NLP library for Matlab.

General-Purpose Machine Learning
Training a deep autoencoder or a classifier on MNIST digits - Training a deep autoencoder or a classifier on MNIST digits[DEEP LEARNING].
Convolutional-Recursive Deep Learning for 3D Object Classification - Convolutional-Recursive Deep Learning for 3D Object Classification[DEEP LEARNING].
Spider - The spider is intended to be a complete object orientated environment for machine learning in Matlab.
LibSVM - A Library for Support Vector Machines.
ThunderSVM - An Open-Source SVM Library on GPUs and CPUs
LibLinear - A Library for Large Linear Classification.
Machine Learning Module - Class on machine w/ PDF, lectures, code
Caffe - A deep learning framework developed with cleanliness, readability, and speed in mind.
Pattern Recognition Toolbox - A complete object-oriented environment for machine learning in Matlab.
Pattern Recognition and Machine Learning - This package contains the matlab implementation of the algorithms described in the book Pattern Recognition and Machine Learning by C. Bishop.
Optunity - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly with MATLAB.
MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.
Machine Learning in MatLab/Octave - examples of popular machine learning algorithms (neural networks, linear/logistic regressions, K-Means, etc.) with code examples and mathematics behind them being explained.

Data Analysis / Data Visualization
matlab_bgl - MatlabBGL is a Matlab package for working with graphs.
gaimc - Efficient pure-Matlab implementations of graph algorithms to complement MatlabBGL's mex functions.

.NET

Computer Vision
OpenCVDotNet - A wrapper for the OpenCV project to be used with .NET applications.
Emgu CV - Cross platform wrapper of OpenCV which can be compiled in Mono to be run on Windows, Linus, Mac OS X, iOS, and Android.
AForge.NET - Open source C# framework for developers and researchers in the fields of Computer Vision and Artificial Intelligence. Development has now shifted to GitHub.
Accord.NET - Together with AForge.NET, this library can provide image processing and computer vision algorithms to Windows, Windows RT and Windows Phone. Some components are also available for Java and Android.

Natural Language Processing
Stanford.NLP for .NET - A full port of Stanford NLP packages to .NET and also available precompiled as a NuGet package.

General-Purpose Machine Learning
Accord-Framework -The Accord.NET Framework is a complete framework for building machine learning, computer vision, computer audition, signal processing and statistical applications.
Accord.MachineLearning - Support Vector Machines, Decision Trees, Naive Bayesian models, K-means, Gaussian Mixture models and general algorithms such as Ransac, Cross-validation and Grid-Search for machine-learning applications. This package is part of the Accord.NET Framework.
DiffSharp - An automatic differentiation (AD) library providing exact and efficient derivatives (gradients, Hessians, Jacobians, directional derivatives, and matrix-free Hessian- and Jacobian-vector products) for machine learning and optimization applications. Operations can be nested to any level, meaning that you can compute exact higher-order derivatives and differentiate functions that are internally making use of differentiation, for applications such as hyperparameter optimization.
Encog - An advanced neural network and machine learning framework. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using multithreaded resilient propagation. Encog can also make use of a GPU to further speed processing time. A GUI based workbench is also provided to help model and train neural networks.
GeneticSharp - Multi-platform genetic algorithm library for .NET Core and .NET Framework. The library has several implementations of GA operators, like: selection, crossover, mutation, reinsertion and termination.
Infer.NET - Infer.NET is a framework for running Bayesian inference in graphical models. One can use Infer.NET to solve many different kinds of machine learning problems, from standard problems like classification, recommendation or clustering through to customised solutions to domain-specific problems. Infer.NET has been used in a wide variety of domains including information retrieval, bioinformatics, epidemiology, vision, and many others.
ML.NET - ML.NET is a cross-platform open-source machine learning framework which makes machine learning accessible to .NET developers. ML.NET was originally developed in Microsoft Research and evolved into a significant framework over the last decade and is used across many product groups in Microsoft like Windows, Bing, PowerPoint, Excel and more.
Neural Network Designer - DBMS management system and designer for neural networks. The designer application is developed using WPF, and is a user interface which allows you to design your neural network, query the network, create and configure chat bots that are capable of asking questions and learning from your feed back. The chat bots can even scrape the internet for information to return in their output as well as to use for learning.
Vulpes - Deep belief and deep learning implementation written in F# and leverages CUDA GPU execution with Alea.cuBase.

Data Analysis / Data Visualization
numl - numl is a machine learning library intended to ease the use of using standard modeling techniques for both prediction and clustering.
Math.NET Numerics - Numerical foundation of the Math.NET project, aiming to provide methods and algorithms for numerical computations in science, engineering and every day use. Supports .Net 4.0, .Net 3.5 and Mono on Windows, Linux and Mac; Silverlight 5, WindowsPhone/SL 8, WindowsPhone 8.1 and Windows 8 with PCL Portable Profiles 47 and 344; Android/iOS with Xamarin.
Sho - Sho is an interactive environment for data analysis and scientific computing that lets you seamlessly connect scripts (in IronPython) with compiled code (in .NET) to enable fast and flexible prototyping. The environment includes powerful and efficient libraries for linear algebra as well as data visualization that can be used from any .NET language, as well as a feature-rich interactive shell for rapid development.

Objective C

General-Purpose Machine Learning
YCML - A Machine Learning framework for Objective-C and Swift (OS X / iOS).
MLPNeuralNet - Fast multilayer perceptron neural network library for iOS and Mac OS X. MLPNeuralNet predicts new examples by trained neural network. It is built on top of the Apple's Accelerate Framework, using vectorized operations and hardware acceleration if available. [Deprecated]
MAChineLearning - An Objective-C multilayer perceptron library, with full support for training through backpropagation. Implemented using vDSP and vecLib, it's 20 times faster than its Java equivalent. Includes sample code for use from Swift.
BPN-NeuralNetwork - It implemented 3 layers neural network ( Input Layer, Hidden Layer and Output Layer ) and it named Back Propagation Neural Network (BPN). This network can be used in products recommendation, user behavior analysis, data mining and data analysis. [Deprecated]
Multi-Perceptron-NeuralNetwork - it implemented multi-perceptrons neural network (ニューラルネットワーク) based on Back Propagation Neural Network (BPN) and designed unlimited-hidden-layers.
KRHebbian-Algorithm - It is a non-supervisor and self-learning algorithm (adjust the weights) in neural network of Machine Learning. [Deprecated]
KRKmeans-Algorithm - It implemented K-Means the clustering and classification algorithm. It could be used in data mining and image compression. [Deprecated]
KRFuzzyCMeans-Algorithm - It implemented Fuzzy C-Means (FCM) the fuzzy clustering / classification algorithm on Machine Learning. It could be used in data mining and image compression. [Deprecated]

OCaml

General-Purpose Machine Learning
Oml - A general statistics and machine learning library.
GPR - Efficient Gaussian Process Regression in OCaml.
Libra-Tk - Algorithms for learning and inference with discrete probabilistic models.
TensorFlow - OCaml bindings for TensorFlow.

Perl

Data Analysis / Data Visualization
Perl Data Language, a pluggable architecture for data and image processing, which can be used for machine learning.

General-Purpose Machine Learning
MXnet for Deep Learning, in Perl, also released in CPAN.
Perl Data Language, using AWS machine learning platform from Perl.
Algorithm::SVMLight, implementation of Support Vector Machines with SVMLight under it. [Deprecated]
Several machine learning and artificial intelligence models are included in the AI namespace. For instance, you can find Naïve Bayes.

Perl 6
Support Vector Machines
Naïve Bayes
Data Analysis / Data Visualization
Perl Data Language, a pluggable architecture for data and image processing, which can be used for machine learning.
General-Purpose Machine Learning

PHP

Natural Language Processing
jieba-php - Chinese Words Segmentation Utilities.

General-Purpose Machine Learning
PHP-ML - Machine Learning library for PHP. Algorithms, Cross Validation, Neural Network, Preprocessing, Feature Extraction and much more in one library.
PredictionBuilder - A library for machine learning that builds predictions using a linear regression.
Rubix ML - A high-level machine learning (ML) library that lets you build programs that learn from data using the PHP language.
19 Questions - A machine learning / bayesian inference assigning attributes to objects.

Python

Computer Vision
Scikit-Image - A collection of algorithms for image processing in Python.
SimpleCV - An open source computer vision framework that gives access to several high-powered computer vision libraries, such as OpenCV. Written on Python and runs on Mac, Windows, and Ubuntu Linux.
Vigranumpy - Python bindings for the VIGRA C++ computer vision library.
OpenFace - Free and open source face recognition with deep neural networks.
PCV - Open source Python module for computer vision. [Deprecated]
face_recognition - Face recognition library that recognize and manipulate faces from Python or from the command line.
dockerface - Easy to install and use deep learning Faster R-CNN face detection for images and video in a docker container.
Detectron - FAIR's software system that implements state-of-the-art object detection algorithms, including Mask R-CNN. It is written in Python and powered by the Caffe2 deep learning framework.
albumentations - А fast and framework agnostic image augmentation library that implements a diverse set of augmentation techniques. Supports classification, segmentation, detection out of the box. Was used to win a number of Deep Learning competitions at Kaggle, Topcoder and those that were a part of the CVPR workshops.
pytessarct - Python-tesseract is an optical character recognition (OCR) tool for python. That is, it will recognize and "read" the text embedded in images.Python-tesseract is a wrapper for Google's Tesseract-OCR Engine>.
imutils - A library containg Convenience functions to make basic image processing operations such as translation, rotation, resizing, skeletonization, and displaying Matplotlib images easier with OpenCV and Python.
PyTorchCV - A PyTorch-Based Framework for Deep Learning in Computer Vision.

Natural Language Processing
pkuseg-python - A better version of Jieba, developed by Peking University.
NLTK - A leading platform for building Python programs to work with human language data.
Pattern - A web mining module for the Python programming language. It has tools for natural language processing, machine learning, among others.
Quepy - A python framework to transform natural language questions to queries in a database query language.
TextBlob - Providing a consistent API for diving into common natural language processing (NLP) tasks. Stands on the giant shoulders of NLTK and Pattern, and plays nicely with both.
YAlign - A sentence aligner, a friendly tool for extracting parallel sentences from comparable corpora. [Deprecated]
jieba - Chinese Words Segmentation Utilities.
SnowNLP - A library for processing Chinese text.
spammy - A library for email Spam filtering built on top of nltk
loso - Another Chinese segmentation library. [Deprecated]
genius - A Chinese segment base on Conditional Random Field.
KoNLPy - A Python package for Korean natural language processing.
nut - Natural language Understanding Toolkit. [Deprecated]
Rosetta - Text processing tools and wrappers (e.g. Vowpal Wabbit)
BLLIP Parser - Python bindings for the BLLIP Natural Language Parser (also known as the Charniak-Johnson parser). [Deprecated]
PyNLPl - Python Natural Language Processing Library. General purpose NLP library for Python. Also contains some specific modules for parsing common NLP formats, most notably for FoLiA, but also ARPA language models, Moses phrasetables, GIZA++ alignments.
python-ucto - Python binding to ucto (a unicode-aware rule-based tokenizer for various languages).
python-frog - Python binding to Frog, an NLP suite for Dutch. (pos tagging, lemmatisation, dependency parsing, NER)
python-zpar - Python bindings for ZPar, a statistical part-of-speech-tagger, constiuency parser, and dependency parser for English.
colibri-core - Python binding to C++ library for extracting and working with with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way.
spaCy - Industrial strength NLP with Python and Cython.
PyStanfordDependencies - Python interface for converting Penn Treebank trees to Stanford Dependencies.
Distance - Levenshtein and Hamming distance computation. [Deprecated]
Fuzzy Wuzzy - Fuzzy String Matching in Python.
jellyfish - a python library for doing approximate and phonetic matching of strings.
editdistance - fast implementation of edit distance.
textacy - higher-level NLP built on Spacy.
stanford-corenlp-python - Python wrapper for Stanford CoreNLP [Deprecated]
CLTK - The Classical Language Toolkit.
rasa_nlu - turn natural language into structured data.
yase - Transcode sentence (or other sequence) to list of word vector .
Polyglot - Multilingual text (NLP) processing toolkit.
DrQA - Reading Wikipedia to answer open-domain questions.
Dedupe - A python library for accurate and scalable fuzzy matching, record deduplication and entity-resolution.
Snips NLU - Natural Language Understanding library for intent classification and entity extraction
NeuroNER - Named-entity recognition using neural networks providing state-of-the-art-results
DeepPavlov - conversational AI library with many pretrained Russian NLP models.
BigARTM - topic modelling platform.

General-Purpose Machine Learning
PyOD -> Python Outlier Detection, comprehensive and scalable Python toolkit for detecting outlying objects in multivariate data. Featured for Advanced models, including Neural Networks/Deep Learning and Outlier Ensembles.
steppy -> Lightweight, Python library for fast and reproducible machine learning experimentation. Introduces very simple interface that enables clean machine learning pipeline design.
steppy-toolkit -> Curated collection of the neural networks, transformers and models that make your machine learning work faster and more effective.
CNTK - Microsoft Cognitive Toolkit (CNTK), an open source deep-learning toolkit. Documentation can be found here.
auto_ml - Automated machine learning for production and analytics. Lets you focus on the fun parts of ML, while outputting production-ready code, and detailed analytics of your dataset and results. Includes support for NLP, XGBoost, CatBoost, LightGBM, and soon, deep learning.
machine learning - automated build consisting of a web-interface, and set of programmatic-interface API, for support vector machines. Corresponding dataset(s) are stored into a SQL database, then generated model(s) used for prediction(s), are stored into a NoSQL datastore.
XGBoost - Python bindings for eXtreme Gradient Boosting (Tree) Library.
Apache SINGA - An Apache Incubating project for developing an open source machine learning library.
Bayesian Methods for Hackers - Book/iPython notebooks on Probabilistic Programming in Python.
Featureforge A set of tools for creating and testing machine learning features, with a scikit-learn compatible API.
MLlib in Apache Spark - Distributed machine learning library in Spark
Hydrosphere Mist - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.
scikit-learn - A Python module for machine learning built on top of SciPy.
metric-learn - A Python module for metric learning.
SimpleAI Python implementation of many of the artificial intelligence algorithms described on the book "Artificial Intelligence, a Modern Approach". It focuses on providing an easy to use, well documented and tested library.
astroML - Machine Learning and Data Mining for Astronomy.
graphlab-create - A library with various machine learning models (regression, clustering, recommender systems, graph analytics, etc.) implemented on top of a disk-backed DataFrame.
BigML - A library that contacts external servers.
pattern - Web mining module for Python.
NuPIC - Numenta Platform for Intelligent Computing.
Pylearn2 - A Machine Learning library based on Theano.
keras - High-level neural networks frontend for TensorFlow, CNTK and Theano.
Lasagne - Lightweight library to build and train neural networks in Theano.
hebel - GPU-Accelerated Deep Learning Library in Python. [Deprecated]
Chainer - Flexible neural network framework.
prophet - Fast and automated time series forecasting framework by Facebook.
gensim - Topic Modelling for Humans.
topik - Topic modelling toolkit. [Deprecated]
PyBrain - Another Python Machine Learning Library.
Brainstorm - Fast, flexible and fun neural networks. This is the successor of PyBrain.
Surprise - A scikit for building and analyzing recommender systems.
Crab - A flexible, fast recommender engine. [Deprecated]
python-recsys - A Python library for implementing a Recommender System.
thinking bayes - Book on Bayesian Analysis.
Image-to-Image Translation with Conditional Adversarial Networks - Implementation of image to image (pix2pix) translation from the paper by isola et al.[DEEP LEARNING]
Restricted Boltzmann Machines -Restricted Boltzmann Machines in Python. [DEEP LEARNING]
Bolt - Bolt Online Learning Toolbox. [Deprecated]
CoverTree - Python implementation of cover trees, near-drop-in replacement for scipy.spatial.kdtree [Deprecated]
nilearn - Machine learning for NeuroImaging in Python.
neuropredict - Aimed at novice machine learners and non-expert programmers, this package offers easy (no coding needed) and comprehensive machine learning (evaluation and full report of predictive performance WITHOUT requiring you to code) in Python for NeuroImaging and any other type of features. This is aimed at absorbing the much of the ML workflow, unlike other packages like nilearn and pymvpa, which require you to learn their API and code to produce anything useful.
imbalanced-learn - Python module to perform under sampling and over sampling with various techniques.
Shogun - The Shogun Machine Learning Toolbox.
Pyevolve - Genetic algorithm framework. [Deprecated]
Caffe - A deep learning framework developed with cleanliness, readability, and speed in mind.
breze - Theano based library for deep and recurrent neural networks. [Deprecated]
pyhsmm - library for approximate unsupervised inference in Bayesian Hidden Markov Models (HMMs) and explicit-duration Hidden semi-Markov Models (HSMMs), focusing on the Bayesian Nonparametric extensions, the HDP-HMM and HDP-HSMM, mostly with weak-limit approximations.
mrjob - A library to let Python program run on Hadoop.
SKLL - A wrapper around scikit-learn that makes it simpler to conduct experiments.
neurolab
Spearmint - Spearmint is a package to perform Bayesian optimization according to the algorithms outlined in the paper: Practical Bayesian Optimization of Machine Learning Algorithms. Jasper Snoek, Hugo Larochelle and Ryan P. Adams. Advances in Neural Information Processing Systems, 2012. [Deprecated]
Pebl - Python Environment for Bayesian Learning. [Deprecated]
Theano - Optimizing GPU-meta-programming code generating array oriented optimizing math compiler in Python.
TensorFlow - Open source software library for numerical computation using data flow graphs.
pomegranate - Hidden Markov Models for Python, implemented in Cython for speed and efficiency.
python-timbl - A Python extension module wrapping the full TiMBL C++ programming interface. Timbl is an elaborate k-Nearest Neighbours machine learning toolkit.
deap - Evolutionary algorithm framework.
pydeep - Deep Learning In Python. [Deprecated]
mlxtend - A library consisting of useful tools for data science and machine learning tasks.
neon - Nervana's high-performance Python-based Deep Learning framework [DEEP LEARNING].
Optunity - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search.
Neural Networks and Deep Learning - Code samples for my book "Neural Networks and Deep Learning" [DEEP LEARNING].
Annoy - Approximate nearest neighbours implementation.
TPOT - Tool that automatically creates and optimizes machine learning pipelines using genetic programming. Consider it your personal data science assistant, automating a tedious part of machine learning.
pgmpy A python library for working with Probabilistic Graphical Models.
DIGITS - The Deep Learning GPU Training System (DIGITS) is a web application for training deep learning models.
Orange - Open source data visualization and data analysis for novices and experts.
MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.
milk - Machine learning toolkit focused on supervised classification. [Deprecated]
TFLearn - Deep learning library featuring a higher-level API for TensorFlow.
REP - an IPython-based environment for conducting data-driven research in a consistent and reproducible way. REP is not trying to substitute scikit-learn, but extends it and provides better user experience. [Deprecated]
rgf_python - Python bindings for Regularized Greedy Forest (Tree) Library.
skbayes - Python package for Bayesian Machine Learning with scikit-learn API.
fuku-ml - Simple machine learning library, including Perceptron, Regression, Support Vector Machine, Decision Tree and more, it's easy to use and easy to learn for beginners.
Xcessiv - A web-based application for quick, scalable, and automated hyperparameter tuning and stacked ensembling.
PyTorch - Tensors and Dynamic neural networks in Python with strong GPU acceleration
ML-From-Scratch - Implementations of Machine Learning models from scratch in Python with a focus on transparency. Aims to showcase the nuts and bolts of ML in an accessible way.
Edward - A library for probabilistic modeling, inference, and criticism. Built on top of TensorFlow.
xRBM - A library for Restricted Boltzmann Machine (RBM) and its conditional variants in Tensorflow.
CatBoost - General purpose gradient boosting on decision trees library with categorical features support out of the box. It is easy to install, well documented and supports CPU and GPU (even multi-GPU) computation.
stacked_generalization - Implementation of machine learning stacking technic as handy library in Python.
modAL - A modular active learning framework for Python, built on top of scikit-learn.
Cogitare: A Modern, Fast, and Modular Deep Learning and Machine Learning framework for Python.
Parris - Parris, the automated infrastructure setup tool for machine learning algorithms.
neonrvm - neonrvm is an open source machine learning library based on RVM technique. It's written in C programming language and comes with Python programming language bindings.
Turi Create - Machine learning from Apple. Turi Create simplifies the development of custom machine learning models. You don't have to be a machine learning expert to add recommendations, object detection, image classification, image similarity or activity classification to your app.
xLearn - A high performance, easy-to-use, and scalable machine learning package, which can be used to solve large-scale machine learning problems. xLearn is especially useful for solving machine learning problems on large-scale sparse data, which is very common in Internet services such as online advertisement and recommender systems.
mlens - A high performance, memory efficient, maximally parallelized ensemble learning, integrated with scikit-learn.
Netron - Visualizer for machine learning models.
Thampi - Machine Learning Prediction System on AWS Lambda
MindsDB - Open Source framework to streamline use of neural networks.
Gorgonia - Gorgonia is a library that helps facilitate machine learning in Golang.
Microsoft Recommenders: Examples and best practices for building recommendation systems, provided as Jupyter notebooks. The repo contains some of the latest state of the art algorithms from Microsoft Research as well as from other companies and institutions.
StellarGraph: Machine Learning on Graphs, a Python library for machine learning on graph-structured (network-structured) data.
BentoML: Toolkit for package and deploy machine learning models for serving in production
MiraiML: An asynchronous engine for continuous & autonomous machine learning, built for real-time usage.
numpy-ML: Reference implementations of ML models written in numpy
creme: A framework for online machine learning.
Neuraxle: A framework providing the right abstractions to ease research, development, and deployment of your ML pipelines.

Data Analysis / Data Visualization
SciPy - A Python-based ecosystem of open-source software for mathematics, science, and engineering.
NumPy - A fundamental package for scientific computing with Python.
Numba - Python JIT (just in time) compiler to LLVM aimed at scientific Python by the developers of Cython and NumPy.
Mars - A tensor-based framework for large-scale data computation which often regarded as a parallel and distributed version of NumPy.
NetworkX - A high-productivity software for complex networks.
igraph - binding to igraph library - General purpose graph library.
Pandas - A library providing high-performance, easy-to-use data structures and data analysis tools.
Open Mining - Business Intelligence (BI) in Python (Pandas web interface) [Deprecated]
PyMC - Markov Chain Monte Carlo sampling toolkit.
zipline - A Pythonic algorithmic trading library.
PyDy - Short for Python Dynamics, used to assist with workflow in the modeling of dynamic motion based around NumPy, SciPy, IPython, and matplotlib.
SymPy - A Python library for symbolic mathematics.
statsmodels - Statistical modeling and econometrics in Python.
astropy - A community Python library for Astronomy.
matplotlib - A Python 2D plotting library.
bokeh - Interactive Web Plotting for Python.
plotly - Collaborative web plotting for Python and matplotlib.
altair - A Python to Vega translator.
d3py - A plotting library for Python, based on D3.js.
PyDexter - Simple plotting for Python. Wrapper for D3xterjs; easily render charts in-browser.
ggplot - Same API as ggplot2 for R. [Deprecated]
ggfortify - Unified interface to ggplot2 popular R packages.
Kartograph.py - Rendering beautiful SVG maps in Python.
pygal - A Python SVG Charts Creator.
PyQtGraph - A pure-python graphics and GUI library built on PyQt4 / PySide and NumPy.
pycascading [Deprecated]
Petrel - Tools for writing, submitting, debugging, and monitoring Storm topologies in pure Python.
Blaze - NumPy and Pandas interface to Big Data.
emcee - The Python ensemble sampling toolkit for affine-invariant MCMC.
windML - A Python Framework for Wind Energy Analysis and Prediction.
vispy - GPU-based high-performance interactive OpenGL 2D/3D data visualization library.
cerebro2 A web-based visualization and debugging platform for NuPIC. [Deprecated]
NuPIC Studio An all-in-one NuPIC Hierarchical Temporal Memory visualization and debugging super-tool! [Deprecated]
SparklingPandas Pandas on PySpark (POPS).
Seaborn - A python visualization library based on matplotlib.
bqplot - An API for plotting in Jupyter (IPython).
pastalog - Simple, realtime visualization of neural network training performance.
Superset - A data exploration platform designed to be visual, intuitive, and interactive.
Dora - Tools for exploratory data analysis in Python.
Ruffus - Computation Pipeline library for python.
SOMPY - Self Organizing Map written in Python (Uses neural networks for data analysis).
somoclu Massively parallel self-organizing maps: accelerate training on multicore CPUs, GPUs, and clusters, has python API.
HDBScan - implementation of the hdbscan algorithm in Python - used for clustering
visualize_ML - A python package for data exploration and data analysis. [Deprecated]
scikit-plot - A visualization library for quick and easy generation of common plots in data analysis and machine learning.
Bowtie - A dashboard library for interactive visualizations using flask socketio and react.
lime - Lime is about explaining what machine learning classifiers (or models) are doing. It is able to explain any black box classifier, with two or more classes.
PyCM - PyCM is a multi-class confusion matrix library written in Python that supports both input data vectors and direct matrix, and a proper tool for post-classification model evaluation that supports most classes and overall statistics parameters
Dash - A framework for creating analytical web applications built on top of Plotly.js, React, and Flask
Lambdo - A workflow engine for solving machine learning problems by combining in one analysis pipeline (i) feature engineering and machine learning (ii) model training and prediction (iii) table population and column evaluation via user-defined (Python) functions.
TensorWatch - Debugging and visualization tool for machine learning and data science. It extensively leverages Jupyter Notebook to show real-time visualizations of data in running processes such as machine learning training.

Misc Scripts / iPython Notebooks / Codebases
Map/Reduce implementations of common ML algorithms: Jupyter notebooks that cover how to implement from scratch different ML algorithms (ordinary least squares, gradient descent, k-means, alternating least squares), using Python NumPy, and how to then make these implementations scalable using Map/Reduce and Spark.
BioPy - Biologically-Inspired and Machine Learning Algorithms in Python. [Deprecated]
SVM Explorer - Interactive SVM Explorer, using Dash and scikit-learn
pattern_classification
thinking stats 2
hyperopt
numpic
2012-paper-diginorm
A gallery of interesting IPython notebooks
ipython-notebooks
data-science-ipython-notebooks - Continually updated Data Science Python Notebooks: Spark, Hadoop MapReduce, HDFS, AWS, Kaggle, scikit-learn, matplotlib, pandas, NumPy, SciPy, and various command lines.
decision-weights
Sarah Palin LDA - Topic Modeling the Sarah Palin emails.
Diffusion Segmentation - A collection of image segmentation algorithms based on diffusion methods.
Scipy Tutorials - SciPy tutorials. This is outdated, check out scipy-lecture-notes.
Crab - A recommendation engine library for Python.
BayesPy - Bayesian Inference Tools in Python.
scikit-learn tutorials - Series of notebooks for learning scikit-learn.
sentiment-analyzer - Tweets Sentiment Analyzer
sentiment_classifier - Sentiment classifier using word sense disambiguation.
group-lasso - Some experiments with the coordinate descent algorithm used in the (Sparse) Group Lasso model.
jProcessing - Kanji / Hiragana / Katakana to Romaji Converter. Edict Dictionary & parallel sentences Search. Sentence Similarity between two JP Sentences. Sentiment Analysis of Japanese Text. Run Cabocha(ISO--8859-1 configured) in Python.
mne-python-notebooks - IPython notebooks for EEG/MEG data processing using mne-python.
Neon Course - IPython notebooks for a complete course around understanding Nervana's Neon.
pandas cookbook - Recipes for using Python's pandas library.
climin - Optimization library focused on machine learning, pythonic implementations of gradient descent, LBFGS, rmsprop, adadelta and others.
Allen Downey’s Data Science Course - Code for Data Science at Olin College, Spring 2014.
Allen Downey’s Think Bayes Code - Code repository for Think Bayes.
Allen Downey’s Think Complexity Code - Code for Allen Downey's book Think Complexity.
Allen Downey’s Think OS Code - Text and supporting code for Think OS: A Brief Introduction to Operating Systems.
Python Programming for the Humanities - Course for Python programming for the Humanities, assuming no prior knowledge. Heavy focus on text processing / NLP.
GreatCircle - Library for calculating great circle distance.
Optunity examples - Examples demonstrating how to use Optunity in synergy with machine learning libraries.
Dive into Machine Learning with Python Jupyter notebook and scikit-learn - "I learned Python by hacking first, and getting serious later. I wanted to do this with Machine Learning. If this is your style, join me in getting a bit ahead of yourself."
TDB - TensorDebugger (TDB) is a visual debugger for deep learning. It features interactive, node-by-node debugging and visualization for TensorFlow.
Suiron - Machine Learning for RC Cars.
Introduction to machine learning with scikit-learn - IPython notebooks from Data School's video tutorials on scikit-learn.
Practical XGBoost in Python - comprehensive online course about using XGBoost in Python.
Introduction to Machine Learning with Python - Notebooks and code for the book "Introduction to Machine Learning with Python"
Pydata book - Materials and IPython notebooks for "Python for Data Analysis" by Wes McKinney, published by O'Reilly Media
Homemade Machine Learning - Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained
Prodmodel - Build tool for data science pipelines.
the-elements-of-statistical-learning - This repository contains Jupyter notebooks implementing the algorithms found in the book and summary of the textbook.

Neural Networks
NeuralTalk - NeuralTalk is a Python+numpy project for learning Multimodal Recurrent Neural Networks that describe images with sentences. [Deprecated]
Neuron - Neuron is simple class for time series predictions. It's utilize LNU (Linear Neural Unit), QNU (Quadratic Neural Unit), RBF (Radial Basis Function), MLP (Multi Layer Perceptron), MLP-ELM (Multi Layer Perceptron - Extreme Learning Machine) neural networks learned with Gradient descent or LeLevenberg–Marquardt algorithm. [Deprecated]
Data Driven Code - Very simple implementation of neural networks for dummies in python without using any libraries, with detailed comments.

Kaggle Competition Source Code
open-solution-home-credit -> source code and experiments results for Home Credit Default Risk.
open-solution-googleai-object-detection -> source code and experiments results for Google AI Open Images - Object Detection Track.
open-solution-salt-identification -> source code and experiments results for TGS Salt Identification Challenge.
open-solution-ship-detection -> source code and experiments results for Airbus Ship Detection Challenge.
open-solution-data-science-bowl-2018 -> source code and experiments results for 2018 Data Science Bowl.
open-solution-value-prediction -> source code and experiments results for Santander Value Prediction Challenge.
open-solution-toxic-comments -> source code for Toxic Comment Classification Challenge.
wiki challenge - An implementation of Dell Zhang's solution to Wikipedia's Participation Challenge on Kaggle.
kaggle insults - Kaggle Submission for "Detecting Insults in Social Commentary".
kaggle_acquire-valued-shoppers-challenge - Code for the Kaggle acquire valued shoppers challenge.
kaggle-cifar - Code for the CIFAR-10 competition at Kaggle, uses cuda-convnet.
kaggle-blackbox - Deep learning made easy.
kaggle-accelerometer - Code for Accelerometer Biometric Competition at Kaggle.
kaggle-advertised-salaries - Predicting job salaries from ads - a Kaggle competition.
kaggle amazon - Amazon access control challenge.
kaggle-bestbuy_big - Code for the Best Buy competition at Kaggle.
kaggle-bestbuy_small
Kaggle Dogs vs. Cats - Code for Kaggle Dogs vs. Cats competition.
Kaggle Galaxy Challenge - Winning solution for the Galaxy Challenge on Kaggle.
Kaggle Gender - A Kaggle competition: discriminate gender based on handwriting.
Kaggle Merck - Merck challenge at Kaggle.
Kaggle Stackoverflow - Predicting closed questions on Stack Overflow.
kaggle_acquire-valued-shoppers-challenge - Code for the Kaggle acquire valued shoppers challenge.
wine-quality - Predicting wine quality.

Reinforcement Learning
DeepMind Lab - DeepMind Lab is a 3D learning environment based on id Software's Quake III Arena via ioquake3 and other open source software. Its primary purpose is to act as a testbed for research in artificial intelligence, especially deep reinforcement learning.
Gym - OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms.
Serpent.AI - Serpent.AI is a game agent framework that allows you to turn any video game you own into a sandbox to develop AI and machine learning experiments. For both researchers and hobbyists.
ViZDoom - ViZDoom allows developing AI bots that play Doom using only the visual information (the screen buffer). It is primarily intended for research in machine visual learning, and deep reinforcement learning, in particular.
Roboschool - Open-source software for robot simulation, integrated with OpenAI Gym.
Retro - Retro Games in Gym
SLM Lab - Modular Deep Reinforcement Learning framework in PyTorch.
Coach - Reinforcement Learning Coach by Intel® AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms

Ruby

Natural Language Processing
Awesome NLP with Ruby - Curated link list for practical natural language processing in Ruby.
Treat - Text REtrieval and Annotation Toolkit, definitely the most comprehensive toolkit I’ve encountered so far for Ruby.
Stemmer - Expose libstemmer_c to Ruby. [Deprecated]
Raspel - raspell is an interface binding for ruby. [Deprecated]
UEA Stemmer - Ruby port of UEALite Stemmer - a conservative stemmer for search and indexing.
Twitter-text-rb - A library that does auto linking and extraction of usernames, lists and hashtags in tweets.

General-Purpose Machine Learning
Awesome Machine Learning with Ruby - Curated list of ML related resources for Ruby.
Ruby Machine Learning - Some Machine Learning algorithms, implemented in Ruby. [Deprecated]
Machine Learning Ruby [Deprecated]
jRuby Mahout - JRuby Mahout is a gem that unleashes the power of Apache Mahout in the world of JRuby. [Deprecated]
CardMagic-Classifier - A general classifier module to allow Bayesian and other types of classifications.
rb-libsvm - Ruby language bindings for LIBSVM which is a Library for Support Vector Machines.
Scoruby - Creates Random Forest classifiers from PMML files.

Data Analysis / Data Visualization
rsruby - Ruby - R bridge.
data-visualization-ruby - Source code and supporting content for my Ruby Manor presentation on Data Visualisation with Ruby. [Deprecated]
ruby-plot - gnuplot wrapper for Ruby, especially for plotting ROC curves into SVG files. [Deprecated]
plot-rb - A plotting library in Ruby built on top of Vega and D3. [Deprecated]
scruffy - A beautiful graphing toolkit for Ruby.
SciRuby
Glean - A data management tool for humans. [Deprecated]
Bioruby
Arel [Deprecated]

Misc
Big Data For Chimps
Listof - Community based data collection, packed in gem. Get list of pretty much anything (stop words, countries, non words) in txt, json or hash. Demo/Search for a list

Rust

General-Purpose Machine Learning
deeplearn-rs - deeplearn-rs provides simple networks that use matrix multiplication, addition, and ReLU under the MIT license.
rustlearn - a machine learning framework featuring logistic regression, support vector machines, decision trees and random forests.
rusty-machine - a pure-rust machine learning library.
leaf - open source framework for machine intelligence, sharing concepts from TensorFlow and Caffe. Available under the MIT license. [Deprecated]
RustNN - RustNN is a feedforward neural network library. [Deprecated]
RusticSOM - A Rust library for Self Organising Maps (SOM).

R

General-Purpose Machine Learning
ahaz - ahaz: Regularization for semiparametric additive hazards regression. [Deprecated]
arules - arules: Mining Association Rules and Frequent Itemsets
biglasso - biglasso: Extending Lasso Model Fitting to Big Data in R.
bmrm - bmrm: Bundle Methods for Regularized Risk Minimization Package.
Boruta - Boruta: A wrapper algorithm for all-relevant feature selection.
bst - bst: Gradient Boosting.
C50 - C50: C5.0 Decision Trees and Rule-Based Models.
caret - Classification and Regression Training: Unified interface to ~150 ML algorithms in R.
caretEnsemble - caretEnsemble: Framework for fitting multiple caret models as well as creating ensembles of such models. [Deprecated]
CatBoost - General purpose gradient boosting on decision trees library with categorical features support out of the box for R.
Clever Algorithms For Machine Learning
CORElearn - CORElearn: Classification, regression, feature evaluation and ordinal evaluation.
CoxBoost - CoxBoost: Cox models by likelihood based boosting for a single survival endpoint or competing risks [Deprecated]
Cubist - Cubist: Rule- and Instance-Based Regression Modeling.
e1071 - e1071: Misc Functions of the Department of Statistics (e1071), TU Wien
earth - earth: Multivariate Adaptive Regression Spline Models
elasticnet - elasticnet: Elastic-Net for Sparse Estimation and Sparse PCA.
ElemStatLearn - ElemStatLearn: Data sets, functions and examples from the book: "The Elements of Statistical Learning, Data Mining, Inference, and Prediction" by Trevor Hastie, Robert Tibshirani and Jerome Friedman Prediction" by Trevor Hastie, Robert Tibshirani and Jerome Friedman.
evtree - evtree: Evolutionary Learning of Globally Optimal Trees.
forecast - forecast: Timeseries forecasting using ARIMA, ETS, STLM, TBATS, and neural network models.
forecastHybrid - forecastHybrid: Automatic ensemble and cross validation of ARIMA, ETS, STLM, TBATS, and neural network models from the "forecast" package.
fpc - fpc: Flexible procedures for clustering.
frbs - frbs: Fuzzy Rule-based Systems for Classification and Regression Tasks. [Deprecated]
GAMBoost - GAMBoost: Generalized linear and additive models by likelihood based boosting. [Deprecated]
gamboostLSS - gamboostLSS: Boosting Methods for GAMLSS.
gbm - gbm: Generalized Boosted Regression Models.
glmnet - glmnet: Lasso and elastic-net regularized generalized linear models.
glmpath - glmpath: L1 Regularization Path for Generalized Linear Models and Cox Proportional Hazards Model.
GMMBoost - GMMBoost: Likelihood-based Boosting for Generalized mixed models. [Deprecated]
grplasso - grplasso: Fitting user specified models with Group Lasso penalty.
grpreg - grpreg: Regularization paths for regression models with grouped covariates.
h2o - A framework for fast, parallel, and distributed machine learning algorithms at scale -- Deeplearning, Random forests, GBM, KMeans, PCA, GLM.
hda - hda: Heteroscedastic Discriminant Analysis. [Deprecated]
Introduction to Statistical Learning
ipred - ipred: Improved Predictors.
kernlab - kernlab: Kernel-based Machine Learning Lab.
klaR - klaR: Classification and visualization.
L0Learn - L0Learn: Fast algorithms for best subset selection.
lars - lars: Least Angle Regression, Lasso and Forward Stagewise. [Deprecated]
lasso2 - lasso2: L1 constrained estimation aka ‘lasso’.
LiblineaR - LiblineaR: Linear Predictive Models Based On The Liblinear C/C++ Library.
LogicReg - LogicReg: Logic Regression.
Machine Learning For Hackers
maptree - maptree: Mapping, pruning, and graphing tree models. [Deprecated]
mboost - mboost: Model-Based Boosting.
medley - medley: Blending regression models, using a greedy stepwise approach.
mlr - mlr: Machine Learning in R.
ncvreg - ncvreg: Regularization paths for SCAD- and MCP-penalized regression models.
nnet - nnet: Feed-forward Neural Networks and Multinomial Log-Linear Models. [Deprecated]
pamr - pamr: Pam: prediction analysis for microarrays. [Deprecated]
party - party: A Laboratory for Recursive Partytioning.
partykit - partykit: A Toolkit for Recursive Partytioning.
penalized - penalized: L1 (lasso and fused lasso) and L2 (ridge) penalized estimation in GLMs and in the Cox model.
penalizedLDA - penalizedLDA: Penalized classification using Fisher's linear discriminant. [Deprecated]
penalizedSVM - penalizedSVM: Feature Selection SVM using penalty functions.
quantregForest - quantregForest: Quantile Regression Forests.
randomForest - randomForest: Breiman and Cutler's random forests for classification and regression.
randomForestSRC - randomForestSRC: Random Forests for Survival, Regression and Classification (RF-SRC).
rattle - rattle: Graphical user interface for data mining in R.
rda - rda: Shrunken Centroids Regularized Discriminant Analysis.
rdetools - rdetools: Relevant Dimension Estimation (RDE) in Feature Spaces. [Deprecated]
REEMtree - REEMtree: Regression Trees with Random Effects for Longitudinal (Panel) Data. [Deprecated]
relaxo - relaxo: Relaxed Lasso. [Deprecated]
rgenoud - rgenoud: R version of GENetic Optimization Using Derivatives
Rmalschains - Rmalschains: Continuous Optimization using Memetic Algorithms with Local Search Chains (MA-LS-Chains) in R.
rminer - rminer: Simpler use of data mining methods (e.g. NN and SVM) in classification and regression. [Deprecated]
ROCR - ROCR: Visualizing the performance of scoring classifiers. [Deprecated]
RoughSets - RoughSets: Data Analysis Using Rough Set and Fuzzy Rough Set Theories. [Deprecated]
rpart - rpart: Recursive Partitioning and Regression Trees.
RPMM - RPMM: Recursively Partitioned Mixture Model.
RSNNS - RSNNS: Neural Networks in R using the Stuttgart Neural Network Simulator (SNNS).
RWeka - RWeka: R/Weka interface.
RXshrink - RXshrink: Maximum Likelihood Shrinkage via Generalized Ridge or Least Angle Regression.
sda - sda: Shrinkage Discriminant Analysis and CAT Score Variable Selection. [Deprecated]
spectralGraphTopology - spectralGraphTopology: Learning Graphs from Data via Spectral Constraints.
SuperLearner - Multi-algorithm ensemble learning packages.
svmpath - svmpath: svmpath: the SVM Path algorithm. [Deprecated]
tgp - tgp: Bayesian treed Gaussian process models. [Deprecated]
tree - tree: Classification and regression trees.
varSelRF - varSelRF: Variable selection using random forests.
XGBoost.R - R binding for eXtreme Gradient Boosting (Tree) Library.
Optunity - A library dedicated to automated hyperparameter optimization with a simple, lightweight API to facilitate drop-in replacement of grid search. Optunity is written in Python but interfaces seamlessly to R.
igraph - binding to igraph library - General purpose graph library.
MXNet - Lightweight, Portable, Flexible Distributed/Mobile Deep Learning with Dynamic, Mutation-aware Dataflow Dep Scheduler; for Python, R, Julia, Go, Javascript and more.
TDSP-Utilities - Two data science utilities in R from Microsoft: 1) Interactive Data Exploration, Analysis, and Reporting (IDEAR) ; 2) Automated Modeling and Reporting (AMR).

Data Analysis / Data Visualization
ggplot2 - A data visualization package based on the grammar of graphics.
tmap for visualizing geospatial data with static maps and leaflet for interactive maps
tm and quanteda are the main packages for managing, analyzing, and visualizing textual data.
shiny is the basis for truly interactive displays and dashboards in R. However, some measure of interactivity can be achieved with htmlwidgets bringing javascript libraries to R. These include, plotly, dygraphs, highcharter, and several others.

SAS

General-Purpose Machine Learning
Visual Data Mining and Machine Learning - Interactive, automated, and programmatic modeling with the latest machine learning algorithms in and end-to-end analytics environment, from data prep to deployment. Free trial available.
Enterprise Miner - Data mining and machine learning that creates deployable models using a GUI or code.
Factory Miner - Automatically creates deployable machine learning models across numerous market or customer segments using a GUI.

Data Analysis / Data Visualization
SAS/STAT - For conducting advanced statistical analysis.
University Edition - FREE! Includes all SAS packages necessary for data analysis and visualization, and includes online SAS courses.

Natural Language Processing
Contextual Analysis - Add structure to unstructured text using a GUI.
Sentiment Analysis - Extract sentiment from text using a GUI.
Text Miner - Text mining using a GUI or code.

Demos and Scripts
ML_Tables - Concise cheat sheets containing machine learning best practices.
enlighten-apply - Example code and materials that illustrate applications of SAS machine learning techniques.
enlighten-integration - Example code and materials that illustrate techniques for integrating SAS with other analytics technologies in Java, PMML, Python and R.
enlighten-deep - Example code and materials that illustrate using neural networks with several hidden layers in SAS.
dm-flow - Library of SAS Enterprise Miner process flow diagrams to help you learn by example about specific data mining topics.

Scala

Natural Language Processing
ScalaNLP - ScalaNLP is a suite of machine learning and numerical computing libraries.
Breeze - Breeze is a numerical processing library for Scala.
Chalk - Chalk is a natural language processing library. [Deprecated]
FACTORIE - FACTORIE is a toolkit for deployable probabilistic modeling, implemented as a software library in Scala. It provides its users with a succinct language for creating relational factor graphs, estimating parameters and performing inference.
Montague - Montague is a semantic parsing library for Scala with an easy-to-use DSL.
Spark NLP - Natural language processing library built on top of Apache Spark ML to provide simple, performant, and accurate NLP annotations for machine learning pipelines, that scale easily in a distributed environment.

Data Analysis / Data Visualization
MLlib in Apache Spark - Distributed machine learning library in Spark
Hydrosphere Mist - a service for deployment Apache Spark MLLib machine learning models as realtime, batch or reactive web services.
Scalding - A Scala API for Cascading.
Summing Bird - Streaming MapReduce with Scalding and Storm.
Algebird - Abstract Algebra for Scala.
xerial - Data management utilities for Scala. [Deprecated]
PredictionIO - PredictionIO, a machine learning server for software developers and data engineers.
BIDMat - CPU and GPU-accelerated matrix library intended to support large-scale exploratory data analysis.
Flink - Open source platform for distributed stream and batch data processing.
Spark Notebook - Interactive and Reactive Data Science using Scala and Spark.

General-Purpose Machine Learning
DeepLearning.scala - Creating statically typed dynamic neural networks from object-oriented & functional programming constructs.
Conjecture - Scalable Machine Learning in Scalding.
brushfire - Distributed decision tree ensemble learning in Scala.
ganitha - Scalding powered machine learning. [Deprecated]
adam - A genomics processing engine and specialized file format built using Apache Avro, Apache Spark and Parquet. Apache 2 licensed.
bioscala - Bioinformatics for the Scala programming language
BIDMach - CPU and GPU-accelerated Machine Learning Library.
Figaro - a Scala library for constructing probabilistic models.
H2O Sparkling Water - H2O and Spark interoperability.
FlinkML in Apache Flink - Distributed machine learning library in Flink.
DynaML - Scala Library/REPL for Machine Learning Research.
Saul - Flexible Declarative Learning-Based Programming.
SwiftLearner - Simply written algorithms to help study ML or write your own implementations.
Smile - Statistical Machine Intelligence and Learning Engine.
doddle-model - An in-memory machine learning library built on top of Breeze. It provides immutable objects and exposes its functionality through a scikit-learn-like API.
TensorFlow Scala - Strongly-typed Scala API for TensorFlow.

Scheme

Neural Networks
layer - Neural network inference from the command line, implemented in CHICKEN Scheme.

Swift

General-Purpose Machine Learning
Bender - Fast Neural Networks framework built on top of Metal. Supports TensorFlow models.
Swift AI - Highly optimized artificial intelligence and machine learning library written in Swift.
BrainCore - The iOS and OS X neural network framework.
swix - A bare bones library that includes a general matrix language and wraps some OpenCV for iOS development. [Deprecated]
AIToolbox - A toolbox framework of AI modules written in Swift: Graphs/Trees, Linear Regression, Support Vector Machines, Neural Networks, PCA, KMeans, Genetic Algorithms, MDP, Mixture of Gaussians.
MLKit - A simple Machine Learning Framework written in Swift. Currently features Simple Linear Regression, Polynomial Regression, and Ridge Regression.
Swift Brain - The first neural network / machine learning library written in Swift. This is a project for AI algorithms in Swift for iOS and OS X development. This project includes algorithms focused on Bayes theorem, neural networks, SVMs, Matrices, etc...
Perfect TensorFlow - Swift Language Bindings of TensorFlow. Using native TensorFlow models on both macOS / Linux.
PredictionBuilder - A library for machine learning that builds predictions using a linear regression.
Awesome CoreML - A curated list of pretrained CoreML models.
Awesome Core ML Models - A curated list of machine learning models in CoreML format.

TensorFlow

General-Purpose Machine Learning
Awesome TensorFlow - A list of all things related to TensorFlow.
Golden TensorFlow - A """

str2 = str1.split("\n")
str3 = {}
for each in str2:
    
    if( each != ""):
        lang = each.split(" ")
        if( len(lang) == 1 ):
            key = each
            str3[key] = []

        index = each.find(" - ")
        if( index != -1 ):
            str3[key].append( each[0:index] )

# print("text,label")
# i =0
# for key,value in str3.items():
#     if( i%2 ==0):
#         print("\"",key.lower()," : ", " ".join(each.lower() for each in value),"\",__label__1")
#     else:
#         print("\"",key.lower()," : ", " ".join(each.lower() for each in value),"\",__label__2")
#     i = i+1

print( str3 )# # interests = [
# # (0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"),
# # (0, "Spark"), (0, "Storm"), (0, "Cassandra"),
# # (1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"),
# # (1, "Postgres"), (2, "Python"), (2, "scikit-learn"), (2, "scipy"),
# # (2, "numpy"), (2, "statsmodels"), (2, "pandas"), (3, "R"), (3, "Python"),
# # (3, "statistics"), (3, "regression"), (3, "probability"),
# # (4, "machine learning"), (4, "regression"), (4, "decision trees"),
# # (4, "libsvm"), (5, "Python"), (5, "R"), (5, "Java"), (5, "C++"),
# # (5, "Haskell"), (5, "programming languages"), (6, "statistics"),
# # (6, "probability"), (6, "mathematics"), (6, "theory"),
# # (7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),
# # (7, "neural networks"), (8, "neural networks"), (8, "deep learning"),
# # (8, "Big Data"), (8, "artificial intelligence"), (9, "Hadoop"),
# # (9, "Java"), (9, "MapReduce"), (9, "Big Data")
# # ]
# from collections import Counter
# from collections import defaultdict
# # # keys are interests, values are lists of user_ids with that interest
# # user_ids_by_interest = defaultdict(list)
# # for user_id, interest in interests:
# # 	user_ids_by_interest[interest].append(user_id)


# # interests_by_user_id = defaultdict(list)
# # for user_id, interest in interests:
# # 	interests_by_user_id[user_id].append(interest)



# # def most_common_interests_with(user):
# # 	return Counter(interested_user_id
# # 	for interest in interests_by_user_id[user["id"]]
# # 	for interested_user_id in user_ids_by_interest[interest]
# # 	if interested_user_id != user["id"])

# # print(most_common_interests_with({"id":0}))

# # salaries_and_tenures = [(83000, 8.7), (88000, 8.1),
# # (48000, 0.7), (76000, 6),
# # (69000, 6.5), (76000, 7.5),
# # (60000, 2.5), (83000, 10),
# # (48000, 1.9), (63000, 4.2)]

# # def tenure_bucket(tenure):
# # 	if tenure < 2:
# # 		return "less than two"
# # 	elif tenure < 5:
# # 		return "between two and five"
# # 	else:
# # 		return "more than five"
# # salary_by_tenure = defaultdict(list)
# # for salary, tenure in salaries_and_tenures:
# # 	salary_by_tenure[tenure].append(salary)

# # salary_by_tenure_bucket = defaultdict(list)
# # for salary, tenure in salaries_and_tenures:
# # 	bucket = tenure_bucket(tenure)
# # 	salary_by_tenure_bucket[bucket].append(salary)

# # # keys are tenure buckets, values are average salary for that bucket
# # average_salary_by_bucket = {
# # tenure_bucket : sum(salaries) / len(salaries)
# # for tenure_bucket, salaries in salary_by_tenure_bucket.items()
# # }

# # print(average_salary_by_bucket)

# interests = [
# (0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"),
# (0, "Spark"), (0, "Storm"), (0, "Cassandra"),
# (1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"),
# (1, "Postgres"), (2, "Python"), (2, "scikit-learn"), (2, "scipy"),
# (2, "numpy"), (2, "statsmodels"), (2, "pandas"), (3, "R"), (3, "Python"),
# (3, "statistics"), (3, "regression"), (3, "probability"),
# (4, "machine learning"), (4, "regression"), (4, "decision trees"),
# (4, "libsvm"), (5, "Python"), (5, "R"), (5, "Java"), (5, "C++"),
# (5, "Haskell"), (5, "programming languages"), (6, "statistics"),
# (6, "probability"), (6, "mathematics"), (6, "theory"),
# (7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),
# (7, "neural networks"), (8, "neural networks"), (8, "deep learning"),
# (8, "Big Data"), (8, "artificial intelligence"), (9, "Hadoop"),
# (9, "Java"), (9, "MapReduce"), (9, "Big Data")
# ]

# words_and_counts = Counter(word
# for user, interest in interests
# for word in interest.lower().split())

# # print(words_and_counts)

# for word, count in words_and_counts.most_common():
# 	if count > 1:
# 		print( word, count)

# def lazy_range(n):
# 	i = 0
# 	print(i)
# 	while i< n:
# 		yield i
# 		print(i)
# 		i = i + 1

# for i in lazy_range(10):
# 	print("here")

def doubler(f):
	print(f)
	def g(x):sss
		print("hi")
		return 2*f(x)
	return g

def f1(x):
	return x+1

g = doubler(f1)
print(g(3))
from matplotlib import pyplot as plt
years = [1950, 1960, 1970, 1980, 1990, 2000, 2010]
gdp = [300.2, 543.3, 1075.9, 2862.5, 5979.6, 10289.7, 14958.3]
# create a line chart, years on x-axis, gdp on y-axis
plt.plot(years, gdp, color='green', marker='o', linestyle='solid')
# add a title
plt.title("Nominal GDP")
# add a label to the y-axis
plt.ylabel("Billions of $")
plt.show() import math, random
from collections import defaultdict, Counter
from data_science_04 import dot

users_interests = [
    ["Hadoop", "Big Data", "HBase", "Java", "Spark", "Storm", "Cassandra"],
    ["NoSQL", "MongoDB", "Cassandra", "HBase", "Postgres"],
    ["Python", "scikit-learn", "scipy", "numpy", "statsmodels", "pandas"],
    ["R", "Python", "statistics", "regression", "probability"],
    ["machine learning", "regression", "decision trees", "libsvm"],
    ["Python", "R", "Java", "C++", "Haskell", "programming languages"],
    ["statistics", "probability", "mathematics", "theory"],
    ["machine learning", "scikit-learn", "Mahout", "neural networks"],
    ["neural networks", "deep learning", "Big Data", "artificial intelligence"],
    ["Hadoop", "Java", "MapReduce", "Big Data"],
    ["statistics", "R", "statsmodels"],
    ["C++", "deep learning", "artificial intelligence", "probability"],
    ["pandas", "R", "Python"],
    ["databases", "HBase", "Postgres", "MySQL", "MongoDB"],
    ["libsvm", "regression", "support vector machines"]
]


#リコメンドシステム

#人気が高いものをリコメンドする
popular_interests = Counter(interest for user_interests in users_interests for interests in user_interests).most_common()
"""
結果
[('Python', 4), ('R', 4), ('Java', 3), ('regression', 3), ('statistics', 3), ('probability', 3), ...]
"""

def most_popular_new_interests(user_interests, max_results = 5):
    suggestions = [(interests, frequency) for interest, frequency in popular_interests
                    if interest not in user_interests]
    return suggestions[:max_results]

"""
ユーザー１は既に次の興味を持っている
["NoSOL", "MongoDB", "Cassandra", "HBase", "Postgres"]
よって
most_popular_new_interests(user_interests[1], 5)
#[('Python', 4), ('R', 4), 'Java', 3), ('regression', 3), ('statistics', 3)]
"""

"""
ユーザー３は
[('Java', 3), ('HBase', 3), ('Big Data', 3), ('neural networks', 2), ('Hadoop', 2)]
"""


#ユーザーベース協調フィルタリング

#コサイン類似度
def cosine_similarity(v, w):
    return dot(v, w) / math.squt(dot(v, v) * dot(w, w))

unique_interests = sorted(list({ interest for user_interests in users_interests for interest in user_interests}))
#['Big Data', 'C++', 'Cassandra', 'HBasa', 'Hadoop', 'Haskell', ...]

def make_user_interest_vector(user_interests):#興味を持ってれば1、持っていなければ0のベクトルを作る
    return [1 if interest in user_interests else 0 for interest in unique_interests]

user_interest_matrix = map(make_user_interest_vector, user_interests)

#全てのユーザーの類似度を計算
user_similarities = [[cosine_similarity(interest_vector_i, interest_vector_j)
                     for interest_vector_j in user_interest_matrix] for interest_vector_i in user_interest_matrix]

def most_similar_users_to(user_id):
    #類似度が0以外のユーザーを検索する
    pairs = [(other_user_id, similarity)
             for other_user_id, similarity in enumerate(user_similarities[user__id])
             if user_id != other_user_id and similarity > 0]

    return sorted(pairs, key = lambda ( , similarity): similarity, reverse = True)

"""
most_similar_users_to(0)
[(9, 0.5669467095138409),
 (1, 0.3380617018914066),
 (8, 0.1889822365046136),
 (13, 0.1690308509457033),
 (5, 0.1543033499620919)]
"""

#これを生かしてリコメンドする
def user_based_suggestions(user_id, include_current_interests = False):
    #類似度を加算
    suggestions = defaultdict(float)
    for other_user_id, similarity in most_similar_users_to(user_to):
        for interest im user_interests[other_user_id]:
            suggestions[interest] += similarity

    #リストをソートする
    suggestions = sorted(suggestions.items(), key = lambda (_, weight): weight, reverse = True)

    #おそらく既に興味として持っているものを除く
    if include_current_interests:
        return suggestions
    else:
        return [(suggestion, weight) for suggestion, weight in suggestions if suggestion not in user_interests[user_id]]

"""
user_based_suggestions(0)
[('MapReduce', 0.566694670905138409),
 ('MongoDB', 0.50709255283711),
 ('Postgres', 0.50709255283711),
 ('NoSQL', 0.3380617018914066),
 ('neural networks', 0.1889822365046136),
 ('deep learning', 0.1889822365046136),
 ('artificial intelligence', 0.1889822365046136),
 ...]
"""


#アイテムベース協調フィルタリング

interest_user_matrix = [[user_interest_vector[j] for user_interest_vector in user_interest_matrix]
                        for j, _ in enumerate(unique_interests)]
"""
Big Dataの場合
interst_user_matrix[0] = [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]
"""

interest_similarities = [[cosine_similarity(user_vector_i, user_vector_j)
                         for user_vector_j in interest_user_matrix]
                         for user_vector_i in interest_user_matrix]

def most_similar_interests_to(interest_id):
    similarities = interest_similarities[interest_id]
    pairs = [(unique_interests[others_interest_id], similarity) for others_interest_id, similarity in enumerate(similarities)
             if interest_id != other_interest_id and similarity > 0]

    return sorted(pairs, key = lambda (_, similarity): similarity, reverse = True)

"""
類似度の結果
[('Hadoop', 0.8164965809277261),
 ('Java', 0.6666666666666666),
 ('MapReduce', 0.5773502691896258),
 ('Spark', 0.5773502691896258),
 ('Storm', 0.5773502691896258),
 ('Cassandra', 0.4082482904638631),
 ('artificial intelligence', 0.4082482904638631),
 ('deep learning', 0.4082482904638631),
 ('neural networks', 0.4082482904638631),
 ('HBase', 0.3333333333333333)]
"""

#これを使って興味を持っている分野の類似度をユーザーごとに合計する
def item_based_suggestions(user_id, include_current_interests = False):
    #持っている興味に対する類似の分野の類似度を比較する
    suggestions = defaultdict(float)
    user_interest_vector = user_interest_matrix[user_id]
    for interest_id, is_interested in enumerate(user_interest_vector):
        if is_interested == 1:
            similar_interests = most_similar_interests_to(interested_id)
            for interest, similarity in similar_interests:
                suggestions[interest] += similarity

    #類似度の合計でソートする
    suggestions = sorted(suggestions.item(), key = lambda (_, similarity): similarity, reserve = True)

    if include_current_interests:
        return suggestions
    else:
        return [(suggestion, weight) for suggestion, weight in suggestions if suggestion not in user_interests[user_id]]

"""
ユーザー0へのおすすめ
[('MapReduce', 1.861807319565799),
 ('Postgres', 1.3164965809277263),
 ('MongoDB', 1.3164965809277263),
 ('NoSQL', 1.2844570503761732),
 ('programming languages', 0.5773502691896258),
 ('MySQL', 0.5773502691896258),
 ('Haskell', 0.5773502691896258),
 ('database', 0.5773502691896258),
 ('neural networks', 0.4082482904638631),
 ('deep learning', 0.4082482904638631),
 ('C++', 0.4082482904638631),
 ('artificial intelligence', 0.4082482904638631),
 ('Python', 0.2886751345948129),
 ('R', 0.2886751345948129)]
"""

interests = [
(0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"),
(0, "Spark"), (0, "Storm"), (0, "Cassandra"),
(1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"),
(1, "Postgres"), (2, "Python"), (2, "scikit-learn"), (2, "scipy"),
(2, "numpy"), (2, "statsmodels"), (2, "pandas"), (3, "R"), (3, "Python"),
(3, "statistics"), (3, "regression"), (3, "probability"),
(4, "machine learning"), (4, "regression"), (4, "decision trees"),
(4, "libsvm"), (5, "Python"), (5, "R"), (5, "Java"), (5, "C++"),
(5, "Haskell"), (5, "programming languages"), (6, "statistics"),
(6, "probability"), (6, "mathematics"), (6, "theory"),
(7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),
(7, "neural networks"), (8, "neural networks"), (8, "deep learning"),
(8, "Big Data"), (8, "artificial intelligence"), (9, "Hadoop"),
(9, "Java"), (9, "MapReduce"), (9, "Big Data")
]


def data_scientists_who_like(target_interest):
    return [user_id
    for user_id, user_interest in interests
    if user_interest == target_interest]


print(data_scientists_who_like("Java"))from collections import defaultdict

interests = [
(0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"),
(0, "Spark"), (0, "Storm"), (0, "Cassandra"),
(1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"),
(1, "Postgres"), (2, "Python"), (2, "scikit-learn"), (2, "scipy"),
(2, "numpy"), (2, "statsmodels"), (2, "pandas"), (3, "R"), (3, "Python"),
(3, "statistics"), (3, "regression"), (3, "probability"),
(4, "machine learning"), (4, "regression"), (4, "decision trees"),
(4, "libsvm"), (5, "Python"), (5, "R"), (5, "Java"), (5, "C++"),
(5, "Haskell"), (5, "programming languages"), (6, "statistics"),
(6, "probability"), (6, "mathematics"), (6, "theory"),
(7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),
(7, "neural networks"), (8, "neural networks"), (8, "deep learning"),
(8, "Big Data"), (8, "artificial intelligence"), (9, "Hadoop"),
(9, "Java"), (9, "MapReduce"), (9, "Big Data")
]

user_ids_by_interest = defaultdict(list)
for user_id, interest in interests:
    user_ids_by_interest[interest].append(user_id)

print(user_ids_by_interest)

for item, val in user_ids_by_interest.items():
    print(item,val)

################################################
# File name: download.py                       #
# Author: Mahmoud Badry                        #
# Date created: 2/11/2018                      #
# Date last modified: 2/11/2018                #
# Python Version: 3                            #
# Purpose: Download all notes in PDF format    #
# Requirements: pypandoc >= 1.4                #
################################################
import pypandoc


def main():
    home_link = "https://raw.githubusercontent.com/mbadry1/DeepLearning.ai-Summary/master/"
    marks_down_links = {
        "Deeplearning.ai summary Homepage":
            home_link + "Readme.md",
        "01- Neural Networks and Deep Learning":
            home_link + "1-%20Neural%20Networks%20and%20Deep%20Learning/Readme.md",
        "02- Improving Deep Neural Networks Hyperparameter tuning, Regularization and Optimization":
            home_link + "2-%20Improving%20Deep%20Neural%20Networks/Readme.md",
        "03- Structuring Machine Learning Projects":
            home_link + "3-%20Structuring%20Machine%20Learning%20Projects/Readme.md",
        "04- Convolutional Neural Networks":
            home_link + "4-%20Convolutional%20Neural%20Networks/Readme.md",
        "05- Sequence Models":
            home_link + "5-%20Sequence%20Models/Readme.md",
    }

    # Extracting pandoc version
    print("pandoc_version:", pypandoc.get_pandoc_version())
    print("pandoc_path:", pypandoc.get_pandoc_path())
    print("\n")

    # Starting downloading and converting
    for key, value in marks_down_links.items():
        print("Converting", key)
        pypandoc.convert_file(
            value,
            'pdf',
            extra_args=['--latex-engine=xelatex', '-V', 'geometry:margin=1.5cm'],
            outputfile=(key + ".pdf")
        )
        print("Converting", key, "completed")


if __name__ == "__main__":
    main()
from matplotlib import pyplot as plt
from collections import Counter

#  5 Construa um histograma de palavras em interesses. Por exemplo, a palavra 
# learning pode aparecer em machine learning e em deep learning. Quebre cada 
# interesse em palavras para fazer a contagem e montar o histograma.
interesses = [
(0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"), (0, "Spark"), (0, "Storm"), (0, "Cassandra"),
(1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"), (1, "Postgres"), 
(2, "Python"), (2, "scikit-learn"), (2, "scipy"), (2, "numpy"), (2, "statsmodel"), (2, "pandas"), 
(3, "R"), (3, "Python"), (3, "statistics"), (3, "regression"), (3, "probability"),
(4, "machine learning"), (4, "regression"), (4, "decision trees"), (4, "libsvm"), 
(5, "Python"), (5, "R"),(5, "Java"), (5, "C++"), (5, "Haskell"), (5, "programming languages"), 
(6, "theory"),
(7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),(7, "neural networks"), 
(8, "neural networks"), (8, "deep learning"), (8, "Big Data"), (8, "artificial intelligence"), (8, "Hadoop"),
(9, "Java"), (9, "MapReduce"), (9, "Big Data"),
]
frequencia_palavras = Counter (
    palavra
    for usuario, assunto in interesses
    for palavra in assunto.lower().split()
)

d1 = [ e for e in frequencia_palavras.items() if e[1] > 1 ]

plt.bar (
    [
        palavra[0] for palavra in d1
    ],
    [
        palavra[1] for palavra in d1
    ],
    .8
)
plt.title ("Tecnologias com mais citações")
plt.axis ([-0.5, 13.5, 1, 4])
plt.xticks ([i for i in range(14)])
plt.xlabel ("Tecnologia")
plt.yticks ([i for i in range(4)])
plt.ylabel ("Número de citações")
plt.show()from math import sqrt
import pandas as pd

def get_users_interests():
    return pd.read_csv('interest.csv', sep=',', header=None, index_col=0).values

def get_users_interests_poor():
    return [
        ["Hadoop", "Big Data", "HBase", "Java", "Spark", "Storm", "Cassandra"],
        ["NoSQL", "MongoDB", "Cassandra", "HBase", "Postgres"],
        ["Python", "scikit-learn", "scipy", "numpy", "statsmodels", "pandas"],
        ["R", "Python", "statistics", "regression", "probability"],
        ["machine learning", "regression", "decision trees", "libsvm"],
        ["Python", "R", "Java", "C++", "Haskell", "programming languages"],
        ["statistics", "probability", "mathematics", "theory"],
        ["machine learning", "scikit-learn", "Mahout", "neural networks"],
        ["neural networks", "deep learning", "Big Data", "artificial intelligence"],
        ["Hadoop", "Java", "MapReduce", "Big Data"],
        ["statistics", "R", "statsmodels"],
        ["C++", "deep learning", "artificial intelligence", "probability"],
        ["pandas", "R", "Python"],
        ["databases", "HBase", "Postgres", "MySQL", "MongoDB"],
        ["libsvm", "regression", "support vector machines"]
    ]

def print_matrix(m):
    for r in m:
        print rfrom collections import Counter, defaultdict

users = [
        { "id": 0, "name": "Hero" },
        { "id": 1, "name": "Dunn" },
        { "id": 2, "name": "Sue" },
        { "id": 3, "name": "Chi" },
        { "id": 4, "name": "Thor" },
        { "id": 5, "name": "Clive" },
        { "id": 6, "name": "Hicks" },
        { "id": 7, "name": "Devin" },
        { "id": 8, "name": "Kate" },
        { "id": 9, "name": "Klein" }
]

friendships = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),
               (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]


users_and_friends = map(lambda x: dict(id=x["id"], name=x["name"], friends=[]), users)

for friendship in friendships:
    i, j = friendship
    users_and_friends[i]["friends"].append(users_and_friends[j])
    users_and_friends[j]["friends"].append(users_and_friends[i])


def friendlen(user):
    return len(user["friends"])

#answers

total_connections = sum(friendlen(user) for user in users_and_friends)
total_peoples = len(users_and_friends)
avg_connections = total_connections / total_peoples
mapped_connections = map(lambda x: (x["id"], len(x["friends"])), users_and_friends)

print "Total Connections, {}".format(total_connections)
print "Total Peoples, {}".format(total_peoples)
print "Average Connectins, {}".format(avg_connections)
print "Mapped Connections, {}".format(sorted(mapped_connections, key=lambda x: x[1]))

# suggesting friends
def friends_of_friends(user):
    return [foaf["id"] for friend in user["friends"] for foaf in friend["friends"]]

def suggestion(user):
    lst = friends_of_friends(user)
    friends = [x["id"] for x in users_and_friends[user["id"]]["friends"]]
    result = Counter(lst) - Counter(friends)
    result.pop(user["id"], None)
    return result

print "Suggested Friend for 3 is, {}".format(suggestion(users_and_friends[3]))


## Data once again
interests = [
        (0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"),
        (0, "Spark"), (0, "Storm"), (0, "Cassandra"),
        (1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"),
        (1, "Postgres"), (2, "Python"), (2, "scikit-learn"), (2, "scipy"),
        (2, "numpy"), (2, "statsmodels"), (2, "pandas"), (3, "R"), (3, "Python"),
        (3, "statistics"), (3, "regression"), (3, "probability"),
        (4, "machine learning"), (4, "regression"), (4, "decision trees"),
        (4, "libsvm"), (5, "Python"), (5, "R"), (5, "Java"), (5, "C++"),
        (5, "Haskell"), (5, "programming languages"), (6, "statistics"),
        (6, "probability"), (6, "mathematics"), (6, "theory"),
        (7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),
        (7, "neural networks"), (8, "neural networks"), (8, "deep learning"),
        (8, "Big Data"), (8, "artificial intelligence"), (9, "Hadoop"),
        (9, "Java"), (9, "MapReduce"), (9, "Big Data")
]

user_by_interests = defaultdict(list)
interest_by_user = defaultdict(list)


for user, interest in interests:
    user_by_interests[interest].append(user)
    interest_by_user[user].append(interest)

def most_common_interests_with(user):
     return Counter(interested_user_id
                    for interest in interest_by_user[user["id"]]
                    for interested_user_id in user_by_interests[interest]
                    if interested_user_id != user["id"])

# Answers for most_common interest
print "Most Common interest : {}".format(most_common_interests_with(users_and_friends[3]))


salaries_and_tenures = [(83000, 8.7), (88000, 8.1),
                            (48000, 0.7), (76000, 6),
                            (69000, 6.5), (76000, 7.5),
                            (60000, 2.5), (83000, 10),
                            (48000, 1.9), (63000, 4.2)]


def group_tenure(gp):
    sal, tenure = gp
    if tenure <= 2:
        return "genin", sal
    if 2 < tenure <= 5:
        return "chunin", sal
    if 5 < tenure:
        return "jounin", sal

mapped_bucked = map(group_tenure, salaries_and_tenures)

grouped_bucket = defaultdict(list)

for key, value in mapped_bucked:
    grouped_bucket[key].append(value)

grouped_dict = { tenure: sum(values)/len(values)
                      for tenure, values in grouped_bucket.items() }

print grouped_dict

paid = 1,
unpaid = 0

paying_data = [(0.7, paid),(1.9, unpaid),
    (2.5, paid),
    (4.2, unpaid),
    (6, unpaid),
    (6.5, unpaid),
    (7.5, unpaid),
    (8.1, unpaid),
    (8.7, paid),
    (10,  paid)
]


"""
Question:

Accordingly,
if you wanted to create a model though this is definitely not
enough data to base a model on you might try to predict paid for users with
very few and very many years of experience
and unpaid for users with middling amounts of experience

"""

def group_paid(data):
    yeard, status = data
    if yeard <= 3:
        return "paid"
    elif 3< yeard <= 10:
        return "unpaid"
    return "paid"

group_payee = map(group_paid, paying_data)

#answer
print group_payee


interests = [
        (0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"),
        (0, "Spark"), (0, "Storm"), (0, "Cassandra"),
        (1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"),
        (1, "Postgres"), (2, "Python"), (2, "scikit-learn"), (2, "scipy"),
        (2, "numpy"), (2, "statsmodels"), (2, "pandas"), (3, "R"), (3, "Python"),
        (3, "statistics"), (3, "regression"), (3, "probability"),
        (4, "machine learning"), (4, "regression"), (4, "decision trees"),
        (4, "libsvm"), (5, "Python"), (5, "R"), (5, "Java"), (5, "C++"),
        (5, "Haskell"), (5, "programming languages"), (6, "statistics"),
        (6, "probability"), (6, "mathematics"), (6, "theory"),
        (7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),
        (7, "neural networks"), (8, "neural networks"), (8, "deep learning"),
        (8, "Big Data"), (8, "artificial intelligence"), (9, "Hadoop"),
        (9, "Java"), (9, "MapReduce"), (9, "Big Data")
]


"""
Question

As you re wrapping up your first day,
the VP of Content Strategy asks you for data about what topics users are most interested in,
so that she can plan out her blog calendar accordingly.
You already have the raw data from the friend-suggester project:
"""

print Counter(map(lambda x: x[1], interests))
import json

def genCourseraData():
	dct = {
		'Develop': [
			{
				'name': 'HTML, CSS, and Javascript for Web Developers',
				'certificate': 'https://www.coursera.org/account/accomplishments/certificate/CYZLFKN6FTFP',
				'link': 'https://www.coursera.org/learn/html-css-javascript-for-web-developers',
				'img': 'imgs/coursera/jhep-coursera-course4.jpeg',
				'university': "John Hopkins University",
				'specialization': False,
			},
			{
				'name': 'Concurrent Programming in Java',
				'certificate': 'https://www.coursera.org/account/accomplishments/certificate/QB77Z9N5NS7B',
				'link': 'https://www.coursera.org/learn/concurrent-programming-in-java',
				'img': 'imgs/coursera/concurrent.jpeg',
				'university': "Rice University",
				'specialization': False,
			},
		],
		'Machine Learning & Deep Learning': [
			{
				'name': 'Machine Learning',
				'certificate': 'https://www.coursera.org/account/accomplishments/specialization/certificate/78ACWG225K4F',
				'link': 'https://www.coursera.org/specializations/machine-learning',
				'img': 'imgs/coursera/machinelearning.jpeg',
				'specialization': True,
				'university': "Washington University",
				'courses': [
					{
						'name': 'Machine Learning Foundations: A Case Study Approach',
						'certificate': 'https://www.coursera.org/account/accomplishments/verify/6N9Q44KUHQW9',
					},
					{
						'name': 'Machine Learning: Regression',
						'certificate': 'https://www.coursera.org/account/accomplishments/certificate/RK6HF8G58QDX',
					},
					{
						'name': 'Machine Learning: Classification',
						'certificate': 'https://www.coursera.org/account/accomplishments/verify/PYEK24TJMY49',
					},
					{
						'name': 'Machine Learning: Clustering & Retrieval',
						'certificate': 'https://www.coursera.org/account/accomplishments/verify/5LHYMJJLLAE4',
					},
				]
			},
			{
				'name': 'Structuring Machine Learning Projects',
				'certificate': 'https://www.coursera.org/account/accomplishments/certificate/KPGAGAFYWGPM',
				'link': 'https://www.coursera.org/learn/machine-learning-projects',
				'img': 'imgs/coursera/CarouselAds_DL_ML.jpeg',
				'university': "deeplearning.ai",
				'specialization': False,
			},
			{
				'name': 'Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/SVSUUCSYK6CM',
				'link': 'https://www.coursera.org/learn/deep-neural-network',
				'img': 'imgs/coursera/CarouselAds_DL_Tuning.jpeg',
				'university': "deeplearning.ai",
				'specialization': False,
			},
			{
				'name': 'Neural Networks and Deep Learning',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/ADWV3R3AW2BY',
				'link': 'https://www.coursera.org/learn/neural-networks-deep-learning',
				'img': 'imgs/coursera/CarouselAds_DL_Neural.jpeg',
				'university': "deeplearning.ai",
				'specialization': False,
			},
			{
				'name': 'Applied Machine Learning in Python',
				'certificate': 'https://www.coursera.org/account/accomplishments/certificate/8XRWSBU6XVH3',
				'link': 'https://www.coursera.org/learn/python-machine-learning',
				'img': 'imgs/coursera/python_datascience_thumbnail_machinelearning_1x1.jpeg',
				'university': "University of Michigan",
				'specialization': False,
			},

		],
		'Programming Languages & Data Structures and Algorithms': [
			{
				'name': 'Introduction to Scripting in Python',
				'certificate': 'https://www.coursera.org/account/accomplishments/specialization/certificate/DNGX8GPV9YYA',
				'link': 'https://www.coursera.org/specializations/introduction-scripting-in-python',
				'img': 'imgs/coursera/Python-Developer.jpeg',
				'university': "Rice University",
				'specialization': True,
				'courses': [
					{
						'name': 'Python Programming Essentials',
						'certificate': 'https://www.coursera.org/account/accomplishments/verify/3YKERP76G22W',
					},
					{
						'name': 'Python Data Representations',
						'certificate': 'https://www.coursera.org/account/accomplishments/verify/WGT94QAV6Q7Y',
					},
					{
						'name': 'Python Data Visualization',
						'certificate': 'https://www.coursera.org/account/accomplishments/verify/UPMRTDPJMGTX',
					},
					{
						'name': 'Python Data Analysis',
						'certificate': 'https://www.coursera.org/account/accomplishments/verify/QWCL5WF6JPLD',
					},
				],
			},
			{
				'name': 'Java Programming: Arrays, Lists, and Structured Data',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/6T23MRAV3UKV',
				'link': 'https://www.coursera.org/learn/java-programming-arrays-lists-data',
				'img': 'imgs/coursera/work-731198_1280.jpeg',
				'university': "Duke University",
				'specialization': False,
			},
			{
				'name': 'Java Programming: Solving Problems with Software',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/ZDBKB6R84J8R',
				'link': 'https://www.coursera.org/learn/java-programming',
				'img': 'imgs/coursera/Java.jpeg',
				'university': "Duke University",
				'specialization': False,
			},
			{
				'name': 'Data structures Basics',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/6UQDAY2WSSCZ',
				'link': 'https://www.coursera.org/learn/shuju-jiegou-suanfa',
				'img': 'imgs/coursera/sjjg_608x211_info.jpeg',
				'university': "Peking University",
				'specialization': False,
			},
			{
				'name': 'Advanced Data Structures and Algorithms',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/CEJYKXA6LPN9',
				'link': 'https://www.coursera.org/learn/gaoji-shuju-jiegou',
				'img': 'imgs/coursera/dsalgo2_logo_g.jpeg',
				'university': "Peking University",
				'specialization': False,
			},
			{
				'name': 'C++ Programming',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/CEG2ZPN7SMWQ',
				'link': 'https://www.coursera.org/learn/cpp-chengxu-sheji',
				'img': 'imgs/coursera/__logo2.jpeg',
				'university': "Peking University",
				'specialization': False,
			},
			{
				'name': 'Programming for Everybody (Getting Started with Python)',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/4RWHWQYZ5FTD',
				'link': 'https://www.coursera.org/learn/python',
				'img': 'imgs/coursera/pythonlearn_thumbnail_1x1.jpeg',
				'university': "University of Michigan",
				'specialization': False,
			},
			{
				'name': 'Python Data Structures',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/7K9QJMYT6U8K',
				'link': 'https://www.coursera.org/learn/python-data',
				'img': 'imgs/coursera/pythondata_thumbnail_1x1.jpeg',
				'university': "University of Michigan",
				'specialization': False,
			},
			{
				'name': 'Using Databases with Python',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/75V78SAT59A6',
				'link': 'https://www.coursera.org/learn/python-databases',
				'img': 'imgs/coursera/pythondatabases_thumbnail_1x1.jpeg',
				'university': "University of Michigan",
				'specialization': False,
			},
			{
				'name': 'Using Python to Access Web Data',
				'certificate': 'https://www.coursera.org/account/accomplishments/verify/S5XHVKSMNWC3',
				'link': 'https://www.coursera.org/learn/python-network-data',
				'img': 'imgs/coursera/pythonnetworkdata_thumbnail_1x1.jpeg',
				'university': "University of Michigan",
				'specialization': False,
			},
		],
		'Basics': [
			{
				'name': 'Operating Systems',
				'certificate': 'https://www.coursera.org/account/accomplishments/certificate/LEUMDCW6D2BY',
				'link': 'https://www.coursera.org/learn/os-pku',
				'img': 'imgs/coursera/os_pku.jpg',
				'university': "Peking University",
				'specialization': False,
			},
			{
				'name': 'Computer Organization',
				'certificate': 'https://www.coursera.org/account/accomplishments/certificate/GW32J55D66RX',
				'link': 'https://www.coursera.org/learn/jisuanji-zucheng',
				'img': 'imgs/coursera/jisuanjizucheng.jpeg',
				'university': "Peking University",
				'specialization': False,
			},
			{
				'name': 'The Unix Workbench',
				'certificate': 'https://www.coursera.org/account/accomplishments/certificate/8LV65K4JXYWN',
				'link': 'https://www.coursera.org/learn/unix',
				'img': 'imgs/coursera/cover_square.jpeg',
				'university': "John Hopkins University",
				'specialization': False,
			},
			{
				'name': 'Version Control with Git',
				'certificate': 'https://www.coursera.org/account/accomplishments/certificate/G6Z9FFYZTWXJ',
				'link': 'https://www.coursera.org/learn/version-control-with-git',
				'img': 'imgs/coursera/Course-1-Logo.jpeg',
				'university': "Atlassian",
				'specialization': False,
			},
			{
				'name': 'Introduction to MongoDB',
				'certificate': 'https://www.coursera.org/account/accomplishments/certificate/9SDK5VHMWUU5',
				'link': 'https://www.coursera.org/learn/introduction-mongodb',
				'img': 'imgs/coursera/logo-first-app-coursera.jpeg',
				'university': "MongoDB Inc.",
				'specialization': False,
			},

		],
	}
	jsonStr = json.dumps(dct)
	return jsonStr

def gen():
	with open('data/coursera.json', 'w') as hd:
		hd.write(genCourseraData())

if __name__ == '__main__':
	gen()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Oct 26 21:30:34 2018

@author: wuming
"""
import pandas as pd
import xgboost as xgb
from sklearn.metrics  import  accuracy_score
import numpy as np
train=pd.read_csv('/Users/wuming/study/python_study/neural-networks-and-deep-learning-master/杂例子/kaggle/boston-housing/train.csv')
test=pd.read_csv('/Users/wuming/study/python_study/neural-networks-and-deep-learning-master/杂例子/kaggle/boston-housing/test.csv')
y_train=target=train['medv'].values
train.drop('medv',axis=1,inplace=True)
b=test['ID'].values


test_df=test.drop('ID',axis=1)
field_df = train.iloc[:,1:]


X_train=field_df1=field_df.values
test_df1=test_df.values
cv_params = {'n_estimators': [400, 500, 600, 700, 800]}
other_params = {'learning_rate': 0.1, 'n_estimators': 500, 'max_depth': 5, 'min_child_weight': 1, 'seed': 0,'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}
model = xgb.XGBRegressor(**other_params)
model=optimized_GBM = GridSearchCV(estimator=model, param_grid=cv_params, scoring='r2', cv=5, verbose=1, n_jobs=4)
model.fit(X_train, y_train)
a=model.predict(test_df1)
datafram=pd.DataFrame({'ID':b,'medv':a})
datafram.to_csv('/Users/wuming/study/python_study/neural-networks-and-deep-learning-master/杂例子/kaggle/boston-housing/submit3.csv',index=False,sep=',')

#!/usr/bin/env python
# coding: utf-8

# # Machine Learning Notebooks
# 
# *Welcome to the Machine Learning Notebooks!*
# 
# [Prerequisites](#Prerequisites) (see below)
# 
# ## Notebooks
# 1. [The Machine Learning landscape](01_the_machine_learning_landscape.ipynb)
# 2. [End-to-end Machine Learning project](02_end_to_end_machine_learning_project.ipynb)
# 3. [Classification](03_classification.ipynb)
# 4. [Training Models](04_training_linear_models.ipynb)
# 5. [Support Vector Machines](05_support_vector_machines.ipynb)
# 6. [Decision Trees](06_decision_trees.ipynb)
# 7. [Ensemble Learning and Random Forests](07_ensemble_learning_and_random_forests.ipynb)
# 8. [Dimensionality Reduction](08_dimensionality_reduction.ipynb)
# 9. [Unsupervised Learning Techniques](09_unsupervised_learning.ipynb)
# 10. [Artificial Neural Nets with Keras](10_neural_nets_with_keras.ipynb)
# 11. [Training Deep Neural Networks](11_training_deep_neural_networks.ipynb)
# 12. [Custom Models and Training with TensorFlow](12_custom_models_and_training_with_tensorflow.ipynb)
# 13. [Loading and Preprocessing Data](13_loading_and_preprocessing_data.ipynb)
# 14. [Deep Computer Vision Using Convolutional Neural Networks](14_deep_computer_vision_with_cnns.ipynb)
# 15. [Processing Sequences Using RNNs and CNNs](15_processing_sequences_using_rnns_and_cnns.ipynb)
# 16. [Natural Language Processing with RNNs and Attention](16_nlp_with_rnns_and_attention.ipynb)
# 17. [Representation Learning Using Autoencoders](17_autoencoders.ipynb)
# 18. [Reinforcement Learning](18_reinforcement_learning.ipynb)
# 19. [Training and Deploying TensorFlow Models at Scale](19_training_and_deploying_at_scale.ipynb)
# 
# ## Scientific Python tutorials
# * [NumPy](tools_numpy.ipynb)
# * [Matplotlib](tools_matplotlib.ipynb)
# * [Pandas](tools_pandas.ipynb)
# 
# ## Math Tutorials
# * [Linear Algebra](math_linear_algebra.ipynb)
# 
# ## Extra Material
# Work in progress
# 
# ## Misc.
# * [Equations](book_equations.ipynb) (list of equations in the book)
# 

# ## Prerequisites
# ### To understand
# * **Python** – you don't need to be an expert python programmer, but you do need to know the basics. If you don't, the official [Python tutorial](https://docs.python.org/3/tutorial/) is a good place to start.
# * **Scientific Python** – We will be using a few popular python libraries, in particular NumPy, matplotlib and pandas. If you are not familiar with these libraries, you should probably start by going through the tutorials in the Tools section (especially NumPy).
# * **Math** – We will also use some notions of Linear Algebra, Calculus, Statistics and Probability theory. You should be able to follow along if you learned these in the past as it won't be very advanced, but if you don't know about these topics or you need a refresher then go through the appropriate introduction in the Math section.
# 
# ### To run the examples
# * **Jupyter** – These notebooks are based on Jupyter. You can run these notebooks in just one click using a hosted platform such as Binder, Deepnote or Colaboratory (no installation required), or you can just view them using Jupyter.org's viewer, or you can install everything on your machine, as you prefer. Check out the [home page](https://github.com/ageron/handson-ml2/) for more details.

# In[ ]:




interests = [
(0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"),
(0, "Spark"), (0, "Storm"), (0, "Cassandra"),
(1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"),
(1, "Postgres"), (2, "Python"), (2, "scikit-learn"), (2, "scipy"),
(2, "numpy"), (2, "statsmodels"), (2, "pandas"), (3, "R"), (3, "Python"),
(3, "statistics"), (3, "regression"), (3, "probability"),
(4, "machine learning"), (4, "regression"), (4, "decision trees"),
(4, "libsvm"), (5, "Python"), (5, "R"), (5, "Java"), (5, "C++"),
(5, "Haskell"), (5, "programming languages"), (6, "statistics"),
(6, "probability"), (6, "mathematics"), (6, "theory"),
(7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),
(7, "neural networks"), (8, "neural networks"), (8, "deep learning"),
(8, "Big Data"), (8, "artificial intelligence"), (9, "Hadoop"),
(9, "Java"), (9, "MapReduce"), (9, "Big Data")
]#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Aug 22 08:52:54 2018

@author: wuming
"""
import pandas as pd 
train = pd.read_csv('/Users/wuming/study/python_study/neural-networks-and-deep-learning-master/杂例子/kaggle/minist/train.csv')
test = pd.read_csv('/Users/wuming/study/python_study/neural-networks-and-deep-learning-master/杂例子/kaggle/minist/test.csv')

train=train.values.tolist()
test=test.values.tolist()
b=[i[0] for i in train]
train=list(map(lambda x:x[1:],train))
train_valid=train[:8000]
b_valid=b[:8000]
train_train=train[8000:]
b_train=b[8000:]
train_train=np.array(train_train)
test=np.array(test)
b_train=np.array(b_train)



import keras
from keras.utils.np_utils import to_categorical
b= keras.utils.to_categorical(b, num_classes=10)
from keras import models
from keras import layers
model = models.Sequential()
model.add(layers.Dense(30, activation='sigmoid', input_shape=(784,)))
model.add(layers.Dense(30, activation='sigmoid'))
model.add(layers.Dense(10, activation='softmax'))
model.compile(optimizer='adam', loss='mse', metrics=['mae'])
model.fit(train_train, b_train, epochs=5, batch_size=64)
a=model.predict(test)
a=a.tolist()
b=[a[i].index(max(a[i])) for i in range(len(a))]
num=[i+1 for i in range(len(b))]
dataframe = pd.DataFrame({'ImageId':num,'label':b})
dataframe.to_csv("/Users/wuming/study/python_study/neural-networks-and-deep-learning-master/杂例子/kaggle/minist/submit1.csv",index=False,sep=',')# Python Codes in Data Science

Codes in NLP, Deep Learning, Reinforcement Learning and Artificial Intelligence

<b> Welcome to my GitHub repo. </b>

I am a Data Scientist and I code in R, Python and Wolfram Mathematica. Here you will find some Machine Learning, Deep Learning, Natural Language Processing and Artificial Intelligence models I developed.

<b> Outputs of the models can be seen at my portfolio: </b> https://drive.google.com/file/d/0B0RLknmL54khdjRQWVBKeTVxSHM/view?usp=sharing

----------------
Keras version used in models: keras==1.1.0

<b> Autoencoder for Audio  </b> is a model where I compressed an audio file and used Autoencoder to reconstruct the audio file, for use in phoneme classification.

<b> Collaborative Filtering  </b> is a Recommender System where the algorithm predicts a movie review based on genre of movie and similarity among people who watched the same movie.

<b> Convolutional NN Lasagne  </b> is a Convolutional Neural Network model in Lasagne to solve the MNIST task.

<b> Ensembled Machine Learning </b> is a .py file where 7 Machine Learning algorithms are used in a classification task with 3 classes and all possible hyperparameters of each algorithm are adjusted. Iris dataset of scikit-learn.

<p align="center">
<img src=https://github.com/RubensZimbres/Repo-2017/raw/master/Pictures%20-%20Formulas/Ensembled.MachineLearning.png?raw=true>
</p>

<b> GAN Generative Adversarial  </b> are models of Generative Adversarial Neural Networks.

<b> Hyperparameter Tuning RL  </b> is a model where hyperparameters of Neural Networks are adjusted via Reinforcement Learning. According to a reward, hyperparameter tuning (environment) is changed through a policy (mechanization of knowledge) using the Boston Dataset. Hyperparameters tuned are: learning rate, epochs, decay, momentum, number of hidden layers and nodes and initial weights.

<b> Keras Regularization L2  </b> is a Neural Network model for regression made with Keras where a L2 regularization was applied to prevent overfitting.

<b> Lasagne Neural Nets Regression  </b> is a Neural Network model based in Theano and Lasagne, that makes a linear regression with a continuous target variable and reaches 99.4% accuracy. It uses the DadosTeseLogit.csv sample file.

<b> Lasagne Neural Nets + Weights  </b> is a Neural Network model based in Theano and Lasagne, where is possible to visualize weights between X1 and X2 to hidden layer. Can also be adapted to visualize weights between hidden layer and output. It uses the DadosTeseLogit.csv sample file.

<b> Multinomial Regression  </b> is a regression model where target variable has 3 classes.

<b> Neural Networks for Regression  </b> shows multiple solutions for a regression problem, solved with sklearn, Keras, Theano and Lasagne. It uses the Boston dataset sample file from sklearn and reaches more than 98% accuracy.

<p align="center">
<img src=https://github.com/RubensZimbres/Repo-2017/raw/master/Pictures%20-%20Formulas/HiddenLayers.jpg?raw=true>
</p>

<b> NLP + Naive Bayes Classifier  </b> is a model where movie reviews were labeled as positive and negative and the algorithm then classifies a totally new set of reviews using Logistic Regression, Decision Trees and Naive Bayes, reaching an accuracy of 92%.

<b> NLP Anger Analysis  </b> is a Doc2Vec model associated with Word2Vec model to analyze level of anger using synonyms in consumer complaints of a U.S. retailer in Facebook posts.

<b> NLP Consumer Complaint  </b> is a model where Facebook posts of a U.S. computer retailer were scraped, tokenized, lemmatized and applied Word2Vec. After that, t-SNE and Latent Dirichlet Allocation were developed in order to classify the arguments and weights of each keyword used by a consumer in his complaint. The code also analyzes frequency of words in 100 posts.

<b> NLP Convolutional Neural Network </b> is a Convolutional Neural Network for Text in order to classify movie reviews.

<b> NLP Doc2Vec  </b> is a Natural Language Procesing file where cosine similarity among phrases is measured through Doc2Vec.

<b> NLP Document Classification  </b> is a code for Document Classification according to Latent Dirichlet Allocation.

<b> NLP Facebook Analysis  </b> analyzes Facebook posts regarding Word Frequency and Topic Modelling using LDA.

<b> NLP Facebook Scrap  </b> is a Python code for scraping data from Facebook.

<b> NLP - Latent Dirichlet Allocation  </b> is a Natural Language Processing model where a Wikipedia page on Statistical Inference is classified regarding topics, using Latent Dirichlet Allocation with Gensim, NLTK, t-SNE and K-Means.

<b> NLP Probabilistic ANN  </b> is a Natural Language Processing model where sentences are vectorized by Gensim and a probabilistic Neural Network model is deveoped using Gensim, for sentiment analysis.

<b> NLP Semantic Doc2Vec + Neural Network  </b> is a model where positive and negative movie reviews were extracted and semantically classified with NLTK and BeautifulSoup, then labeled as positive or negative. Text was then used as an input for the Neural Network model training. After training, new sentences are entered in the Keras Neural Network model and then classified. It uses the zip file.

<b> NLP Sentiment Positive  </b> is a model that identifies website content as positive, neutral or negative using BeautifulSoup and NLTK libraries, plotting the results.

<b> NLP Twitter Analysis ID #  </b> is a model that extracts posts from Twitter based in ID of user or Hashtag.

<b> NLP Twitter Scrap  </b> is a model that scraps Twitter data and shows the cleaned text as output.

<b> NLP Twitter Streaming  </b> is a model of analysis of real-time data from Twitter (under development).

<b> NLP Twitter Streaming Mood  </b> is a model where the evolution of mood Twitter posts is measured during a period of time.

<b> NLP Wikipedia Summarization  </b> is a Python code that summarizes any given page in a few sentences.

<b> NLP Word Frequency  </b> is a model that calculates the frequency of nouns, verbs, words in Facebook posts.

<b> Probabilistic Neural Network  </b> is a Probabilistic Neural Network for Time Series Prediction.

<b> REAL-TIME Twitter Analysis  </b> is a model where Twitter streaming is extracted, words and sentences tokenized, word embeddings were created, topic modeling was made and classified using K-Means. Then, NLTK SentimentAnalyzer was used to classify each sentence of the streaming into positive, neutral or negative. Accumulated sum was used to generate the plot and the code loops each 1 second, collecting new tweets.

<b> RESNET-2  </b> is a Deep Residual Neural Network.

<b> ROC Curve Multiclass  </b> is a .py file where Naive Bayes was used to solve the IRIS Dataset task and ROC curve of different classes are plotted.

<b> SQUEEZENET  </b> is a simplified version of the AlexNet.

<b> Stacked Machine Learning  </b> is a .py notebook where t-SNE, Principal Components Analysis and Factor Analysis were applied to reduce dimensionality of data. Classification performances were measured after applying K-Means.

<b> Support Vector Regression  </b> is a SVM model for non linear regression in an artificial dataset.

<b> Text-to-Speech  </b> is a .py file where Python speaks any given text and saves it as an audio .wav file.

<b> Time Series ARIMA </b>  is a ARIMA model to forecast time series, with an error margin of 0.2%.

<b> Time Series Prediction with Neural Networks - Keras </b>  is a Neural Network model to forecast time series, using Keras with an adaptive learning rate depending upon derivative of loss.

<p align="center">
<img src=https://github.com/RubensZimbres/Repo-2017/blob/master/Pictures%20-%20Formulas/ARIMA.10Period.png?raw=true> 
</p>

<b> Variational Autoencoder  </b> is a VAE made with Keras.

<b> Web Crawler  </b> is a code that scraps data from different URLs of a hotel website.

<b> t-SNE Dimensionality Reduction  </b> is a t-SNE model for dimensionality reduction which is compared to Principal Components Analysis regarding its discriminatory power.

<b> t-SNE PCA + Neural Networks  </b> is a model that compares performance or Neural Networks made after t-SNE, PCA and K-Means.

<b> t-SNE PCA LDA embeddings </b> is a model where t-SNE, Principal Components Analysis, Linear Discriminant Analysis and Random Forest embeddings are compared in a task to classify clusters of similar digits.

<p align="center">
<img src=https://github.com/RubensZimbres/Repo-2017/raw/master/Pictures%20-%20Formulas/Doc2Vec.png?raw=true>
</p>

<p align="center">
<img src=https://github.com/RubensZimbres/Repo-2017/raw/master/Pictures%20-%20Formulas/t_SNE_Lk.png?raw=true>
</p>

<p align="center">
<img src=https://github.com/RubensZimbres/Repo-2017/blob/master/Pictures%20-%20Formulas/RESNET_Me.jpg?raw=true>
</p>

from collections import defaultdict, Counter

users_interests = [
    ["Hadoop", "Big Data", "HBase", "Java", "Spark", "Storm", "Cassandra"],
    ["NoSQL", "MongoDB", "Cassandra", "HBase", "Postgres"],
    ["Python", "scikit-learn", "scipy", "numpy", "statsmodels", "pandas"],
    ["R", "Python", "statistics", "regression", "probability"],
    ["machine learning", "regression", "decision trees", "libsvm"],
    ["Python", "R", "Java", "C++", "Haskell", "programming languages"],
    ["statistics", "probability", "mathematics", "theory"],
    ["machine learning", "scikit-learn", "Mahout", "neural networks"],
    ["neural networks", "deep learning", "Big Data", "artificial intelligence"],
    ["Hadoop", "Java", "MapReduce", "Big Data"],
    ["statistics", "R", "statsmodels"],
    ["C++", "deep learning", "artificial intelligence", "probability"],
    ["pandas", "R", "Python"],
    ["databases", "HBase", "Postgres", "MySQL", "MongoDB"],
    ["libsvm", "regression", "support vector machines"]
]

popular_interests = Counter(interest
                            for users_interests in users_interests
                            for interest in users_interests).most_common()

def most_popular_new_interests(users_interests, max_results=5):
    suggestions = [(interest, frequency)
                    for interest, frequency in popular_interests
                    if interest not in users_interests]
    return suggestions[:max_results]

print(most_popular_new_interests(users_interests[5], 5))from collections import Counter
from collections import defaultdict
interests = [
    (0, "Hadoop"), (0, "Big Data"), (0, "HBase"), (0, "Java"),
    (0, "Spark"), (0, "Storm"), (0, "Cassandra"),
    (1, "NoSQL"), (1, "MongoDB"), (1, "Cassandra"), (1, "HBase"),
    (1, "Postgres"), (2, "Python"), (2, "scikit-learn"), (2, "scipy"),
    (2, "numpy"), (2, "statsmodels"), (2, "pandas"), (3, "R"), (3, "Python"),
    (3, "statistics"), (3, "regression"), (3, "probability"),
    (4, "machine learning"), (4, "regression"), (4, "decision trees"),
    (4, "libsvm"), (5, "Python"), (5, "R"), (5, "Java"), (5, "C++"),
    (5, "Haskell"), (5, "programming languages"), (6, "statistics"),
    (6, "probability"), (6, "mathematics"), (6, "theory"),
    (7, "machine learning"), (7, "scikit-learn"), (7, "Mahout"),
    (7, "neural networks"), (8, "neural networks"), (8, "deep learning"),
    (8, "Big Data"), (8, "artificial intelligence"), (9, "Hadoop"),
    (9, "Java"), (9, "MapReduce"), (9, "Big Data")
]


#1. Lowercase each interest (since different users may or may not capitalize their
#interests).
#2. Split it into words.
#3. Count the results.

words_and_counts = Counter(word
                           for user, interest in interests
                           for word in interest.lower().split())
print(words_and_counts)

for word, count in words_and_counts.most_common():
    if count > 1:
        print(word, count)import os
import sys
from setuptools import setup, find_packages


pwd = os.path.abspath(os.path.dirname(__file__))
sys.path.append(pwd)

try:
    README = open(os.path.join(pwd, 'docs/pypi.rst')).read()
except IOError:
    README = ''

try:
    import sknn
    VERSION = sknn.__version__
except ImportError:
    VERSION = 'N/A'


install_requires = [
    'scikit-learn>=0.17',
    'Theano>=0.8',
    'Lasagne>=0.1',
    'colorama' if sys.platform == 'win32' else '',
]

tests_require = [
    'nosetests',
]

docs_require = [
    'Sphinx',
]

setup(name='scikit-neuralnetwork',
      version=VERSION,
      description="Deep neural networks without the learning cliff! A wrapper library compatible with scikit-learn.",
      long_description=README,
      classifiers=[
          "Development Status :: 3 - Alpha",
          "Programming Language :: Python :: 2.7",
          "Programming Language :: Python :: 3.4",
          "Programming Language :: Python :: 3.5",
          ],
      keywords='deep learning, neural networks',
      url='https://github.com/aigamedev/scikit-neuralnetwork',
      license='BSD 3-clause license',
      packages=find_packages(),
      include_package_data=True,
      zip_safe=False,
      install_requires=install_requires,
      extras_require={
          'testing': tests_require,
          'docs': docs_require,
          },
      )
"""
Good TensorFlow websites:

TensorFlow docs --> Recurrent Neural Networks
https://www.tensorflow.org/tutorials/recurrent

Deep Learning with TensorFlow - How the Network Will Run
https://pythonprogramming.net/tensorflow-neural-network-session-machine-learning-tutorial/

RNN w/LSTM cell example in TensorFlow and Python
https://pythonprogramming.net/rnn-tensorflow-python-machine-learning-tutorial/

Neural Networks with TensorFlow
https://students.washington.edu/adelak/2017/04/?p=350

Python TensorFlow Tutorial - Build a Neural Network
http://adventuresinmachinelearning.com/python-tensorflow-tutorial/

An Introduction to Implementing Neural Networks Using TensorFlow
https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/


"""



import pprint
from recommendation_system import Recommender

users_interests = [
    ["Hadoop", "Big Data", "HBase", "Java", "Spark", "Storm", "Cassandra"],
    ["NoSQL", "MongoDB", "Cassandra", "HBase", "Postgres"],
    ["Python", "scikit-learn", "scipy", "numpy", "statsmodels", "pandas"],
    ["R", "Python", "statistics", "regression", "probability"],
    ["machine learning", "regression", "decision trees", "libsvm"],
    ["Python", "R", "Java", "C++", "Haskell", "programming languages"],
    ["statistics", "probability", "mathematics", "theory"],
    ["machine learning", "scikit-learn", "Mahout", "neural networks"],
    ["neural networks", "deep learning", "Big Data", "artificial intelligence"],
    ["Hadoop", "Java", "MapReduce", "Big Data"],
    ["statistics", "R", "statsmodels"],
    ["C++", "deep learning", "artificial intelligence", "probability"],
    ["pandas", "R", "Python"],
    ["databases", "HBase", "Postgres", "MySQL", "MongoDB"],
    ["libsvm", "regression", "support vector machines"]
]


rs = Recommender(users_interests)
obj = rs.popular(users_interests[0], n=10)
# obj = rs.user_based(0)[:10]
# obj = rs.item_based(0)


pp = pprint.PrettyPrinter(indent=4)
for vec in rs.item_based(10):
    print(vec)

#
print('initializing recommender...', end='\t')
print('done')
from collections import Counter

interests = [
    (0, 'Hadoo'), (0, 'Big Data'), (0, 'HBase'), (0, 'Java'),
    (0, 'Spark'), (0, 'Storm'), (0, 'Cassandra'),
    (1, 'NoSQL'), (1, 'MongoDB'), (1, 'Cassandra'),
    (1, 'HBase'), (1, 'Postgres'),
    (2, 'Python'), (2, 'sk-learn'), (2, 'scipy'),
    (2, 'numpy'), (2, 'statsmodels'), (2, 'pandas'),
    (3, 'R'), (3, 'Python'), (3, 'statistics'),
    (3, 'regression'), (3, 'probability'),
    (4, 'machine learning'), (4, 'regression'),
    (4, 'decision trees'), (4, 'libsvm'),
    (5, 'Python'), (5, 'R'), (5, 'Java'), (5, 'C++'),
    (5, 'Haskell'), (5, 'programming languages'),
    (6, 'statistics'), (6, 'probability'),
    (6, 'mathematics'), (6, 'theory'),
    (7, 'machine learning'), (7, 'sk-learn'), (7, 'Mahout'),
    (7, 'neural networks'),
    (8, 'neural networks'), (8, 'deep learning'),
    (8, 'Big Data'), (8, 'artificial intelligence'),
    (9, 'Hadoop'), (9, 'Java'), (9, 'MapReduce'), (9, 'Big Data'),
]

words_and_counts = Counter(
    word
    for user, interest in interests
    for word in interest.lower().split()
)

for word, count in words_and_counts.most_common():
    if count > 1:
        print(word, count)
users_interests = [
["Hadoop", "Big Data", "HBase", "Java", "Spark", "Storm", "Cassandra"],
["NoSQL", "MongoDB", "Cassandra", "HBase", "Postgres"],
["Python", "scikit-learn", "scipy", "numpy", "statsmodels","pandas"],
["R", "Python", "statistics", "regression", "probability"],
["machine learning", "regression", "decision trees","libsvm"],
["Python", "R", "Java", "C++", "Haskell", "programming languages"],
["statistics", "probability", "mathematics", "theory"],
["machine learning", "scikit-learn", "Mahout", "neural networks"],
["neural networks", "deep learning", "Big Data", "artificial intelligence"],
["Hadoop", "Java", "MapReduce", "Big Data"],
["statistics", "R", "statsmodels"],
["C++", "deep learning", "artificial intelligence", "probability"],
["pandas", "R", "Python"],
["databases", "HBase", "Postgres", "MySQL", "MongoDB"],
["libsvm", "regression", "support vector machines"]
]
# https://deeplearningcourses.com/c/deep-learning-recurrent-neural-networks-in-python
# https://udemy.com/deep-learning-recurrent-neural-networks-in-python
import json
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, TruncatedSVD

def main(we_file='word_embeddings.npy', w2i_file='wikipedia_word2idx.json', Model=PCA):
    We = np.load(we_file)
    V, D = We.shape
    with open(w2i_file) as f:
        word2idx = json.load(f)
    idx2word = {v:k for k,v in word2idx.iteritems()}

    model = Model()
    Z = model.fit_transform(We)
    plt.scatter(Z[:,0], Z[:,1])
    for i in xrange(V):
        plt.annotate(s=idx2word[i], xy=(Z[i,0], Z[i,1]))
    plt.show()


if __name__ == '__main__':
    # main(Model=TSNE)

    # D=80, M=80
    # main(we_file='gru_nonorm_part1_word_embeddings.npy', w2i_file='gru_nonorm_part1_wikipedia_word2idx.json', Model=TSNE)
    main(we_file='working_files/batch_gru_word_embeddings.npy', w2i_file='working_files/batch_wikipedia_word2idx.json', Model=TSNE)
