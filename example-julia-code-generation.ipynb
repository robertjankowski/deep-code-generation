{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Based on [C code Generation using LSTM](https://blogs.oracle.com/meena/code-generation-using-lstm-long-short-term-memory-rnn-network)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name = \"data/julia_sources/\" # julia repo\n",
    "\n",
    "## concat all files into training file\n",
    "with open(\"data/julia_sources/julia_training.txt\", \"w\") as a:\n",
    "    for file in os.listdir(path_name):\n",
    "        f = os.path.join(path_name, file)\n",
    "        current_file = open(f).read()\n",
    "        a.write(current_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"data/julia_sources/julia_training.txt\", 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up -- remove comments\n",
    "\n",
    "- `#` ...\n",
    "- #= \n",
    "\n",
    "  ...\n",
    "  \n",
    "  =#\n",
    "    \n",
    "- \"\"\" \n",
    "\n",
    "  ... \n",
    "\n",
    "  \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_comments(text):\n",
    "    single_comments_r = r'#.*'\n",
    "    multiple_comments_r = r'#.*\\n.*\\n+=#'\n",
    "    string_comments_r = r'\"{3}([\\s\\S]*?\"{3})'\n",
    "    \n",
    "    text = re.sub(multiple_comments_r, '', text)\n",
    "    text = re.sub(string_comments_r, '', text)\n",
    "    text = re.sub(single_comments_r, '', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "text_without_comments = remove_comments(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 4766833\n",
      "Length of file without comments: 3294376\n",
      "Total vocab length: 161\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text_without_comments)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "\n",
    "print(f\"Length of file: {len(text)}\")\n",
    "print(f\"Length of file without comments: {len(text_without_comments)}\")\n",
    "print(f\"Total vocab length: {VOCAB_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapping of unique chars to integers and a reverse mapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, '*': 11, '+': 12, ',': 13, '-': 14, '.': 15, '/': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ':': 27, ';': 28, '<': 29, '=': 30, '>': 31, '?': 32, '@': 33, 'A': 34, 'B': 35, 'C': 36, 'D': 37, 'E': 38, 'F': 39, 'G': 40, 'H': 41, 'I': 42, 'J': 43, 'K': 44, 'L': 45, 'M': 46, 'N': 47, 'O': 48, 'P': 49, 'Q': 50, 'R': 51, 'S': 52, 'T': 53, 'U': 54, 'V': 55, 'W': 56, 'X': 57, 'Y': 58, 'Z': 59, '[': 60, '\\\\': 61, ']': 62, '^': 63, '_': 64, '`': 65, 'a': 66, 'b': 67, 'c': 68, 'd': 69, 'e': 70, 'f': 71, 'g': 72, 'h': 73, 'i': 74, 'j': 75, 'k': 76, 'l': 77, 'm': 78, 'n': 79, 'o': 80, 'p': 81, 'q': 82, 'r': 83, 's': 84, 't': 85, 'u': 86, 'v': 87, 'w': 88, 'x': 89, 'y': 90, 'z': 91, '{': 92, '|': 93, '}': 94, '~': 95, '\\xa0': 96, '²': 97, '³': 98, '´': 99, '÷': 100, 'Δ': 101, 'Ω': 102, 'β': 103, 'γ': 104, 'η': 105, 'θ': 106, 'λ': 107, 'ξ': 108, 'π': 109, 'ρ': 110, 'φ': 111, 'ϒ': 112, 'ϕ': 113, 'ϵ': 114, 'ᵖ': 115, 'ᵢ': 116, 'ᵣ': 117, 'ᶜ': 118, '–': 119, '…': 120, '′': 121, '⁴': 122, '₊': 123, 'ℓ': 124, 'ℯ': 125, '∈': 126, '∉': 127, '∋': 128, '∌': 129, '∘': 130, '√': 131, '∛': 132, '∞': 133, '∩': 134, '∪': 135, '≈': 136, '≉': 137, '≠': 138, '≡': 139, '≢': 140, '≤': 141, '≥': 142, '⊆': 143, '⊇': 144, '⊈': 145, '⊉': 146, '⊊': 147, '⊋': 148, '⊑': 149, '⊻': 150, '⋅': 151, '─': 152, '│': 153, '┃': 154, '┄': 155, '┌': 156, '┐': 157, '└': 158, '╷': 159, '╻': 160}\n",
      "{0: '\\t', 1: '\\n', 2: ' ', 3: '!', 4: '\"', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: '*', 12: '+', 13: ',', 14: '-', 15: '.', 16: '/', 17: '0', 18: '1', 19: '2', 20: '3', 21: '4', 22: '5', 23: '6', 24: '7', 25: '8', 26: '9', 27: ':', 28: ';', 29: '<', 30: '=', 31: '>', 32: '?', 33: '@', 34: 'A', 35: 'B', 36: 'C', 37: 'D', 38: 'E', 39: 'F', 40: 'G', 41: 'H', 42: 'I', 43: 'J', 44: 'K', 45: 'L', 46: 'M', 47: 'N', 48: 'O', 49: 'P', 50: 'Q', 51: 'R', 52: 'S', 53: 'T', 54: 'U', 55: 'V', 56: 'W', 57: 'X', 58: 'Y', 59: 'Z', 60: '[', 61: '\\\\', 62: ']', 63: '^', 64: '_', 65: '`', 66: 'a', 67: 'b', 68: 'c', 69: 'd', 70: 'e', 71: 'f', 72: 'g', 73: 'h', 74: 'i', 75: 'j', 76: 'k', 77: 'l', 78: 'm', 79: 'n', 80: 'o', 81: 'p', 82: 'q', 83: 'r', 84: 's', 85: 't', 86: 'u', 87: 'v', 88: 'w', 89: 'x', 90: 'y', 91: 'z', 92: '{', 93: '|', 94: '}', 95: '~', 96: '\\xa0', 97: '²', 98: '³', 99: '´', 100: '÷', 101: 'Δ', 102: 'Ω', 103: 'β', 104: 'γ', 105: 'η', 106: 'θ', 107: 'λ', 108: 'ξ', 109: 'π', 110: 'ρ', 111: 'φ', 112: 'ϒ', 113: 'ϕ', 114: 'ϵ', 115: 'ᵖ', 116: 'ᵢ', 117: 'ᵣ', 118: 'ᶜ', 119: '–', 120: '…', 121: '′', 122: '⁴', 123: '₊', 124: 'ℓ', 125: 'ℯ', 126: '∈', 127: '∉', 128: '∋', 129: '∌', 130: '∘', 131: '√', 132: '∛', 133: '∞', 134: '∩', 135: '∪', 136: '≈', 137: '≉', 138: '≠', 139: '≡', 140: '≢', 141: '≤', 142: '≥', 143: '⊆', 144: '⊇', 145: '⊈', 146: '⊉', 147: '⊊', 148: '⊋', 149: '⊑', 150: '⊻', 151: '⋅', 152: '─', 153: '│', 154: '┃', 155: '┄', 156: '┌', 157: '┐', 158: '└', 159: '╷', 160: '╻'}\n"
     ]
    }
   ],
   "source": [
    "char_to_int = {c:i for i, c in enumerate(chars)}\n",
    "int_to_char = {i:c for i, c in enumerate(chars)}\n",
    "\n",
    "print(char_to_int)\n",
    "print(int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this example we would use word based model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100\n",
    "EPOCHES = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(text_without_comments) - SEQ_LENGTH):\n",
    "    seq_in = text_without_comments[i:i + SEQ_LENGTH]\n",
    "    seq_out = text_without_comments[i + SEQ_LENGTH] # we try to predict next character\n",
    "    X.append([char_to_int[char] for char in seq_in])\n",
    "    y.append(char_to_int[seq_out])\n",
    "    \n",
    "dataX = X\n",
    "dataY = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dule) = ccall(:jl_module_name, Ref{Symbol}, (Any,), m)\n",
      "\n",
      "\n",
      "parentmodule(m::Module) = ccall(:jl_module_\n",
      "Next character: p\n"
     ]
    }
   ],
   "source": [
    "print(''.join([int_to_char[x] for x in X[12]]))\n",
    "print(f\"Next character: {int_to_char[y[12]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 3294276\n"
     ]
    }
   ],
   "source": [
    "samples = len(X)\n",
    "print(f\"Total samples: {samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3294276, 100, 1)\n",
      "y shape: (3294276, 161)\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(X, (samples, SEQ_LENGTH, 1))\n",
    "X = X / float(VOCAB_SIZE) # normalization\n",
    "\n",
    "y = keras.utils.to_categorical(y)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create simple model with 2 LSTMs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_size, rnn_units, batch_size):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.LSTM(rnn_units, input_shape=(X.shape[1], X.shape[2])),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(vocab_size, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 161)               41377     \n",
      "=================================================================\n",
      "Total params: 305,569\n",
      "Trainable params: 305,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "RNN_UNITS = 256\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_SIZE, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints_julia'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.0001,\n",
    "  patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X,\n",
    "                    y, \n",
    "                    epochs=EPOCHES, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    verbose=1, \n",
    "                    callbacks=[checkpoint_callback, earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_output = 'output/checkpoints_lstms_small_character_model' \n",
    "latest = tf.train.latest_checkpoint(checkpoint_output)\n",
    "print(latest)\n",
    "\n",
    "# remember to change output layer size to 95 (smaller dict)\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print('Seed:')\n",
    "print(\"\".join([int_to_char[value] for value in pattern]))\n",
    "print('\\nGenerated:\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(VOCAB_SIZE)\n",
    "    pred = model.predict(x, verbose=0)\n",
    "    index = np.argmax(pred)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
